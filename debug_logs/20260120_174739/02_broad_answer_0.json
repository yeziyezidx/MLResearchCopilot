{"summary": "“检索后证据抽取”指的是在信息检索（IR）或基于检索的生成（RAG）流程中，对检索到的原始文档或片段进行精加工，提取出最能支持推断或回答的“证据”内容，并将其结构化，以供下游任务（如关系抽取、问答生成或事件识别）使用。这一过程连接了**信息抽取（IE）**与**检索优化**两个领域，核心目标是提升模型利用检索结果的精度、效率和可解释性。  \n\n综合近期资料和技术趋势，检索后证据抽取通常包含三个关键环节：  \n\n1. **证据识别（Evidence Identification）**  \n   - 在文档级关系抽取（DocRE）等任务中，证据是用于推断实体关系的最小句子集合（evidence sentences）。如 EIDER 框架中，关系预测与证据预测共享编码器，通过联合训练相互增强，直接从文档中标注并识别相关句子。  \n\n2. **上下文压缩与过滤（Contextual Compression / Filtering）**  \n   - 在 RAG 场景下，检索结果往往冗长且包含大量无关信息。通过 LLMChainExtractor、LLMChainFilter、EmbeddingsFilter 等策略，可以只保留与查询高度相关的段落。上下文压缩既能减少 token 消耗，又能让生成模型专注于核心证据，显著提升答案质量。  \n\n3. **证据融合与重排序（Evidence Fusion & Re-ranking）**  \n   - 当来自多个检索通道的证据存在冗余或顺序混乱时，可采用 RAG-Fusion、长上下文重排序等技术，将重要证据提前、去重，并在最终预测中融合原文档与“证据伪文档”的预测分数（EIDER 方法）。  \n\n在应用层面，这类技术在**法律文档分析**（抽取案件关键证据）、**医疗临床文本处理**（识别诊断相关数据）、**金融舆情监控**（锁定影响市场的关键信息）等领域都具有显著价值。  \n\n整体趋势是从“全文处理”转向“证据驱动”，不仅提升了效率和准确性，也增强了可解释性和可控性，符合当前大模型在高风险场景下的应用需求。", "problem": null, "key_concepts": ["- **信息抽取（Information Extraction, IE）**：从非结构化文本中识别结构化信息（如实体、关系、事件）。", "- **命名实体识别（NER）**：识别文本中的特定类别实体（人名、地点、组织等）。", "- **关系抽取（Relation Extraction）**：识别两个或多个实体之间的关系。", "- **事件抽取（Event Extraction）**：识别文本中发生的事件及其参与要素。", "- **文档级关系抽取（DocRE）**：跨句推理，识别长文档中实体对的关系。", "- **证据句（Evidence Sentence）**：支持某一关系推断的最小句子集合。", "- **上下文压缩（Contextual Compression）**：过滤或提取检索文档中与查询最相关的内容。", "- **RAG（Retrieval-Augmented Generation）**：结合检索与生成的问答或内容生产方法。"], "recent_developments": ["- **EIDER 框架（Evidence-enhanced Document-level Relation Extraction）**：提出三阶段流程（联合关系与证据提取、证据中心关系提取、结果融合），在 DocRED 数据集上提升了跨句关系抽取性能。", "- **Advanced RAG 检索后优化技术**：引入上下文压缩、RAG-Fusion、长上下文重排序、冗余过滤等策略，显著提升检索结果利用率与生成答案质量。", "- **证据驱动趋势**：在 NLP 中逐步形成从全量文本处理转向基于证据的推理与生成，提升模型可解释性与稳健性。"], "authoritative_sources": ["- 腾讯云开发者社区：《NLP信息抽取全解析：从命名实体到事件抽取的PyTorch实战指南》——系统介绍 IE 子任务及实现。", "- 知乎专栏：《EIDER: Evidence-enhanced Document-level Relation Extraction》——权威解读证据增强关系抽取方法。", "- 掘金：《Advanced RAG实战：检索后优化的三大核心技术揭秘》——详述 RAG 检索后优化与证据提取的工程策略。"], "search_results": [{"title": "NLP信息抽取全解析：从命名实体到事件抽取的PyTorch实战指南-腾讯云开发者社区-腾讯云", "url": "https://cloud.tencent.com.cn/developer/article/2348464", "snippet": "<H1>NLP信息抽取全解析：从命名实体到事件抽取的PyTorch实战指南</H1><P>本文深入探讨了信息抽取的关键组成部分：命名实体识别、关系抽取和事件抽取，并提供了基于PyTorch的实现代码。</P><H3>背景和信息抽取的重要性</H3><P>随着互联网和社交媒体的飞速发展，我们每天都会接触到大量的非 结构化数据，如文本、图片和音频等。这些数据包含了丰富的信息，但也提出了一个重要问题：如何从这些海量数据中提取有用的信息和知识？这就是 信息抽取（Information Extraction, IE） 的任务。</P><P>信息抽取不仅是 自然语言处理 （NLP）的一个核心组成部分，也是许多实际应用的关键技术。例如：</P><UL><LI>在医疗领域，信息抽取技术可以用于从临床文档中提取病人的重要信息，以便医生作出更准确的诊断。</LI><LI>在金融领域，通过抽取新闻或社交媒体中的关键信息，机器可以更准确地预测股票价格的走势。</LI><LI>在法律领域，信息抽取可以帮助律师从大量文档中找出关键证据，从而更有效地构建或驳斥案件。</LI></UL><H3>文章的目标和结构</H3><P>本文的目标是提供一个全面而深入的指南，介绍信息抽取以及其三个主要子任务： 命名实体识别（NER）、关系抽取和事件抽取。</P><UL><LI>信息抽取概述 部分将为你提供这一领域的基础知识，包括其定义、应用场景和主要挑战。</LI><LI>命名实体识别（NER） 部分将详细解释如何识别和分类文本中的命名实体（如人名、地点和组织）。</LI><LI>关系抽取 部分将探讨如何识别文本中两个或多个命名实体之间的关系。</LI><LI>事件抽取 部分将解释如何从文本中识别特定的事件，以及这些事件与命名实体的关联。</LI></UL><P>每个部分都会包括相关的技术框架与方法，以及使用 Python 和PyTorch实现的实战代码。</P><P>我们希望这篇文章能成为这一领域的终极指南，不论你是一个AI新手还是有经验的研究者，都能从中获得有用的洞见和知识。</P><H3>信息抽取概述</H3><P>信息抽取（Information Extraction, IE）是自然语言处理（NLP）中的一个关键任务，目标是从非结构化或半结构化数据（通常为文本）中识别和提取特定类型的信息。换句话说，信息抽取旨在将散在文本中的信息转化为结构化数据，如 数据库 、表格或特定格式的 XML 文件。</P><P>信息抽取技术被广泛应用于多个领域，这里列举几个典型的应用场景：</P><OL><LI>搜索引擎：通过信息抽取，搜索引擎能更精准地理解网页内容，从而提供更相关的搜索结果。</LI><LI>情感分析：企业和品牌经常使用信息抽取来识别客户评价中的关键观点或情感。</LI><LI>知识图谱 构建：通过信息抽取，我们可以从大量文本中识别实体和它们之间的关系，进而构建知识图谱。</LI><LI>舆情监控和危机管理：政府和非营利组织使用信息抽取来快速识别可能的社会或环境问题。</LI></OL><H3>信息抽取的主要挑战</H3><P>虽然信息抽取有着广泛的应用，但也面临几个主要的挑战：</P><OL><LI>多样性和模糊性：文本数据经常含有模糊或双关的表述，这给准确抽取信息带来挑战。</LI><LI>规模和复杂性：由于需要处理大量数据，计算资源和算法效率成为瓶颈。</LI><LI>实时性和动态性：许多应用场景（如舆情监控）要求实时抽取信息，这需要高度优化的算法和架构。</LI><LI>领域依赖性：不同的应用场景（如医疗、法律或金融）可能需要特定领域的先验知识。</LI></OL><P>以上内容旨在为你提供信息抽取领域的一个全面而深入的入口，接下来我们将逐一探讨其主要子任务：命名实体识别、关系抽取和事件抽取。</P><H3>实体识别</H3><P>实体识别（Entity Recognition）是自然语言处理中的一项基础任务，它的目标是从非结构化文本中识别出具有特定意义的实体项，如术语、产品、组织、人名、时间、数量等。</P><H3>实体识别的应用场景</H3><OL><LI>搜索引擎优化：改进搜索结果，使之更加相关。</LI><LI>知识图谱构建：从大量文本中提取信息，建立实体间的关联。</LI><LI>客户服务：自动识别客户查询中的关键实体，以便进行更精准的服务。</LI></OL><P>以下代码使用PyTorch构建了一个简单的实体识别模型：</P><P> import  torch.nn  as  nn</P><P> import  torch.optim  as  optim</P><P> class EntityRecognitionModel(nn.Module): </P><P>    def  __init__(self,  vocab_size,  embedding_dim,  hidden_dim,  tagset_size): super(EntityRecognitionModel,  self).__init__() </P><P>        self.embedding  =  nn.Embedding(vocab_size,  embedding_dim) </P><P>        self.lstm  =  nn.LSTM(embedding_dim,  hidden_dim,  bidirectional =True) </P><P>        self.hidden2tag  =  nn.Linear(hidden_dim  * 2,  tagset_size) </P><P>    def  forward(self,  sentence): </P><P>        embeds  =  self.embedding(sentence) </P><P>        lstm_out,  _  =  self.lstm(embeds.view(len(sentence), 1, -1)) </P><P>        tag_space  =  self.hidden2tag(lstm_out.view(len(sentence), -1)) </P><P>        tag_scores  =  torch.log_softmax(tag_space,  dim =1) return  tag_scores</P><P> VOCAB_SIZE = 10000 EMBEDDING_DIM = 100 HIDDEN_DIM = 50 TAGSET_SIZE = 7   # 比如: 'O', 'TERM', 'PROD', 'ORG', 'PER', 'TIME', 'QUAN' </P><P> for  epoch  in range(300): </P><P>    model.zero_grad() </P><P>    tag_scores  = model(sentence) </P><P>    loss  = loss_function(tag_scores,  ", "source": "bing"}, {"title": "EIDER: Evidence-enhanced Document-level Relation Extraction - 知乎", "url": "https://zhuanlan.zhihu.com/p/479978951", "snippet": "<H1>EIDER: Evidence-enhanced Document-level Relation Extraction</H1><P>文章解读：《EIDER: Evidence-enhanced Document-level Relation Extraction》</P><P>一、Motivation</P><P>背景：文档级关系抽取的目的是提取文档中实体对之间的关系，文档中的推断关系所需的最小句子集称为“evidence sentences”，能够帮助预测特定实体对之间的关系。</P><P>Motivation：为了更好地利用证据句，本文提出了一个包含三个阶段的证据增强框架EIDER，包括 联合抽取 关系和证据，以证据为中心的关系抽取，以及抽取结果融合。</P><P>二、Method</P><P>2.1 模型结构</P><P>2.2 Joint Relation and Evidence Extraction</P><P>关系和证据提取模型共享一个预先训练的编码器，并有自己的预测头，通过共享基本编码器，两个模型能够相互提供额外的训练信号，从而相互增强。</P><P>Encoder在每个实体mention前和后加入“*”符号作为提示，使用BERT进行编码；Relation Prediction Head首先结合实体和上下文embedding，将其映射到上下文感知，通过 bilinear 获得关系的功率，期间使用了自适应阈值损失；Evidence Prediction Head预测每个句子是否是实体对的证据句，由于实体对可能包含不止一个证据句，采用 二元交叉熵 作为模型目标函数。</P><P>2.3 Evidence-centered Relation Extraction</P><P>如果已经掌握与关系相关的所有信息，就没有必要对整个文档进行关系抽取，所以本文按照原文档的顺序，为每个实体对构建一个 伪文档，包含所有的证据句，将其填充入模型。</P><P>证据信息仅在训练中有用，将伪文档中的证据句替换为模型抽取的证据，并获得一组 关系预测 分数，最终关系预测的结果是原文档和伪文档的预测分数进行融合。</P><P>三、Experiment&Result</P><P>3.1 数据集</P><P>DocRED。</P><P>3.2 实验结果</P><P>四、Conclusion</P><P>本文提出了一个包含联合关系和证据提取、以证据为中心的关系提取和提取结果融合的三阶段DocRE框架。关系提取和证据提取模型相互提供额外的训练信号，并相互增强，最后将原文档和提取证据的预测结果结合起来，鼓励模型在减少信息损失的同时关注重要句子，在 句间关系 上取得成效。</P><P>五、思考</P><P>感觉本文和另一篇文章“三个句子”有一定相似性，但是是另外一个角度的介绍，对于文档级关系抽取，进行长篇大论式的一顿乱抽，可能不如专攻一处，提取出能够真正表征关系的句子，这也是符合直觉的，毕竟如果要多条句子才能表征出关系，可能仅会出现在解谜推理等任务中，传统文本的描述不会如此复杂。</P><P>By 天天</P><P>2021-10-17</P>", "source": "bing"}, {"title": "Advanced RAG实战：检索后优化的三大核心技术揭秘从\"找到资料\"到\"用好资料\"的最后一公里 想象一下这个场景：经 - 掘金", "url": "https://juejin.cn/post/7575006095389360137", "snippet": "<H1>Advanced RAG实战：检索后优化的三大核心技术揭秘</H1><P>></P><P>本文是《Advanced RAG进阶指南》系列的第三篇，也是最后一篇，将深入探讨检索后优化的三大核心技术。通过完整的代码示例和生动的业务场景，带你掌握如何让大模型基于检索结果生成更精准、更可靠的答案。</P><H2>引言：从\"找到资料\"到\"用好资料\"的最后一公里</H2><P>想象一下这个场景：经过检索前优化的精心准备和检索优化的精准查找，你已经从海量知识库中找到了最相关的文档。就像一位研究员，面前堆满了从图书馆找来的各种参考资料。</P><P>但新的挑战出现了：</P><UL><LI>资料太多，大模型\"看不过来\"</LI><LI>重要信息被埋没在大量细节中</LI><LI>不同资料之间可能存在矛盾</LI><LI>大模型容易只关注开头内容，忽略后面的关键信息</LI></UL><P>检索后优化 就是要解决这个\"最后一公里\"的问题： 对检索结果进行精加工，让大模型能够高效、准确地利用这些信息生成最佳答案。</P><H2>检索后优化的核心价值</H2><P>在深入技术细节前，我们先通过一个对比表格了解检索后优化的核心价值：</P><TABLE><TR><TH>问题场景</TH><TH>传统RAG的困境</TH><TH>检索后优化解决方案</TH><TH>效果提升</TH></TR><TR><TD>检索结果过多</TD><TD>大模型被无关信息干扰，答案质量下降</TD><TD>上下文压缩：只保留核心信息</TD><TD>答案质量↑180%</TD></TR><TR><TD>多路检索结果排序混乱</TD><TD>重要文档被排在后边，大模型忽略</TD><TD>RAG-Fusion：智能融合多路结果</TD><TD>关键信息利用率↑220%</TD></TR><TR><TD>长上下文注意力偏差</TD><TD>大模型只关注开头，忽略后面关键内容</TD><TD>长上下文重排序：优化信息分布</TD><TD>信息完整性↑150%</TD></TR><TR><TD>信息冗余重复</TD><TD>相同内容多次出现，浪费token且造成干扰</TD><TD>冗余过滤：去除重复信息</TD><TD>效率提升↑200%</TD></TR></TABLE><H2>一、上下文压缩：让大模型专注于核心信息</H2><H3>核心原理</H3><P>上下文压缩基于一个重要洞察： 检索到的文档中，往往只有部分内容与当前问题真正相关。</P><P>就像阅读一篇长文报告时，你会自动跳过无关章节，只关注与当前任务相关的部分。上下文压缩技术就是为大模型实现这个\"跳读\"能力。</P><H3>技术架构</H3><P># contextual_compression.py 核心实现 # 1. 基础检索器（未经压缩） </P><P> # 2. 四种压缩策略 class CompressionStrategies:</P><P>     def __init__ (self, llm, embeddings_model):</P><P>        self.llm = llm</P><P>        self.embeddings_model = embeddings_model</P><P>     def get_llm_extractor (self):</P><P>         \"\"\"LLMChainExtractor：智能提取相关句子\"\"\" return  LLMChainExtractor.from_llm(self.llm)</P><P>     def get_llm_filter (self):</P><P>         \"\"\"LLMChainFilter：LLM判断文档相关性\"\"\" return  LLMChainFilter.from_llm(self.llm)</P><P>     def get_embeddings_filter (self, similarity_threshold=0.66):</P><P>         \"\"\"EmbeddingsFilter：基于嵌入相似度的快速过滤\"\"\" return  EmbeddingsFilter(</P><P>            embeddings=self.embeddings_model, </P><P>            similarity_threshold=similarity_threshold</P><P>     def get_pipeline_compressor (self):</P><P>         \"\"\"DocumentCompressorPipeline：组合多种压缩器\"\"\" </P><P>        splitter = CharacterTextSplitter(chunk_size= 300, chunk_overlap= 0, separator= \". \")</P><P>        redundant_filter = EmbeddingsRedundantFilter(embeddings=self.embeddings_model)</P><P>        relevant_filter = EmbeddingsFilter(embeddings=self.embeddings_model, similarity_threshold= 0.66)</P><P>         return  DocumentCompressorPipeline(</P><P>            transformers=[splitter, redundant_filter, relevant_filter]</P><H3>四种压缩策略深度解析</H3><H4>1. LLMChainExtractor：精准的内容外科医生</H4><P>工作原理：</P><UL><LI>对每个检索到的文档，让LLM识别并提取与问题直接相关的部分</LI><LI>保留原文的语义完整性，只移除无关内容</LI></UL><P>适用场景：</P><UL><LI>文档内容复杂，需要精确提取特定信息</LI><LI>对压缩质量要求极高的场景</LI></UL><P>    base_compressor=compressor, </P><P>    base_retriever=retriever</P><P> # 压缩效果对比 </P><P> print (f\"压缩前:  {len(original_docs)}个文档，{sum(len(d.page_content)  for  d  in  original_docs)}字符\")</P><P> print (f\"压缩后:  {len(compressed_docs)}个文档，{sum(len(d.page_content)  for  d  in  compressed_docs)}字符\")</P><H4>2. LLMChainFilter：高效的文档过滤器", "source": "bing"}]}