"{\"webpage evidence extraction RAG\": [{\"paper_id\": \"2410.11315v1\", \"title\": \"[2410.11315v1] SEER: Self-Aligned Evidence Extraction for Retrieval-Augmented Generation\", \"authors\": [], \"abstract\": \"<H1>Computer Science > Computation and Language</H1><H1>SEER: Self-Aligned Evidence Extraction for Retrieval-Augmented Generation</H1><P>Recent studies in Retrieval-Augmented Generation (RAG) have investigated extracting evidence from retrieved passages to reduce computational costs and enhance the final RAG performance, yet it remains challenging. Existing methods heavily rely on heuristic-based augmentation, encountering several issues: (1) Poor generalization due to hand-crafted context filtering; (2) Semantics deficiency due to rule-based context chunking; (3) Skewed length due to sentence-wise filter learning. To address these issues, we propose a model-based evidence extraction learning framework, SEER, optimizing a vanilla model as an evidence extractor with desired properties through self-aligned learning. Extensive experiments show that our method largely improves the final RAG performance, enhances the faithfulness, helpfulness, and conciseness of the extracted evidence, and reduces the evidence length by 9.25 times. The code will be available at this https URL.</P><TABLE><TR><TD>Comments:</TD><TD>15 pages, 6 figures, 5 tables. Accepted by EMNLP 2024 (main)</TD></TR><TR><TD>Subjects:</TD><TD>Computation and Language (cs.CL)</TD></TR><TR><TD>Cite as:</TD><TD>arXiv:2410.11315 [cs.CL]</TD></TR><TR><TD>(or arXiv:2410.11315v1 [cs.CL] for this version)</TD></TR><TR><TD>https://doi.org/10.48550/arXiv.2410.11315\\nFocus to learn more\\narXiv-issued DOI via DataCite (pending registration)</TD></TR></TABLE><H2>Submission history</H2><H1>Bibliographic and Citation Tools</H1><P>Bibliographic Explorer (What is the Explorer?)</P><P>Litmaps (What is Litmaps?)</P><P>scite Smart Citations (What are Smart Citations?)</P>\", \"url\": \"https://arxiv.org/abs/2410.11315v1\", \"pdf_url\": \"https://arxiv.org/pdf/2410.11315v1.pdf\", \"source\": \"web\", \"published_date\": \"N/A\", \"score_bm25\": 0.0}, {\"paper_id\": null, \"title\": \"SEER: Self-Aligned Evidence Extraction for Retrieval-Augmented Generation - ACL Anthology\", \"authors\": [], \"abstract\": \"<P>Important: The Anthology treat PDFs as authoritative. Please use this form only to correct data that is out of line with the PDF. See our corrections guidelines if you need to change the PDF.</P><P>Title Adjust the title. Retain tags such as <fixed-case>.</P><P>Abstract Correct abstract if needed. Retain XML formatting tags such as <tex-math>.</P><P>Verification against PDF Ensure that the new title/authors match the snapshot below. (If there is no snapshot or it is too small, consult the PDF.)Authors concatenated from the text boxes above:</P><P>ALL author names match the snapshot above‚Äîincluding middle initials, hyphens, and accents.</P><H5>Abstract</H5><P>Recent studies in Retrieval-Augmented Generation (RAG) have investigated extracting evidence from retrieved passages to reduce computational costs and enhance the final RAG performance, yet it remains challenging. Existing methods heavily rely on heuristic-based augmentation, encountering several issues: (1) Poor generalization due to hand-crafted context filtering; (2) Semantics deficiency due to rule-based context chunking; (3) Skewed length due to sentence-wise filter learning. To address these issues, we propose a model-based evidence extraction learning framework, SEER, optimizing a vanilla model as an evidence extractor with desired properties through self-aligned learning. Extensive experiments show that our method largely improves the final RAG performance, enhances the faithfulness, helpfulness, and conciseness of the extracted evidence, and reduces the evidence length by 9.25 times. The code will be available at https://github.com/HITsz-TMG/SEER.</P><P>Xinping Zhao, Dongfang Li, Yan Zhong, Boren Hu, Yibin Chen, Baotian Hu, and Min Zhang. 2024. SEER: Self-Aligned Evidence Extraction for Retrieval-Augmented Generation. In Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing, pages 3027‚Äì3041, Miami, Florida, USA. Association for Computational Linguistics.</P><P>More options‚Ä¶</P>\", \"url\": \"https://aclanthology.org/2024.emnlp-main.178/\", \"pdf_url\": \"https://aclanthology.org/2024.emnlp-main.178.pdf\", \"source\": \"web\", \"published_date\": \"N/A\", \"score_bm25\": 0.0}, {\"paper_id\": \"2401.15391v1\", \"title\": \"MultiHop-RAG: Benchmarking Retrieval-Augmented Generation for Multi-Hop Queries\", \"authors\": [\"Yixuan Tang\", \"Yi Yang\"], \"abstract\": \"Retrieval-augmented generation (RAG) augments large language models (LLM) by retrieving relevant knowledge, showing promising potential in mitigating LLM hallucinations and enhancing response quality, thereby facilitating the great adoption of LLMs in practice. However, we find that existing RAG systems are inadequate in answering multi-hop queries, which require retrieving and reasoning over multiple pieces of supporting evidence. Furthermore, to our knowledge, no existing RAG benchmarking dataset focuses on multi-hop queries. In this paper, we develop a novel dataset, MultiHop-RAG, which consists of a knowledge base, a large collection of multi-hop queries, their ground-truth answers, and the associated supporting evidence. We detail the procedure of building the dataset, utilizing an English news article dataset as the underlying RAG knowledge base. We demonstrate the benchmarking utility of MultiHop-RAG in two experiments. The first experiment compares different embedding models for retrieving evidence for multi-hop queries. In the second experiment, we examine the capabilities of various state-of-the-art LLMs, including GPT-4, PaLM, and Llama2-70B, in reasoning and answering multi-hop queries given the evidence. Both experiments reveal that existing RAG methods perform unsatisfactorily in retrieving and answering multi-hop queries. We hope MultiHop-RAG will be a valuable resource for the community in developing effective RAG systems, thereby facilitating greater adoption of LLMs in practice. The MultiHop-RAG and implemented RAG system is publicly available at https://github.com/yixuantt/MultiHop-RAG/.\", \"url\": \"http://arxiv.org/abs/2401.15391v1\", \"pdf_url\": \"https://arxiv.org/pdf/2401.15391v1\", \"source\": \"arxiv\", \"published_date\": \"2024-01-27T11:41:48Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2404.15939v3\", \"title\": \"Telco-RAG: Navigating the Challenges of Retrieval-Augmented Language Models for Telecommunications\", \"authors\": [\"Andrei-Laurentiu Bornea\", \"Fadhel Ayed\", \"Antonio De Domenico\", \"Nicola Piovesan\", \"Ali Maatouk\"], \"abstract\": \"The application of Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) systems in the telecommunication domain presents unique challenges, primarily due to the complex nature of telecom standard documents and the rapid evolution of the field. The paper introduces Telco-RAG, an open-source RAG framework designed to handle the specific needs of telecommunications standards, particularly 3rd Generation Partnership Project (3GPP) documents. Telco-RAG addresses the critical challenges of implementing a RAG pipeline on highly technical content, paving the way for applying LLMs in telecommunications and offering guidelines for RAG implementation in other technical domains.\", \"url\": \"http://arxiv.org/abs/2404.15939v3\", \"pdf_url\": \"https://arxiv.org/pdf/2404.15939v3\", \"source\": \"arxiv\", \"published_date\": \"2024-04-24T15:58:59Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2510.25518v1\", \"title\": \"Retrieval Augmented Generation (RAG) for Fintech: Agentic Design and Evaluation\", \"authors\": [\"Thomas Cook\", \"Richard Osuagwu\", \"Liman Tsatiashvili\", \"Vrynsia Vrynsia\", \"Koustav Ghosal\", \"Maraim Masoud\", \"Riccardo Mattivi\"], \"abstract\": \"Retrieval-Augmented Generation (RAG) systems often face limitations in specialized domains such as fintech, where domain-specific ontologies, dense terminology, and acronyms complicate effective retrieval and synthesis. This paper introduces an agentic RAG architecture designed to address these challenges through a modular pipeline of specialized agents. The proposed system supports intelligent query reformulation, iterative sub-query decomposition guided by keyphrase extraction, contextual acronym resolution, and cross-encoder-based context re-ranking. We evaluate our approach against a standard RAG baseline using a curated dataset of 85 question--answer--reference triples derived from an enterprise fintech knowledge base. Experimental results demonstrate that the agentic RAG system outperforms the baseline in retrieval precision and relevance, albeit with increased latency. These findings suggest that structured, multi-agent methodologies offer a promising direction for enhancing retrieval robustness in complex, domain-specific settings.\", \"url\": \"http://arxiv.org/abs/2510.25518v1\", \"pdf_url\": \"https://arxiv.org/pdf/2510.25518v1\", \"source\": \"arxiv\", \"published_date\": \"2025-10-29T13:41:36Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2409.03708v2\", \"title\": \"RAG based Question-Answering for Contextual Response Prediction System\", \"authors\": [\"Sriram Veturi\", \"Saurabh Vaichal\", \"Reshma Lal Jagadheesh\", \"Nafis Irtiza Tripto\", \"Nian Yan\"], \"abstract\": \"Large Language Models (LLMs) have shown versatility in various Natural Language Processing (NLP) tasks, including their potential as effective question-answering systems. However, to provide precise and relevant information in response to specific customer queries in industry settings, LLMs require access to a comprehensive knowledge base to avoid hallucinations. Retrieval Augmented Generation (RAG) emerges as a promising technique to address this challenge. Yet, developing an accurate question-answering framework for real-world applications using RAG entails several challenges: 1) data availability issues, 2) evaluating the quality of generated content, and 3) the costly nature of human evaluation. In this paper, we introduce an end-to-end framework that employs LLMs with RAG capabilities for industry use cases. Given a customer query, the proposed system retrieves relevant knowledge documents and leverages them, along with previous chat history, to generate response suggestions for customer service agents in the contact centers of a major retail company. Through comprehensive automated and human evaluations, we show that this solution outperforms the current BERT-based algorithms in accuracy and relevance. Our findings suggest that RAG-based LLMs can be an excellent support to human customer service representatives by lightening their workload.\", \"url\": \"http://arxiv.org/abs/2409.03708v2\", \"pdf_url\": \"https://arxiv.org/pdf/2409.03708v2\", \"source\": \"arxiv\", \"published_date\": \"2024-09-05T17:14:23Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2402.07483v2\", \"title\": \"T-RAG: Lessons from the LLM Trenches\", \"authors\": [\"Masoomali Fatehkia\", \"Ji Kim Lucas\", \"Sanjay Chawla\"], \"abstract\": \"Large Language Models (LLM) have shown remarkable language capabilities fueling attempts to integrate them into applications across a wide range of domains. An important application area is question answering over private enterprise documents where the main considerations are data security, which necessitates applications that can be deployed on-prem, limited computational resources and the need for a robust application that correctly responds to queries. Retrieval-Augmented Generation (RAG) has emerged as the most prominent framework for building LLM-based applications. While building a RAG is relatively straightforward, making it robust and a reliable application requires extensive customization and relatively deep knowledge of the application domain. We share our experiences building and deploying an LLM application for question answering over private organizational documents. Our application combines the use of RAG with a finetuned open-source LLM. Additionally, our system, which we call Tree-RAG (T-RAG), uses a tree structure to represent entity hierarchies within the organization. This is used to generate a textual description to augment the context when responding to user queries pertaining to entities within the organization's hierarchy. Our evaluations, including a Needle in a Haystack test, show that this combination performs better than a simple RAG or finetuning implementation. Finally, we share some lessons learned based on our experiences building an LLM application for real-world use.\", \"url\": \"http://arxiv.org/abs/2402.07483v2\", \"pdf_url\": \"https://arxiv.org/pdf/2402.07483v2\", \"source\": \"arxiv\", \"published_date\": \"2024-02-12T08:45:08Z\", \"score_bm25\": 0.0}, {\"paper_id\": null, \"title\": \"GitHub - happymondaynkanta/Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant: An end-to-end Retrieval-Augmented Generation (RAG) pipeline that crawls websites, cleans and extracts text, splits documents into chunks, generates semantic embeddings with HuggingFace, stores them in ChromaDB. Built with LangChain, HuggingFace Sentence-Transformers, and Chroma.\", \"authors\": [], \"abstract\": \"<H2>Folders and files</H2><TABLE><TR><TH>Name</TH><TH>Name</TH><TH>Last commit message</TH><TH>Last commit date</TH></TR><TR><TD colspan=3><H2>Latest commit</H2><H2>History</H2></TD></TR><TR><TD colspan=2>LLM_RAG_Project_1.ipynb</TD><TD colspan=1>LLM_RAG_Project_1.ipynb</TD></TR><TD> </TD><TD> </TD><TR><TD colspan=2>README.md</TD><TD colspan=1>README.md</TD></TR><TD> </TD><TD> </TD><TR><TD colspan=2>rag_pipeline_flowchart.svg</TD><TD colspan=1>rag_pipeline_flowchart.svg</TD></TR><TD> </TD><TD> </TD><TR><TD colspan=3>View all files</TD></TR></TABLE><H2>Repository files navigation</H2><H1>Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant</H1><P>An end-to-end Retrieval-Augmented Generation (RAG) pipeline that crawls websites, cleans and extracts text, splits documents into chunks, generates semantic embeddings with HuggingFace, stores them in ChromaDB. Built with LangChain, HuggingFace Sentence-Transformers, and Chroma.</P><H2>üîÑ RAG Pipeline Flow</H2><H1>Web RAG Pipeline: Intelligent Website Knowledge Assistant</H1><H2>üìñ Overview</H2><P>This repository demonstrates how to build a Retrieval-Augmented Generation (RAG) system that transforms static website content into an interactive AI-powered knowledge assistant.</P><P>The pipeline:</P><OL><LI>Crawls a target website recursively.\\nCleans and extracts meaningful text using HTML parsing.\\nSplits documents into manageable chunks for downstream tasks.\\nGenerates embeddings with HuggingFace‚Äôs Sentence-Transformers.\\nStores embeddings in ChromaDB for semantic similarity search.\\nRetrieves context-aware documents in response to user queries.\\nGenerates grounded answers using a large language model, with sources cited.</LI></OL><P>This project highlights practical experience in LangChain, ChromaDB, HuggingFace embeddings, and RAG architectures, making it directly relevant for AI/ML engineering and applied NLP roles.</P><H2>‚ú® Features</H2><UL><LI>üåê Recursive Website Crawler with domain and depth control\\nüßπ HTML Cleaner & Extractor to remove irrelevant tags\\n‚úÇÔ∏è Document Chunking with overlap for context preservation\\nüß† Embeddings via HuggingFace (all-MiniLM-L6-v2)\\nüì¶ ChromaDB Integration for efficient semantic retrieval\\nüîç Retriever Interface for top-k relevant results\\nü§ñ RAG Answering Function with context-grounded LLM outputs\\nüìë Source Transparency ‚Äî every answer includes references</LI></UL><H2>üéØ Applications</H2><UL><LI>Education ‚Üí Course catalog assistants for universities\\nCorporate Knowledge Bases ‚Üí Internal semantic search tools\\nResearch Portals ‚Üí Summarization and Q&A over academic repositories\\nCustomer Support ‚Üí AI assistants with verifiable, grounded responses</LI></UL><H2>üßë‚Äçüíª Author</H2><P>Developed by Happy Nkanta Monday ‚Äî AI/ML Engineer specializing in Retrieval-Augmented Generation, Large Language Model, Deep Learning, and Applied Machine Learning.</P><P>If you find this project useful, feel free to ‚≠ê star the repo or connect with me.</P><H2>About</H2><P>An end-to-end Retrieval-Augmented Ge\", \"url\": \"https://github.com/happymondaynkanta/Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant\", \"pdf_url\": \"https://github.com/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/branches\\\" class=\\\"prc-Button-ButtonBase-9n-Xk OverviewContent-module__Button--bbZn8\\\" data-loading=\\\"false\\\" data-size=\\\"medium\\\" data-variant=\\\"invisible\\\"><span data-component=\\\"buttonContent\\\" data-align=\\\"center\\\" class=\\\"prc-Button-ButtonContent-Iohp5\\\"><span data-component=\\\"leadingVisual\\\" class=\\\"prc-Button-Visual-YNt2F prc-Button-VisualWrap-E4cnq\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-git-branch\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z\\\"></path></svg></span><span data-component=\\\"text\\\" class=\\\"prc-Button-Label-FWkx3\\\">Branches</span></span></a><a type=\\\"button\\\" href=\\\"/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/tags\\\" class=\\\"prc-Button-ButtonBase-9n-Xk OverviewContent-module__Button--bbZn8\\\" data-loading=\\\"false\\\" data-size=\\\"medium\\\" data-variant=\\\"invisible\\\"><span data-component=\\\"buttonContent\\\" data-align=\\\"center\\\" class=\\\"prc-Button-ButtonContent-Iohp5\\\"><span data-component=\\\"leadingVisual\\\" class=\\\"prc-Button-Visual-YNt2F prc-Button-VisualWrap-E4cnq\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-tag\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.752 1.752 0 0 1 1 7.775Zm1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2Z\\\"></path></svg></span><span data-component=\\\"text\\\" class=\\\"prc-Button-Label-FWkx3\\\">Tags</span></span></a></div><div class=\\\"OverviewContent-module__Box_5--wttWN\\\"><a type=\\\"button\\\" aria-label=\\\"Go to Branches page\\\" href=\\\"/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/branches\\\" class=\\\"prc-Button-ButtonBase-9n-Xk OverviewContent-module__Button_1--AQow7\\\" data-loading=\\\"false\\\" data-no-visuals=\\\"true\\\" data-size=\\\"medium\\\" data-variant=\\\"invisible\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-git-branch\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z\\\"></path></svg></a><a type=\\\"button\\\" aria-label=\\\"Go to Tags page\\\" href=\\\"/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/tags\\\" class=\\\"prc-Button-ButtonBase-9n-Xk OverviewContent-module__Button_1--AQow7\\\" data-loading=\\\"false\\\" data-no-visuals=\\\"true\\\" data-size=\\\"medium\\\" data-variant=\\\"invisible\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-tag\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.752 1.752 0 0 1 1 7.775Zm1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2Z\\\"></path></svg></a></div></div><div class=\\\"OverviewContent-module__Box_6--tJpBe\\\"><div class=\\\"OverviewContent-module__Box_7--x594V\\\"><div class=\\\"OverviewContent-module__Box_8--TjDBQ\\\"><!--$--><div class=\\\"Box-sc-62in7e-0 OverviewContent-module__FileResultsList--ZnbCo\\\"><span class=\\\"TextInput__StyledTextInput-sc-ttxlvl-0 d-flex FileResultsList-module__FilesSearchBox--fSAh3 TextInput-wrapper prc-components-TextInputWrapper-Hpdqi prc-components-TextInputBaseWrapper-wY-n0\\\" data-leading-visual=\\\"true\\\" data-trailing-visual=\\\"true\\\" aria-busy=\\\"false\\\"><span class=\\\"TextInput-icon\\\" id=\\\"_R_535ab_\\\" aria-hidden=\\\"true\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-search\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"M10.68 11.74a6 6 0 0 1-7.922-8.982 6 6 0 0 1 8.982 7.922l3.04 3.04a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215ZM11.5 7a4.499 4.499 0 1 0-8.997 0A4.499 4.499 0 0 0 11.5 7Z\\\"></path></svg></span><input type=\\\"text\\\" aria-label=\\\"Go to file\\\" role=\\\"combobox\\\" aria-controls=\\\"file-results-list\\\" aria-expanded=\\\"false\\\" aria-haspopup=\\\"dialog\\\" autoCorrect=\\\"off\\\" spellCheck=\\\"false\\\" placeholder=\\\"Go to file\\\" aria-describedby=\\\"_R_535ab_ _R_535abH1_\\\" data-component=\\\"input\\\" class=\\\"prc-components-Input-IwWrt\\\" value=\\\"\\\"/><span class=\\\"TextInput-icon\\\" id=\\\"_R_535abH1_\\\" aria-hidden=\\\"true\\\"></span></span></div><!--/$--></div><div class=\\\"OverviewContent-module__Box_9--kxlwV\\\"><button type=\\\"button\\\" class=\\\"prc-Button-ButtonBase-9n-Xk\\\" data-loading=\\\"false\\\" data-no-visuals=\\\"true\\\" data-size=\\\"medium\\\" data-variant=\\\"default\\\"><span data-component=\\\"buttonContent\\\" data-align=\\\"center\\\" class=\\\"prc-Button-ButtonContent-Iohp5\\\"><span data-component=\\\"text\\\" class=\\\"prc-Button-Label-FWkx3\\\">Go to file</span></span></button></div></div><button type=\\\"button\\\" aria-haspopup=\\\"true\\\" aria-expanded=\\\"false\\\" tabindex=\\\"0\\\" class=\\\"prc-Button-ButtonBase-9n-Xk\\\" data-loading=\\\"false\\\" data-size=\\\"medium\\\" data-variant=\\\"primary\\\" id=\\\"_R_75ab_\\\"><span data-component=\\\"buttonContent\\\" data-align=\\\"center\\\" class=\\\"prc-Button-ButtonContent-Iohp5\\\"><span data-component=\\\"leadingVisual\\\" class=\\\"prc-Button-Visual-YNt2F prc-Button-VisualWrap-E4cnq\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-code hide-sm\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z\\\"></path></svg></span><span data-component=\\\"text\\\" class=\\\"prc-Button-Label-FWkx3\\\">Code</span><span data-component=\\\"trailingVisual\\\" class=\\\"prc-Button-Visual-YNt2F prc-Button-VisualWrap-E4cnq\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-triangle-down\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"m4.427 7.427 3.396 3.396a.25.25 0 0 0 .354 0l3.396-3.396A.25.25 0 0 0 11.396 7H4.604a.25.25 0 0 0-.177.427Z\\\"></path></svg></span></span></button><div class=\\\"OverviewContent-module__Box_10--UMc9C\\\"><button data-component=\\\"IconButton\\\" type=\\\"button\\\" aria-haspopup=\\\"true\\\" aria-expanded=\\\"false\\\" tabindex=\\\"0\\\" class=\\\"prc-Button-ButtonBase-9n-Xk prc-Button-IconButton-fyge7\\\" data-loading=\\\"false\\\" data-no-visuals=\\\"true\\\" data-size=\\\"medium\\\" data-variant=\\\"default\\\" aria-labelledby=\\\"_R_7p5ab_\\\" id=\\\"_R_95ab_\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-kebab-horizontal\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"M8 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3ZM1.5 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Zm13 0a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z\\\"></path></svg></button><span class=\\\"prc-TooltipV2-Tooltip-tLeuB\\\" data-direction=\\\"n\\\" aria-hidden=\\\"true\\\" id=\\\"_R_7p5ab_\\\">Open more actions menu</span></div></div></div><div class=\\\"OverviewContent-module__Box_11--QeUk1\\\"><div data-hpc=\\\"true\\\"><button hidden=\\\"\\\" data-testid=\\\"focus-next-element-button\\\" data-hotkey=\\\"j\\\"></button><button hidden=\\\"\\\" data-testid=\\\"focus-previous-element-button\\\" data-hotkey=\\\"k\\\"></button><h2 class=\\\"sr-only ScreenReaderHeading-module__userSelectNone--vlUbc prc-Heading-Heading-MtWFE\\\" data-testid=\\\"screen-reader-heading\\\" id=\\\"folders-and-files\\\">Folders and files</h2><table class=\\\"Table-module__Box--KyMHK\\\" aria-labelledby=\\\"folders-and-files\\\"><thead class=\\\"DirectoryContent-module__OverviewHeaderRow--FlrUZ Table-module__Box_1--DkRqs\\\"><tr class=\\\"Table-module__Box_2--l1wjV\\\"><th colSpan=\\\"2\\\" class=\\\"DirectoryContent-module__Box--y3Nvf\\\"><span class=\\\"text-bold\\\">Name</span></th><th colSpan=\\\"1\\\" class=\\\"DirectoryContent-module__Box_1--xeAhp\\\"><span class=\\\"text-bold\\\">Name</span></th><th class=\\\"hide-sm\\\"><div class=\\\"width-fit prc-Truncate-Truncate-2G1eo\\\" data-inline=\\\"true\\\" title=\\\"Last commit message\\\" style=\\\"--truncate-max-width:125px\\\"><span class=\\\"text-bold\\\">Last commit message</span></div></th><th colSpan=\\\"1\\\" class=\\\"DirectoryContent-module__Box_2--h912w\\\"><div class=\\\"width-fit prc-Truncate-Truncate-2G1eo\\\" data-inline=\\\"true\\\" title=\\\"Last commit date\\\" style=\\\"--truncate-max-width:125px\\\"><span class=\\\"text-bold\\\">Last commit date</span></div></th></tr></thead><tbody><tr class=\\\"DirectoryContent-module__Box_3--zI0N1\\\"><td colSpan=\\\"3\\\" class=\\\"bgColor-muted p-1 rounded-top-2\\\"><div class=\\\"LatestCommit-module__Box--Fimpo\\\"><h2 class=\\\"sr-only ScreenReaderHeading-module__userSelectNone--vlUbc prc-Heading-Heading-MtWFE\\\" data-testid=\\\"screen-reader-heading\\\">Latest commit</h2><div style=\\\"width:120px\\\" class=\\\"Skeleton Skeleton--text\\\" data-testid=\\\"loading\\\">¬†</div><div class=\\\"d-flex flex-shrink-0 gap-2\\\"><div data-testid=\\\"latest-commit-details\\\" class=\\\"d-none d-sm-flex flex-items-center\\\"></div><div class=\\\"d-flex gap-2\\\"><h2 class=\\\"sr-only ScreenReaderHeading-module__userSelectNone--vlUbc prc-Heading-Heading-MtWFE\\\" data-testid=\\\"screen-reader-heading\\\">History</h2><a href=\\\"/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/commits/main/\\\" class=\\\"prc-Button-ButtonBase-9n-Xk d-none d-lg-flex LinkButton-module__code-view-link-button--thtqc flex-items-center fgColor-default\\\" data-loading=\\\"false\\\" data-size=\\\"small\\\" data-variant=\\\"invisible\\\"><span data-component=\\\"buttonContent\\\" data-align=\\\"center\\\" class=\\\"prc-Button-ButtonContent-Iohp5\\\"><span data-component=\\\"leadingVisual\\\" class=\\\"prc-Button-Visual-YNt2F prc-Button-VisualWrap-E4cnq\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-history\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"m.427 1.927 1.215 1.215a8.002 8.002 0 1 1-1.6 5.685.75.75 0 1 1 1.493-.154 6.5 6.5 0 1 0 1.18-4.458l1.358 1.358A.25.25 0 0 1 3.896 6H.25A.25.25 0 0 1 0 5.75V2.104a.25.25 0 0 1 .427-.177ZM7.75 4a.75.75 0 0 1 .75.75v2.992l2.028.812a.75.75 0 0 1-.557 1.392l-2.5-1A.751.751 0 0 1 7 8.25v-3.5A.75.75 0 0 1 7.75 4Z\\\"></path></svg></span><span data-component=\\\"text\\\" class=\\\"prc-Button-Label-FWkx3\\\"><span class=\\\"fgColor-default\\\">14 Commits</span></span></span></a><div class=\\\"d-sm-none\\\"></div><div class=\\\"d-flex d-lg-none\\\"><span role=\\\"tooltip\\\" aria-label=\\\"14 Commits\\\" id=\\\"history-icon-button-tooltip\\\" class=\\\"prc-Tooltip-Tooltip-JLsri prc-Tooltip-Tooltip--n-SqCQ- tooltipped-n\\\"><a aria-label=\\\"View commit history for this file.\\\" href=\\\"/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/commits/main/\\\" class=\\\"prc-Button-ButtonBase-9n-Xk LinkButton-module__code-view-link-button--thtqc flex-items-center fgColor-default\\\" data-loading=\\\"false\\\" data-size=\\\"small\\\" data-variant=\\\"invisible\\\" aria-describedby=\\\"history-icon-button-tooltip\\\"><span data-component=\\\"buttonContent\\\" data-align=\\\"center\\\" class=\\\"prc-Button-ButtonContent-Iohp5\\\"><span data-component=\\\"leadingVisual\\\" class=\\\"prc-Button-Visual-YNt2F prc-Button-VisualWrap-E4cnq\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-history\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"m.427 1.927 1.215 1.215a8.002 8.002 0 1 1-1.6 5.685.75.75 0 1 1 1.493-.154 6.5 6.5 0 1 0 1.18-4.458l1.358 1.358A.25.25 0 0 1 3.896 6H.25A.25.25 0 0 1 0 5.75V2.104a.25.25 0 0 1 .427-.177ZM7.75 4a.75.75 0 0 1 .75.75v2.992l2.028.812a.75.75 0 0 1-.557 1.392l-2.5-1A.751.751 0 0 1 7 8.25v-3.5A.75.75 0 0 1 7.75 4Z\\\"></path></svg></span></span></a></span></div></div></div></div></td></tr><tr class=\\\"react-directory-row undefined\\\" id=\\\"folder-row-0\\\"><td class=\\\"react-directory-row-name-cell-small-screen\\\" colSpan=\\\"2\\\"><div class=\\\"react-directory-filename-column\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-file color-fg-muted\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\\\"></path></svg><div class=\\\"overflow-hidden\\\"><div class=\\\"react-directory-filename-cell\\\"><div class=\\\"react-directory-truncate\\\"><a title=\\\"LLM_RAG_Project_1.ipynb\\\" aria-label=\\\"LLM_RAG_Project_1.ipynb, (File)\\\" class=\\\"Link--primary\\\" href=\\\"/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/blob/main/LLM_RAG_Project_1.ipynb\\\" data-discover=\\\"true\\\">LLM_RAG_Project_1.ipynb</a></div></div></div></div></td><td class=\\\"react-directory-row-name-cell-large-screen\\\" colSpan=\\\"1\\\"><div class=\\\"react-directory-filename-column\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-file color-fg-muted\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\\\"></path></svg><div class=\\\"overflow-hidden\\\"><div class=\\\"react-directory-filename-cell\\\"><div class=\\\"react-directory-truncate\\\"><a title=\\\"LLM_RAG_Project_1.ipynb\\\" aria-label=\\\"LLM_RAG_Project_1.ipynb, (File)\\\" class=\\\"Link--primary\\\" href=\\\"/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/blob/main/LLM_RAG_Project_1.ipynb\\\" data-discover=\\\"true\\\">LLM_RAG_Project_1.ipynb</a></div></div></div></div></td><td class=\\\"react-directory-row-commit-cell\\\"><div class=\\\"Skeleton Skeleton--text\\\">¬†</div></td><td><div class=\\\"Skeleton Skeleton--text\\\">¬†</div></td></tr><tr class=\\\"react-directory-row undefined\\\" id=\\\"folder-row-1\\\"><td class=\\\"react-directory-row-name-cell-small-screen\\\" colSpan=\\\"2\\\"><div class=\\\"react-directory-filename-column\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-file color-fg-muted\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\\\"></path></svg><div class=\\\"overflow-hidden\\\"><div class=\\\"react-directory-filename-cell\\\"><div class=\\\"react-directory-truncate\\\"><a title=\\\"README.md\\\" aria-label=\\\"README.md, (File)\\\" class=\\\"Link--primary\\\" href=\\\"/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/blob/main/README.md\\\" data-discover=\\\"true\\\">README.md</a></div></div></div></div></td><td class=\\\"react-directory-row-name-cell-large-screen\\\" colSpan=\\\"1\\\"><div class=\\\"react-directory-filename-column\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-file color-fg-muted\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\\\"></path></svg><div class=\\\"overflow-hidden\\\"><div class=\\\"react-directory-filename-cell\\\"><div class=\\\"react-directory-truncate\\\"><a title=\\\"README.md\\\" aria-label=\\\"README.md, (File)\\\" class=\\\"Link--primary\\\" href=\\\"/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/blob/main/README.md\\\" data-discover=\\\"true\\\">README.md</a></div></div></div></div></td><td class=\\\"react-directory-row-commit-cell\\\"><div class=\\\"Skeleton Skeleton--text\\\">¬†</div></td><td><div class=\\\"Skeleton Skeleton--text\\\">¬†</div></td></tr><tr class=\\\"react-directory-row undefined\\\" id=\\\"folder-row-2\\\"><td class=\\\"react-directory-row-name-cell-small-screen\\\" colSpan=\\\"2\\\"><div class=\\\"react-directory-filename-column\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-file color-fg-muted\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\\\"></path></svg><div class=\\\"overflow-hidden\\\"><div class=\\\"react-directory-filename-cell\\\"><div class=\\\"react-directory-truncate\\\"><a title=\\\"Technical_Report_with_code.pdf\", \"source\": \"web\", \"published_date\": \"N/A\", \"score_bm25\": 0.0}, {\"paper_id\": \"2504.01346v4\", \"title\": \"RAG over Tables: Hierarchical Memory Index, Multi-Stage Retrieval, and Benchmarking\", \"authors\": [\"Jiaru Zou\", \"Dongqi Fu\", \"Sirui Chen\", \"Xinrui He\", \"Zihao Li\", \"Yada Zhu\", \"Jiawei Han\", \"Jingrui He\"], \"abstract\": \"Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by integrating them with an external knowledge base to improve the answer relevance and accuracy. In real-world scenarios, beyond pure text, a substantial amount of knowledge is stored in tables, and user questions often require retrieving answers that are distributed across multiple tables. Retrieving knowledge from a table corpora (i.e., various individual tables) for a question remains nascent, at least, for (i) how to understand intra- and inter-table knowledge effectively, (ii) how to filter unnecessary tables and how to retrieve the most relevant tables efficiently, (iii) how to prompt LLMs to infer over the retrieval, (iv) how to evaluate the corresponding performance in a realistic setting. Facing the above challenges, in this paper, we first propose a table-corpora-aware RAG framework, named T-RAG, which consists of the hierarchical memory index, multi-stage retrieval, and graph-aware prompting for effective and efficient table knowledge retrieval and inference. Further, we first develop a multi-table question answering benchmark named MultiTableQA, which spans 3 different task types, 57,193 tables, and 23,758 questions in total, and the sources are all from real-world scenarios. Based on MultiTableQA, we did the holistic comparison over table retrieval methods, RAG methods, and table-to-graph representation learning methods, where T-RAG shows the leading accuracy, recall, and running time performance. Also, under T-RAG, we evaluate the inference ability upgrade of different LLMs. Code and Data are available at https://github.com/jiaruzouu/T-RAG\", \"url\": \"http://arxiv.org/abs/2504.01346v4\", \"pdf_url\": \"https://arxiv.org/pdf/2504.01346v4\", \"source\": \"arxiv\", \"published_date\": \"2025-04-02T04:24:41Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2412.12881v1\", \"title\": \"RAG-Star: Enhancing Deliberative Reasoning with Retrieval Augmented Verification and Refinement\", \"authors\": [\"Jinhao Jiang\", \"Jiayi Chen\", \"Junyi Li\", \"Ruiyang Ren\", \"Shijie Wang\", \"Wayne Xin Zhao\", \"Yang Song\", \"Tao Zhang\"], \"abstract\": \"Existing large language models (LLMs) show exceptional problem-solving capabilities but might struggle with complex reasoning tasks. Despite the successes of chain-of-thought and tree-based search methods, they mainly depend on the internal knowledge of LLMs to search over intermediate reasoning steps, limited to dealing with simple tasks involving fewer reasoning steps. In this paper, we propose \\\\textbf{RAG-Star}, a novel RAG approach that integrates the retrieved information to guide the tree-based deliberative reasoning process that relies on the inherent knowledge of LLMs. By leveraging Monte Carlo Tree Search, RAG-Star iteratively plans intermediate sub-queries and answers for reasoning based on the LLM itself. To consolidate internal and external knowledge, we propose an retrieval-augmented verification that utilizes query- and answer-aware reward modeling to provide feedback for the inherent reasoning of LLMs. Our experiments involving Llama-3.1-8B-Instruct and GPT-4o demonstrate that RAG-Star significantly outperforms previous RAG and reasoning methods.\", \"url\": \"http://arxiv.org/abs/2412.12881v1\", \"pdf_url\": \"https://arxiv.org/pdf/2412.12881v1\", \"source\": \"arxiv\", \"published_date\": \"2024-12-17T13:05:36Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2511.22858v1\", \"title\": \"RAG System for Supporting Japanese Litigation Procedures: Faithful Response Generation Complying with Legal Norms\", \"authors\": [\"Yuya Ishihara\", \"Atsushi Keyaki\", \"Hiroaki Yamada\", \"Ryutaro Ohara\", \"Mihoko Sumida\"], \"abstract\": \"This study discusses the essential components that a Retrieval-Augmented Generation (RAG)-based LLM system should possess in order to support Japanese medical litigation procedures complying with legal norms. In litigation, expert commissioners, such as physicians, architects, accountants, and engineers, provide specialized knowledge to help judges clarify points of dispute. When considering the substitution of these expert roles with a RAG-based LLM system, the constraint of strict adherence to legal norms is imposed. Specifically, three requirements arise: (1) the retrieval module must retrieve appropriate external knowledge relevant to the disputed issues in accordance with the principle prohibiting the use of private knowledge, (2) the responses generated must originate from the context provided by the RAG and remain faithful to that context, and (3) the retrieval module must reference external knowledge with appropriate timestamps corresponding to the issues at hand. This paper discusses the design of a RAG-based LLM system that satisfies these requirements.\", \"url\": \"http://arxiv.org/abs/2511.22858v1\", \"pdf_url\": \"https://arxiv.org/pdf/2511.22858v1\", \"source\": \"arxiv\", \"published_date\": \"2025-11-28T03:28:27Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2502.13957v2\", \"title\": \"RAG-Gym: Systematic Optimization of Language Agents for Retrieval-Augmented Generation\", \"authors\": [\"Guangzhi Xiong\", \"Qiao Jin\", \"Xiao Wang\", \"Yin Fang\", \"Haolin Liu\", \"Yifan Yang\", \"Fangyuan Chen\", \"Zhixing Song\", \"Dengyu Wang\", \"Minjia Zhang\", \"Zhiyong Lu\", \"Aidong Zhang\"], \"abstract\": \"Retrieval-augmented generation (RAG) has shown great promise for knowledge-intensive tasks and recently advanced with agentic RAG, where language agents engage in multi-round interactions with external knowledge sources for adaptive information retrieval. However, existing agentic RAG methods often depend on ad-hoc prompt engineering and lack a unified optimization framework. We introduce RAG-Gym, a comprehensive platform that systematically explores three optimization dimensions: (1) prompt engineering, (2) actor tuning, and (3) critic training. For prompt engineering, we propose Re$^2$Search, a novel agent incorporating reasoning reflection that significantly outperforms standard prompts. In actor tuning, we evaluate three popular post-training algorithms with fine-grained process supervision and identify direct preference optimization as the most effective. We further demonstrate that a trained critic can enhance inference by selecting higher-quality intermediate reasoning steps. Together, these findings lead to the optimized Re$^2$Search++ agent, which surpasses most recent methods like Search-R1 by a relative increase of 3.2% to 11.6% in average F1. Finally, we examine the impact of different reward sources and analyze scaling properties in training and inference, offering practical insights for agentic RAG optimization. The project homepage is available at https://rag-gym.github.io.\", \"url\": \"http://arxiv.org/abs/2502.13957v2\", \"pdf_url\": \"https://arxiv.org/pdf/2502.13957v2\", \"source\": \"arxiv\", \"published_date\": \"2025-02-19T18:56:03Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2409.18313v5\", \"title\": \"Embodied-RAG: General Non-parametric Embodied Memory for Retrieval and Generation\", \"authors\": [\"Quanting Xie\", \"So Yeon Min\", \"Pengliang Ji\", \"Yue Yang\", \"Tianyi Zhang\", \"Kedi Xu\", \"Aarav Bajaj\", \"Ruslan Salakhutdinov\", \"Matthew Johnson-Roberson\", \"Yonatan Bisk\"], \"abstract\": \"There is no limit to how much a robot might explore and learn, but all of that knowledge needs to be searchable and actionable. Within language research, retrieval augmented generation (RAG) has become the workhorse of large-scale non-parametric knowledge; however, existing techniques do not directly transfer to the embodied domain, which is multimodal, where data is highly correlated, and perception requires abstraction. To address these challenges, we introduce Embodied-RAG, a framework that enhances the foundational model of an embodied agent with a non-parametric memory system capable of autonomously constructing hierarchical knowledge for both navigation and language generation. Embodied-RAG handles a full range of spatial and semantic resolutions across diverse environments and query types, whether for a specific object or a holistic description of ambiance. At its core, Embodied-RAG's memory is structured as a semantic forest, storing language descriptions at varying levels of detail. This hierarchical organization allows the system to efficiently generate context-sensitive outputs across different robotic platforms. We demonstrate that Embodied-RAG effectively bridges RAG to the robotics domain, successfully handling over 250 explanation and navigation queries across kilometer-level environments, highlighting its promise as a general-purpose non-parametric system for embodied agents.\", \"url\": \"http://arxiv.org/abs/2409.18313v5\", \"pdf_url\": \"https://arxiv.org/pdf/2409.18313v5\", \"source\": \"arxiv\", \"published_date\": \"2024-09-26T21:44:11Z\", \"score_bm25\": 0.0}], \"HTML parsing for information retrieval\": [{\"paper_id\": null, \"title\": \"Semantic-Sensitive Web Information Retrieval Model for HTML Documents\", \"authors\": [\"Youssef Bassil\", \"Paul Semaan\"], \"abstract\": \"With the advent of the Internet, a new era of digital information exchange has begun. Currently, the Internet encompasses more than five billion online sites and this number is exponentially increasing every day. Fundamentally, Information Retrieval (IR) is the science and practice of storing documents and retrieving information from within these documents. Mathematically, IR systems are at the core based on a feature vector model coupled with a term weighting scheme that weights terms in a document according to their significance with respect to the context in which they appear. Practically, Vector Space Model (VSM), Term Frequency (TF), and Inverse Term Frequency (IDF) are among other long-established techniques employed in mainstream IR systems. However, present IR models only target generic-type text documents, in that, they do not consider specific formats of files such as HTML web documents. This paper proposes a new semantic-sensitive web information retrieval model for HTML documents. It consists of a vector model called SWVM and a weighting scheme called BTF-IDF, particularly designed to support the indexing and retrieval of HTML web documents. The chief advantage of the proposed model is that it assigns extra weights for terms that appear in certain pre-specified HTML tags that are correlated to the semantics of the document. Additionally, the model is semantic-sensitive as it generates synonyms for every term being indexed and later weights them appropriately to increase the likelihood of retrieving documents with similar context but different vocabulary terms. Experiments conducted, revealed a momentous enhancement in the precision of web IR systems and a radical increase in the number of relevant documents being retrieved. As further research, the proposed model is to be upgraded so as to support the indexing and retrieval of web images in multimedia-rich web documents.\", \"url\": \"http://arxiv.org/abs/1204.0186v1\", \"pdf_url\": \"https://arxiv.org/pdf/1204.0186v1\", \"source\": \"arxiv\", \"published_date\": \"2012-04-01T09:50:42Z\", \"score_bm25\": 0.0}, {\"paper_id\": null, \"title\": \"Editorial for the Bibliometric-enhanced Information Retrieval Workshop at ECIR 2014\", \"authors\": [\"Philipp Mayr\", \"Philipp Schaer\", \"Andrea Scharnhorst\", \"Peter Mutschke\"], \"abstract\": \"This first \\\"Bibliometric-enhanced Information Retrieval\\\" (BIR 2014) workshop aims to engage with the IR community about possible links to bibliometrics and scholarly communication. Bibliometric techniques are not yet widely used to enhance retrieval processes in digital libraries, although they offer value-added effects for users. In this workshop we will explore how statistical modelling of scholarship, such as Bradfordizing or network analysis of co-authorship network, can improve retrieval services for specific communities, as well as for large, cross-domain collections. This workshop aims to raise awareness of the missing link between information retrieval (IR) and bibliometrics / scientometrics and to create a common ground for the incorporation of bibliometric-enhanced services into retrieval at the digital library interface. Our interests include information retrieval, information seeking, science modelling, network analysis, and digital libraries. The goal is to apply insights from bibliometrics, scientometrics, and informetrics to concrete practical problems of information retrieval and browsing.\", \"url\": \"http://arxiv.org/abs/1404.7099v1\", \"pdf_url\": \"https://arxiv.org/pdf/1404.7099v1\", \"source\": \"arxiv\", \"published_date\": \"2014-04-28T19:17:49Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"1601.04605v1\", \"title\": \"Dynamic Information Retrieval: Theoretical Framework and Application\", \"authors\": [\"Marc Sloan\", \"Jun Wang\"], \"abstract\": \"Theoretical frameworks like the Probability Ranking Principle and its more recent Interactive Information Retrieval variant have guided the development of ranking and retrieval algorithms for decades, yet they are not capable of helping us model problems in Dynamic Information Retrieval which exhibit the following three properties; an observable user signal, retrieval over multiple stages and an overall search intent. In this paper a new theoretical framework for retrieval in these scenarios is proposed. We derive a general dynamic utility function for optimizing over these types of tasks, that takes into account the utility of each stage and the probability of observing user feedback. We apply our framework to experiments over TREC data in the dynamic multi page search scenario as a practical demonstration of its effectiveness and to frame the discussion of its use, its limitations and to compare it against the existing frameworks.\", \"url\": \"http://arxiv.org/abs/1601.04605v1\", \"pdf_url\": \"https://arxiv.org/pdf/1601.04605v1\", \"source\": \"arxiv\", \"published_date\": \"2016-01-18T17:01:34Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"1501.02646v1\", \"title\": \"Bibliometric-enhanced Information Retrieval: 2nd International BIR Workshop\", \"authors\": [\"Philipp Mayr\", \"Ingo Frommholz\", \"Andrea Scharnhorst\", \"Peter Mutschke\"], \"abstract\": \"This workshop brings together experts of communities which often have been perceived as different once: bibliometrics / scientometrics / informetrics on the one side and information retrieval on the other. Our motivation as organizers of the workshop started from the observation that main discourses in both fields are different, that communities are only partly overlapping and from the belief that a knowledge transfer would be profitable for both sides. Bibliometric techniques are not yet widely used to enhance retrieval processes in digital libraries, although they offer value-added effects for users. On the other side, more and more information professionals, working in libraries and archives are confronted with applying bibliometric techniques in their services. This way knowledge exchange becomes more urgent. The first workshop set the research agenda, by introducing in each other methods, reporting about current research problems and brainstorming about common interests. This follow-up workshop continues the overall communication, but also puts one problem into the focus. In particular, we will explore how statistical modelling of scholarship can improve retrieval services for specific communities, as well as for large, cross-domain collections like Mendeley or ResearchGate. This second BIR workshop continues to raise awareness of the missing link between Information Retrieval (IR) and bibliometrics and contributes to create a common ground for the incorporation of bibliometric-enhanced services into retrieval at the scholarly search engine interface.\", \"url\": \"http://arxiv.org/abs/1501.02646v1\", \"pdf_url\": \"https://arxiv.org/pdf/1501.02646v1\", \"source\": \"arxiv\", \"published_date\": \"2015-01-12T13:59:13Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"1606.06137v1\", \"title\": \"LSTM-Based Predictions for Proactive Information Retrieval\", \"authors\": [\"Petri Luukkonen\", \"Markus Koskela\", \"Patrik Flor√©en\"], \"abstract\": \"We describe a method for proactive information retrieval targeted at retrieving relevant information during a writing task. In our method, the current task and the needs of the user are estimated, and the potential next steps are unobtrusively predicted based on the user's past actions. We focus on the task of writing, in which the user is coalescing previously collected information into a text. Our proactive system automatically recommends the user relevant background information. The proposed system incorporates text input prediction using a long short-term memory (LSTM) network. We present simulations, which show that the system is able to reach higher precision values in an exploratory search setting compared to both a baseline and a comparison system.\", \"url\": \"http://arxiv.org/abs/1606.06137v1\", \"pdf_url\": \"https://arxiv.org/pdf/1606.06137v1\", \"source\": \"arxiv\", \"published_date\": \"2016-06-20T14:26:33Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2503.17876v1\", \"title\": \"Satisfactory Medical Consultation based on Terminology-Enhanced Information Retrieval and Emotional In-Context Learning\", \"authors\": [\"Kaiwen Zuo\", \"Jing Tang\", \"Hanbing Qin\", \"Binli Luo\", \"Ligang He\", \"Shiyan Tang\"], \"abstract\": \"Recent advancements in Large Language Models (LLMs) have marked significant progress in understanding and responding to medical inquiries. However, their performance still falls short of the standards set by professional consultations. This paper introduces a novel framework for medical consultation, comprising two main modules: Terminology-Enhanced Information Retrieval (TEIR) and Emotional In-Context Learning (EICL). TEIR ensures implicit reasoning through the utilization of inductive knowledge and key terminology retrieval, overcoming the limitations of restricted domain knowledge in public databases. Additionally, this module features capabilities for processing long context. The EICL module aids in generating sentences with high attribute relevance by memorizing semantic and attribute information from unlabelled corpora and applying controlled retrieval for the required information. Furthermore, a dataset comprising 803,564 consultation records was compiled in China, significantly enhancing the model's capability for complex dialogues and proactive inquiry initiation. Comprehensive experiments demonstrate the proposed method's effectiveness in extending the context window length of existing LLMs. The experimental outcomes and extensive data validate the framework's superiority over five baseline models in terms of BLEU and ROUGE performance metrics, with substantial leads in certain capabilities. Notably, ablation studies confirm the significance of the TEIR and EICL components. In addition, our new framework has the potential to significantly improve patient satisfaction in real clinical consulting situations.\", \"url\": \"http://arxiv.org/abs/2503.17876v1\", \"pdf_url\": \"https://arxiv.org/pdf/2503.17876v1\", \"source\": \"arxiv\", \"published_date\": \"2025-03-22T23:01:07Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2404.08628v1\", \"title\": \"Accessibility in Information Retrieval\", \"authors\": [\"Leif Azzopardi\", \"Vishwa Vinay\"], \"abstract\": \"This paper introduces the concept of accessibility from the field of transportation planning and adopts it within the context of Information Retrieval (IR). An analogy is drawn between the fields, which motivates the development of document accessibility measures for IR systems. Considering the accessibility of documents within a collection given an IR System provides a different perspective on the analysis and evaluation of such systems which could be used to inform the design, tuning and management of current and future IR systems.\", \"url\": \"http://arxiv.org/abs/2404.08628v1\", \"pdf_url\": \"https://arxiv.org/pdf/2404.08628v1\", \"source\": \"arxiv\", \"published_date\": \"2024-04-12T17:46:13Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"1811.08772v1\", \"title\": \"Overcoming low-utility facets for complex answer retrieval\", \"authors\": [\"Sean MacAvaney\", \"Andrew Yates\", \"Arman Cohan\", \"Luca Soldaini\", \"Kai Hui\", \"Nazli Goharian\", \"Ophir Frieder\"], \"abstract\": \"Many questions cannot be answered simply; their answers must include numerous nuanced details and additional context. Complex Answer Retrieval (CAR) is the retrieval of answers to such questions. In their simplest form, these questions are constructed from a topic entity (e.g., `cheese') and a facet (e.g., `health effects'). While topic matching has been thoroughly explored, we observe that some facets use general language that is unlikely to appear verbatim in answers. We call these low-utility facets. In this work, we present an approach to CAR that identifies and addresses low-utility facets. We propose two estimators of facet utility. These include exploiting the hierarchical structure of CAR queries and using facet frequency information from training data. To improve the retrieval performance on low-utility headings, we also include entity similarity scores using knowledge graph embeddings. We apply our approaches to a leading neural ranking technique, and evaluate using the TREC CAR dataset. We find that our approach perform significantly better than the unmodified neural ranker and other leading CAR techniques. We also provide a detailed analysis of our results, and verify that low-utility facets are indeed more difficult to match, and that our approach improves the performance for these difficult queries.\", \"url\": \"http://arxiv.org/abs/1811.08772v1\", \"pdf_url\": \"https://arxiv.org/pdf/1811.08772v1\", \"source\": \"arxiv\", \"published_date\": \"2018-11-21T15:09:00Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2210.09877v1\", \"title\": \"Towards Proactive Information Retrieval in Noisy Text with Wikipedia Concepts\", \"authors\": [\"Tabish Ahmed\", \"Sahan Bulathwela\"], \"abstract\": \"Extracting useful information from the user history to clearly understand informational needs is a crucial feature of a proactive information retrieval system. Regarding understanding information and relevance, Wikipedia can provide the background knowledge that an intelligent system needs. This work explores how exploiting the context of a query using Wikipedia concepts can improve proactive information retrieval on noisy text. We formulate two models that use entity linking to associate Wikipedia topics with the relevance model. Our experiments around a podcast segment retrieval task demonstrate that there is a clear signal of relevance in Wikipedia concepts while a ranking model can improve precision by incorporating them. We also find Wikifying the background context of a query can help disambiguate the meaning of the query, further helping proactive information retrieval.\", \"url\": \"http://arxiv.org/abs/2210.09877v1\", \"pdf_url\": \"https://arxiv.org/pdf/2210.09877v1\", \"source\": \"arxiv\", \"published_date\": \"2022-10-18T14:12:06Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2403.13468v1\", \"title\": \"DESIRE-ME: Domain-Enhanced Supervised Information REtrieval using Mixture-of-Experts\", \"authors\": [\"Pranav Kasela\", \"Gabriella Pasi\", \"Raffaele Perego\", \"Nicola Tonellotto\"], \"abstract\": \"Open-domain question answering requires retrieval systems able to cope with the diverse and varied nature of questions, providing accurate answers across a broad spectrum of query types and topics. To deal with such topic heterogeneity through a unique model, we propose DESIRE-ME, a neural information retrieval model that leverages the Mixture-of-Experts framework to combine multiple specialized neural models. We rely on Wikipedia data to train an effective neural gating mechanism that classifies the incoming query and that weighs the predictions of the different domain-specific experts correspondingly. This allows DESIRE-ME to specialize adaptively in multiple domains. Through extensive experiments on publicly available datasets, we show that our proposal can effectively generalize domain-enhanced neural models. DESIRE-ME excels in handling open-domain questions adaptively, boosting by up to 12% in NDCG@10 and 22% in P@1, the underlying state-of-the-art dense retrieval model.\", \"url\": \"http://arxiv.org/abs/2403.13468v1\", \"pdf_url\": \"https://arxiv.org/pdf/2403.13468v1\", \"source\": \"arxiv\", \"published_date\": \"2024-03-20T10:18:05Z\", \"score_bm25\": 0.0}], \"named entity recognition web content\": [{\"paper_id\": null, \"title\": \"NER: Overview, Techniques, Methods, and Implementation Guide | SapientPro\", \"authors\": [], \"abstract\": \"<H1>All Named Entity Recognition: Mechanism, Methods, Use Cases, and Implementation Tips</H1><P>Businesses are all about automation now, using chatbots and voice assistants to do tasks that previously required people. Machine learning and natural language processing (NLP) have become essential. For example, Google Cloud's NLP platform uses Google machine learning to help users understand and gain insights from unstructured texts.</P><P>According to a MarketsandMarkets report, the NLP market is expected to reach $68.1 billion by 2028, with Named Entity Recognition (NER) being a key driver of this growth. Since about 80‚Äì90% of all data is unorganized, tools like NER are necessary for finding meaningful information.</P><H3>Intro</H3><H3>What Is Named Entity Recognition?</H3><H3>NER Benefits & Challenges?</H3><H3>How Named-entity Recognition Works?</H3><H3>Named Entity Recognition Techniques</H3><H3>NER Methodologies</H3><H3>Use Cases for Named Entity Recognition</H3><H3>NER Examples</H3><H3>How to Implement Named Entity Recognition</H3><H3>Recent Trends in Named Entity Recognition (NER) and Its Future</H3><H3>Summary</H3><H2>Intro</H2><P>NER is popular because it can automatically find and categorize key information from large pieces of text. This allows organizations to easily extract needed data from customer interactions, financial reports, legal contracts, social media, etc.</P><P>This guide provides all the information about Named Entity Recognition. You'll learn how NER works, what named entity recognition custom entities are, discover its use cases, and learn how to build named entity recognition model.</P><H2>What Is Named Entity Recognition?</H2><P>Named entity recognition means a technique in natural language processing used to recognize specific types of entities in a text, like names, places, dates, and organizations. Named entity recognition history began in 1996. NER mostly used rule-based methods and ontologies at that time. By 2007, NER models started to adopt machine learning to engineer features.</P><P>Implementation of deep learning has greatly improved NER. Deep learning models for named entity recognition are more flexible and can manage different domains and new data by using characters, sub-words, and word embeddings.</P><P>Machines can process large amounts of text and extract key information in organized named entity recognition categories. By identifying specific entities within the text, NER changes how we manage and use written information.</P><P>NER on New York Times Dataset</P><H2>NER Benefits & Challenges?</H2><P>Named entity recognition has several great benefits, but also some limitations. We‚Äôll explain both to you.</P><H3>Advantages of Using NER</H3><P><H3>The main advantage of NER is that it helps us find important details in large amounts of textual data, like articles, social media posts, websites, and research papers. Let‚Äôs check out some more benefits of NER:</H3></P><UL><LI>Enhanced user experience: NER improv\", \"url\": \"https://sapient.pro/blog/named-entity-recognition-implementation-tips\", \"pdf_url\": \"https://sapient.pro/_next/static/chunks/webpack-8f2f3a22d4058924.js\\\"/><script src=\\\"/_next/static/chunks/4bd1b696-30718bd562604751.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/8261-87b8c652f4859a63.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/main-app-bb2c9f756d1b5869.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/5692-72f59cbd0b2d4e1c.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/372-451cb83d29080205.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/2425-439c7bb72af23a79.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/1610-347058d2d6f072f3.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/2255-4738241640ea2919.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/8171-cddb9006621c7c00.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/5920-07a1fcdb22c875d8.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/8050-6fe88ce55f02cc11.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/47-eff6aa59faf62008.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/9568-fae9ea3a1f7a897e.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/8762-904b9dccec4bdcbe.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/9379-b268cb89893422b9.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/6005-ebaace4f89cd1040.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/7733-f85527123dbb52bd.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/app/(pages)/blog/%5BfirstRoute%5D/page-fdb8479ab01af442.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/app/layout-b137356a30e39ace.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/app/error-65374cf82c16a100.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/app/not-found-75717f0b381a5717.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/160b575a-21c0702096c443fe.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/13b76428-d0865967e61b6767.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/6429-39f4a61cddb917a1.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/7040-a126503cb486062f.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/1325-c421be758bae2d4b.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/2602-4efe96ee0869cd95.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/7871-7eabec075b2300c6.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/app/(pages)/layout-0627809657c81bf2.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/app/(pages)/page-7ab8cf56416bc535.js\\\" async=\\\"\\\"></script><link rel=\\\"preload\\\" href=\\\"https://tag.clearbitscripts.com/v1/pk\\\\_f50bf055ee2830aedf119b8ace4bc540/tags.js\\\" as=\\\"script\\\"/><title>NER: Overview, Techniques, Methods, and Implementation Guide | SapientPro</title><meta name=\\\"description\\\" content=\\\"Learn the basics of named entity recognition, its use cases, and how it works in natural language processing (NLP).\\\"/><link rel=\\\"manifest\\\" href=\\\"/manifest.webmanifest\\\"/><link rel=\\\"canonical\\\" href=\\\"https://sapient.pro/blog/named-entity-recognition-implementation-tips\\\"/><meta property=\\\"og:title\\\" content=\\\"NER: Overview, Techniques, Methods, and Implementation Guide | SapientPro\\\"/><meta property=\\\"og:description\\\" content=\\\"Learn the basics of named entity recognition, its use cases, and how it works in natural language processing (NLP).\\\"/><meta property=\\\"og:url\\\" content=\\\"https://sapient.pro/blog/named-entity-recognition-implementation-tips\\\"/><meta property=\\\"og:site_name\\\" content=\\\"SapientPro\\\"/><meta property=\\\"og:locale\\\" content=\\\"en_US\\\"/><meta property=\\\"og:image\\\" content=\\\"https://sapientpro.fra1.digitaloceanspaces.com/1c43931be7e6058e1569acd847be3460.jpg\\\"/><meta property=\\\"og:type\\\" content=\\\"website\\\"/><meta name=\\\"twitter:card\\\" content=\\\"summary_large_image\\\"/><meta name=\\\"twitter:creator\\\" content=\\\"@sapientpro\\\"/><meta name=\\\"twitter:title\\\" content=\\\"NER: Overview, Techniques, Methods, and Implementation Guide | SapientPro\\\"/><meta name=\\\"twitter:description\\\" content=\\\"Learn the basics of named entity recognition, its use cases, and how it works in natural language processing (NLP).\\\"/><meta name=\\\"twitter:image\\\" content=\\\"https://sapientpro.fra1.digitaloceanspaces.com/1c43931be7e6058e1569acd847be3460.jpg\\\"/><link rel=\\\"icon\\\" href=\\\"/favicon.ico\\\" type=\\\"image/x-icon\\\" sizes=\\\"48x48\\\"/><link rel=\\\"icon\\\" href=\\\"/icon.png?c21dbdf8726499f9\\\" type=\\\"image/png\\\" sizes=\\\"160x160\\\"/><link rel=\\\"apple-touch-icon\\\" href=\\\"/apple-icon.png?d13d4c1b561cc588\\\" type=\\\"image/png\\\" sizes=\\\"180x180\\\"/><script src=\\\"/_next/static/chunks/polyfills-42372ed130431b0a.js\\\" noModule=\\\"\\\"></script></head><body><div hidden=\\\"\\\"><!--$--><!--/$--></div><header class=\\\"Header_header__MwWvM Header_header_absolute__x4DUv\\\"><a aria-label=\\\"Get back to main page\\\" class=\\\"Header_logo__V9h3K\\\" href=\\\"/\\\"><div class=\\\"Logo_logo__zBwGf\\\" style=\\\"width:100px;height:32px\\\"><svg><use width=\\\"100\\\" height=\\\"32\\\" xlink:href=\\\"/media/logo.svg#logo\\\" href=\\\"/media/logo.svg#logo\\\"></use></svg></div></a><div class=\\\"Header_header__rightBlock__YuLgy\\\"><nav class=\\\"Menu_menu__N68p_\\\"><ul class=\\\"Menu_menu__list__NkMaT\\\"><li id=\\\"headedNavItem-1\\\" class=\\\"Menu_menu__item__Ze9KX\\\"><button type=\\\"button\\\" class=\\\"Menu_menuItem__lORev Menu_linkless__XjyKx\\\">Services<svg class=\\\"Menu_dropdownIcon__A4roo\\\"><use xlink:href=\\\"/media/angle_down.svg#angleDown\\\" href=\\\"/media/angle_down.svg#angleDown\\\"></use></svg><div class=\\\"Submenu_submenuWrapper__F9bWI Menu_submenuWrapper__SQlb2\\\"><section class=\\\"Submenu_submenu__4X1GF Menu_submenu__VGcRf Submenu_isVisible__vc3Zx\\\"><ul class=\\\"Submenu_submenu__mainlist__OEZcO\\\"><li></li><li class=\\\"Submenu_submenu__mainlist__item__7VGcv\\\"><ul class=\\\"Submenu_submenu__sublist__NLlB7\\\"><li><div class=\\\"Submenu_submenu__sublist__item__z1vTi\\\"><div class=\\\"Submenu_imageWrapper__nMh6K\\\"><div class=\\\"Submenu_image__cH19Y\\\"><img alt=\\\"submenu icon\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent\\\" src=\\\"https://sapientpro.fra1.digitaloceanspaces.com/63ac20be9e26fbf5da726aa0f6441139.svg\\\"/></div></div><div><a class=\\\"Submenu_title__ceSEA\\\" href=\\\"/legacy-software-modernization-services\\\">Legacy Software Modernization</a></div></div></li><li><div class=\\\"Submenu_submenu__sublist__item__z1vTi\\\"><div class=\\\"Submenu_imageWrapper__nMh6K\\\"><div class=\\\"Submenu_image__cH19Y\\\"><img alt=\\\"submenu icon\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent\\\" src=\\\"https://sapientpro.fra1.digitaloceanspaces.com/cc6f2e1fe7df157b60eaa254cdac5721.svg\\\"/></div></div><div><a class=\\\"Submenu_title__ceSEA\\\" href=\\\"/web-development-services\\\">Web 3.0 Development</a></div></div></li><li><div class=\\\"Submenu_submenu__sublist__item__z1vTi\\\"><div class=\\\"Submenu_imageWrapper__nMh6K\\\"><div class=\\\"Submenu_image__cH19Y\\\"><img alt=\\\"submenu icon\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent\\\" src=\\\"https://sapientpro.fra1.digitaloceanspaces.com/c87d62e9b8a55c2708a4ba2ba1489935.svg\\\"/></div></div><div><a class=\\\"Submenu_title__ceSEA\\\" href=\\\"/custom-software-development\\\">Custom Software Development </a></div></div></li><li><div class=\\\"Submenu_submenu__sublist__item__z1vTi\\\"><div class=\\\"Submenu_imageWrapper__nMh6K\\\"><div class=\\\"Submenu_image__cH19Y\\\"><img alt=\\\"submenu icon\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent\\\" src=\\\"https://sapientpro.fra1.digitaloceanspaces.com/1fcf391753fad4c59a797d4cf4438530.svg\\\"/></div></div><div><a class=\\\"Submenu_title__ceSEA\\\" href=\\\"/business-digitalization-solutions\\\">Business Digitalization</a></div></div></li><li><div class=\\\"Submenu_submenu__sublist__item__z1vTi\\\"><div class=\\\"Submenu_imageWrapper__nMh6K\\\"><div class=\\\"Submenu_image__cH19Y\\\"><img alt=\\\"submenu icon\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent\\\" src=\\\"https://sapientpro.fra1.digitaloceanspaces.com/ed786473dd7f304528d1226e9e98dbea.svg\\\"/></div></div><div><a class=\\\"Submenu_title__ceSEA\\\" href=\\\"/big-data-and-scraping-services\\\">BigData and Scraping</a></div></div></li></ul></li><li class=\\\"Submenu_submenu__mainlist__item__7VGcv\\\"><ul class=\\\"Submenu_submenu__sublist__NLlB7\\\"><li><div class=\\\"Submenu_submenu__sublist__item__z1vTi\\\"><div class=\\\"Submenu_imageWrapper__nMh6K\\\"><div class=\\\"Submenu_image__cH19Y\\\"><img alt=\\\"submenu icon\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent\\\" src=\\\"https://sapientpro.fra1.digitaloceanspaces.com/da7c2ffd03d6bfe325b052a6cea90ba1.svg\\\"/></div></div><div><a class=\\\"Submenu_title__ceSEA\\\" href=\\\"/software-development-for-startups\\\">Startups Launching</a></div></div></li><li><div class=\\\"Submenu_submenu__sublist__item__z1vTi\\\"><div class=\\\"Submenu_imageWrapper__nMh6K\\\"><div class=\\\"Submenu_image__cH19Y\\\"><img alt=\\\"submenu icon\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent\\\" src=\\\"https://sapientpro.fra1.digitaloceanspaces.com/Services_Icon_2_1_6d37e4e23b.svg\\\"/></div></div><div><a class=\\\"Submenu_title__ceSEA\\\" href=\\\"/ui-ux-design-services\\\">UI/UX Design Services</a></div></div></li><li><div class=\\\"Submenu_submenu__sublist__item__z1vTi\\\"><div class=\\\"Submenu_imageWrapper__nMh6K\\\"><div class=\\\"Submenu_image__cH19Y\\\"><img alt=\\\"submenu icon\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent\\\" src=\\\"https://sapientpro.fra1.digitaloceanspaces.com/6c5df13ffb3ac21667c42ed4eb141be6.svg\\\"/></div></div><div><a class=\\\"Submenu_title__ceSEA\\\" href=\\\"/saas-development\\\">SaaS Development </a></div></div></li><li><div class=\\\"Submenu_submenu__sublist__item__z1vTi\\\"><div class=\\\"Submenu_imageWrapper__nMh6K\\\"><div class=\\\"Submenu_image__cH19Y\\\"><img alt=\\\"submenu icon\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent\\\" src=\\\"https://sapientpro.fra1.digitaloceanspaces.com/3e3d0656915b4d8d5479f5b21774cc14.svg\\\"/></div></div><div><a class=\\\"Submenu_title__ceSEA\\\" href=\\\"/ecommerce-development-services\\\">E-commerce Development</a></div></div></li><li><div class=\\\"Submenu_submenu__sublist__item__z1vTi\\\"><div class=\\\"Submenu_imageWrapper__nMh6K\\\"><div class=\\\"Submenu_image__cH19Y\\\"><img alt=\\\"submenu icon\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent\\\" src=\\\"https://sapientpro.fra1.digitaloceanspaces.com/71af5d77fc049335a840785c4df5b87b.svg\\\"/></div></div><div><a class=\\\"Submenu_title__ceSEA\\\" href=\\\"/ai-development-services\\\">AI-driven Solutions</a></div></div></li></ul></li></ul></section></div></button></li><li id=\\\"headedNavItem-10\\\" class=\\\"Menu_menu__item__Ze9KX\\\"><a class=\\\"Menu_menuItem__lORev\\\" href=\\\"/cases\\\">Cases</a></li><li id=\\\"headedNavItem-15\\\" class=\\\"Menu_menu__item__Ze9KX\\\"><a class=\\\"Menu_menuItem__lORev\\\" href=\\\"/company\\\">Company</a></li><li id=\\\"headedNavItem-1\\\" class=\\\"Menu_menu__item__Ze9KX\\\"><a class=\\\"Menu_menuItem__lORev\\\" href=\\\"/blog\\\">Blog</a></li><li id=\\\"headedNavItem-11\\\" class=\\\"Menu_menu__item__Ze9KX\\\"><a class=\\\"Menu_menuItem__lORev\\\" href=\\\"/contacts\\\">Contacts</a></li><li id=\\\"headedNavItem-6\\\" class=\\\"Menu_menu__item__Ze9KX\\\"><button type=\\\"button\\\" class=\\\"Menu_menuItem__lORev Menu_linkless__XjyKx Menu_dropdownButton__AheqL\\\">Career<svg class=\\\"Menu_dropdownIcon__A4roo\\\"><use xlink:href=\\\"/media/angle_down.svg#angleDown\\\" href=\\\"/media/angle_down.svg#angleDown\\\"></use></svg><div class=\\\"DropdownMenu_dropdown__GymYD Menu_dropdown__GwiQD\\\"><a class=\\\"DropdownMenu_link__pgZ4G\\\" href=\\\"/career/vacancies\\\"><div class=\\\"DropdownMenu_link__icon__3DwsB\\\"><img alt=\\\"Vacancies\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent\\\" src=\\\"https://sapientpro.fra1.digitaloceanspaces.com/cbe572143c839c95f74007a19671ca97.svg\\\"/></div>Vacancies</a><a class=\\\"DropdownMenu_link__pgZ4G\\\" href=\\\"/career/education\\\"><div class=\\\"DropdownMenu_link__icon__3DwsB\\\"><img alt=\\\"Education\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent\\\" src=\\\"https://sapientpro.fra1.digitaloceanspaces.com/dc1c85ce7203d624f1d0a60608b306f1.svg\\\"/></div>Education</a></div></button></li></ul></nav><button type=\\\"button\\\" aria-label=\\\"search\\\" class=\\\"Header_searchButton__tLL_S\\\" name=\\\"Search\\\"><svg><use xlink:href=\\\"/media/search.svg#searchSVG\\\" href=\\\"/media/search.svg#searchSVG\\\"></use></svg></button><button type=\\\"button\\\" class=\\\"ThemeToggle_toggle__KXKLn\\\"><div class=\\\"ThemeToggle_circle__gfBDv\\\"><img alt=\\\"particles\\\" loading=\\\"lazy\\\" width=\\\"16\\\" height=\\\"16\\\" decoding=\\\"async\\\" data-nimg=\\\"1\\\" class=\\\"ThemeToggle_particles__uQsJU\\\" style=\\\"color:transparent\\\" srcSet=\\\"/_next/image?url=%2Fmedia%2FthemeToggle%2FthemeParticles-dark.webp&amp;w=16&amp;q=75 1x, /_next/image?url=%2Fmedia%2FthemeToggle%2FthemeParticles-dark.webp&amp;w=32&amp;q=75 2x\\\" src=\\\"/_next/image?url=%2Fmedia%2FthemeToggle%2FthemeParticles-dark.webp&amp;w=32&amp;q=75\\\"/><img alt=\\\"shadow\\\" loading=\\\"lazy\\\" width=\\\"16\\\" height=\\\"16\\\" decoding=\\\"async\\\" data-nimg=\\\"1\\\" class=\\\"ThemeToggle_particles__shadow__Ap5A2\\\" style=\\\"color:transparent\\\" src=\\\"/media/themeToggle/themeShadow-dark.svg\\\"/></div></button></div><button aria-label=\\\"Toggle menu\\\" type=\\\"button\\\" class=\\\"Header_menuButton__0azx_\\\"><div class=\\\"Header_menuButton__line__x3Q44\\\"></div><div class=\\\"Header_menuButton__line__x3Q44\\\"></div></button></header><main class=\\\"Article_article__Njabh\\\"><section class=\\\"Article_hero__X7BaQ\\\"><div class=\\\"container\\\"><div class=\\\"ArticleBreadcrumbs_breadcrumbs__1jiWc\\\"><a class=\\\"ArticleBreadcrumbs_breadcrumb__hwLTB\\\" href=\\\"/blog\\\">Blog</a><svg class=\\\"ArticleBreadcrumbs_arrowIcon__Y2Cea\\\"><use href=\\\"/media/angle_down.svg#angleDown\\\" xlink:href=\\\"/media/angle_down.svg#angleDown\\\"></use></svg><a class=\\\"ArticleBreadcrumbs_breadcrumb__hwLTB\\\" href=\\\"/blog/category/reviews\\\">Techs‚Äô reviews</a><svg class=\\\"ArticleBreadcrumbs_arrowIcon__Y2Cea\\\"><use href=\\\"/media/angle_down.svg#angleDown\\\" xlink:href=\\\"/media/angle_down.svg#angleDown\\\"></use></svg><a class=\\\"ArticleBreadcrumbs_breadcrumb__hwLTB ArticleBreadcrumbs_active__YMqNN\\\" href=\\\"/blog/named-entity-recognition-implementation-tips\\\">Named Entity Recognition: Mechanism, Methods, Use Cases, and Implementation Tips</a><svg class=\\\"ArticleBreadcrumbs_arrowIcon__Y2Cea\\\"><use href=\\\"/media/angle_down.svg#angleDown\\\" xlink:href=\\\"/media/angle_down.svg#angleDown\\\"></use></svg></div><div class=\\\"Article_titleBlock__kvIpz\\\"><h1 class=\\\"Article_title__VtXM_\\\"><a type=\\\"button\\\" class=\\\"Button_button__nbDXA Article_titleButton__6F_vg Button_outlined__mOu3b Button_withIcon__JksZi Button_withIcon_left__zz_uA\\\" href=\\\"/blog\\\">All<div class=\\\"Button_icon__BGcBT\\\" style=\\\"width:24px;height:24px\\\"><svg><use xlink:href=\\\"/media/arrow-left-bold.svg#arrowLeft\\\" href=\\\"/media/arrow-left-bold.svg#arrowLeft\\\"></use></svg></div></a> <span>Named Entity Recognition: Mechanism, Methods, Use Cases, and Implementation Tips</span></h1></div><div class=\\\"Article_articleDetails__Tjv1Q\\\"><p class=\\\"Article_articleInfo__N5Aar\\\"><span class=\\\"Article_articleInfo__updated__3Jpb8\\\">Updated:</span><span class=\\\"Article_articleInfo__date__ul54n\\\">April 28, 2025</span><span>15 min read</span></p><div class=\\\"Article_authorBlock__ipWmC\\\"><div class=\\\"AuthorCard_author__6xxtE\\\"><a class=\\\"AuthorCard_author__avatar__nH9od\\\" style=\\\"width:48px;height:48px\\\" href=\\\"/blog/author/Max\\\"><img alt=\\\"Max Tatarchenko\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent;background-size:cover;background-position:50% 50%;background-repeat:no-repeat;background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns=&#x27;http://www.w3.org/2000/svg&#x27; %3E%3Cfilter id=&#x27;b&#x27; color-interpolation-filters=&#x27;sRGB&#x27;%3E%3CfeGaussianBlur stdDeviation=&#x27;20&#x27;/%3E%3CfeColorMatrix values=&#x27;1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 100 -1&#x27; result=&#x27;s&#x27;/%3E%3CfeFlood x=&#x27;0&#x27; y=&#x27;0&#x27; width=&#x27;100%25&#x27; height=&#x27;100%25&#x27;/%3E%3CfeComposite operator=&#x27;out&#x27; in=&#x27;s&#x27;/%3E%3CfeComposite in2=&#x27;SourceGraphic&#x27;/%3E%3CfeGaussianBlur stdDeviation=&#x27;20&#x27;/%3E%3C/filter%3E%3Cimage width=&#x27;100%25&#x27; height=&#x27;100%25&#x27; x=&#x27;0&#x27; y=&#x27;0&#x27; preserveAspectRatio=&#x27;none&#x27; style=&#x27;filter: url(%23b);&#x27; href=&#x27;data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEASABIAAD/2wBDAAUDBAQEAwUEBAQFBQUGBwwIBwcHBw8LCwkMEQ8SEhEPERETFhwXExQaFRERGCEYGh0dHx8fExciJCIeJBweHx7/2wBDAQUFBQcGBw4ICA4eFBEUHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh7/wAARCAAKAAoDAREAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAABgQH/8QAIBAAAgIBAwUAAAAAAAAAAAAAAQIDEQASEyEEFEFhof/EABYBAQEBAAAAAAAAAAAAAAAAAAIBA//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oADAMBAAIRAxEAPwDXJJITFvqSgdLbULqvPzLUg5LKjSue2ha2JsR8HFUVxs2vp11GtscXmZDk7MJ5ACQAxoX7xC//2Q==&#x27;/%3E%3C/svg%3E&quot;)\\\" sizes=\\\"100vw\\\" srcSet=\\\"/_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2Fimage_29_1fa9833b8d.webp&amp;w=640&amp;q=75 640w, /_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2Fimage_29_1fa9833b8d.webp&amp;w=750&amp;q=75 750w, /_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2Fimage_29_1fa9833b8d.webp&amp;w=828&amp;q=75 828w, /_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2Fimage_29_1fa9833b8d.webp&amp;w=1080&amp;q=75 1080w, /_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2Fimage_29_1fa9833b8d.webp&amp;w=1200&amp;q=75 1200w, /_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2Fimage_29_1fa9833b8d.webp&amp;w=1920&amp;q=75 1920w, /_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2Fimage_29_1fa9833b8d.webp&amp;w=2048&amp;q=75 2048w, /_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2Fimage_29_1fa9833b8d.webp&amp;w=3840&amp;q=75 3840w\\\" src=\\\"/_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2Fimage_29_1fa9833b8d.webp&amp;w=3840&amp;q=75\\\"/></a><div class=\\\"AuthorCard_author__content__p18vL\\\"><a class=\\\"AuthorCard_author__name__6f1Iq\\\" href=\\\"/blog/author/Max\\\">Max Tatarchenko</a><p class=\\\"AuthorCard_author__info__Sb3ke\\\">CTO</p></div></div></div></div><div class=\\\"Article_firstEllipse__Z1OxB\\\"></div><div class=\\\"Article_secondEllipse__0bCgJ\\\"></div></div></section><div class=\\\"container\\\"><section class=\\\"Article_main__v_hZi\\\"><aside class=\\\"Article_aside__1zKJ2\\\"><div class=\\\"Article_asideSticky__SjNnf\\\"><nav class=\\\"Article_articleMenuWrapper__72zxu\\\"><div class=\\\"Article_articleMenu__03hi8\\\"><button type=\\\"button\\\" class=\\\"Article_articleAnchor__1HoGo\\\"><span class=\\\"Article_sectionNumber__PX9Wo\\\">1</span><p>Intro</p></button><button type=\\\"button\\\" class=\\\"Article_articleAnchor__1HoGo\\\"><span class=\\\"Article_sectionNumber__PX9Wo\\\">2</span><p>What Is Named Entity Recognition?</p></button><button type=\\\"button\\\" class=\\\"Article_articleAnchor__1HoGo\\\"><span class=\\\"Article_sectionNumber__PX9Wo\\\">3</span><p>NER Benefits &amp; Challenges?</p></button><button type=\\\"button\\\" class=\\\"Article_articleAnchor__1HoGo\\\"><span class=\\\"Article_sectionNumber__PX9Wo\\\">4</span><p>How Named-entity Recognition Works?</p></button><button type=\\\"button\\\" class=\\\"Article_articleAnchor__1HoGo\\\"><span class=\\\"Article_sectionNumber__PX9Wo\\\">5</span><p>Named Entity Recognition Techniques</p></button><button type=\\\"button\\\" class=\\\"Article_articleAnchor__1HoGo\\\"><span class=\\\"Article_sectionNumber__PX9Wo\\\">6</span><p>NER Methodologies</p></button><button type=\\\"button\\\" class=\\\"Article_articleAnchor__1HoGo\\\"><span class=\\\"Article_sectionNumber__PX9Wo\\\">7</span><p>Use Cases for Named Entity Recognition</p></button><button type=\\\"button\\\" class=\\\"Article_articleAnchor__1HoGo\\\"><span class=\\\"Article_sectionNumber__PX9Wo\\\">8</span><p>NER Examples</p></button><button type=\\\"button\\\" class=\\\"Article_articleAnchor__1HoGo\\\"><span class=\\\"Article_sectionNumber__PX9Wo\\\">9</span><p>How to Implement Named Entity Recognition </p></button><button type=\\\"button\\\" class=\\\"Article_articleAnchor__1HoGo\\\"><span class=\\\"Article_sectionNumber__PX9Wo\\\">10</span><p>Recent Trends in Named Entity Recognition (NER) and Its Future</p></button><button type=\\\"button\\\" class=\\\"Article_articleAnchor__1HoGo\\\"><span class=\\\"Article_sectionNumber__PX9Wo\\\">11</span><p>Summary</p></button></div></nav><div class=\\\"Article_socialBar__JZfBi\\\"><p class=\\\"Article_socialBar__title__ohqqE\\\">Share this article</p><div class=\\\"Article_socialBar__content__BL8wn\\\"><a href=\\\"https://twitter.com/intent/tweet?url=https://sapient.pro/blog/named-entity-recognition-implementation-tips&amp;mini=true&amp;text=Named Entity Recognition: Mechanism, Methods, Use Cases, and Implementation Tips\\\" class=\\\"Article_social__tk25G\\\" target=\\\"_blank\\\" aria-label=\\\"Twitter\\\" rel=\\\"noreferrer\\\"><svg><use xlink:href=\\\"/media/socials/twitter.svg#twitterSVG\\\" href=\\\"/media/socials/twitter.svg#twitterSVG\\\"></use></svg></a><a href=\\\"https://www.linkedin.com/shareArticle?url=https://sapient.pro/blog/named-entity-recognition-implementation-tips&amp;mini=true\\\" class=\\\"Article_social__tk25G\\\" target=\\\"_blank\\\" aria-label=\\\"LinkedIn\\\" rel=\\\"noreferrer\\\"><svg><use xlink:href=\\\"/media/socials/linkedin.svg#linkedinSVG\\\" href=\\\"/media/socials/linkedin.svg#linkedinSVG\\\"></use></svg></a><a href=\\\"https://telegram.me/share/https://sapient.pro?url=https://sapient.pro/blog/named-entity-recognition-implementation-tips&amp;text=Named Entity Recognition: Mechanism, Methods, Use Cases, and Implementation Tips\\\" class=\\\"Article_social__tk25G\\\" target=\\\"_blank\\\" aria-label=\\\"Telegram\\\" rel=\\\"noreferrer\\\"><svg><use xlink:href=\\\"/media/socials/telegram.svg#telegramSVG\\\" href=\\\"/media/socials/telegram.svg#telegramSVG\\\"></use></svg></a><a href=\\\"https://www.facebook.com/sharer/sharer.php?u=https://sapient.pro/blog/named-entity-recognition-implementation-tips&amp;quote=Named Entity Recognition: Mechanism, Methods, Use Cases, and Implementation Tips\\\" class=\\\"Article_social__tk25G\\\" target=\\\"_blank\\\" aria-label=\\\"Facebook\\\" rel=\\\"noreferrer\\\"><svg><use xlink:href=\\\"/media/socials/facebook.svg#facebookSVG\\\" href=\\\"/media/socials/facebook.svg#facebookSVG\\\"></use></svg></a></div></div></div></aside><div class=\\\"Article_mainContent__eMCzN\\\"><div class=\\\"Article_articleContent__yMQdW\\\"><div class=\\\"Article_contentStyles__FOoh1 Article_contentStyles__withoutPaddingTopForFirstH2__LejJ1\\\"><p>Businesses are all about automation now, using chatbots and voice assistants to do tasks that previously required people. Machine learning and natural language processing (NLP) have become essential. For example,¬†<a href=\\\"https://technologymagazine.com/top10/top-10-companies-advancing-natural-language-processing\\\" target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\">Google Cloud&#x27;s NLP platform</a> uses Google machine learning to help users understand and gain insights from unstructured texts.¬†</p><p>According to a<a href=\\\"https://www.marketsandmarkets.com/Market-Reports/natural-language-processing-nlp-825.html\\\" target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\">¬†MarketsandMarkets</a>¬†report, the NLP market is expected to reach $68.1 billion by 2028, with¬†Named Entity Recognition (NER) being a key driver of this growth. Since about<a href=\\\"https://mitsloan.mit.edu/ideas-made-to-matter/tapping-power-unstructured-data\\\" target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\">¬†80‚Äì90%</a>¬†of all data is unorganized, tools like NER are necessary for finding meaningful information.</p></div><div class=\\\"Article_contentStyles__FOoh1\\\" data-id=\\\"1798\\\"><h2>Intro</h2><div class=\\\"\\\"><p>NER is popular because it can automatically find and categorize key information from large pieces of text. This allows organizations to easily extract needed data from customer interactions, financial reports, legal contracts, social media, etc.</p><p>This guide provides all the information about Named Entity Recognition. You'll learn how NER works, what&nbsp;named entity recognition custom entities are, discover its use cases, and learn&nbsp;how to build named entity recognition model.</p></div></div><div class=\\\"Article_contentStyles__FOoh1\\\" data-id=\\\"1799\\\"><h2>What Is Named Entity Recognition?</h2><div class=\\\"\\\"><p>Named entity recognition means&nbsp;a technique in natural language processing used to recognize specific types of entities in a text, like names, places, dates, and organizations.&nbsp;Named entity recognition history began in 1996. NER mostly used rule-based methods and ontologies at that time. By 2007, NER models started to adopt machine learning to engineer features.&nbsp;</p><p>&nbsp;</p><p>Implementation of deep learning has greatly improved NER. Deep learning&nbsp;models for named entity recognition&nbsp;are more flexible and can manage different domains and new data by using characters, sub-words, and word embeddings.</p><p>&nbsp;</p><p>Machines can process large amounts of text and extract key information in organized&nbsp;named entity recognition categories. By identifying specific entities within the text, NER changes how we manage and use written information.</p></div><figure class=\\\"Article_imageBlock__JlKMT\\\"><div class=\\\"Article_image__QmZ2p\\\"><img alt=\\\"NER on New York Times Dataset\\\" loading=\\\"lazy\\\" width=\\\"1296\\\" height=\\\"1394\\\" decoding=\\\"async\\\" data-nimg=\\\"1\\\" style=\\\"color:transparent;background-size:cover;background-position:50% 50%;background-repeat:no-repeat;background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns=&#x27;http://www.w3.org/2000/svg&#x27; viewBox=&#x27;0 0 1296 1394&#x27;%3E%3Cfilter id=&#x27;b&#x27; color-interpolation-filters=&#x27;sRGB&#x27;%3E%3CfeGaussianBlur stdDeviation=&#x27;20&#x27;/%3E%3CfeColorMatrix values=&#x27;1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 100 -1&#x27; result=&#x27;s&#x27;/%3E%3CfeFlood x=&#x27;0&#x27; y=&#x27;0&#x27; width=&#x27;100%25&#x27; height=&#x27;100%25&#x27;/%3E%3CfeComposite operator=&#x27;out&#x27; in=&#x27;s&#x27;/%3E%3CfeComposite in2=&#x27;SourceGraphic&#x27;/%3E%3CfeGaussianBlur stdDeviation=&#x27;20&#x27;/%3E%3C/filter%3E%3Cimage width=&#x27;100%25&#x27; height=&#x27;100%25&#x27; x=&#x27;0&#x27; y=&#x27;0&#x27; preserveAspectRatio=&#x27;none&#x27; style=&#x27;filter: url(%23b);&#x27; href=&#x27;data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEASABIAAD/2wBDAAUDBAQEAwUEBAQFBQUGBwwIBwcHBw8LCwkMEQ8SEhEPERETFhwXExQaFRERGCEYGh0dHx8fExciJCIeJBweHx7/2wBDAQUFBQcGBw4ICA4eFBEUHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh7/wAARCAAKAAoDAREAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAABgQH/8QAIBAAAgIBAwUAAAAAAAAAAAAAAQIDEQASEyEEFEFhof/EABYBAQEBAAAAAAAAAAAAAAAAAAIBA//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oADAMBAAIRAxEAPwDXJJITFvqSgdLbULqvPzLUg5LKjSue2ha2JsR8HFUVxs2vp11GtscXmZDk7MJ5ACQAxoX7xC//2Q==&#x27;/%3E%3C/svg%3E&quot;)\\\" srcSet=\\\"/_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2FDark_1_727de2f7a4.webp&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2FDark_1_727de2f7a4.webp&amp;w=3840&amp;q=75 2x\\\" src=\\\"/_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2FDark_1_727de2f7a4.webp&amp;w=3840&amp;q=75\\\"/></div><figcaption>NER on New York Times Dataset</figcaption></figure></div><div class=\\\"Article_contentStyles__FOoh1\\\" data-id=\\\"1800\\\"><h2>NER Benefits &amp; Challenges?</h2><div class=\\\"\\\"><p>Named entity recognition has several great benefits, but also some limitations. We‚Äôll explain both to you.</p><h3>Advantages of Using NER</h3><p>The main advantage of NER is that it helps us find important details in large amounts of textual data, like articles, social media posts, websites, and research papers. Let‚Äôs check out some more benefits of NER:</p><ul><li><strong>Enhanced user experience</strong>: NER improves customer experience by providing better search results and personalized recommendations.</li><li><strong>Simple analysis of data and trends</strong>: NER makes it easier to analyze data to identify tendencies.&nbsp;&nbsp;</li><li><strong>Automated workflows</strong>:&nbsp;NER automates processes, which helps save our time and resources.</li></ul><h3>Any Limitations of NER?</h3><p>Now let's look at some&nbsp;named entity recognition challenges:</p><ul><li><strong>Context misunderstanding</strong>:&nbsp;algorithms often struggle to understand context because words get meaning from the surrounding text. For example, the word \\\"Bat\\\" can mean a flying animal or a baseball tool (depending on the context).</li><li><strong>Language variation</strong>:&nbsp;human language includes slang, dialects, and regional differences, which can make it harder to understand words that are common in one place but not in another.</li><li><strong>Data sparsity</strong>: machine learning models need a lot of labeled data to identify entities. This can be difficult to find, especially for rare languages or specialized areas.</li></ul></div></div><div class=\\\"Article_contentStyles__FOoh1\\\" data-id=\\\"1801\\\"><h2>How Named-entity Recognition Works?</h2><div class=\\\"\\\"><p>Named&nbsp;Entity Recognition&nbsp;<a href=\\\"https://sapient.pro/natural-language-processing-services\\\" target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\">NLP&nbsp;</a>uses unique algorithms with grammar rules and statistical models to find and tag names in text. It identifies categories like people, locations, dates, percentages,&nbsp; organizations, and currency amounts. These categories often use abbreviations, such as LOC for location, PER for person, and ORG for organization.</p><p>Once the&nbsp;named entity recognition best model&nbsp;can work with labeled text data, it automatically analyzes new text, identifies named entities, and sorts them into categories.&nbsp;</p><p>After identifying the information, a tool collects details about these entities and creates a machine-readable document. Other tools can then use this document to extract additional information.</p></div><figure class=\\\"Article_imageBlock__JlKMT\\\"><div class=\\\"Article_image__QmZ2p\\\"><img alt=\\\"article image\\\" loading=\\\"lazy\\\" width=\\\"1296\\\" height=\\\"1216\\\" decoding=\\\"async\\\" data-nimg=\\\"1\\\" style=\\\"color:transparent;background-size:cover;background-position:50% 50%;background-repeat:no-repeat;background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns=&#x27;http://www.w3.org/2000/svg&#x27; viewBox=&#x27;0 0 1296 1216&#x27;%3E%3Cfilter id=&#x27;b&#x27; color-interpolation-filters=&#x27;sRGB&#x27;%3E%3CfeGaussianBlur stdDeviation=&#x27;20&#x27;/%3E%3CfeColorMatrix values=&#x27;1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 100 -1&#x27; result=&#x27;s&#x27;/%3E%3CfeFlood x=&#x27;0&#x27; y=&#x27;0&#x27; width=&#x27;100%25&#x27; height=&#x27;100%25&#x27;/%3E%3CfeComposite operator=&#x27;out&#x27; in=&#x27;s&#x27;/%3E%3CfeComposite in2=&#x27;SourceGraphic&#x27;/%3E%3CfeGaussianBlur stdDeviation=&#x27;20&#x27;/%3E%3C/filter%3E%3Cimage width=&#x27;100%25&#x27; height=&#x27;100%25&#x27; x=&#x27;0&#x27; y=&#x27;0&#x27; preserveAspectRatio=&#x27;none&#x27; style=&#x27;filter: url(%23b);&#x27; href=&#x27;data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEASABIAAD/2wBDAAUDBAQEAwUEBAQFBQUGBwwIBwcHBw8LCwkMEQ8SEhEPERETFhwXExQaFRERGCEYGh0dHx8fExciJCIeJBweHx7/2wBDAQUFBQcGBw4ICA4eFBEUHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh7/wAARCAAKAAoDAREAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAABgQH/8QAIBAAAgIBAwUAAAAAAAAAAAAAAQIDEQASEyEEFEFhof/EABYBAQEBAAAAAAAAAAAAAAAAAAIBA//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oADAMBAAIRAxEAPwDXJJITFvqSgdLbULqvPzLUg5LKjSue2ha2JsR8HFUVxs2vp11GtscXmZDk7MJ5ACQAxoX7xC//2Q==&#x27;/%3E%3C/svg%3E&quot;)\\\" srcSet=\\\"/_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2FDark_2_ba6b1ca0e0.webp&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2FDark_2_ba6b1ca0e0.webp&amp;w=3840&amp;q=75 2x\\\" src=\\\"/_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2FDark_2_ba6b1ca0e0.webp&amp;w=3840&amp;q=75\\\"/></div></figure></div><div class=\\\"Article_contentStyles__FOoh1\\\" data-id=\\\"1802\\\"><h2>Named Entity Recognition Techniques</h2><div class=\\\"\\\"><p>To develop the best model for named entity recognition, the text must go through various steps like tokenization and tagging. In tagging, each word in a sentence is labeled with tags like ‚ÄúPerson‚Äù or ‚ÄúLocation‚Äù.&nbsp; We‚Äôll explain what techniques NER uses:&nbsp;</p><h3>IO Tagging</h3><p>In this simple tagging method, each word in a sentence is tagged as ‚Äúinside‚Äù (I) if it's part of an entity or ‚Äúoutside‚Äù (O) if it's not.</p><p>In the sentence ‚ÄúSara is going to London,‚Äù the words ‚ÄúSara‚Äù and ‚ÄúLondon‚Äù are tagged as entities (I tag), while the words \\\"is,\\\" \\\"going,\\\" and \\\"to\\\" are not entities (O tag).</p><p>This method has limitations, especially with tagging consecutive entities of the same type.</p><h3>BIO / IOB Tagging</h3><p>IOB is a widely used tagging method. This system labels each word to show if it is at the beginning (B) of a named entity, inside (I) of a named entity, or outside (O) of any named entity.</p><p>In the sentence ‚ÄúSara is going to London,‚Äù ‚ÄúSara‚Äù is marked as ‚ÄúB-PER‚Äù to show it's the start of a person's name, while ‚ÄúLondon‚Äù is tagged as ‚ÄúI-LOC‚Äù because it's a place.</p><h3>IOE Tagging</h3><p>This approach is similar to IOB, but it uses an&nbsp;E tag&nbsp;to mark the end of an entity instead of the beginning.</p><h3>BILOU Tagging</h3><p>BILOU is a more detailed version of the BIO labeling system that detects entities. It includes two extra labels, Last (L) and Unit (U), to improve&nbsp;ner metrics accuracy, especially with longer entities.</p><p>In a sentence like ‚ÄúSteve Jobs was born in San Francisco,‚Äù BILOU tagging would be: Steve ‚Äî&nbsp;&nbsp;B-PER (beginning of a Person entity), Jobs ‚Äî&nbsp;&nbsp;L-PER (last token of a Person entity), was ‚Äî&nbsp;&nbsp;O (outside any named entity), born ‚Äî&nbsp;&nbsp;O, in ‚Äî&nbsp;&nbsp;O, San Francisco ‚Äî&nbsp;&nbsp;U-LOC (Location).</p><h3>Conditional Random Fields (CRFs)</h3><p>CRFs are statistical tools that help make structured predictions. They consider the context and relationships between nearby tokens. CRFs are quite practical for custom named entity recognition, which involve labeling sequences.</p><p>In the sentence ‚ÄúSamsung announced the new Galaxy Buds in California,‚Äù Samsung is marked as an organization (B-ORG), Galaxy Buds as a product (B-PROD), and California as a location (B-LOC). CRFs use the context and relationships between words to identify these distinctions.</p></div></div><div class=\\\"Article_contentStyles__FOoh1\\\" data-id=\\\"1803\\\"><h2>NER Methodologies</h2><div class=\\\"\\\"><p>Named entity recognition data augmentation uses different methodologies to help identify and classify names and other specific entities in large texts. Let's see what they are.</p><h3>Named Entity Recognition Methods Based on Rules</h3><p>Rule-based methods often use linguistic patterns, expressions, or dictionaries. They are effective in tasks like extracting standard medical terms from clinical notes. Yet, rule-based techniques can't handle a large&nbsp;named entity recognition dataset because they follow fixed rules.</p><h3>Statistical Methods</h3><p>Statistical methods, like&nbsp; Conditional Random Fields (CRF) and Hidden Markov Models (HMM), use probabilities learned from training data to indicate named entities. These methods work well with lots of labeled data because they can adapt to different types of text.&nbsp;</p><h3>Machine Learning Methods&nbsp;</h3><p><a href=\\\"https://sapient.pro/blog/best-programming-languages-for-machine-learning\\\">Machine learning techniques&nbsp;</a>use algorithms like support vector machines and decision trees to learn from labeled data and predict specific named entities. These techniques help run large datasets and complex patterns.&nbsp;</p><h3>Deep Learning Methods</h3><p>Deep learning methods are the latest development that uses neural networks. Techniques like Recurrent Neural Networks (RNNs) and transformers are popular because they can handle long-term text patterns. These methods work great for big tasks with lots of training data, but they require a lot of computing power.</p><h3>Hybrid Methodologies</h3><p>No single method works for every situation in NER. So, this led to the development of hybrid methods. They use a mix of rules, stats, and machine learning to get the best of each. For example, rule-based methods can work with specific entities in a particular field, while machine learning or deep learning is better for identifying more general entities.</p></div></div><div class=\\\"Article_contentStyles__FOoh1\\\" data-id=\\\"1804\\\"><h2>Use Cases for Named Entity Recognition</h2><div class=\\\"\\\"><p>NER has changed how different businesses and industries operate by efficiently processing large datasets. Here are some key&nbsp;named entity recognition use cases.</p><h3>News Search</h3><p>News companies create online content daily. NER helps automatically identify the who, what, when, where, and why in news and other articles. It highlights key details and helps understand the context better.&nbsp;</p><p>If you're searching for information about a celebrity or a particular event, NER can categorize articles based on the entities they mention. For example, if you want to find news about Mark Zuckerberg, an NER-powered platform can suggest articles that mention ‚ÄúMark Zuckerberg‚Äù or ‚ÄúFacebook,‚Äù even if these terms aren't in the headlines.</p><h3>Chatbots</h3><p>Chatbots use NER to understand user questions. By identifying key information, like names or places, they can accurately respond. For example, if a person asks a chatbot to find a fast casual restaurant in the City Hall Park, NER helps the chatbot identify entities such as the type of food (fast casual), the type of place (restaurants), and the location (City Hall Park).</p><h3>Scientific research</h3><p>An online journal or publication platform hosts millions of research papers and academic articles. With possibly hundreds of papers on the same topic, organizing this information can be quite challenging. For example, with about 100,000 publications on Machine Learning, tagging them by key topics makes it easy to find articles on how two-layer neural networks learn.</p><h3>Legal documentation</h3><p>Legal documents, especially contracts, provide important information about the parties and specifics like duration and scope. Tracking these details is a must to manage contracts and avoid accidental renewals. NER automatically finds key details like names and dates in long documents.</p><h3>Pharmaceuticals and healthcare</h3><p>The healthcare system has about<a href=\\\"https://pmc.ncbi.nlm.nih.gov/articles/PMC6372467/#:~:text=The%20big%20problem%20of%20healthcare,image%2C%20signal%2C%20etc.)\\\" target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\"> 80% of unstructured medical data.&nbsp;</a>NER helps identify and organize medical information like treatments, drugs, diseases, tests, and medication names in different documents. For example, tagging promotional materials makes it easier for medical representatives to find and share the most relevant information with healthcare professionals.</p><h3>Cybersecurity</h3><p>NER helps companies detect potential threats in network logs and other security data. The tool detects suspicious URLs, IP addresses, filenames, and usernames. This makes the network more secure and helps with safety investigations.</p><h3>Finance</h3><p>In finance, NER helps identify trends and improve risk assessments. It not only manages financial data like loans and earnings reports, but also analyzes company mentions on social media. This also helps to track events that might affect stock prices.</p><h3>Social Media</h3><p>Businesses use NER in social media analysis because it helps them find mentions of their brands, products, or competitors in conversations. This information helps improve brand reputation and create more targeted marketing strategies.</p></div><figure class=\\\"Article_imageBlock__JlKMT\\\"><div class=\\\"Article_image__QmZ2p\\\"><img alt=\\\"article image\\\" loading=\\\"lazy\\\" width=\\\"1296\\\" height=\\\"1386\\\" decoding=\\\"async\\\" data-nimg=\\\"1\\\" style=\\\"color:transparent;background-size:cover;background-position:50% 50%;background-repeat:no-repeat;background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns=&#x27;http://www.w3.org/2000/svg&#x27; viewBox=&#x27;0 0 1296 1386&#x27;%3E%3Cfilter id=&#x27;b&#x27; color-interpolation-filters=&#x27;sRGB&#x27;%3E%3CfeGaussianBlur stdDeviation=&#x27;20&#x27;/%3E%3CfeColorMatrix values=&#x27;1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 100 -1&#x27; result=&#x27;s&#x27;/%3E%3CfeFlood x=&#x27;0&#x27; y=&#x27;0&#x27; width=&#x27;100%25&#x27; height=&#x27;100%25&#x27;/%3E%3CfeComposite operator=&#x27;out&#x27; in=&#x27;s&#x27;/%3E%3CfeComposite in2=&#x27;SourceGraphic&#x27;/%3E%3CfeGaussianBlur stdDeviation=&#x27;20&#x27;/%3E%3C/filter%3E%3Cimage width=&#x27;100%25&#x27; height=&#x27;100%25&#x27; x=&#x27;0&#x27; y=&#x27;0&#x27; preserveAspectRatio=&#x27;none&#x27; style=&#x27;filter: url(%23b);&#x27; href=&#x27;data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEASABIAAD/2wBDAAUDBAQEAwUEBAQFBQUGBwwIBwcHBw8LCwkMEQ8SEhEPERETFhwXExQaFRERGCEYGh0dHx8fExciJCIeJBweHx7/2wBDAQUFBQcGBw4ICA4eFBEUHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh7/wAARCAAKAAoDAREAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAABgQH/8QAIBAAAgIBAwUAAAAAAAAAAAAAAQIDEQASEyEEFEFhof/EABYBAQEBAAAAAAAAAAAAAAAAAAIBA//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oADAMBAAIRAxEAPwDXJJITFvqSgdLbULqvPzLUg5LKjSue2ha2JsR8HFUVxs2vp11GtscXmZDk7MJ5ACQAxoX7xC//2Q==&#x27;/%3E%3C/svg%3E&quot;)\\\" srcSet=\\\"/_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2FDark_3_bef01613af.webp&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2FDark_3_bef01613af.webp&amp;w=3840&amp;q=75 2x\\\" src=\\\"/_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2FDark_3_bef01613af.webp&amp;w=3840&amp;q=75\\\"/></div></figure></div><div class=\\\"Article_contentStyles__FOoh1\\\" data-id=\\\"1805\\\"><h2>NER Examples</h2><div class=\\\"\\\"><p>Named Entity Recognition lets systems understand the context of words. For example, it allows a search engine to know if ‚ÄúApple‚Äù means the company or the fruit, depending on the sentence.</p><p><a href=\\\"https://sapient.pro/ai-development-services\\\" target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\">AI-driven solutions&nbsp;</a>like chatbots and virtual assistants also use NER to specify key entities in user questions, like names, places, or dates. So they can give more precise answers.</p><p>To understand how NER works, let's look at an example where it identifies entities like people, organizations, locations, and dates in a text. Consider this passage:</p><p><strong>Martin Eberhard and Marc Tarpenning&nbsp;</strong><a href=\\\"https://www.forbes.com/sites/qai/2022/09/29/tesla-a-history-of-innovation-and-headaches/\\\" target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\"><strong>founded Tesla Motors</strong></a><strong> in July 2003, in San Carlos, California, U.S.</strong></p><p>With NER, we would identify these words:</p><ul><li><strong>Person</strong>: Martin Eberhard, Marc Tarpenning;</li><li><strong>Organization</strong>:&nbsp;Tesla Motors;</li><li><strong>Location</strong>: San Carlos, California;</li><li><strong>Date</strong>: July 1, 2003.</li></ul><p>NER identifies the specific entities that interest you. You define these named entity recognition types&nbsp;and then find the matching words in the text for each category.</p></div><figure class=\\\"Article_imageBlock__JlKMT\\\"><div class=\\\"Article_image__QmZ2p\\\"><img alt=\\\"article image\\\" loading=\\\"lazy\\\" width=\\\"1296\\\" height=\\\"360\\\" decoding=\\\"async\\\" data-nimg=\\\"1\\\" style=\\\"color:transparent;background-size:cover;background-position:50% 50%;background-repeat:no-repeat;background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns=&#x27;http://www.w3.org/2000/svg&#x27; viewBox=&#x27;0 0 1296 360&#x27;%3E%3Cfilter id=&#x27;b&#x27; color-interpolation-filters=&#x27;sRGB&#x27;%3E%3CfeGaussianBlur stdDeviation=&#x27;20&#x27;/%3E%3CfeColorMatrix values=&#x27;1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 100 -1&#x27; result=&#x27;s&#x27;/%3E%3CfeFlood x=&#x27;0&#x27; y=&#x27;0&#x27; width=&#x27;100%25&#x27; height=&#x27;100%25&#x27;/%3E%3CfeComposite operator=&#x27;out&#x27; in=&#x27;s&#x27;/%3E%3CfeComposite in2=&#x27;SourceGraphic&#x27;/%3E%3CfeGaussianBlur stdDeviation=&#x27;20&#x27;/%3E%3C/filter%3E%3Cimage width=&#x27;100%25&#x27; height=&#x27;100%25&#x27; x=&#x27;0&#x27; y=&#x27;0&#x27; preserveAspectRatio=&#x27;none&#x27; style=&#x27;filter: url(%23b);&#x27; href=&#x27;data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEASABIAAD/2wBDAAUDBAQEAwUEBAQFBQUGBwwIBwcHBw8LCwkMEQ8SEhEPERETFhwXExQaFRERGCEYGh0dHx8fExciJCIeJBweHx7/2wBDAQUFBQcGBw4ICA4eFBEUHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh7/wAARCAAKAAoDAREAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAABgQH/8QAIBAAAgIBAwUAAAAAAAAAAAAAAQIDEQASEyEEFEFhof/EABYBAQEBAAAAAAAAAAAAAAAAAAIBA//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oADAMBAAIRAxEAPwDXJJITFvqSgdLbULqvPzLUg5LKjSue2ha2JsR8HFUVxs2vp11GtscXmZDk7MJ5ACQAxoX7xC//2Q==&#x27;/%3E%3C/svg%3E&quot;)\\\" srcSet=\\\"/_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2FDark_4_6aa3963993.webp&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2FDark_4_6aa3963993.webp&amp;w=3840&amp;q=75 2x\\\" src=\\\"/_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2FDark_4_6aa3963993.webp&amp;w=3840&amp;q=75\\\"/></div></figure></div><div class=\\\"Article_contentStyles__FOoh1\\\" data-id=\\\"1806\\\"><h2>How to Implement Named Entity Recognition </h2><div class=\\\"\\\"><p>Implementing NER involves 8 key steps. Let's go through them so you can better understand how the process works.</p><h3>Step #1: Setting Goals</h3><p>Decide which entities to recognize, like people and places, and how you'll use NER, such as for extracting information.</p><h3>Step #2: Data preparation</h3><p>Start by collecting the data with the entities you need. Use tools like SpaCy Prodigy or datasets like CoNLL-03 to tag them. Next, clean and preprocess the data to fix any issues with punctuation or special characters.</p><h3>Step #3: Deciding on Approach</h3><p>Choose from different methods like:</p><ul><li>Rule-based approaches that use set rules for certain tasks;</li><li>Machine Learning techniques, such as Conditional Random Fields (CRFs);</li><li>Deep learning tools.</li></ul><h3>Step #4: Building the Model</h3><p>Pick a library like SpaCy or Transformers. You can train a model from the beginning or adjust an existing one for your special needs.</p><h3>Step #5: Model Assessment</h3><p>Measure how well your model performs using metrics like precision, recall, and F1 score. Also, test it on various datasets to ensure it works properly with new data.</p><h3>Step #6: Deployment and Integration</h3><p>Integrate the NER model into your application and make sure it works with other tools and processes.</p><h3>Step #7: Maintenance</h3><p>Regularly check the model performance in real-world situations and update it as needed.</p><h3>Step #8: Solving Challenges</h3><p>In this last phase, manage any uncertainties and differences in identifying entities. You can adjust the model to fit the language and requirements of your field.</p><p>&nbsp;</p><p>Using an&nbsp;<a href=\\\"https://www.ibm.com/topics/api\\\" target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\">API&nbsp;</a>can make it much easier to set up&nbsp;named entity recognition software. These APIs are available online or as local tools that offer NER features. For example,&nbsp;Stanford Named Entity Recognizer is a popular Java tool used for extracting entities. It uses Conditional Random Fields (CRF) and comes with a pre-trained&nbsp;named entity recognition model&nbsp;to identify entities.</p><p>&nbsp;</p><p>If you‚Äôre interested in&nbsp;how to do named entity recognition in Python, the&nbsp;Natural Language Toolkit (NLTK) is a helpful open-source tool for processing human language data. It's easy to use and works with over 100 pre-trained&nbsp;large language models for named entity recognition. NLTK offers tools for tasks like named entity recognition classification, stemming, tokenization, parsing, tagging, and understanding meaning. It includes a named entity recognizer (`ne_chunk`) and can be used with the Stanford NER in Python.</p></div></div><div class=\\\"Article_contentStyles__FOoh1\\\" data-id=\\\"1807\\\"><h2>Recent Trends in Named Entity Recognition (NER) and Its Future</h2><div class=\\\"\\\"><p>Let's check out some predictions for the future of Named Entity Recognition (NER).</p><p>&nbsp;</p><p>First, experts believe pairing named entity recognition with knowledge graphs, large databases that show how different entities are connected, will improve its performance. This could make NER more precise and help discover new entities more easily.</p><p>&nbsp;</p><p>Next, named entity recognition could play a more significant role in voice assistants and chatbots, like ChatGPT. Recent stats show that&nbsp;<a href=\\\"https://cases.media/en/article/the-chatbot-market-in-2024-forecasts-and-latest-statistics\\\" target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\">67% of clients use chatbots</a> for customer support, while chatbots manage 64% of routine requests.&nbsp;</p><p>&nbsp;</p><p>As these technologies become more popular, it's important to identify specific parts of speech or text to understand what users want and give the right response. If a customer asks the chatbot, \\\"I lost my phone in London yesterday. Can you help me block my number?\\\" a NER system will identify a phone as a PRODUCT, London as a LOCATION, and yesterday as a DATE.&nbsp;</p><p>&nbsp;</p><p>A chatbot will be able to quickly share location services and temporarily block a customer's number. This will make support service faster and more efficient.</p><p>&nbsp;</p><p>Finally, as big data,&nbsp;<a href=\\\"https://sapient.pro/blog/how-to-build-ai-software\\\" target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\">artificial intelligence</a>, and the Internet of Things expand, companies will use named entity recognition for cybersecurity and fraud detection. NER can interpret large amounts of data to find potential threats, which helps protect people and companies from cyberattacks.&nbsp;</p><p>&nbsp;</p><p><a href=\\\"https://www.scitepress.org/Papers/2019/73142/73142.pdf\", \"source\": \"web\", \"published_date\": \"N/A\", \"score_bm25\": 0.0}, {\"paper_id\": \"2206.07318v1\", \"title\": \"CMNEROne at SemEval-2022 Task 11: Code-Mixed Named Entity Recognition by leveraging multilingual data\", \"authors\": [\"Suman Dowlagar\", \"Radhika Mamidi\"], \"abstract\": \"Identifying named entities is, in general, a practical and challenging task in the field of Natural Language Processing. Named Entity Recognition on the code-mixed text is further challenging due to the linguistic complexity resulting from the nature of the mixing. This paper addresses the submission of team CMNEROne to the SEMEVAL 2022 shared task 11 MultiCoNER. The Code-mixed NER task aimed to identify named entities on the code-mixed dataset. Our work consists of Named Entity Recognition (NER) on the code-mixed dataset by leveraging the multilingual data. We achieved a weighted average F1 score of 0.7044, i.e., 6% greater than the baseline.\", \"url\": \"http://arxiv.org/abs/2206.07318v1\", \"pdf_url\": \"https://arxiv.org/pdf/2206.07318v1\", \"source\": \"arxiv\", \"published_date\": \"2022-06-15T06:33:13Z\", \"score_bm25\": 0.0}, {\"paper_id\": null, \"title\": \"Named Entity Recognition: A Practical 2025 Guide | Label Your Data\", \"authors\": [], \"abstract\": \"<H1>Named Entity Recognition:\\nA Practical Guide</H1><OL><LI>TL;DR</LI><LI>What is NER?</LI><LI><OL><LI>Search Engines</LI><LI>Customer Support</LI><LI>Healthcare</LI><LI>Finance</LI><LI>News and Media</LI><LI>Human Resources</LI></OL></LI><LI><OL><LI>Standard Entities</LI><LI>Domain-Specific Entities</LI></OL></LI><LI><OL><LI>Rule-Based Systems</LI><LI>Dictionary-Based Systems</LI><LI>Machine Learning-Based NER</LI><LI>Deep Learning-Based NER</LI></OL></LI><LI><OL><LI>Ambiguity and Context Dependency</LI><LI>Handling Multilingual Texts</LI><LI>Detecting Rare or New Entities</LI><LI>Data Annotation Complexity</LI></OL></LI><LI><OL><LI>Key Steps in NER Data Annotation</LI><LI>Choosing the Right Annotation Tool</LI><LI>Managing Annotation Complexity</LI></OL></LI><LI><OL><LI>Focus on Data Quality</LI><LI>Handle Imbalanced Entity Classes</LI><LI>Incorporate Domain Knowledge</LI><LI>Evaluate and Fine-Tune Regularly</LI></OL></LI><LI><H3>Named Entity Recognition Tools and Libraries\\nOpen-Source Libraries for NER\\nCloud-Based NER Solutions</H3><OL><LI>Open-Source Libraries for NER</LI><LI>Cloud-Based NER Solutions</LI></OL></LI><LI><OL><LI>Few-Shot Learning</LI><LI>Multimodal NER</LI><LI>Integration with LLMs</LI><LI>Domain-Specific NER Models</LI><LI>Joint NER and Entity Linking</LI></OL></LI><LI>About Label Your Data</LI><LI><H3>FAQ\\nWhat are the three types of NER?\\nHow does an NER work?\\nWhat are the disadvantages of NER?\\nWhat is an example of named entity recognition text?</H3><OL><LI>What are the three types of NER?</LI><LI>How does an NER work?</LI><LI>What are the disadvantages of NER?</LI><LI>What is an example of named entity recognition text?</LI></OL></LI></OL><H2>TL;DR</H2><P>1 Named Entity Recognition (NER) finds and sorts key information like names, places, and dates in text.</P><P>2 It helps search engines, customer support, and healthcare by turning messy text into organized data.</P><P>3 A NER model includes rule-based systems, machine learning, and deep learning like BERT.</P><P>4 Challenges include dealing with tricky words, different languages, and inconsistent labeled data.</P><P>5 Future trends focus on learning from fewer examples, combining text with images, and using large language models (LLMs).</P><H3>Data Labeling Services</H3><H2>What is NER?</H2><P>Named Entity Recognition (NER) is a Natural Language Processing technique that picks out important information from text and puts it into categories like people, places, organizations, dates, and more.</P><P>It turns messy text into organized data that‚Äôs easy to understand and use.</P><P>NER helps answer questions like who, where, and when by finding key parts of text. For example, it can highlight names, dates, and places in a news article. This process is also called entity extraction or entity chunking and is used in search engines, chatbots, and text summaries.</P><P><H3>Here‚Äôs how it works:</H3></P><OL><LI>First, NER finds possible important words (like names or dates).</LI><LI>\", \"url\": \"https://labelyourdata.com/articles/data-annotation/named-entity-recognition\", \"pdf_url\": \"https://cta-eu1.hubspot.com/web-interactives/public/v1/track/redirect?encryptedPayload=AVxigLJqORkF%2BRvYYGuy6h9%2B8IxF3iPZDTaB95Qpgek5gvm7%2BLKlI9zadL5tiM%2FLwx3xblSlmcZG9XfKBEpqXpXUlTHhfP0HQI86PTKOOdj5YUjrbdbWs2AWGZderzN0M3Anr4VCOjqXV35KFFPTC%2FeJ%2Bq90xulOrb0muRVrpfZebcH3WmK6VbBiwageJmtLQErKsdu3duvUIvsDToWzbA%3D%3D&amp;webInteractiveContentId=182768045260&amp;portalId=143515705\\\" target=\\\"_blank\\\" class=\\\"button b-xl b-black-filled f13 mt-30\\\"> LEARN MORE </a></div><h2 class=\\\"h2\\\" id=\\\"what-is-ner\\\">What is NER?</h2><p class=\\\"f16 mt-20 mb0\\\">Named Entity Recognition (NER) is a <a href=\\\"https://labelyourdata.com/articles/natural-language-processing/techniques\\\">Natural Language Processing technique</a> that picks out important information from text and puts it into categories like people, places, organizations, dates, and more.</p><p class=\\\"f16 mt-20 mb0\\\">It turns messy text into organized data that&rsquo;s easy to understand and use.</p><p class=\\\"f16 mt-20 mb0\\\">NER helps answer questions like <i>who</i>, <i>where</i>, and <i>when</i> by finding key parts of text. For example, it can highlight names, dates, and places in a <a target=\\\"_blank\\\" rel=\\\"nofollow\\\" href=\\\"https://github.com/RiadBensalem/Real-Time-News-Article-Analysis-with-NER\\\">news article</a>. This process is also called entity extraction or entity chunking and is used in search engines, chatbots, and text summaries.</p><div class=\\\"mt-40\\\"><figure><div class=\\\"flex flex-stretch gallery-tile\\\"><div class=\\\"flex-1 img-tile\\\"><img src=\\\"/img/article-illustrations/named-entity-recognition_1.jpg\\\" class=\\\"dblock\\\" alt=\\\"Example of NER\\\"></div></div><figcaption class=\\\"mt-10 f12 cgrey\\\">Example of NER</figcaption></figure></div><p class=\\\"f16 mt-20 mb0\\\"><strong>Here&rsquo;s how it works:</strong></p><ol class=\\\"mt-10\\\"><li><p class=\\\"f16\\\">First, NER finds possible important words (like names or dates).</p></li><li><p class=\\\"f16\\\">Next, it sorts those words into categories.</p></li></ol><p class=\\\"f16 mt-20 mb0\\\">For example, in the sentence: <i>&ldquo;Tesla unveiled its latest model in California on January 1, 2025,&rdquo;</i></p><ul class=\\\"mt-10\\\"><li><p class=\\\"f16\\\"><strong>Tesla &rarr; </strong>Organization</p></li><li><p class=\\\"f16\\\"><strong>California &rarr; </strong>Location</p></li><li><p class=\\\"f16\\\"><strong>January 1, 2025 &rarr; </strong>Date</p></li></ul><p class=\\\"f16 mt-20 mb0\\\">Modern named entity recognition models uses a <a href=\\\"https://labelyourdata.com/articles/how-to-choose-a-machine-learning-algorithm\\\">machine learning algorithm</a> and deep learning to improve over time. These models learn from data and get better at recognizing entities.</p><p class=\\\"f16 mt-20 mb0\\\">NER is useful because it saves time, improves search accuracy, and helps organize large amounts of text. Businesses use it to process reports, answer customer questions faster, and make better decisions with data.</p><h2 class=\\\"h2\\\" id=\\\"common-applications-of-named-entity-recognition\\\">Common Applications of Named Entity Recognition</h2><div class=\\\"mt-40\\\"><figure><div class=\\\"flex flex-stretch gallery-tile\\\"><div class=\\\"flex-1 img-tile\\\"><img src=\\\"/img/article-illustrations/named-entity-recognition_2.jpg\\\" class=\\\"dblock\\\" alt=\\\"Named entity recognition workflow\\\"></div></div><figcaption class=\\\"mt-10 f12 cgrey\\\">Named entity recognition workflow</figcaption></figure></div><p class=\\\"f16 mt-20 mb0\\\">Named Entity Recognition (NER) is used in many industries to make sense of large amounts of text. It helps businesses, researchers, and organizations organize and analyze text faster.</p><p class=\\\"f16 mt-20 mb0\\\">Now that you know what is named entity recognition, here are some of its most common applications:</p><h3 class=\\\"h3 mt-40 mb0\\\" id=\\\"search-engines\\\">Search Engines</h3><p class=\\\"f16 mt-20 mb0\\\">NER improves search accuracy by identifying names, places, and dates in search queries. This makes it easier for users to find the right information.</p><h3 class=\\\"h3 mt-40 mb0\\\" id=\\\"customer-support\\\">Customer Support</h3><p class=\\\"f16 mt-20 mb0\\\">Companies use NER to sort customer questions and complaints. This helps support teams respond faster by sending requests to the right department.</p><h3 class=\\\"h3 mt-40 mb0\\\" id=\\\"healthcare\\\">Healthcare</h3><p class=\\\"f16 mt-20 mb0\\\">NER extracts key details from patient records, such as symptoms, treatments, and dates. This reduces manual work for doctors and helps them make quicker decisions.</p><h3 class=\\\"h3 mt-40 mb0\\\" id=\\\"finance\\\">Finance</h3><p class=\\\"f16 mt-20 mb0\\\">Financial companies use NER to process <a href=\\\"https://labelyourdata.com/articles/financial-datasets-for-machine-learning\\\">financial datasets</a>, extract company names, transaction details, and identify trends. It speeds up tasks like credit analysis and fraud detection.</p><h3 class=\\\"h3 mt-40 mb0\\\" id=\\\"news-and-media\\\">News and Media</h3><p class=\\\"f16 mt-20 mb0\\\">NER helps categorize news articles by identifying people, events, and locations mentioned in stories. This makes it easier to find related news.</p><h3 class=\\\"h3 mt-40 mb0\\\" id=\\\"human-resources\\\">Human Resources</h3><p class=\\\"f16 mt-20 mb0\\\">NER can analyze job applications by picking out key details like skills, experience, and education, helping recruiters find the right candidates faster.</p><p class=\\\"f16 mt-20 mb0\\\">NER&rsquo;s ability to quickly turn raw text into organized data makes it essential for improving search accuracy, automating data entry, and gaining valuable insights from <a href=\\\"https://labelyourdata.com/articles/unlabeled-data-in-machine-learning\\\">unlabeled data</a>.</p><h2 class=\\\"h2\\\" id=\\\"types-of-entities-recognized-in-ner\\\">Types of Entities Recognized in NER</h2><p class=\\\"f16 mt-20 mb0\\\">Named entity recognition in NLP can identify a wide range of entities in text. These entities fall into standard categories and specialized ones, depending on the task.</p><h3 class=\\\"h3 mt-40 mb0\\\" id=\\\"standard-entities\\\">Standard Entities</h3><p class=\\\"f16 mt-20 mb0\\\">These are common types used in NER:</p><ul class=\\\"mt-10\\\"><li><p class=\\\"f16\\\"><strong>Person: </strong>Names of individuals (e.g., Elon Musk)</p></li><li><p class=\\\"f16\\\"><strong>Location: </strong>Cities, countries, and geographic regions (e.g., Paris, France)</p></li><li><p class=\\\"f16\\\"><strong>Organization: </strong>Companies, institutions, and groups (e.g., Tesla, United Nations)</p></li><li><p class=\\\"f16\\\"><strong>Date/Time: </strong>Specific dates or times (e.g., January 1, 2025, 2 PM)</p></li><li><p class=\\\"f16\\\"><strong>Monetary Values: </strong>Amounts of money (e.g., $1,000,000)</p></li><li><p class=\\\"f16\\\"><strong>Percentages: </strong>Percent-based information (e.g., 85%)</p></li></ul><h3 class=\\\"h3 mt-40 mb0\\\" id=\\\"domain-specific-entities\\\">Domain-Specific Entities</h3><p class=\\\"f16 mt-20 mb0\\\">Some industries need custom entity categories that go beyond the standard ones:</p><ul class=\\\"mt-10\\\"><li><p class=\\\"f16\\\"><strong>Healthcare: </strong>Disease names, drug names, medical codes (e.g., diabetes, Ibuprofen)</p></li><li><p class=\\\"f16\\\"><strong>Finance: </strong>Stock symbols, financial instruments (e.g., AAPL, Bitcoin)</p></li><li><p class=\\\"f16\\\"><strong>E-commerce: </strong>Product names, SKUs, brands (e.g., iPhone 15 Pro)</p></li></ul><p class=\\\"f16 mt-20 mb0\\\">Customizing NER to recognize these specialized entities is essential for tasks like medical research, financial analysis, or product management. Modern named entity recognition models allow this level of customization by training on domain-specific datasets.</p><h2 class=\\\"h2\\\" id=\\\"techniques-for-building-a-ner-model\\\">Techniques for Building a NER Model</h2><div class=\\\"mt-40\\\"><figure><div class=\\\"flex flex-stretch gallery-tile\\\"><div class=\\\"flex-1 img-tile\\\"><img src=\\\"/img/article-illustrations/named-entity-recognition_3.jpg\\\" class=\\\"dblock\\\" alt=\\\"Key steps in Named Entity Recognition (NER)\\\"></div></div><figcaption class=\\\"mt-10 f12 cgrey\\\">Key steps in Named Entity Recognition (NER)</figcaption></figure></div><p class=\\\"f16 mt-20 mb0\\\">There are several techniques for building a NER model, ranging from simple rule-based approaches to advanced deep learning models. The right technique depends on your data and the complexity of the task.</p><h3 class=\\\"h3 mt-40 mb0\\\" id=\\\"rule-based-systems\\\">Rule-Based Systems</h3><p class=\\\"f16 mt-20 mb0\\\">These systems use predefined rules like word patterns, capitalization, and context to identify entities.</p><ul class=\\\"mt-10\\\"><li><p class=\\\"f16\\\"><strong>Example: </strong>Capitalized words after titles like &ldquo;Mr.&rdquo; or &ldquo;Dr.&rdquo; may be identified as names.</p></li><li><p class=\\\"f16\\\"><strong>Limitations: </strong>Hard to scale and struggles with variations in text.</p></li></ul><h3 class=\\\"h3 mt-40 mb0\\\" id=\\\"dictionary-based-systems\\\">Dictionary-Based Systems</h3><p class=\\\"f16 mt-20 mb0\\\">This method checks words against a dictionary of known entities. It works well for simple tasks but needs constant updating.</p><ul class=\\\"mt-10\\\"><li><p class=\\\"f16\\\"><strong>Example: </strong>A list of company names to identify business-related entities.</p></li><li><p class=\\\"f16\\\"><strong>Limitations: </strong>Misses new or uncommon terms not in the dictionary.</p></li></ul><h3 class=\\\"h3 mt-40 mb0\\\" id=\\\"machine-learning-based-ner\\\">Machine Learning-Based NER</h3><p class=\\\"f16 mt-20 mb0\\\">Machine learning models are trained on labeled datasets to identify and classify entities. These models require feature engineering and can generalize well to unseen data. Common algorithms include <a target=\\\"_blank\\\" rel=\\\"nofollow\\\" href=\\\"https://medium.com/data-science-in-your-pocket/named-entity-recognition-ner-using-conditional-random-fields-in-nlp-3660df22e95c\\\">Conditional Random Fields (CRF)</a> and <a target=\\\"_blank\\\" rel=\\\"nofollow\\\" href=\\\"https://www.ibm.com/think/topics/support-vector-machine\\\">Support Vector Machines (SVM)</a>.</p><ul class=\\\"mt-10\\\"><li><p class=\\\"f16\\\"><strong>Advantages: </strong>More adaptable than rule-based methods.</p></li><li><p class=\\\"f16\\\"><strong>Example: </strong>Training a model to recognize names and dates in news articles.</p></li></ul><h3 class=\\\"h3 mt-40 mb0\\\" id=\\\"deep-learning-based-ner\\\">Deep Learning-Based NER</h3><p class=\\\"f16 mt-20 mb0\\\">Deep learning models, like <a target=\\\"_blank\\\" rel=\\\"nofollow\\\" href=\\\"https://arxiv.org/pdf/2409.10521\\\">LSTM</a> and <a target=\\\"_blank\\\" rel=\\\"nofollow\\\" href=\\\"https://peerj.com/articles/cs-1731.pdf\", \"source\": \"web\", \"published_date\": \"N/A\", \"score_bm25\": 0.0}, {\"paper_id\": \"1805.03784v1\", \"title\": \"SlugNERDS: A Named Entity Recognition Tool for Open Domain Dialogue Systems\", \"authors\": [\"Kevin K. Bowden\", \"Jiaqi Wu\", \"Shereen Oraby\", \"Amita Misra\", \"Marilyn Walker\"], \"abstract\": \"In dialogue systems, the tasks of named entity recognition (NER) and named entity linking (NEL) are vital preprocessing steps for understanding user intent, especially in open domain interaction where we cannot rely on domain-specific inference. UCSC's effort as one of the funded teams in the 2017 Amazon Alexa Prize Contest has yielded Slugbot, an open domain social bot, aimed at casual conversation. We discovered several challenges specifically associated with both NER and NEL when building Slugbot, such as that the NE labels are too coarse-grained or the entity types are not linked to a useful ontology. Moreover, we have discovered that traditional approaches do not perform well in our context: even systems designed to operate on tweets or other social media data do not work well in dialogue systems. In this paper, we introduce Slugbot's Named Entity Recognition for dialogue Systems (SlugNERDS), a NER and NEL tool which is optimized to address these issues. We describe two new resources that we are building as part of this work: SlugEntityDB and SchemaActuator. We believe these resources will be useful for the research community.\", \"url\": \"http://arxiv.org/abs/1805.03784v1\", \"pdf_url\": \"https://arxiv.org/pdf/1805.03784v1\", \"source\": \"arxiv\", \"published_date\": \"2018-05-10T02:07:02Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2303.09306v2\", \"title\": \"BanglaCoNER: Towards Robust Bangla Complex Named Entity Recognition\", \"authors\": [\"HAZ Sameen Shahgir\", \"Ramisa Alam\", \"Md. Zarif Ul Alam\"], \"abstract\": \"Named Entity Recognition (NER) is a fundamental task in natural language processing that involves identifying and classifying named entities in text. But much work hasn't been done for complex named entity recognition in Bangla, despite being the seventh most spoken language globally. CNER is a more challenging task than traditional NER as it involves identifying and classifying complex and compound entities, which are not common in Bangla language. In this paper, we present the winning solution of Bangla Complex Named Entity Recognition Challenge - addressing the CNER task on BanglaCoNER dataset using two different approaches, namely Conditional Random Fields (CRF) and finetuning transformer based Deep Learning models such as BanglaBERT.\\n  The dataset consisted of 15300 sentences for training and 800 sentences for validation, in the .conll format. Exploratory Data Analysis (EDA) on the dataset revealed that the dataset had 7 different NER tags, with notable presence of English words, suggesting that the dataset is synthetic and likely a product of translation.\\n  We experimented with a variety of feature combinations including Part of Speech (POS) tags, word suffixes, Gazetteers, and cluster information from embeddings, while also finetuning the BanglaBERT (large) model for NER. We found that not all linguistic patterns are immediately apparent or even intuitive to humans, which is why Deep Learning based models has proved to be the more effective model in NLP, including CNER task. Our fine tuned BanglaBERT (large) model achieves an F1 Score of 0.79 on the validation set. Overall, our study highlights the importance of Bangla Complex Named Entity Recognition, particularly in the context of synthetic datasets. Our findings also demonstrate the efficacy of Deep Learning models such as BanglaBERT for NER in Bangla language.\", \"url\": \"http://arxiv.org/abs/2303.09306v2\", \"pdf_url\": \"https://arxiv.org/pdf/2303.09306v2\", \"source\": \"arxiv\", \"published_date\": \"2023-03-16T13:31:31Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"1912.10016v2\", \"title\": \"A Neural Model for Text Localization, Transcription and Named Entity Recognition in Full Pages\", \"authors\": [\"Manuel Carbonell\", \"Alicia Forn√©s\", \"Mauricio Villegas\", \"Josep Llad√≥s\"], \"abstract\": \"In the last years, the consolidation of deep neural network architectures for information extraction in document images has brought big improvements in the performance of each of the tasks involved in this process, consisting of text localization, transcription, and named entity recognition. However, this process is traditionally performed with separate methods for each task. In this work we propose an end-to-end model that combines a one stage object detection network with branches for the recognition of text and named entities respectively in a way that shared features can be learned simultaneously from the training error of each of the tasks. By doing so the model jointly performs handwritten text detection, transcription, and named entity recognition at page level with a single feed forward step. We exhaustively evaluate our approach on different datasets, discussing its advantages and limitations compared to sequential approaches. The results show that the model is capable of benefiting from shared features for simultaneously solving interdependent tasks.\", \"url\": \"http://arxiv.org/abs/1912.10016v2\", \"pdf_url\": \"https://arxiv.org/pdf/1912.10016v2\", \"source\": \"arxiv\", \"published_date\": \"2019-12-20T18:45:19Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"1908.10261v1\", \"title\": \"A Morpho-Syntactically Informed LSTM-CRF Model for Named Entity Recognition\", \"authors\": [\"Lilia Simeonova\", \"Kiril Simov\", \"Petya Osenova\", \"Preslav Nakov\"], \"abstract\": \"We propose a morphologically informed model for named entity recognition, which is based on LSTM-CRF architecture and combines word embeddings, Bi-LSTM character embeddings, part-of-speech (POS) tags, and morphological information. While previous work has focused on learning from raw word input, using word and character embeddings only, we show that for morphologically rich languages, such as Bulgarian, access to POS information contributes more to the performance gains than the detailed morphological information. Thus, we show that named entity recognition needs only coarse-grained POS tags, but at the same time it can benefit from simultaneously using some POS information of different granularity. Our evaluation results over a standard dataset show sizable improvements over the state-of-the-art for Bulgarian NER.\", \"url\": \"http://arxiv.org/abs/1908.10261v1\", \"pdf_url\": \"https://arxiv.org/pdf/1908.10261v1\", \"source\": \"arxiv\", \"published_date\": \"2019-08-27T15:10:24Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2112.04189v1\", \"title\": \"Transformer-Based Approach for Joint Handwriting and Named Entity Recognition in Historical documents\", \"authors\": [\"Ahmed Cheikh Rouhoua\", \"Marwa Dhiaf\", \"Yousri Kessentini\", \"Sinda Ben Salem\"], \"abstract\": \"The extraction of relevant information carried out by named entities in handwriting documents is still a challenging task. Unlike traditional information extraction approaches that usually face text transcription and named entity recognition as separate subsequent tasks, we propose in this paper an end-to-end transformer-based approach to jointly perform these two tasks. The proposed approach operates at the paragraph level, which brings two main benefits. First, it allows the model to avoid unrecoverable early errors due to line segmentation. Second, it allows the model to exploit larger bi-dimensional context information to identify the semantic categories, reaching a higher final prediction accuracy. We also explore different training scenarios to show their effect on the performance and we demonstrate that a two-stage learning strategy can make the model reach a higher final prediction accuracy. As far as we know, this work presents the first approach that adopts the transformer networks for named entity recognition in handwritten documents. We achieve the new state-of-the-art performance in the ICDAR 2017 Information Extraction competition using the Esposalles database, for the complete task, even though the proposed technique does not use any dictionaries, language modeling, or post-processing.\", \"url\": \"http://arxiv.org/abs/2112.04189v1\", \"pdf_url\": \"https://arxiv.org/pdf/2112.04189v1\", \"source\": \"arxiv\", \"published_date\": \"2021-12-08T09:26:21Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"1908.09138v2\", \"title\": \"Query-Based Named Entity Recognition\", \"authors\": [\"Yuxian Meng\", \"Xiaoya Li\", \"Zijun Sun\", \"Jiwei Li\"], \"abstract\": \"In this paper, we propose a new strategy for the task of named entity recognition (NER). We cast the task as a query-based machine reading comprehension task: e.g., the task of extracting entities with PER is formalized as answering the question of \\\"which person is mentioned in the text ?\\\". Such a strategy comes with the advantage that it solves the long-standing issue of handling overlapping or nested entities (the same token that participates in more than one entity categories) with sequence-labeling techniques for NER. Additionally, since the query encodes informative prior knowledge, this strategy facilitates the process of entity extraction, leading to better performances. We experiment the proposed model on five widely used NER datasets on English and Chinese, including MSRA, Resume, OntoNotes, ACE04 and ACE05. The proposed model sets new SOTA results on all of these datasets.\", \"url\": \"http://arxiv.org/abs/1908.09138v2\", \"pdf_url\": \"https://arxiv.org/pdf/1908.09138v2\", \"source\": \"arxiv\", \"published_date\": \"2019-08-24T13:42:57Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2412.16976v3\", \"title\": \"On Fusing ChatGPT and Ensemble Learning in Discon-tinuous Named Entity Recognition in Health Corpora\", \"authors\": [\"Tzu-Chieh Chen\", \"Wen-Yang Lin\"], \"abstract\": \"Named Entity Recognition has traditionally been a key task in natural language processing, aiming to identify and extract important terms from unstructured text data. However, a notable challenge for contemporary deep-learning NER models has been identifying discontinuous entities, which are often fragmented within the text. To date, methods to address Discontinuous Named Entity Recognition have not been explored using ensemble learning to the best of our knowledge. Furthermore, the rise of large language models, such as ChatGPT in recent years, has shown significant effectiveness across many NLP tasks. Most existing approaches, however, have primarily utilized ChatGPT as a problem-solving tool rather than exploring its potential as an integrative element within ensemble learning algorithms. In this study, we investigated the integration of ChatGPT as an arbitrator within an ensemble method, aiming to enhance performance on DNER tasks. Our method combines five state-of-the-art NER models with ChatGPT using custom prompt engineering to assess the robustness and generalization capabilities of the ensemble algorithm. We conducted experiments on three benchmark medical datasets, comparing our method against the five SOTA models, individual applications of GPT-3.5 and GPT-4, and a voting ensemble method. The results indicate that our proposed fusion of ChatGPT with the ensemble learning algorithm outperforms the SOTA results in the CADEC, ShARe13, and ShARe14 datasets, showcasing its potential to enhance NLP applications in the healthcare domain.\", \"url\": \"http://arxiv.org/abs/2412.16976v3\", \"pdf_url\": \"https://arxiv.org/pdf/2412.16976v3\", \"source\": \"arxiv\", \"published_date\": \"2024-12-22T11:26:49Z\", \"score_bm25\": 0.0}, {\"paper_id\": null, \"title\": \"Named Entity Recognition (NER): From Rule-Based to Transformer Models\", \"authors\": [], \"abstract\": \"<H1>Named Entity Recognition (NER): From Rule-Based to Transformer Models</H1><UL><LI>Jared Chung</LI></UL><H1>Introduction</H1><P>Named Entity Recognition (NER) is a fundamental NLP task that identifies and classifies named entities in text into predefined categories such as person names, organizations, locations, dates, and more. NER is the foundation of information extraction pipelines and powers features like:</P><UL><LI>Extracting contacts from emails</LI><LI>Identifying companies mentioned in news articles</LI><LI>Parsing resumes for candidate information</LI><LI>Anonymizing sensitive data (PII detection)</LI><LI>Building knowledge graphs</LI></UL><P>In this comprehensive guide, we'll explore NER from basic concepts to production implementations.</P><H2>Prerequisites</H2><P> # Download spaCy models python  -m  spacy download en_core_web_sm</P><P> python  -m  spacy download en_core_web_trf   # Transformer-based (better but slower)</P><H1>Understanding NER</H1><H2>What Does NER Do?</H2><P>NER takes unstructured text and extracts structured information:</P><P>Input:  \\\"Apple Inc. was founded by Steve Jobs in Cupertino, California in 1976.\\\"</P><P> Output:</P><P> - Apple Inc.   ‚Üí ORGANIZATION (ORG)</P><P> - Steve Jobs   ‚Üí PERSON (PER)</P><P> - Cupertino    ‚Üí GEOPOLITICAL ENTITY (GPE)</P><P> - California   ‚Üí GEOPOLITICAL ENTITY (GPE)</P><P> - 1976         ‚Üí DATE</P><H2>Standard Entity Types</H2><P>Different datasets define different entity types. Here are the most common:</P><H3>OntoNotes 5.0 (spaCy default)</H3><TABLE><TR><TH>Type</TH><TH>Description</TH><TH>Examples</TH></TR><TR><TD>PERSON</TD><TD>People, including fictional</TD><TD>Barack Obama, Sherlock Holmes</TD></TR><TR><TD>ORG</TD><TD>Companies, agencies, institutions</TD><TD>Google, FBI, Stanford University</TD></TR><TR><TD>GPE</TD><TD>Countries, cities, states</TD><TD>France, New York, California</TD></TR><TR><TD>LOC</TD><TD>Non-GPE locations</TD><TD>Mount Everest, Pacific Ocean</TD></TR><TR><TD>DATE</TD><TD>Absolute or relative dates</TD><TD>June 2023, yesterday, next week</TD></TR><TR><TD>TIME</TD><TD>Times smaller than a day</TD><TD>3:00 PM, morning</TD></TR><TR><TD>MONEY</TD><TD>Monetary values</TD><TD>$500, fifty euros</TD></TR><TR><TD>PERCENT</TD><TD>Percentages</TD><TD>25%, three percent</TD></TR><TR><TD>CARDINAL</TD><TD>Numerals not covered by other types</TD><TD>one, 1000, dozens</TD></TR><TR><TD>ORDINAL</TD><TD>First, second, etc.</TD><TD>first, 3rd</TD></TR><TR><TD>PRODUCT</TD><TD>Objects, vehicles, foods (not services)</TD><TD>iPhone, Boeing 747</TD></TR><TR><TD>EVENT</TD><TD>Named events</TD><TD>World War II, Olympics</TD></TR><TR><TD>WORK_OF_ART</TD><TD>Titles of books, songs, etc.</TD><TD>Harry Potter, Let It Be</TD></TR><TR><TD>LAW</TD><TD>Named documents made into laws</TD><TD>Roe v. Wade, GDPR</TD></TR><TR><TD>LANGUAGE</TD><TD>Named languages</TD><TD>English, Spanish</TD></TR></TABLE><H3>CoNLL-2003 (Common benchmark)</H3><TABLE><TR><TH>Type</TH><TH>Description</TH></TR>\", \"url\": \"https://jaredai-website.vercel.app/blog/2025-01-14-named-entity-recognition\", \"pdf_url\": \"#conclusion\\\" aria-hidden=\\\"true\\\" tabindex=\\\"-1\\\"><span class=\\\"icon icon-link\\\"></span></a>Conclusion</h1><p>NER extracts structured entities from unstructured text. Key takeaways:</p><p><strong>Understanding NER:</strong></p><ul><li>BIO tagging handles multi-token entities</li><li>Entity types depend on your use case</li><li>Evaluation must be entity-level, not token-level</li></ul><p><strong>Choosing an approach:</strong></p><ul><li>Rule-based for known patterns</li><li>spaCy statistical for general production use</li><li>Transformers for maximum accuracy</li><li>Combine approaches for best results</li></ul><p><strong>Custom training:</strong></p><ul><li>Needed for domain-specific entities</li><li>Quality of labels matters more than quantity</li><li>200-500 diverse examples is a good starting point</li></ul><p><strong>Production tips:</strong></p><ul><li>Use batch processing (<code>nlp.pipe</code>)</li><li>Start simple, add complexity as needed</li><li>Monitor and iterate on real data</li></ul><h1 id=\\\"references\\\"><a href=\\\"#references\\\" aria-hidden=\\\"true\\\" tabindex=\\\"-1\\\"><span class=\\\"icon icon-link\\\"></span></a>References</h1><ul><li><a target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\" href=\\\"https://spacy.io/usage/linguistic-features#named-entities\\\">spaCy NER Documentation</a> - Production NLP library.</li><li><a target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\" href=\\\"https://huggingface.co/docs/transformers/tasks/token_classification\\\">Hugging Face Token Classification</a> - Transformer-based NER.</li><li><a target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\" href=\\\"https://github.com/chakki-works/seqeval\\\">seqeval</a> - Sequence labeling evaluation.</li><li>Devlin, J., et al. (2019). <a target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\" href=\\\"https://arxiv.org/abs/1810.04805\\\">&quot;BERT: Pre-training of Deep Bidirectional Transformers&quot;</a>. NAACL 2019.</li><li><a target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\" href=\\\"https://catalog.ldc.upenn.edu/docs/LDC2013T19/OntoNotes-Release-5.0.pdf\", \"source\": \"web\", \"published_date\": \"N/A\", \"score_bm25\": 0.0}, {\"paper_id\": \"2109.15121v1\", \"title\": \"Feature-Rich Named Entity Recognition for Bulgarian Using Conditional Random Fields\", \"authors\": [\"Georgi Georgiev\", \"Preslav Nakov\", \"Kuzman Ganchev\", \"Petya Osenova\", \"Kiril Ivanov Simov\"], \"abstract\": \"The paper presents a feature-rich approach to the automatic recognition and categorization of named entities (persons, organizations, locations, and miscellaneous) in news text for Bulgarian. We combine well-established features used for other languages with language-specific lexical, syntactic and morphological information. In particular, we make use of the rich tagset annotation of the BulTreeBank (680 morpho-syntactic tags), from which we derive suitable task-specific tagsets (local and nonlocal). We further add domain-specific gazetteers and additional unlabeled data, achieving F1=89.4%, which is comparable to the state-of-the-art results for English.\", \"url\": \"http://arxiv.org/abs/2109.15121v1\", \"pdf_url\": \"https://arxiv.org/pdf/2109.15121v1\", \"source\": \"arxiv\", \"published_date\": \"2021-09-26T12:00:06Z\", \"score_bm25\": 0.0}, {\"paper_id\": null, \"title\": \"An HMM Based Named Entity Recognition System for Indian Languages: The JU System at ICON 2013\", \"authors\": [\"Vivekananda Gayen\", \"Kamal Sarkar\"], \"abstract\": \"This paper reports about our work in the ICON 2013 NLP TOOLS CONTEST on Named Entity Recognition. We submitted runs for Bengali, English, Hindi, Marathi, Punjabi, Tamil and Telugu. A statistical HMM (Hidden Markov Models) based model has been used to implement our system. The system has been trained and tested on the NLP TOOLS CONTEST: ICON 2013 datasets. Our system obtains F-measures of 0.8599, 0.7704, 0.7520, 0.4289, 0.5455, 0.4466, and 0.4003 for Bengali, English, Hindi, Marathi, Punjabi, Tamil and Telugu respectively.\", \"url\": \"http://arxiv.org/abs/1405.7397v1\", \"pdf_url\": \"https://arxiv.org/pdf/1405.7397v1\", \"source\": \"arxiv\", \"published_date\": \"2014-05-28T21:05:00Z\", \"score_bm25\": 0.0}], \"passage ranking in QA systems\": [{\"paper_id\": null, \"title\": \"AN EFFICIENT PASSAGE RANKING TECHNIQUE FOR A QA SYSTEM\", \"authors\": [], \"abstract\": \"<P>AN EFFICIENT PASSAGE RANKING TECHNIQUE FOR A QA SYSTEM\\nIn this paper, we propose a technique to tackle the third challenge. The proposed technique does this by considering lexical, semantic and syntactic features to determine the passage from the corpus that most likely contains the answer to the posed question. The lexical features are obtained by considering the n-grams of the terms present in question/relevant data. The semantic features are generated using NLP tools and knowledge bases like WordNet and Wikipedia. The syntactic features are derived from the parse tree of question/relevant data. Finally, the answer extraction from the ranked data is performed by using answer type matches as well as syntactic matches. The technique is shown to work efficiently with a factoid based QA System but can be extended to subjective QAs as well, as the features considered are not specific to factoid Questions and Passages. The techniques it has been compared to are also not Factoid specific and can be employed in Complex QA Systems as well (such as the SSTK shown in this paper[3]). The rest of the paper is organized as follows: Section 2 provides the related work. Section 3 gives the overview of the Question Answering System used, Section 4 details passage ranking technique and Section 5 gives e</P><H3>2. RELATED WORK</H3><P>There has been extensive work in the field of question answering systems. However, we concentrate on prior work related to passage ranking. A survey [2]of all the state-of-the-art lexical passage ranking algorithms like Mitre, IBM, bm25, etc. indicates the scope for improvement in them and also notes that the passage retrieval performance depends on document retriever as well. [3] Paper describes and compares the various methods of passage ranking right from the initial n-gram and tf-idf measures to more recent Syntactic and Semantic measures like the SSTK[4] in the context of complex question answering.</P><P>With respect to this paper, the SSTK[4]and AType-DP-IP[5] techniques are the most relevant ones as both of these methods consider all the three category of features that we consider. It is to be noted that most of the work prior to these considered a subset of the features and hence, will be inferior in performance as we show in the experiments section. Works like [6], use semantic and syntactic techniques, but do not consider lexical techniques such as mismatch and inverse passage frequency (ipf). Other techniques like [7], don‚Äôt consider semantic similarities and employ the use of ontologies like Wordnet[8]. SSTK[4] is a kernel function proposed for automatic question categorization and it incorporates syntactic dependencies and term similarity based on WordNet[8]. The same kernel is used for Question Answering [3] and is shown to outperform prior passage ranking techniques. A more recent technique, AType-DP-IP[5], ranks the passages after aligning the syntactic structures based on the question‚Äôs answer type and detected n\", \"url\": \"https://www.researchgate.net/publication/288266760_An_Efficient_Passage_Ranking_Technique_For_a_QA_System/fulltext/57aa188608ae0932c96e6154/An-Efficient-Passage-Ranking-Technique-For-a-QA-System.pdf\", \"pdf_url\": \"https://www.researchgate.net/publication/288266760_An_Efficient_Passage_Ranking_Technique_For_a_QA_System/fulltext/57aa188608ae0932c96e6154/An-Efficient-Passage-Ranking-Technique-For-a-QA-System.pdf\", \"source\": \"web\", \"published_date\": \"N/A\", \"score_bm25\": 0.0}, {\"paper_id\": \"1511.05806v1\", \"title\": \"Ranking library materials\", \"authors\": [\"Dirk Lewandowski\"], \"abstract\": \"Purpose: This paper discusses ranking factors suitable for library materials and shows that ranking in general is a complex process and that ranking for library materials requires a variety of techniques. Design/methodology/approach: The relevant literature is reviewed to provide a systematic overview of suitable ranking factors. The discussion is based on an overview of ranking factors used in Web search engines. Findings: While there are a wide variety of ranking factors applicable to library materials, todays library systems use only some of them. When designing a ranking component for the library catalogue, an individual weighting of applicable factors is necessary. Research limitations/applications: While this article discusses different factors, no particular ranking formula is given. However, this article presents the argument that such a formula must always be individual to a certain use case. Practical implications: The factors presented can be considered when designing a ranking component for a librarys search system or when discussing such a project with an ILS vendor. Originality/value: This paper is original in that it is the first to systematically discuss ranking of library materials based on the main factors used by Web search engines.\", \"url\": \"http://arxiv.org/abs/1511.05806v1\", \"pdf_url\": \"https://arxiv.org/pdf/1511.05806v1\", \"source\": \"arxiv\", \"published_date\": \"2015-11-18T14:36:20Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2103.16669v3\", \"title\": \"An In-depth Analysis of Passage-Level Label Transfer for Contextual Document Ranking\", \"authors\": [\"Koustav Rudra\", \"Zeon Trevor Fernando\", \"Avishek Anand\"], \"abstract\": \"Pre-trained contextual language models such as BERT, GPT, and XLnet work quite well for document retrieval tasks. Such models are fine-tuned based on the query-document/query-passage level relevance labels to capture the ranking signals. However, the documents are longer than the passages and such document ranking models suffer from the token limitation (512) of BERT. Researchers proposed ranking strategies that either truncate the documents beyond the token limit or chunk the documents into units that can fit into the BERT. In the later case, the relevance labels are either directly transferred from the original query-document pair or learned through some external model. In this paper, we conduct a detailed study of the design decisions about splitting and label transfer on retrieval effectiveness and efficiency. We find that direct transfer of relevance labels from documents to passages introduces label noise that strongly affects retrieval effectiveness for large training datasets. We also find that query processing times are adversely affected by fine-grained splitting schemes. As a remedy, we propose a careful passage level labelling scheme using weak supervision that delivers improved performance (3-14% in terms of nDCG score) over most of the recently proposed models for ad-hoc retrieval while maintaining manageable computational complexity on four diverse document retrieval datasets.\", \"url\": \"http://arxiv.org/abs/2103.16669v3\", \"pdf_url\": \"https://arxiv.org/pdf/2103.16669v3\", \"source\": \"arxiv\", \"published_date\": \"2021-03-30T20:28:02Z\", \"score_bm25\": 0.0}, {\"paper_id\": null, \"title\": \"Joint Inference of Retrieval and Generation for Passage Re-ranking | Wei Fang\", \"authors\": [], \"abstract\": \"<H1>Joint Inference of Retrieval and Generation for Passage Re-ranking</H1><H3>Abstract</H3><P>Passage retrieval is a crucial component of modern open-domain question answering (QA) systems, providing information for downstream QA components to generate accurate and transparent answers. In this study we focus on passage re-ranking, proposing a simple yet effective method, Joint Passage Re-ranking (JPR), that optimizes the mutual information between query and passage distributions, integrating both cross-encoders and generative models in the re-ranking process. Experimental results demonstrate that JPR outperforms conventional re-rankers and language model scorers in both open-domain QA retrieval settings and diverse retrieval benchmarks under zero-shot settings.</P><H3>Type</H3><H3>Publication</H3><H5>Wei Fang</H5>\", \"url\": \"https://people.csail.mit.edu/weifang/publication/eacl24-jpr/\", \"pdf_url\": \"https://people.csail.mit.edu/weifang/files/resume.pdf\", \"source\": \"web\", \"published_date\": \"N/A\", \"score_bm25\": 0.0}, {\"paper_id\": null, \"title\": \"Joint Inference of Retrieval and Generation for Passage Re-ranking\", \"authors\": [], \"abstract\": \"<P>Findings of the Association for Computational Linguistics: EACL 2024, pages 2289‚Äì2298 March 17-22, 2024 c 2024 Association for Computational Linguistics</P><P>Joint Inference of Retrieval and Generation for Passage Re-ranking</P><P>Wei Fang and Yung-Sung Chuang and James Glass Massachusetts Institute of Technology {weifang,yungsung,glass}@mit.edu Abstract</P><P>Passageretrievalisacrucialcomponentofmod- ern open-domain question answering (QA) sys- tems, providing information for downstream QA components to generate accurate and trans- parent answers. In this study we focus on pas- sage re-ranking, proposing a simple yet effec- tive method, Joint Passage Re-ranking (JPR), that optimizes the mutual information between query and passage distributions, integrating both cross-encoders and generative models in the re-ranking process. Experimental results demonstrate that JPRoutperforms conventional re-rankers and language model scorers in both open-domain QA retrieval settings and diverse retrieval benchmarks under zero-shot settings.1</P><P>1 Introduction</P><P>Passage retrieval is a crucial component in open- domain question answering (QA) (Chen and Yih, 2020), a task that requires answering questions from a wide range of domains and could be ap- plied in systems that fulll user's information needs (Voorhees et al.,1999). Retrieval offers downstream QA systems grounding information, which not only improves accuracy in a lot of cases but also provides transparency to how systems gen- erate answers, similar to how articles provide refer- ences and citations, such that model hallucinations can be checked with ease. Furthermore, the set of documentstoberetrievedfrom, orknowledgebase, can be quickly updated with new documents and knowledge such that models can adapt to tempo- ral changes, and do not need to be continuously re-trained nor require online training paradigms for continual learning. Early retrieval methods are typically based on term-matching, such as BM25 (Robertson et al., 2009) or TF-IDF (Salton et al.,1975). Such meth- ods, called sparse retrievers, perform keyword</P><P>1Source code is available at https://github.com/ wfangtw/jpr</P><P>matching efciently with an inverted index to nd relevant contexts. Sparse retrievers often achieve reasonable performance while being computation- ally efcient and does not require training, but are shown to have limited abilities beyond lexical matching. Recently, dense retrievers that encode text with continuous embeddings have been heavily stud- ied and utilized in contemporary QA systems, of- ten outperforming their sparse counterparts on high resource evaluation settings (Karpukhin et al., 2020). There are a few drawbacks however, such as higher computational demands during both train- ing and inference, inability to handle large con- texts (Luan et al.,2021), and difculty in gener- alizing to new domains especially those with lim- ited data (Reddy et al.,2021). Hybrid methods have been explored to g\", \"url\": \"https://aclanthology.org/2024.findings-eacl.151.pdf\", \"pdf_url\": \"https://aclanthology.org/2024.findings-eacl.151.pdf\", \"source\": \"web\", \"published_date\": \"N/A\", \"score_bm25\": 0.0}, {\"paper_id\": null, \"title\": \"Joint Inference of Retrieval and Generation for Passage Re-ranking - ACL Anthology\", \"authors\": [], \"abstract\": \"<H3>Wei Fang, Yung-Sung Chuang, James Glass</H3><P>Important: The Anthology treat PDFs as authoritative. Please use this form only to correct data that is out of line with the PDF. See our corrections guidelines if you need to change the PDF.</P><P>Title Adjust the title. Retain tags such as <fixed-case>.</P><P>Abstract Correct abstract if needed. Retain XML formatting tags such as <tex-math>.</P><P>Verification against PDF Ensure that the new title/authors match the snapshot below. (If there is no snapshot or it is too small, consult the PDF.)Authors concatenated from the text boxes above:</P><P>ALL author names match the snapshot above‚Äîincluding middle initials, hyphens, and accents.</P><H5>Abstract</H5><P>Passage retrieval is a crucial component of modern open-domain question answering (QA) systems, providing information for downstream QA components to generate accurate and transparent answers. In this study we focus on passage re-ranking, proposing a simple yet effective method, Joint Passage Re-ranking (JPR), that optimizes the mutual information between query and passage distributions, integrating both cross-encoders and generative models in the re-ranking process. Experimental results demonstrate that JPR outperforms conventional re-rankers and language model scorers in both open-domain QA retrieval settings and diverse retrieval benchmarks under zero-shot settings.</P><P>Wei Fang, Yung-Sung Chuang, and James Glass. 2024. Joint Inference of Retrieval and Generation for Passage Re-ranking. In Findings of the Association for Computational Linguistics: EACL 2024, pages 2289‚Äì2298, St. Julian‚Äôs, Malta. Association for Computational Linguistics.</P><P>More options‚Ä¶</P>\", \"url\": \"https://aclanthology.org/2024.findings-eacl.151/\", \"pdf_url\": \"https://aclanthology.org/2024.findings-eacl.151.pdf\", \"source\": \"web\", \"published_date\": \"N/A\", \"score_bm25\": 0.0}, {\"paper_id\": \"2101.00294v1\", \"title\": \"https://arxiv.org/pdf/2101.00294v1\", \"authors\": [], \"abstract\": \"<H1>Reader-Guided Passage Reranking for Open-Domain Question Answering</H1><P>Yuning Mao1, Pengcheng He2, Xiaodong Liu3, Yelong Shen2, Jianfeng Gao3, Jiawei Han1, Weizhu Chen2</P><P>1University of Illinois, Urbana-Champaign 2Microsoft Dynamics 365 AI 3Microsoft Research 1fyuningm2, hanjg@illinois.edu 2;3fpenhe, xiaodl, yeshe, jfgao,wzcheng@microsoft.com</P><H3>Abstract</H3><P>Current open-domain question answering (QA) systems often follow a Retriever-Reader (R2) architecture, where the retriever first re-trieves relevant passages and the reader then reads the retrieved passages to form an an-swer. In this paper, we propose a simple and effective passage reranking method, Reader-guIDEd Reranker (RIDER), which does not involve any training and reranks the retrieved passages solely based on the top predictions of the reader before reranking. We show that RIDER, despite its simplicity, achieves 10 to</P><P>20 absolute gains in top-1 retrieval accuracy and 1 to 4 Exact Match (EM) score gains with-out refining the retriever or reader. In particu-lar, RIDER achieves 48.3 EM on the Natural Questions dataset and 66.4 on the TriviaQA dataset when only 1,024 tokens (7.8 passages on average) are used as the reader input.</P><H3>1 Introduction</H3><P>Current open-domain question answering (QA) sys-tems often follow a Retriever-Reader (R2) archi-tecture, where the retriever first retrieves relevant passages and the reader then reads the retrieved passages to form an answer. Since the retriever retrieves passages from a large candidate pool (e.g., millions of Wikipedia passages), it often fails to rank the most relevant passages at the very top. One line of work (Mao et al., 2020; Karpukhin et al., 2020) aims to improve the quality of pas-sage retrieval and shows that significantly better retrieval accuracy as well as QA performance can be achieved when the retriever is improved. An alternative solution is to rerank the initial retrieval results via a reranker, which is widely used in information retrieval (Nogueira and Cho, 2019; Qiao et al., 2019) and explored in early open-domain QA systems (Wang et al., 2018a;</P><P>Work was done during Yuning‚Äôs internship at Microsoft Dynamics 365 AI.</P><P>Lee et al., 2018). However, current state-of-the-art open-domain QA systems (Karpukhin et al., 2020; Izacard and Grave, 2020b; Lewis et al., 2020)</P><P>do not distinguish the order of the retrieved pas-sages and instead equally consider a large number of retrieved passages (e.g., 100), which could be computationally prohibitive as the model size of the readers becomes larger (Izacard and Grave, 2020b). We argue that a Retriever-Reranker-Reader (R3) architecture is beneficial in terms of both model effectiveness and efficiency: passage reranking im-proves the retrieval accuracy of the retriever at top positions and allows the reader to achieve compara-ble performance with fewer passages as the input. However, one bottleneck of R3 is that the reranker, previously based\", \"url\": \"https://arxiv.org/pdf/2101.00294v1\", \"pdf_url\": \"https://arxiv.org/pdf/2101.00294v1.pdf\", \"source\": \"web\", \"published_date\": \"N/A\", \"score_bm25\": 0.0}, {\"paper_id\": \"2101.00294v1\", \"title\": \"https://arxiv.org/pdf/2101.00294v1.pdf\", \"authors\": [], \"abstract\": \"<H1>Reader-Guided Passage Reranking for Open-Domain Question Answering</H1><P>Yuning Mao1, Pengcheng He2, Xiaodong Liu3, Yelong Shen2, Jianfeng Gao3, Jiawei Han1, Weizhu Chen2</P><P>1University of Illinois, Urbana-Champaign 2Microsoft Dynamics 365 AI 3Microsoft Research 1fyuningm2, hanjg@illinois.edu 2;3fpenhe, xiaodl, yeshe, jfgao,wzcheng@microsoft.com</P><H3>Abstract</H3><P>Current open-domain question answering (QA) systems often follow a Retriever-Reader (R2) architecture, where the retriever first re-trieves relevant passages and the reader then reads the retrieved passages to form an an-swer. In this paper, we propose a simple and effective passage reranking method, Reader-guIDEd Reranker (RIDER), which does not involve any training and reranks the retrieved passages solely based on the top predictions of the reader before reranking. We show that RIDER, despite its simplicity, achieves 10 to</P><P>20 absolute gains in top-1 retrieval accuracy and 1 to 4 Exact Match (EM) score gains with-out refining the retriever or reader. In particu-lar, RIDER achieves 48.3 EM on the Natural Questions dataset and 66.4 on the TriviaQA dataset when only 1,024 tokens (7.8 passages on average) are used as the reader input.</P><H3>1 Introduction</H3><P>Current open-domain question answering (QA) sys-tems often follow a Retriever-Reader (R2) archi-tecture, where the retriever first retrieves relevant passages and the reader then reads the retrieved passages to form an answer. Since the retriever retrieves passages from a large candidate pool (e.g., millions of Wikipedia passages), it often fails to rank the most relevant passages at the very top. One line of work (Mao et al., 2020; Karpukhin et al., 2020) aims to improve the quality of pas-sage retrieval and shows that significantly better retrieval accuracy as well as QA performance can be achieved when the retriever is improved. An alternative solution is to rerank the initial retrieval results via a reranker, which is widely used in information retrieval (Nogueira and Cho, 2019; Qiao et al., 2019) and explored in early open-domain QA systems (Wang et al., 2018a;</P><P>Work was done during Yuning‚Äôs internship at Microsoft Dynamics 365 AI.</P><P>Lee et al., 2018). However, current state-of-the-art open-domain QA systems (Karpukhin et al., 2020; Izacard and Grave, 2020b; Lewis et al., 2020)</P><P>do not distinguish the order of the retrieved pas-sages and instead equally consider a large number of retrieved passages (e.g., 100), which could be computationally prohibitive as the model size of the readers becomes larger (Izacard and Grave, 2020b). We argue that a Retriever-Reranker-Reader (R3) architecture is beneficial in terms of both model effectiveness and efficiency: passage reranking im-proves the retrieval accuracy of the retriever at top positions and allows the reader to achieve compara-ble performance with fewer passages as the input. However, one bottleneck of R3 is that the reranker, previously based\", \"url\": \"https://arxiv.org/pdf/2101.00294v1.pdf\", \"pdf_url\": \"https://arxiv.org/pdf/2101.00294v1.pdf\", \"source\": \"web\", \"published_date\": \"N/A\", \"score_bm25\": 0.0}, {\"paper_id\": \"2207.13332v2\", \"title\": \"RealTime QA: What's the Answer Right Now?\", \"authors\": [\"Jungo Kasai\", \"Keisuke Sakaguchi\", \"Yoichi Takahashi\", \"Ronan Le Bras\", \"Akari Asai\", \"Xinyan Yu\", \"Dragomir Radev\", \"Noah A. Smith\", \"Yejin Choi\", \"Kentaro Inui\"], \"abstract\": \"We introduce REALTIME QA, a dynamic question answering (QA) platform that announces questions and evaluates systems on a regular basis (weekly in this version). REALTIME QA inquires about the current world, and QA systems need to answer questions about novel events or information. It therefore challenges static, conventional assumptions in open-domain QA datasets and pursues instantaneous applications. We build strong baseline models upon large pretrained language models, including GPT-3 and T5. Our benchmark is an ongoing effort, and this paper presents real-time evaluation results over the past year. Our experimental results show that GPT-3 can often properly update its generation results, based on newly-retrieved documents, highlighting the importance of up-to-date information retrieval. Nonetheless, we find that GPT-3 tends to return outdated answers when retrieved documents do not provide sufficient information to find an answer. This suggests an important avenue for future research: can an open-domain QA system identify such unanswerable cases and communicate with the user or even the retrieval module to modify the retrieval results? We hope that REALTIME QA will spur progress in instantaneous applications of question answering and beyond.\", \"url\": \"http://arxiv.org/abs/2207.13332v2\", \"pdf_url\": \"https://arxiv.org/pdf/2207.13332v2\", \"source\": \"arxiv\", \"published_date\": \"2022-07-27T07:26:01Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2504.11972v2\", \"title\": \"LLM-as-a-Judge: Reassessing the Performance of LLMs in Extractive QA\", \"authors\": [\"Xanh Ho\", \"Jiahao Huang\", \"Florian Boudin\", \"Akiko Aizawa\"], \"abstract\": \"Extractive reading comprehension question answering (QA) datasets are typically evaluated using Exact Match (EM) and F1-score, but these metrics often fail to fully capture model performance. With the success of large language models (LLMs), they have been employed in various tasks, including serving as judges (LLM-as-a-judge). In this paper, we reassess the performance of QA models using LLM-as-a-judge across four reading comprehension QA datasets. We examine different families of LLMs and various answer types to evaluate the effectiveness of LLM-as-a-judge in these tasks. Our results show that LLM-as-a-judge is highly correlated with human judgments and can replace traditional EM/F1 metrics. By using LLM-as-a-judge, the correlation with human judgments improves significantly, from 0.22 (EM) and 0.40 (F1-score) to 0.85. These findings confirm that EM and F1 metrics underestimate the true performance of the QA models. While LLM-as-a-judge is not perfect for more difficult answer types (e.g., job), it still outperforms EM/F1, and we observe no bias issues, such as self-preference, when the same model is used for both the QA and judgment tasks.\", \"url\": \"http://arxiv.org/abs/2504.11972v2\", \"pdf_url\": \"https://arxiv.org/pdf/2504.11972v2\", \"source\": \"arxiv\", \"published_date\": \"2025-04-16T11:08:46Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2204.07496v4\", \"title\": \"Improving Passage Retrieval with Zero-Shot Question Generation\", \"authors\": [\"Devendra Singh Sachan\", \"Mike Lewis\", \"Mandar Joshi\", \"Armen Aghajanyan\", \"Wen-tau Yih\", \"Joelle Pineau\", \"Luke Zettlemoyer\"], \"abstract\": \"We propose a simple and effective re-ranking method for improving passage retrieval in open question answering. The re-ranker re-scores retrieved passages with a zero-shot question generation model, which uses a pre-trained language model to compute the probability of the input question conditioned on a retrieved passage. This approach can be applied on top of any retrieval method (e.g. neural or keyword-based), does not require any domain- or task-specific training (and therefore is expected to generalize better to data distribution shifts), and provides rich cross-attention between query and passage (i.e. it must explain every token in the question). When evaluated on a number of open-domain retrieval datasets, our re-ranker improves strong unsupervised retrieval models by 6%-18% absolute and strong supervised models by up to 12% in terms of top-20 passage retrieval accuracy. We also obtain new state-of-the-art results on full open-domain question answering by simply adding the new re-ranker to existing models with no further changes.\", \"url\": \"http://arxiv.org/abs/2204.07496v4\", \"pdf_url\": \"https://arxiv.org/pdf/2204.07496v4\", \"source\": \"arxiv\", \"published_date\": \"2022-04-15T14:51:41Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2508.10427v2\", \"title\": \"STRIDE-QA: Visual Question Answering Dataset for Spatiotemporal Reasoning in Urban Driving Scenes\", \"authors\": [\"Keishi Ishihara\", \"Kento Sasaki\", \"Tsubasa Takahashi\", \"Daiki Shiono\", \"Yu Yamaguchi\"], \"abstract\": \"Vision-Language Models (VLMs) have been applied to autonomous driving to support decision-making in complex real-world scenarios. However, their training on static, web-sourced image-text pairs fundamentally limits the precise spatiotemporal reasoning required to understand and predict dynamic traffic scenes. We address this critical gap with STRIDE-QA, a large-scale visual question answering (VQA) dataset for physically grounded reasoning from an ego-centric perspective. Constructed from 100 hours of multi-sensor driving data in Tokyo, capturing diverse and challenging conditions, STRIDE-QA is the largest VQA dataset for spatiotemporal reasoning in urban driving, offering 16 million QA pairs over 285K frames. Grounded by dense, automatically generated annotations including 3D bounding boxes, segmentation masks, and multi-object tracks, the dataset uniquely supports both object-centric and ego-centric reasoning through three novel QA tasks that require spatial localization and temporal prediction. Our benchmarks demonstrate that existing VLMs struggle significantly, achieving near-zero scores on prediction consistency. In contrast, VLMs fine-tuned on STRIDE-QA exhibit dramatic performance gains, achieving 55% success in spatial localization and 28% consistency in future motion prediction, compared to near-zero scores from general-purpose VLMs. Therefore, STRIDE-QA establishes a comprehensive foundation for developing more reliable VLMs for safety-critical autonomous systems.\", \"url\": \"http://arxiv.org/abs/2508.10427v2\", \"pdf_url\": \"https://arxiv.org/pdf/2508.10427v2\", \"source\": \"arxiv\", \"published_date\": \"2025-08-14T07:57:06Z\", \"score_bm25\": 0.0}, {\"paper_id\": null, \"title\": \"US11822588B2 - Supporting passage ranking in question answering (QA) system - Google Patents\", \"authors\": [], \"abstract\": \"<H2>Info</H2><P>Legal status (The legal status is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the status listed.)</P><P>Current Assignee (The listed assignees may be inaccurate. Google has not performed a legal analysis and makes no representation or warranty as to the accuracy of the list.)</P><P>Priority date (The priority date is an assumption and is not a legal conclusion. Google has not performed a legal analysis and makes no representation as to the accuracy of the date listed.)</P><H2>Links</H2><H2>Images</H2><H2>Classifications</H2><UL><LI>G ‚Äî PHYSICS\\nG06 ‚Äî COMPUTING OR CALCULATING; COUNTING\\nG06F ‚Äî ELECTRIC DIGITAL DATA PROCESSING\\nG06F40/00 ‚Äî Handling natural language data\\nG06F40/30 ‚Äî Semantic analysis\\nG‚ÄîPHYSICS  G06‚ÄîCOMPUTING OR CALCULATING; COUNTING  G06F‚ÄîELECTRIC DIGITAL DATA PROCESSING  G06F16/00‚ÄîInformation retrieval; Database structures therefor; File system structures therefor  G06F16/30‚ÄîInformation retrieval; Database structures therefor; File system structures therefor of unstructured textual data  G06F16/33‚ÄîQuerying  G06F16/3331‚ÄîQuery processing  G06F16/334‚ÄîQuery execution  G06F16/3344‚ÄîQuery execution using natural language analysis\\nG ‚Äî PHYSICS\\nG06 ‚Äî COMPUTING OR CALCULATING; COUNTING\\nG06F ‚Äî ELECTRIC DIGITAL DATA PROCESSING\\nG06F16/00 ‚Äî Information retrieval; Database structures therefor; File system structures therefor\\nG06F16/30 ‚Äî Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data\\nG06F16/33 ‚Äî Querying\\nG06F16/3331 ‚Äî Query processing\\nG06F16/334 ‚Äî Query execution\\nG06F16/3344 ‚Äî Query execution using natural language analysis\\nG‚ÄîPHYSICS  G06‚ÄîCOMPUTING OR CALCULATING; COUNTING  G06F‚ÄîELECTRIC DIGITAL DATA PROCESSING  G06F16/00‚ÄîInformation retrieval; Database structures therefor; File system structures therefor  G06F16/30‚ÄîInformation retrieval; Database structures therefor; File system structures therefor of unstructured textual data  G06F16/33‚ÄîQuerying  G06F16/332‚ÄîQuery formulation  G06F16/3329‚ÄîNatural language query formulation\\nG ‚Äî PHYSICS\\nG06 ‚Äî COMPUTING OR CALCULATING; COUNTING\\nG06F ‚Äî ELECTRIC DIGITAL DATA PROCESSING\\nG06F16/00 ‚Äî Information retrieval; Database structures therefor; File system structures therefor\\nG06F16/30 ‚Äî Information retrieval; Database structures therefor; File system structures therefor of unstructured textual data\\nG06F16/33 ‚Äî Querying\\nG06F16/332 ‚Äî Query formulation\\nG06F16/3329 ‚Äî Natural language query formulation\\nG‚ÄîPHYSICS  G06‚ÄîCOMPUTING OR CALCULATING; COUNTING  G06F‚ÄîELECTRIC DIGITAL DATA PROCESSING  G06F16/00‚ÄîInformation retrieval; Database structures therefor; File system structures therefor  G06F16/30‚ÄîInformation retrieval; Database structures therefor; File system structures therefor of unstructured textual data  G06F16/33‚ÄîQuerying  G06F16/3331‚ÄîQuery processing  G06F16/3332‚ÄîQuery translation  G06F16/3334‚ÄîSelection or weighting of terms from queries, incl\", \"url\": \"https://patents.google.com/patent/US11822588B2/en\", \"pdf_url\": \"https://patentimages.storage.googleapis.com/65/d9/4a/5476603fdad3e5/US11822588.pdf\", \"source\": \"web\", \"published_date\": \"N/A\", \"score_bm25\": 0.0}, {\"paper_id\": \"2506.00425v1\", \"title\": \"Inter-Passage Verification for Multi-evidence Multi-answer QA\", \"authors\": [\"Bingsen Chen\", \"Shengjie Wang\", \"Xi Ye\", \"Chen Zhao\"], \"abstract\": \"Multi-answer question answering (QA), where questions can have many valid answers, presents a significant challenge for existing retrieval-augmented generation-based QA systems, as these systems struggle to retrieve and then synthesize a large number of evidence passages. To tackle these challenges, we propose a new multi-answer QA framework -- Retrieval-augmented Independent Reading with Inter-passage Verification (RI$^2$VER). Our framework retrieves a large set of passages and processes each passage individually to generate an initial high-recall but noisy answer set. Then we propose a new inter-passage verification pipeline that validates every candidate answer through (1) Verification Question Generation, (2) Gathering Additional Evidence, and (3) Verification with inter-passage synthesis. Evaluations on the QAMPARI and RoMQA datasets demonstrate that our framework significantly outperforms existing baselines across various model sizes, achieving an average F1 score improvement of 11.17%. Further analysis validates that our inter-passage verification pipeline enables our framework to be particularly beneficial for questions requiring multi-evidence synthesis.\", \"url\": \"http://arxiv.org/abs/2506.00425v1\", \"pdf_url\": \"https://arxiv.org/pdf/2506.00425v1\", \"source\": \"arxiv\", \"published_date\": \"2025-05-31T07:03:52Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2509.14635v1\", \"title\": \"SWE-QA: Can Language Models Answer Repository-level Code Questions?\", \"authors\": [\"Weihan Peng\", \"Yuling Shi\", \"Yuhang Wang\", \"Xinyun Zhang\", \"Beijun Shen\", \"Xiaodong Gu\"], \"abstract\": \"Understanding and reasoning about entire software repositories is an essential capability for intelligent software engineering tools. While existing benchmarks such as CoSQA and CodeQA have advanced the field, they predominantly focus on small, self-contained code snippets. These setups fail to capture the complexity of real-world repositories, where effective understanding and reasoning often require navigating multiple files, understanding software architecture, and grounding answers in long-range code dependencies. In this paper, we present SWE-QA, a repository-level code question answering (QA) benchmark designed to facilitate research on automated QA systems in realistic code environments. SWE-QA involves 576 high-quality question-answer pairs spanning diverse categories, including intention understanding, cross-file reasoning, and multi-hop dependency analysis. To construct SWE-QA, we first crawled 77,100 GitHub issues from 11 popular repositories. Based on an analysis of naturally occurring developer questions extracted from these issues, we developed a two-level taxonomy of repository-level questions and constructed a set of seed questions for each category. For each category, we manually curated and validated questions and collected their corresponding answers. As a prototype application, we further develop SWE-QA-Agent, an agentic framework in which LLM agents reason and act to find answers automatically. We evaluate six advanced LLMs on SWE-QA under various context augmentation strategies. Experimental results highlight the promise of LLMs, particularly our SWE-QA-Agent framework, in addressing repository-level QA, while also revealing open challenges and pointing to future research directions.\", \"url\": \"http://arxiv.org/abs/2509.14635v1\", \"pdf_url\": \"https://arxiv.org/pdf/2509.14635v1\", \"source\": \"arxiv\", \"published_date\": \"2025-09-18T05:25:32Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2509.22490v1\", \"title\": \"JGU Mainz's Submission to the WMT25 Shared Task on LLMs with Limited Resources for Slavic Languages: MT and QA\", \"authors\": [\"Hossain Shaikh Saadi\", \"Minh Duc Bui\", \"Mario Sanz-Guerrero\", \"Katharina von der Wense\"], \"abstract\": \"This paper presents the JGU Mainz submission to the WMT25 Shared Task on LLMs with Limited Resources for Slavic Languages: Machine Translation and Question Answering, focusing on Ukrainian, Upper Sorbian, and Lower Sorbian. For each language, we jointly fine-tune a Qwen2.5-3B-Instruct model for both tasks with parameter-efficient finetuning. Our pipeline integrates additional translation and multiple-choice question answering (QA) data. For Ukrainian QA, we further use retrieval-augmented generation. We also apply ensembling for QA in Upper and Lower Sorbian. Experiments show that our models outperform the baseline on both tasks.\", \"url\": \"http://arxiv.org/abs/2509.22490v1\", \"pdf_url\": \"https://arxiv.org/pdf/2509.22490v1\", \"source\": \"arxiv\", \"published_date\": \"2025-09-26T15:35:38Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2210.15133v1\", \"title\": \"Retrieval Oriented Masking Pre-training Language Model for Dense Passage Retrieval\", \"authors\": [\"Dingkun Long\", \"Yanzhao Zhang\", \"Guangwei Xu\", \"Pengjun Xie\"], \"abstract\": \"Pre-trained language model (PTM) has been shown to yield powerful text representations for dense passage retrieval task. The Masked Language Modeling (MLM) is a major sub-task of the pre-training process. However, we found that the conventional random masking strategy tend to select a large number of tokens that have limited effect on the passage retrieval task (e,g. stop-words and punctuation). By noticing the term importance weight can provide valuable information for passage retrieval, we hereby propose alternative retrieval oriented masking (dubbed as ROM) strategy where more important tokens will have a higher probability of being masked out, to capture this straightforward yet essential information to facilitate the language model pre-training process. Notably, the proposed new token masking method will not change the architecture and learning objective of original PTM. Our experiments verify that the proposed ROM enables term importance information to help language model pre-training thus achieving better performance on multiple passage retrieval benchmarks.\", \"url\": \"http://arxiv.org/abs/2210.15133v1\", \"pdf_url\": \"https://arxiv.org/pdf/2210.15133v1\", \"source\": \"arxiv\", \"published_date\": \"2022-10-27T02:43:48Z\", \"score_bm25\": 0.0}], \"summarization for knowledge extraction\": [{\"paper_id\": \"2403.02901v2\", \"title\": \"A Comprehensive Survey on Automatic Text Summarization with Exploration of LLM-Based Methods\", \"authors\": [], \"abstract\": \"<H1>A Comprehensive Survey on Automatic Text Summarization with Exploration of LLM-Based Methods</H1><H6>Abstract</H6><P>The exponential growth of textual content on the internet, alongside vast archives of news articles, scientific papers, legal documents, and other domains, has made Automatic Text Summarization (ATS) increasingly important. ATS aims to create concise and accurate summaries, significantly reducing the effort required to process large volumes of text. Originating in the 1950s, ATS has evolved through several technical shifts, moving from statistical models to machine learning and deep learning approaches, and more recently, to pre-trained models. Previous surveys have focused on conventional ATS methods, which are often constrained by predefined generative paradigms. However, the advent of Large Language Models (LLMs) has introduced a paradigm-flexible approach to summarization. With their superior generative capabilities, in-context learning, and few-shot learning abilities, LLMs have demonstrated remarkable improvements in coherence, fluency, and overall summarization quality. In this survey, we provide a comprehensive review of both conventional ATS approaches and the latest advancements in LLM-based methods. Additionally, we propose a novel retrieval algorithm designed to efficiently collect relevant papers, which could be adapted for use in other types of surveys. Our contributions are threefold: (1) offering an up-to-date survey of ATS, (2) reviewing the latest LLM-based summarization methods, and (3) introducing a new retrieval algorithm for paper collection.</P><H6>keywords:</H6><H2>1 Introduction</H2><P>The exponential growth of the World Wide Web has led to an overwhelming surge in textual data across various domains, including news articles, websites, user reviews, blogs, and social media. Additionally, vast text archives are available in specialized fields such as books, scholarly papers, legal documents, and biomedical records. This rapid expansion of data has far outpaced the ability of individuals to search, read, and process all relevant information. To address this challenge, the field of Automatic Text Summarization (ATS) has emerged, leveraging methods from multiple research areas such as Natural Language Processing (NLP) and Information Retrieval (IR), alongside advanced techniques like Machine Learning (ML), Deep Learning (DL), and Large Language Models (LLMs). ATS enables users to efficiently grasp the key ideas within texts, significantly reducing the time and effort required for document reading and comprehension.</P><P>Historically, ATS has undergone several distinct eras of development. In the pre-2000s, early approaches were primarily statistical, leveraging surface-level features such as word frequency and sentence position to generate summaries [1, 2, 3]. From the 2000s to 2010s, machine learning and shallow neural network-based methods emerged, automating the feature extraction process but still heav\", \"url\": \"https://arxiv.org/html/2403.02901v2\", \"pdf_url\": \"https://arxiv.org/pdf/2403.02901v2.pdf\", \"source\": \"web\", \"published_date\": \"N/A\", \"score_bm25\": 0.0}, {\"paper_id\": \"2402.12001\", \"title\": \"[2402.12001] A Survey on Extractive Knowledge Graph Summarization: Applications, Approaches, Evaluation, and Future Directions\", \"authors\": [], \"abstract\": \"<H1>Computer Science > Artificial Intelligence</H1><H1>A Survey on Extractive Knowledge Graph Summarization: Applications, Approaches, Evaluation, and Future Directions</H1><P>With the continuous growth of large Knowledge Graphs (KGs), extractive KG summarization becomes a trending task. Aiming at distilling a compact subgraph with condensed information, it facilitates various downstream KG-based tasks. In this survey paper, we are among the first to provide a systematic overview of its applications and define a taxonomy for existing methods from its interdisciplinary studies. Future directions are also laid out based on our extensive and comparative review.</P><TABLE><TR><TD>Comments:</TD><TD>9 pages, 13 figures, submitted to the IJCAI 2024 Survey Track</TD></TR><TR><TD>Subjects:</TD><TD>Artificial Intelligence (cs.AI); Databases (cs.DB); Information Retrieval (cs.IR); Social and Information Networks (cs.SI)</TD></TR><TR><TD>Cite as:</TD><TD>arXiv:2402.12001 [cs.AI]</TD></TR><TR><TD> </TD><TD>(or arXiv:2402.12001v1 [cs.AI] for this version)</TD></TR><TR><TD> </TD><TD>https://doi.org/10.48550/arXiv.2402.12001\\nFocus to learn more\\narXiv-issued DOI via DataCite</TD></TR></TABLE><H2>Submission history</H2><P>Bibliographic Explorer (What is the Explorer?)</P><P>Connected Papers (What is Connected Papers?)</P><P>Litmaps (What is Litmaps?)</P><P>scite Smart Citations (What are Smart Citations?)</P>\", \"url\": \"https://arxiv.org/abs/2402.12001\", \"pdf_url\": \"https://arxiv.org/pdf/2402.12001.pdf\", \"source\": \"web\", \"published_date\": \"N/A\", \"score_bm25\": 0.0}, {\"paper_id\": \"2204.11190\", \"title\": \"Knowledge-aware Document Summarization: A Survey of Knowledge, Embedding Methods and Architectures\", \"authors\": [], \"abstract\": \"<H1>Knowledge-aware Document Summarization: A Survey of Knowledge, Embedding Methods and Architectures</H1><P>Yutong Qua, , Wei Emma Zhanga, , Jian Yangb, Lingfei Wuc, Jia Wub</P><P>aSchool of Computer Science, The University of Adelaide, SA 5005, Australia bSchool of Computing, Macquarie University, NSW 2109, Australia cJD.COM Silicon Valley Research Center, CA 94043, USA</P><H3>Abstract</H3><P>Knowledge-aware methods have boosted a range of natural language processing applications over the last decades. With the gathered momentum, knowledge recently has been pumped into enormous attention in document summariza-tion, one of natural language processing applications. Previous works reported that knowledge-embedded document summarizers excel at generating superior digests, especially in terms of informativeness, coherence, and fact consistency. This paper pursues to present the</P><P>rst systematic survey for the state-of-the-art methodologies that embed knowledge into document summarizers. Particularly, we propose novel taxonomies to recapitulate knowledge and knowledge embed-dings under the document summarization view. We further explore how em-beddings are generated in embedding learning architectures of document sum-marization models, especially of deep learning models. At last, we discuss the challenges of this topic and future directions.</P><H3>Keywords:</H3><P>Knowledge, Knowledge embedding, Document summarization</P><P>2010 MSC: 00-01, 99-00</P><P>Corresponding author</P><P>Email addresses: yutong.qu@adelaide.edu.au (Yutong Qu), wei.e.zhang@adelaide.edu.au (Wei Emma Zhang)</P><P>Preprint submitted to Knowledge-Based Systems</P><P>July 12, 2022</P><H3>1. Introduction</H3><P>With the exponential burst of textual data, demands in condensing volu-minous text contents have been ubiquitous, bringing document summarization one of the most immensely researched</P><P>elds in Natural Language Processing (NLP). Document Summarization (DS) aims to generate an abridged version of single or multiple topic-related texts as concise and coherent as possible while preserving the salient and factually consistent information [1]. The document summarization task with a single input document is known as the Single Docu-ment Summarization (SDS). By contrast, the Multi-Document Summarization (MDS) task emphasizes synthesizing a large number of topic-related documents to generate a compressed summary from various times and perspectives. In addition, there are two general methods in document summarization: 1) the Extractive Document Summarization (EDS) method respects the lexicon of the original text, regarding the summary formation is verbatim by key words and phrases selected from the source corpus; and 2) the Abstractive Document Sum-marization (ADS) method respects the semantics of the original text, regarding the summary construction is by rephrasing texts according to the comprehension of text substances. Generally, a document summarization model is to achiev\", \"url\": \"https://arxiv.org/pdf/2204.11190.pdf\", \"pdf_url\": \"https://arxiv.org/pdf/2204.11190.pdf\", \"source\": \"web\", \"published_date\": \"N/A\", \"score_bm25\": 0.0}, {\"paper_id\": \"2306.08302v3\", \"title\": \"Unifying Large Language Models and Knowledge Graphs: A Roadmap\", \"authors\": [\"Shirui Pan\", \"Linhao Luo\", \"Yufei Wang\", \"Chen Chen\", \"Jiapu Wang\", \"Xindong Wu\"], \"abstract\": \"Large language models (LLMs), such as ChatGPT and GPT4, are making new waves in the field of natural language processing and artificial intelligence, due to their emergent ability and generalizability. However, LLMs are black-box models, which often fall short of capturing and accessing factual knowledge. In contrast, Knowledge Graphs (KGs), Wikipedia and Huapu for example, are structured knowledge models that explicitly store rich factual knowledge. KGs can enhance LLMs by providing external knowledge for inference and interpretability. Meanwhile, KGs are difficult to construct and evolving by nature, which challenges the existing methods in KGs to generate new facts and represent unseen knowledge. Therefore, it is complementary to unify LLMs and KGs together and simultaneously leverage their advantages. In this article, we present a forward-looking roadmap for the unification of LLMs and KGs. Our roadmap consists of three general frameworks, namely, 1) KG-enhanced LLMs, which incorporate KGs during the pre-training and inference phases of LLMs, or for the purpose of enhancing understanding of the knowledge learned by LLMs; 2) LLM-augmented KGs, that leverage LLMs for different KG tasks such as embedding, completion, construction, graph-to-text generation, and question answering; and 3) Synergized LLMs + KGs, in which LLMs and KGs play equal roles and work in a mutually beneficial way to enhance both LLMs and KGs for bidirectional reasoning driven by both data and knowledge. We review and summarize existing efforts within these three frameworks in our roadmap and pinpoint their future research directions.\", \"url\": \"http://arxiv.org/abs/2306.08302v3\", \"pdf_url\": \"https://arxiv.org/pdf/2306.08302v3\", \"source\": \"arxiv\", \"published_date\": \"2023-06-14T07:15:26Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"1908.02146v2\", \"title\": \"Knowledge Query Network: How Knowledge Interacts with Skills\", \"authors\": [\"Jinseok Lee\", \"Dit-Yan Yeung\"], \"abstract\": \"Knowledge Tracing (KT) is to trace the knowledge of students as they solve a sequence of problems represented by their related skills. This involves abstract concepts of students' states of knowledge and the interactions between those states and skills. Therefore, a KT model is designed to predict whether students will give correct answers and to describe such abstract concepts. However, existing methods either give relatively low prediction accuracy or fail to explain those concepts intuitively. In this paper, we propose a new model called Knowledge Query Network (KQN) to solve these problems. KQN uses neural networks to encode student learning activities into knowledge state and skill vectors, and models the interactions between the two types of vectors with the dot product. Through this, we introduce a novel concept called \\\\textit{probabilistic skill similarity} that relates the pairwise cosine and Euclidean distances between skill vectors to the odds ratios of the corresponding skills, which makes KQN interpretable and intuitive.\\n  On four public datasets, we have carried out experiments to show the following: 1. KQN outperforms all the existing KT models based on prediction accuracy. 2. The interaction between the knowledge state and skills can be visualized for interpretation. 3. Based on probabilistic skill similarity, a skill domain can be analyzed with clustering using the distances between the skill vectors of KQN. 4. For different values of the vector space dimensionality, KQN consistently exhibits high prediction accuracy and a strong positive correlation between the distance matrices of the skill vectors.\", \"url\": \"http://arxiv.org/abs/1908.02146v2\", \"pdf_url\": \"https://arxiv.org/pdf/1908.02146v2\", \"source\": \"arxiv\", \"published_date\": \"2019-08-03T14:33:10Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2311.17771v1\", \"title\": \"Supervising the Centroid Baseline for Extractive Multi-Document Summarization\", \"authors\": [\"Sim√£o Gon√ßalves\", \"Gon√ßalo Correia\", \"Diogo Pernes\", \"Afonso Mendes\"], \"abstract\": \"The centroid method is a simple approach for extractive multi-document summarization and many improvements to its pipeline have been proposed. We further refine it by adding a beam search process to the sentence selection and also a centroid estimation attention model that leads to improved results. We demonstrate this in several multi-document summarization datasets, including in a multilingual scenario.\", \"url\": \"http://arxiv.org/abs/2311.17771v1\", \"pdf_url\": \"https://arxiv.org/pdf/2311.17771v1\", \"source\": \"arxiv\", \"published_date\": \"2023-11-29T16:11:45Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2505.22950\", \"title\": \"[2505.22950] StrucSum: Graph-Structured Reasoning for Long Document Extractive Summarization with LLMs\", \"authors\": [], \"abstract\": \"<H1>Computer Science > Computation and Language</H1><H1>StrucSum: Graph-Structured Reasoning for Long Document Extractive Summarization with LLMs</H1><P>Large language models (LLMs) have shown strong performance in zero-shot summarization, but often struggle to model document structure and identify salient information in long texts. In this work, we introduce StrucSum, a training-free prompting framework that enhances LLM reasoning through sentence-level graph structures. StrucSum injects structural signals into prompts via three targeted strategies: Neighbor-Aware Prompting (NAP) for local context, Centrality-Aware Prompting (CAP) for importance estimation, and Centrality-Guided Masking (CGM) for efficient input reduction. Experiments on ArXiv, PubMed, and Multi-News demonstrate that StrucSum consistently improves both summary quality and factual consistency over unsupervised baselines and vanilla prompting. Notably, on ArXiv, it boosts FactCC and SummaC by 19.2 and 9.7 points, indicating stronger alignment between summaries and source content. These findings suggest that structure-aware prompting is a simple yet effective approach for zero-shot extractive summarization with LLMs, without any training or task-specific tuning.</P><TABLE><TR><TD>Subjects:</TD><TD>Computation and Language (cs.CL)</TD></TR><TR><TD>Cite as:</TD><TD>arXiv:2505.22950 [cs.CL]</TD></TR><TR><TD> </TD><TD>(or arXiv:2505.22950v1 [cs.CL] for this version)</TD></TR><TR><TD> </TD><TD>https://doi.org/10.48550/arXiv.2505.22950\\nFocus to learn more\\narXiv-issued DOI via DataCite</TD></TR></TABLE><H2>Submission history</H2><H1>Bibliographic and Citation Tools</H1><P>Bibliographic Explorer (What is the Explorer?)</P><P>Connected Papers (What is Connected Papers?)</P><P>Litmaps (What is Litmaps?)</P><P>scite Smart Citations (What are Smart Citations?)</P>\", \"url\": \"https://arxiv.org/abs/2505.22950\", \"pdf_url\": \"https://arxiv.org/pdf/2505.22950.pdf\", \"source\": \"web\", \"published_date\": \"N/A\", \"score_bm25\": 0.0}, {\"paper_id\": \"2509.20461v1\", \"title\": \"Document Summarization with Conformal Importance Guarantees\", \"authors\": [\"Bruce Kuwahara\", \"Chen-Yuan Lin\", \"Xiao Shi Huang\", \"Kin Kwan Leung\", \"Jullian Arta Yapeter\", \"Ilya Stanevich\", \"Felipe Perez\", \"Jesse C. Cresswell\"], \"abstract\": \"Automatic summarization systems have advanced rapidly with large language models (LLMs), yet they still lack reliable guarantees on inclusion of critical content in high-stakes domains like healthcare, law, and finance. In this work, we introduce Conformal Importance Summarization, the first framework for importance-preserving summary generation which uses conformal prediction to provide rigorous, distribution-free coverage guarantees. By calibrating thresholds on sentence-level importance scores, we enable extractive document summarization with user-specified coverage and recall rates over critical content. Our method is model-agnostic, requires only a small calibration set, and seamlessly integrates with existing black-box LLMs. Experiments on established summarization benchmarks demonstrate that Conformal Importance Summarization achieves the theoretically assured information coverage rate. Our work suggests that Conformal Importance Summarization can be combined with existing techniques to achieve reliable, controllable automatic summarization, paving the way for safer deployment of AI summarization tools in critical applications. Code is available at https://github.com/layer6ai-labs/conformal-importance-summarization.\", \"url\": \"http://arxiv.org/abs/2509.20461v1\", \"pdf_url\": \"https://arxiv.org/pdf/2509.20461v1\", \"source\": \"arxiv\", \"published_date\": \"2025-09-24T18:12:59Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"1606.07965v1\", \"title\": \"Summarizing Decisions in Spoken Meetings\", \"authors\": [\"Lu Wang\", \"Claire Cardie\"], \"abstract\": \"This paper addresses the problem of summarizing decisions in spoken meetings: our goal is to produce a concise {\\\\it decision abstract} for each meeting decision. We explore and compare token-level and dialogue act-level automatic summarization methods using both unsupervised and supervised learning frameworks. In the supervised summarization setting, and given true clusterings of decision-related utterances, we find that token-level summaries that employ discourse context can approach an upper bound for decision abstracts derived directly from dialogue acts. In the unsupervised summarization setting,we find that summaries based on unsupervised partitioning of decision-related utterances perform comparably to those based on partitions generated using supervised techniques (0.22 ROUGE-F1 using LDA-based topic models vs. 0.23 using SVMs).\", \"url\": \"http://arxiv.org/abs/1606.07965v1\", \"pdf_url\": \"https://arxiv.org/pdf/1606.07965v1\", \"source\": \"arxiv\", \"published_date\": \"2016-06-25T20:45:14Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2110.01159v2\", \"title\": \"TLDR9+: A Large Scale Resource for Extreme Summarization of Social Media Posts\", \"authors\": [\"Sajad Sotudeh\", \"Hanieh Deilamsalehy\", \"Franck Dernoncourt\", \"Nazli Goharian\"], \"abstract\": \"Recent models in developing summarization systems consist of millions of parameters and the model performance is highly dependent on the abundance of training data. While most existing summarization corpora contain data in the order of thousands to one million, generation of large-scale summarization datasets in order of couple of millions is yet to be explored. Practically, more data is better at generalizing the training patterns to unseen data. In this paper, we introduce TLDR9+ -- a large-scale summarization dataset -- containing over 9 million training instances extracted from Reddit discussion forum (https://github.com/sajastu/reddit_collector). This dataset is specifically gathered to perform extreme summarization (i.e., generating one-sentence summary in high compression and abstraction) and is more than twice larger than the previously proposed dataset. We go one step further and with the help of human annotations, we distill a more fine-grained dataset by sampling High-Quality instances from TLDR9+ and call it TLDRHQ dataset. We further pinpoint different state-of-the-art summarization models on our proposed datasets.\", \"url\": \"http://arxiv.org/abs/2110.01159v2\", \"pdf_url\": \"https://arxiv.org/pdf/2110.01159v2\", \"source\": \"arxiv\", \"published_date\": \"2021-10-04T02:40:55Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"1909.13705v1\", \"title\": \"A Closer Look at Data Bias in Neural Extractive Summarization Models\", \"authors\": [\"Ming Zhong\", \"Danqing Wang\", \"Pengfei Liu\", \"Xipeng Qiu\", \"Xuanjing Huang\"], \"abstract\": \"In this paper, we take stock of the current state of summarization datasets and explore how different factors of datasets influence the generalization behaviour of neural extractive summarization models. Specifically, we first propose several properties of datasets, which matter for the generalization of summarization models. Then we build the connection between priors residing in datasets and model designs, analyzing how different properties of datasets influence the choices of model structure design and training methods. Finally, by taking a typical dataset as an example, we rethink the process of the model design based on the experience of the above analysis. We demonstrate that when we have a deep understanding of the characteristics of datasets, a simple approach can bring significant improvements to the existing state-of-the-art model.A\", \"url\": \"http://arxiv.org/abs/1909.13705v1\", \"pdf_url\": \"https://arxiv.org/pdf/1909.13705v1\", \"source\": \"arxiv\", \"published_date\": \"2019-09-30T13:55:10Z\", \"score_bm25\": 0.0}, {\"paper_id\": null, \"title\": \"https://link.springer.com/content/pdf/10.1007/s10772-025-10215-y.pdf\", \"authors\": [], \"abstract\": \"<P>https://doi.org/10.1007/s10772-025-10215-y</P><P>CASE STUDY</P><H1>A survey of automatic text summarization: concepts, advances and future prospects</H1><H3>Chengyao  Lv1  ¬∑ Yiwen  Tang2  ¬∑ Lian  Ao1  ¬∑ Yanxia  Huang2  ¬∑ Simin  Zhang2  ¬∑ Junqing  Fan2  ¬∑ Wei  Han2</H3><P>Received: 11 March 2025 / Accepted: 26 August 2025 / Published online: 2 October 2025 The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2025</P><H3>Abstract</H3><P>Automatic text summarization has become essential for managing the explosive growth of textual information. While several surveys exist, most concentrate on studies prior to 2019, leaving a gap in systematically reviewing the rapid advances in deep learning‚Äìdriven summarization. This paper addresses this gap by providing a comprehensive review of challenges, methodologies, and emerging directions in automatic text summarization. We categorize summarization techniques into six dimensions: Input Document Number, Summary Language, Output Requirements, Summary Content, Domain Applicability, and Semantic Relationship, with particular emphasis on extractive and abstractive methods. Specifi-cally, we synthesize nine representative extractive approaches and three abstractive approaches developed over the past seventy years, and present performance comparisons across multiple datasets and evaluation metrics. Finally, we identify seven promising future research avenues. This review offers systematic references and practical guidance for advancing research and innovation in automatic text summarization.</P><P>Keywords Automatic text summarization ¬∑ Deep learning ¬∑ Extractive summarization ¬∑ Abstractive summarization</P><P>Lian Ao lianao@cug.edu.cn</P><P>Chengyao Lv 83520583@qq.com</P><P>Yiwen Tang 1343070165@qq.com</P><P>Yanxia Huang huangyx@cug.edu.cn</P><P>Simin Zhang simin.z.cn@icloud.com</P><P>Junqing Fan fanjq@cug.edu.cn</P><P>Wei Han weihan@cug.edu.cn</P><OL><LI><P>School of Foreign Language, China University of Geosciences, Wuhan, China</P></LI><LI><P>School of Computer Science, China University of Geosciences, Wuhan, China</P></LI></OL><H3>Introduction</H3><P>With the widespread adoption of the Internet and advance-ments in mobile technology, people are encountering an unprecedented increase in the amount of textual informa-tion available online. While this abundance of information brings opportunities, it also presents challenges since text data is inherently unstructured. People often spend consid-erable time manually reviewing documents one by one to locate or filter specific information they need, making the process both time-consuming and inefficient. Given the large volumes of lengthy documents, text summarization has become a crucial tool for helping users quickly under-stand the main content of each document. A summary, serv-ing as a concise yet accurate representation of the original document, significantly reduces the time and effort required to process la\", \"url\": \"https://link.springer.com/content/pdf/10.1007/s10772-025-10215-y.pdf\", \"pdf_url\": \"https://link.springer.com/content/pdf/10.1007/s10772-025-10215-y.pdf\", \"source\": \"web\", \"published_date\": \"N/A\", \"score_bm25\": 0.0}, {\"paper_id\": \"2010.06792v2\", \"title\": \"Summarizing Text on Any Aspects: A Knowledge-Informed Weakly-Supervised Approach\", \"authors\": [\"Bowen Tan\", \"Lianhui Qin\", \"Eric P. Xing\", \"Zhiting Hu\"], \"abstract\": \"Given a document and a target aspect (e.g., a topic of interest), aspect-based abstractive summarization attempts to generate a summary with respect to the aspect. Previous studies usually assume a small pre-defined set of aspects and fall short of summarizing on other diverse topics. In this work, we study summarizing on arbitrary aspects relevant to the document, which significantly expands the application of the task in practice. Due to the lack of supervision data, we develop a new weak supervision construction method and an aspect modeling scheme, both of which integrate rich external knowledge sources such as ConceptNet and Wikipedia. Experiments show our approach achieves performance boosts on summarizing both real and synthetic documents given pre-defined or arbitrary aspects.\", \"url\": \"http://arxiv.org/abs/2010.06792v2\", \"pdf_url\": \"https://arxiv.org/pdf/2010.06792v2\", \"source\": \"arxiv\", \"published_date\": \"2020-10-14T03:20:46Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"1805.06266v2\", \"title\": \"A Unified Model for Extractive and Abstractive Summarization using Inconsistency Loss\", \"authors\": [\"Wan-Ting Hsu\", \"Chieh-Kai Lin\", \"Ming-Ying Lee\", \"Kerui Min\", \"Jing Tang\", \"Min Sun\"], \"abstract\": \"We propose a unified model combining the strength of extractive and abstractive summarization. On the one hand, a simple extractive model can obtain sentence-level attention with high ROUGE scores but less readable. On the other hand, a more complicated abstractive model can obtain word-level dynamic attention to generate a more readable paragraph. In our model, sentence-level attention is used to modulate the word-level attention such that words in less attended sentences are less likely to be generated. Moreover, a novel inconsistency loss function is introduced to penalize the inconsistency between two levels of attentions. By end-to-end training our model with the inconsistency loss and original losses of extractive and abstractive models, we achieve state-of-the-art ROUGE scores while being the most informative and readable summarization on the CNN/Daily Mail dataset in a solid human evaluation.\", \"url\": \"http://arxiv.org/abs/1805.06266v2\", \"pdf_url\": \"https://arxiv.org/pdf/1805.06266v2\", \"source\": \"arxiv\", \"published_date\": \"2018-05-16T12:17:09Z\", \"score_bm25\": 0.0}, {\"paper_id\": \"2310.10981v3\", \"title\": \"Instructive Dialogue Summarization with Query Aggregations\", \"authors\": [\"Bin Wang\", \"Zhengyuan Liu\", \"Nancy F. Chen\"], \"abstract\": \"Conventional dialogue summarization methods directly generate summaries and do not consider user's specific interests. This poses challenges in cases where the users are more focused on particular topics or aspects. With the advancement of instruction-finetuned language models, we introduce instruction-tuning to dialogues to expand the capability set of dialogue summarization models. To overcome the scarcity of instructive dialogue summarization data, we propose a three-step approach to synthesize high-quality query-based summarization triples. This process involves summary-anchored query generation, query filtering, and query-based summary generation. By training a unified model called InstructDS (Instructive Dialogue Summarization) on three summarization datasets with multi-purpose instructive triples, we expand the capability of dialogue summarization models. We evaluate our method on four datasets, including dialogue summarization and dialogue reading comprehension. Experimental results show that our approach outperforms the state-of-the-art models and even models with larger sizes. Additionally, our model exhibits higher generalizability and faithfulness, as confirmed by human subjective evaluations.\", \"url\": \"http://arxiv.org/abs/2310.10981v3\", \"pdf_url\": \"https://arxiv.org/pdf/2310.10981v3\", \"source\": \"arxiv\", \"published_date\": \"2023-10-17T04:03:00Z\", \"score_bm25\": 0.0}]}"