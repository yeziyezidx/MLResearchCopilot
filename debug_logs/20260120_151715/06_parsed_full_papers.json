"{\"total\": 68, \"successful\": 62, \"failed\": 6, \"papers\": {\"22fcc91b\": {\"success\": true, \"paper_id\": \"22fcc91b\", \"url\": \"https://arxiv.org/pdf/2410.11315v1.pdf\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_22fcc91b.pdf\", \"extracted_info\": {\"title\": \"SEER: Model-Based Evidence Extraction with Lambda Preference Optimization for Retrieval-Augmented Generation\", \"authors\": [\"Not explicitly provided in given text\"], \"abstract\": \"Recent studies in Retrieval-Augmented Generation (RAG) have investigated extracting evidence from retrieved contexts to improve generation quality. Existing methods heavily rely on heuristic-based augmentation, which suffers from poor generalization due to hand-crafted context filters. This work proposes a model-based augmentation method that improves RAG performance by enhancing the faithfulness, helpfulness, and conciseness of extracted evidence, while reducing computational costs.\", \"methodology\": \"The proposed method, SEER, consists of three key stages: (1) Evidence Extraction Stage, replacing heuristic-based augmentation with a model-based approach; (2) Weighting Oracle Scores using a listwise-aware Lambda Preference Optimization (LPO) algorithm, which incorporates ranking position signals into preference learning; (3) Evidence Alignment and Optimization using expert-assessed preferences to fine-tune the extractor. SEER is evaluated on three benchmark QA datasets against multiple baselines, including heuristic-based and no-evidence methods.\", \"results\": \"Experiments show SEER consistently outperforms state-of-the-art baselines such as FILCO and heuristic-based augmentation methods. On average, SEER improves QA accuracy by 2.58% over the ‘Full’ method while reducing evidence length. SEER achieves higher faithfulness, helpfulness, and conciseness scores compared to baselines, with aligned models showing better generation stability. Ablation studies confirm that deduplication and coverage operations are essential for optimal performance.\", \"conclusion\": \"Key contributions: (1) Introduced SEER, a model-based evidence extraction framework for RAG, eliminating reliance on heuristic-based augmentation; (2) Proposed Lambda Preference Optimization (LPO) to integrate ranking position signals into preference learning; (3) Demonstrated significant improvements in QA accuracy, evidence quality, and computational efficiency across multiple benchmarks; (4) Provided ablation studies validating the necessity of core components; (5) Highlighted potential for scaling to larger models such as Llama2-70B.\", \"figures\": null, \"tables\": null}, \"citations\": [\"Vaibhav Adlakha, Parishad BehnamGhader, Xing Han\", \"Lu, Nicholas Meade, and Siva Reddy. 2023. Eval-\", \"following models for question answering. CoRR ,\", \"Yuntao Bai, Saurav Kadavath, Sandipan Kundu,\", \"Amanda Askell, Jackson Kernion, Andy Jones, Anna\", \"Chen, Anna Goldie, Azalia Mirhoseini, Cameron\", \"McKinnon, Carol Chen, Catherine Olsson, Christo-\", \"pher Olah, Danny Hernandez, Dawn Drain, Deep\", \"Ganguli, Dustin Li, Eli Tran-Johnson, Ethan Perez,\", \"Jamie Kerr, Jared Mueller, Jeffrey Ladish, Joshua\", \"Landau, Kamal Ndousse, Kamile Lukosiute, Liane\", \"Lovitt, Michael Sellitto, Nelson Elhage, Nicholas\", \"Schiefer, Noemí Mercado, Nova DasSarma, Robert\", \"Lasenby, Robin Larson, Sam Ringer, Scott John-\", \"ston, Shauna Kravec, Sheer El Showk, Stanislav Fort,\", \"Tamera Lanham, Timothy Telleen-Lawton, Tom Con-\", \"erly, Tom Henighan, Tristan Hume, Samuel R. Bow-\", \"man, Zac Hatfield-Dodds, Ben Mann, Dario Amodei,\", \"Nicholas Joseph, Sam McCandlish, Tom Brown, and\", \"from AI feedback. CoRR , abs/2212.08073.\", \"Christopher J. C. Burges, Robert Ragno, and Quoc Viet\", \"cessing Systems 19, Proceedings of the Twentieth\", \"ing Systems, Vancouver, British Columbia, Canada,\", \"December 4-7, 2006 , pages 193–200. MIT Press.\", \"Jifan Chen, Grace Kim, Aniruddh Sriram, Greg Dur-\", \"rett, and Eunsol Choi. 2023. Complex claim veri-\", \"fication with evidence retrieved in the wild. CoRR ,\", \"Hyung Won Chung, Le Hou, Shayne Longpre, Barret\", \"Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi\", \"Wang, Mostafa Dehghani, Siddhartha Brahma, et al.\", \"2024. Scaling instruction-finetuned language models.\", \"Journal of Machine Learning Research , 25(70):1–53.\", \"Yujuan Ding, Wenqi Fan, Liangbo Ning, Shijie Wang,\", \"Hengyun Li, Dawei Yin, Tat-Seng Chua, and Qing Li.\", \"2024. A survey on rag meets llms: Towards retrieval-\", \"Pinar Donmez, Krysta M. Svore, and Christopher J. C.\", \"ment in Information Retrieval, SIGIR 2009, Boston,\", \"MA, USA, July 19-23, 2009 , pages 460–467. ACM.\", \"Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia,\", \"Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Qianyu Guo,\", \"Meng Wang, and Haofen Wang. 2023. Retrieval-\", \"survey. CoRR , abs/2312.10997.Rick Groenendijk, Sezer Karaoglu, Theo Gevers, and\", \"on Applications of Computer Vision, WACV 2021,\", \"Waikoloa, HI, USA, January 3-8, 2021 , pages 1468–\", \"1477. IEEE.\", \"Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat,\", \"37th International Conference on Machine Learning,\", \"ICML 2020, 13-18 July 2020, Virtual Event , volume\", \"119 of Proceedings of Machine Learning Research ,\", \"Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan\", \"Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and\", \"Conference on Learning Representations, ICLR 2022,\", \"Virtual Event, April 25-29, 2022 . OpenReview.net.\", \"Manas Jain, Sriparna Saha, Pushpak Bhattacharyya,\", \"Gladvin Chinnadurai, and Manish Kumar Vatsa.\", \"2021. Natural answer generation: From factoid an-\", \"CoRR , abs/2112.03849.\", \"Huiqiang Jiang, Qianhui Wu, Xufang Luo, Dongsheng\", \"Li, Chin-Yew Lin, Yuqing Yang, and Lili Qiu. 2023a.\", \"CoRR , abs/2310.06839.\", \"Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun,\", \"Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie\", \"Callan, and Graham Neubig. 2023b. Active retrieval\", \"guage Processing, EMNLP 2023, Singapore, Decem-\", \"ber 6-10, 2023 , pages 7969–7992. Association for\", \"Jiajie Jin, Yutao Zhu, Yujia Zhou, and Zhicheng Dou.\", \"2024. BIDER: bridging knowledge inconsistency for\", \"evidence. CoRR , abs/2402.12174.\", \"Mandar Joshi, Eunsol Choi, Daniel S. Weld, and Luke\", \"the Association for Computational Linguistics, ACL\", \"2017, Vancouver, Canada, July 30 - August 4, Volume\", \"1: Long Papers , pages 1601–1611. Association for\", \"Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick\", \"S. H. Lewis, Ledell Wu, Sergey Edunov, Danqi Chen,\", \"ural Language Processing, EMNLP 2020, Online,\", \"November 16-20, 2020 , pages 6769–6781. Associa-\", \"Jaehyung Kim, Jaehyun Nam, Sangwoo Mo, Jongjin\", \"Park, Sang-Woo Lee, Minjoon Seo, Jung-Woo Ha,\", \"QA of llms. CoRR , abs/2404.13081.\", \"national Conference on Learning Representations,\", \"ICLR 2015, San Diego, CA, USA, May 7-9, 2015,\", \"SungHo Ko, Hyunjin Cho, Hyungjoo Chae, Jinyoung\", \"Yeo, and Dongha Lee. 2024. Evidence-focused fact\", \"question answering. CoRR , abs/2403.02966.\", \"trieval, 12th International Conference, SPIRE 2005,\", \"Buenos Aires, Argentina, November 2-4, 2005, Pro-\", \"ceedings , volume 3772 of Lecture Notes in Computer\", \"Science , pages 115–126. Springer.\", \"Tom Kwiatkowski, Jennimaria Palomaki, Olivia Red-\", \"field, Michael Collins, Ankur P. Parikh, Chris Alberti,\", \"Danielle Epstein, Illia Polosukhin, Jacob Devlin, Ken-\", \"ton Lee, Kristina Toutanova, Llion Jones, Matthew\", \"Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob\", \"Uszkoreit, Quoc Le, and Slav Petrov. 2019. Natu-\", \"research. Trans. Assoc. Comput. Linguistics , 7:452–\", \"466.\", \"Md. Tahmid Rahman Laskar, Mizanur Rahman, Is-\", \"rat Jahan, Enamul Hoque, and Jimmy Huang. 2023.\", \"pedia. CoRR , abs/2305.06147.\", \"Kenton Lee, Ming-Wei Chang, and Kristina Toutanova.\", \"2019. Latent retrieval for weakly supervised open do-\", \"guistics, ACL 2019, Florence, Italy, July 28- August\", \"2, 2019, Volume 1: Long Papers , pages 6086–6096.\", \"Patrick S. H. Lewis, Ethan Perez, Aleksandra Pik-\", \"tus, Fabio Petroni, Vladimir Karpukhin, Naman\", \"Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih,\", \"Tim Rocktäschel, Sebastian Riedel, and Douwe\", \"2020, NeurIPS 2020, December 6-12, 2020, virtual .\", \"Xian Li, Ping Yu, Chunting Zhou, Timo Schick, Luke\", \"Zettlemoyer, Omer Levy, Jason Weston, and Mike\", \"translation. CoRR , abs/2308.06259.\", \"Yucheng Li, Bo Dong, Frank Guerin, and Chenghua Lin.\", \"2023b. Compressing context to enhance inferenceefficiency of large language models. In Proceedings\", \"ural Language Processing, EMNLP 2023, Singapore,\", \"December 6-10, 2023 , pages 6342–6353. Association\", \"Yuxin Liang, Zhuoyang Song, Hao Wang, and Jiax-\", \"mitigation. CoRR , abs/2401.15449.\", \"Tianqi Liu, Zhen Qin, Junru Wu, Jiaming Shen, Misha\", \"Khalman, Rishabh Joshi, Yao Zhao, Mohammad\", \"Saleh, Simon Baumgartner, Jialu Liu, Peter J. Liu,\", \"ence optimization through learning-to-rank. CoRR ,\", \"Antoine Louis, Gijs van Dijck, and Gerasimos Spanakis.\", \"2024. Interpretable long-form legal question answer-\", \"Intelligence, AAAI 2024, Thirty-Sixth Conference\", \"on Innovative Applications of Artificial Intelligence,\", \"IAAI 2024, Fourteenth Symposium on Educational\", \"Advances in Artificial Intelligence, EAAI 2014, Febru-\", \"ary 20-27, 2024, Vancouver, Canada , pages 22266–\", \"22275. AAAI Press.\", \"Joshua Maynez, Shashi Narayan, Bernd Bohnet, and\", \"Computational Linguistics, ACL 2020, Online, July\", \"5-10, 2020 , pages 1906–1919. Association for Com-\", \"Sewon Min, Danqi Chen, Luke Zettlemoyer, and Han-\", \"ing. CoRR , abs/1911.03868.\", \"Vaishali Pal, Manish Shrivastava, and Irshad Bhat. 2019.\", \"New Frontiers in Summarization , pages 1–9, Hong\", \"Kong, China. Association for Computational Linguis-\", \"Rafael Rafailov, Archit Sharma, Eric Mitchell, Christo-\", \"pher D. Manning, Stefano Ermon, and Chelsea Finn.\", \"2023. Direct preference optimization: Your language\", \"tems 2023, NeurIPS 2023, New Orleans, LA, USA,\", \"December 10 - 16, 2023 .\", \"Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay,\", \"Amnon Shashua, Kevin Leyton-Brown, and Yoav\", \"guage models. CoRR , abs/2302.00083.\", \"Hannah Rashkin, David Reitter, Gaurav Singh Tomar,\", \"Language Processing, ACL/IJCNLP 2021, (Volume 1:\", \"Long Papers), Virtual Event, August 1-6, 2021 , pages\", \"704–718. Association for Computational Linguistics.\", \"Parth Sarthi, Salman Abdullah, Aditi Tuli, Shubh\", \"Khanna, Anna Goldie, and Christopher D. Manning.\", \"2024. RAPTOR: recursive abstractive processing for\", \"tree-organized retrieval. CoRR , abs/2401.18059.\", \"John Schulman, Filip Wolski, Prafulla Dhariwal, Alec\", \"Radford, and Oleg Klimov. 2017. Proximal policy\", \"optimization algorithms. CoRR , abs/1707.06347.\", \"Freda Shi, Xinyun Chen, Kanishka Misra, Nathan\", \"Scales, David Dohan, Ed H. Chi, Nathanael Schärli,\", \"tional Conference on Machine Learning, ICML 2023,\", \"23-29 July 2023, Honolulu, Hawaii, USA , volume\", \"202 of Proceedings of Machine Learning Research ,\", \"Zhiqing Sun, Yikang Shen, Hongxin Zhang, Qinhong\", \"Zhou, Zhenfang Chen, David D. Cox, Yiming Yang,\", \"with principle-following reward models. CoRR ,\", \"Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin\", \"Zhang, Zhenfang Chen, David D. Cox, Yiming\", \"Yang, and Chuang Gan. 2023b. Principle-driven\", \"ence on Neural Information Processing Systems 2023,\", \"NeurIPS 2023, New Orleans, LA, USA, December 10\", \"Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-\", \"bert, Amjad Almahairi, Yasmine Babaei, Nikolay\", \"Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti\", \"Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton-\", \"Ferrer, Moya Chen, Guillem Cucurull, David Esiobu,\", \"Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,\", \"Cynthia Gao, Vedanuj Goswami, Naman Goyal, An-\", \"thony Hartshorn, Saghar Hosseini, Rui Hou, Hakan\", \"Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,\", \"Isabel Kloumann, Artem Korenev, Punit Singh Koura,\", \"Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-\", \"ana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-\", \"tinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-\", \"bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-\", \"stein, Rashi Rungta, Kalyan Saladi, Alan Schelten,\", \"Ruan Silva, Eric Michael Smith, Ranjan Subrama-\", \"nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-\", \"lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,\", \"Melanie Kambadur, Sharan Narang, Aurélien Ro-\", \"driguez, Robert Stojnic, Sergey Edunov, and Thomas\", \"tuned chat models. CoRR , abs/2307.09288.\", \"Xuanhui Wang, Cheng Li, Nadav Golbandi, Michael\", \"Bendersky, and Marc Najork. 2018. The lambdaloss\", \"on Information and Knowledge Management, CIKM\", \"2018, Torino, Italy, October 22-26, 2018 , pages 1313–\", \"1322. ACM.\", \"Zhiruo Wang, Jun Araki, Zhengbao Jiang, Md. Rizwan\", \"Parvez, and Graham Neubig. 2023. Learning to filter\", \"context for retrieval-augmented generation. CoRR ,\", \"Shitao Xiao, Zheng Liu, Peitian Zhang, and Niklas\", \"to advance general chinese embedding. CoRR ,\", \"Miao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie Fu,\", \"Junxian He, and Bryan Hooi. 2023. Can llms express\", \"dence elicitation in llms. CoRR , abs/2306.13063.\", \"Benfeng Xu, Chunxu Zhao, Wenbin Jiang, Pengfei Zhu,\", \"Songtai Dai, Chao Pang, Zhuo Sun, Shuohuan Wang,\", \"8th Workshop on Representation Learning for NLP ,\", \"RepL4NLP@ACL 2023, Toronto, Canada, July 13,\", \"2023 , pages 54–64. Association for Computational\", \"Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Ben-\", \"gio, William W. Cohen, Ruslan Salakhutdinov, and\", \"for diverse, explainable multi-hop question answer-\", \"pirical Methods in Natural Language Processing,\", \"Brussels, Belgium, October 31 - November 4, 2018 ,\", \"Weizhe Yuan, Richard Yuanzhe Pang, Kyunghyun Cho,\", \"Xian Li, Sainbayar Sukhbaatar, Jing Xu, and Ja-\", \"Learning, ICML 2024, Vienna, Austria, July 21-27,\", \"2024 . OpenReview.net.\", \"Cyril Zakka, Rohan Shad, Akash Chaurasia, Alex R\", \"Dalal, Jennifer L Kim, Michael Moor, Robyn Fong,\", \"Curran Phillips, Kevin Alexander, Euan Ashley,\", \"guage models for clinical medicine. NEJM AI ,\", \"1(2):AIoa2300068.\", \"Yuheng Zha, Yichi Yang, Ruichen Li, and Zhiting Hu.\", \"2023. Alignscore: Evaluating factual consistency\", \"Computational Linguistics (Volume 1: Long Papers),\", \"ACL 2023, Toronto, Canada, July 9-14, 2023 , pages\", \"11328–11348. Association for Computational Lin-\", \"Peitian Zhang, Shitao Xiao, Zheng Liu, Zhicheng Dou,\", \"Xiaoying Zhang, Baolin Peng, Ye Tian, Jingyan Zhou,\", \"Lifeng Jin, Linfeng Song, Haitao Mi, and Helen\", \"ing hallucinations in llms via self-evaluation. CoRR ,\", \"Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan\", \"Ye, Zheyan Luo, and Yongqiang Ma. 2024. Llamafac-\", \"models. CoRR , abs/2403.13372.\", \"periments on three benchmark datasets, i.e.,Natu-\", \"ralQuestions (NQ) (Kwiatkowski et al., 2019), Triv-\", \"iaQA (TQA) (Joshi et al., 2017), and HotpotQA\", \"(Yang et al., 2018), for evaluating our proposed\", \"the retrieved passages, we prompt the base extrac-\", \"extraction preferences of the base extractor, we\", \"the responses more varied. Specifically, we set top-\", \"p, top-k, temperature, and the repetition penalty\", \"as 1.0, 80, 1.0, and 1.0 respectively, for collecting\", \"diverse preference data, used to align the responses\", \"(Kingma and Ba, 2015) with β1= 0.9,β2= 0.999,\", \"1.5% warmup ratio and cosine scheduler. The batch\", \"size, gradient accumulation step, and number of\", \"epochs are set as 16, 2, and 2.0, respectively. Weleverage the parameter-efficient fine-tuning tech-\", \"nique, specifically LoRA (Hu et al., 2022), where\", \"work (Zheng et al., 2024) to implement all the pref-\", \"Context relevance details. In Section 2, we use\", \"quality of generation. To this end, we naturally\", \"scr= SBERT cosine(q, e), (10)\", \"where scr∈[−1,1]is the context relevance score;\", \"qandedenote the query and evidence, respectively.\", \"Silver faithfulness details. In Section 4.4, we de-\", \"vise a metric, silver faithfulness, to measure the\", \"narios. Specifically, we fed the mixture of the rele-\", \"irrelevant passages into the extractor. Then, we\", \"evidence as the premise and hypothesis, respec-\", \"tively, measuring how well the extractor is robust\", \"to irrelevant context, which can be formulated as:\", \"ssf=ALIGN SCORE (ˆp, e), e =˜E(·|q⊕˘P),\", \"(11)\", \"where ssf∈[0,1]is the silver faithfulness score; ˆp\", \"To assess the conciseness of the extracted evidence,\", \"ment, as shown in Table 4. Towards this end, we\", \"ally, we prepared a few-shot examples to encour-\", \"In Figure 6, we experiment to verify whether the\", \"9https://github.com/hiyouga/LLaMA-Factory .\", \"Question: What country used the Drachma as its currency, before switching to the Euro in 2001?\", \"Question: Californian rock band Lit recorded A Place in the Sun in 1995, but what’s their best known song?\", \"Full-length answer: The Californian rock band Lit recorded their album A Place in the Sun in 1995, and their best known\", \"Table 4: Three examples of full-length answers from the NQ, TQA, as well as HotpotQA datasets, respectively.\", \"[Instruction]\", \"[Here are three examples]\", \"[Question]: What profession does Nicholas Ray and Elia Kazan have in common?\", \"[Answer]: director\", \"[Full-length answer]: Nicholas Ray and Elia Kazan have the profession of director in common.\", \"[Question]: When is season seven of game of thrones coming out?\", \"[Answer]: July 16, 2017\", \"[Full-length answer]: Season seven of Game of Thrones is coming out on July 16, 2017.\", \"[Question]: What is the moon festival called in Chinese?\", \"[Answer]: Mid-Autumn Festival\", \"[Full-length answer]: The moon festival is called the Mid-Autumn Festival in Chinese.\", \"[Now complete the following]\", \"[Question]: When did the genre of installation art start to gain acceptance?\", \"[Answer]: in the 1970s\", \"[Full-length answer]:\", \"alignment optimization. Specifically, we generate\", \"uration as Section 3.1. Subsequently, we measure\", \"the oracle scores (§3.2), calculate the standard de-\", \"viation, and compute the average value. The ex-\", \"that of the base one in most cases. More precisely,\", \"seen greater improvements compared to the othertwo properties ( i.e.,faithfulness and conciseness),\", \"with an average improvement of 32.2%, showing\", \"can be divided into three stages, i.e.,(1) Evidence\", \"Extraction (line 3-6), (2) Expert Assessment (line\", \"7-10), as well as (3) Self-Alignment (line 11-14).\", \"(a) NQ dataset.\", \"(b) TQA dataset.\", \"(c) HotpotQA dataset.\", \"Figure 6: Model stability w.r.t. faithfulness, helpfulness, and conciseness. The bar represents the standard deviation\", \"results, while the line represents the stability improvement percent of the aligned model compared to the base model.\", \"We use FS, HS, and CS to denote the Faithfulness, Helpfulness, and Conciseness scores, respectively, for simplicity.\", \"Input: Trainig dataset with queries q, answers a, and retrieved passages P={pi}K\", \"1:Initialize the model parameter ˜EwithE\", \"2:foreachi∈[1, T]do\", \"3: #Stage1: Evidence Extraction\", \"4: Sample a mini-batch of ( q,a,P) query-answer-passage triples from the dataset.\", \"5: Get evidence candidates {ej}M\", \"6: Obtain uniformly distributed set {ej}N\", \"7: #Stage2: Expert Assessment\", \"8: Construct a QuadQARE for each evidence candidate < q, a, P, e > .\", \"9: Get the oracle scores (sf, sh, sc)for each evidence candidate with Eq. (2-4).\", \"10: Get the smoothing CoV-weighted score swith Eq. (5-7).\", \"11: #Stage3: Self-Alignment\", \"12: Get the lambda weight λw,lfor each preference pair (x, yw, yl)with Eq. (9).\", \"13: Compute the preference optimization loss LLPO with Eq. (8).\", \"14: Update the model parameter of ˜Eusing gradient descent.\", \"15:end for\", \"16:return ˜E.\"], \"error\": null}, \"f5fbc7de\": {\"success\": true, \"paper_id\": \"f5fbc7de\", \"url\": \"https://aclanthology.org/2024.emnlp-main.178.pdf\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_f5fbc7de.pdf\", \"extracted_info\": {\"title\": \"SEER: Self-Aligned Evidence Extraction for Retrieval-Augmented Generation\", \"authors\": [\"Not specified in provided content\"], \"abstract\": \"Recent studies in Retrieval-Augmented Generation (RAG) have investigated extracting evidence from retrieved contexts to improve generation quality. Existing methods heavily rely on heuristic-based augmentation, which suffers from poor generalization due to hand-crafted context filters. This paper proposes SEER, a model-based augmentation method that improves RAG performance by enhancing the faithfulness, helpfulness, and conciseness of extracted evidence while reducing computational costs.\", \"methodology\": \"SEER consists of three key stages: (1) Evidence Extraction using a model-based approach rather than heuristics; (2) Preference Optimization via a novel listwise-aware Lambda Preference Optimization (LPO) algorithm, which incorporates ranking position signals into preference learning; and (3) Evidence Alignment to ensure high-quality, deduplicated, and contextually relevant evidence. The method uses response sampling, expert-based quality assessment, and optimization of the base extractor to produce better evidence for RAG tasks.\", \"results\": \"Extensive experiments on three benchmark QA datasets (including NQ, TQA, and HotpotQA) show that SEER consistently outperforms state-of-the-art baselines such as FILCO and heuristic-based methods. SEER achieves higher EM and F1 scores, with an average QA accuracy improvement of 2.58% over the \\\"Full\\\" method, while reducing evidence length. Faithfulness, helpfulness, and conciseness scores indicate that all key components of SEER are effective, with aligned models showing better generation stability compared to base models.\", \"conclusion\": \"Key contributions: (1) Introduction of SEER, a model-based evidence extraction framework for RAG that avoids heuristic limitations; (2) Development of the Lambda Preference Optimization algorithm to integrate ranking metrics into preference learning; (3) Demonstration of significant improvements in QA accuracy, evidence quality, and computational efficiency across multiple datasets; (4) Empirical validation of the importance of deduplication and coverage in evidence extraction; (5) Provision of a scalable approach that can be extended to larger models in future work.\", \"figures\": null, \"tables\": null}, \"citations\": [\"Vaibhav Adlakha, Parishad BehnamGhader, Xing Han\", \"Lu, Nicholas Meade, and Siva Reddy. 2023. Eval-\", \"following models for question answering. CoRR ,\", \"Yuntao Bai, Saurav Kadavath, Sandipan Kundu,\", \"Amanda Askell, Jackson Kernion, Andy Jones, Anna\", \"Chen, Anna Goldie, Azalia Mirhoseini, Cameron\", \"McKinnon, Carol Chen, Catherine Olsson, Christo-\", \"pher Olah, Danny Hernandez, Dawn Drain, Deep\", \"Ganguli, Dustin Li, Eli Tran-Johnson, Ethan Perez,\", \"Jamie Kerr, Jared Mueller, Jeffrey Ladish, Joshua\", \"Landau, Kamal Ndousse, Kamile Lukosiute, Liane\", \"Lovitt, Michael Sellitto, Nelson Elhage, Nicholas\", \"Schiefer, Noemí Mercado, Nova DasSarma, Robert\", \"Lasenby, Robin Larson, Sam Ringer, Scott John-\", \"ston, Shauna Kravec, Sheer El Showk, Stanislav Fort,\", \"Tamera Lanham, Timothy Telleen-Lawton, Tom Con-\", \"erly, Tom Henighan, Tristan Hume, Samuel R. Bow-\", \"man, Zac Hatfield-Dodds, Ben Mann, Dario Amodei,\", \"Nicholas Joseph, Sam McCandlish, Tom Brown, and\", \"from AI feedback. CoRR , abs/2212.08073.\", \"Christopher J. C. Burges, Robert Ragno, and Quoc Viet\", \"cessing Systems 19, Proceedings of the Twentieth\", \"ing Systems, Vancouver, British Columbia, Canada,\", \"December 4-7, 2006 , pages 193–200. MIT Press.\", \"Jifan Chen, Grace Kim, Aniruddh Sriram, Greg Dur-\", \"rett, and Eunsol Choi. 2023. Complex claim veri-\", \"fication with evidence retrieved in the wild. CoRR ,\", \"Hyung Won Chung, Le Hou, Shayne Longpre, Barret\", \"Zoph, Yi Tay, William Fedus, Yunxuan Li, Xuezhi\", \"Wang, Mostafa Dehghani, Siddhartha Brahma, et al.\", \"2024. Scaling instruction-finetuned language models.\", \"Journal of Machine Learning Research , 25(70):1–53.\", \"Yujuan Ding, Wenqi Fan, Liangbo Ning, Shijie Wang,\", \"Hengyun Li, Dawei Yin, Tat-Seng Chua, and Qing Li.\", \"2024. A survey on rag meets llms: Towards retrieval-\", \"Pinar Donmez, Krysta M. Svore, and Christopher J. C.\", \"ment in Information Retrieval, SIGIR 2009, Boston,\", \"MA, USA, July 19-23, 2009 , pages 460–467. ACM.\", \"Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia,\", \"Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Qianyu Guo,\", \"Meng Wang, and Haofen Wang. 2023. Retrieval-\", \"survey. CoRR , abs/2312.10997.Rick Groenendijk, Sezer Karaoglu, Theo Gevers, and\", \"on Applications of Computer Vision, WACV 2021,\", \"Waikoloa, HI, USA, January 3-8, 2021 , pages 1468–\", \"1477. IEEE.\", \"Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat,\", \"37th International Conference on Machine Learning,\", \"ICML 2020, 13-18 July 2020, Virtual Event , volume\", \"119 of Proceedings of Machine Learning Research ,\", \"Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan\", \"Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and\", \"Conference on Learning Representations, ICLR 2022,\", \"Virtual Event, April 25-29, 2022 . OpenReview.net.\", \"Manas Jain, Sriparna Saha, Pushpak Bhattacharyya,\", \"Gladvin Chinnadurai, and Manish Kumar Vatsa.\", \"2021. Natural answer generation: From factoid an-\", \"CoRR , abs/2112.03849.\", \"Huiqiang Jiang, Qianhui Wu, Xufang Luo, Dongsheng\", \"Li, Chin-Yew Lin, Yuqing Yang, and Lili Qiu. 2023a.\", \"CoRR , abs/2310.06839.\", \"Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun,\", \"Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie\", \"Callan, and Graham Neubig. 2023b. Active retrieval\", \"guage Processing, EMNLP 2023, Singapore, Decem-\", \"ber 6-10, 2023 , pages 7969–7992. Association for\", \"Jiajie Jin, Yutao Zhu, Yujia Zhou, and Zhicheng Dou.\", \"2024. BIDER: bridging knowledge inconsistency for\", \"evidence. CoRR , abs/2402.12174.\", \"Mandar Joshi, Eunsol Choi, Daniel S. Weld, and Luke\", \"the Association for Computational Linguistics, ACL\", \"2017, Vancouver, Canada, July 30 - August 4, Volume\", \"1: Long Papers , pages 1601–1611. Association for\", \"Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick\", \"S. H. Lewis, Ledell Wu, Sergey Edunov, Danqi Chen,\", \"ural Language Processing, EMNLP 2020, Online,\", \"November 16-20, 2020 , pages 6769–6781. Associa-\", \"Jaehyung Kim, Jaehyun Nam, Sangwoo Mo, Jongjin\", \"Park, Sang-Woo Lee, Minjoon Seo, Jung-Woo Ha,\", \"QA of llms. CoRR , abs/2404.13081.\", \"national Conference on Learning Representations,\", \"ICLR 2015, San Diego, CA, USA, May 7-9, 2015,\", \"SungHo Ko, Hyunjin Cho, Hyungjoo Chae, Jinyoung\", \"Yeo, and Dongha Lee. 2024. Evidence-focused fact\", \"question answering. CoRR , abs/2403.02966.\", \"trieval, 12th International Conference, SPIRE 2005,\", \"Buenos Aires, Argentina, November 2-4, 2005, Pro-\", \"ceedings , volume 3772 of Lecture Notes in Computer\", \"Science , pages 115–126. Springer.\", \"Tom Kwiatkowski, Jennimaria Palomaki, Olivia Red-\", \"field, Michael Collins, Ankur P. Parikh, Chris Alberti,\", \"Danielle Epstein, Illia Polosukhin, Jacob Devlin, Ken-\", \"ton Lee, Kristina Toutanova, Llion Jones, Matthew\", \"Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob\", \"Uszkoreit, Quoc Le, and Slav Petrov. 2019. Natu-\", \"research. Trans. Assoc. Comput. Linguistics , 7:452–\", \"466.\", \"Md. Tahmid Rahman Laskar, Mizanur Rahman, Is-\", \"rat Jahan, Enamul Hoque, and Jimmy Huang. 2023.\", \"pedia. CoRR , abs/2305.06147.\", \"Kenton Lee, Ming-Wei Chang, and Kristina Toutanova.\", \"2019. Latent retrieval for weakly supervised open do-\", \"guistics, ACL 2019, Florence, Italy, July 28- August\", \"2, 2019, Volume 1: Long Papers , pages 6086–6096.\", \"Patrick S. H. Lewis, Ethan Perez, Aleksandra Pik-\", \"tus, Fabio Petroni, Vladimir Karpukhin, Naman\", \"Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih,\", \"Tim Rocktäschel, Sebastian Riedel, and Douwe\", \"2020, NeurIPS 2020, December 6-12, 2020, virtual .\", \"Xian Li, Ping Yu, Chunting Zhou, Timo Schick, Luke\", \"Zettlemoyer, Omer Levy, Jason Weston, and Mike\", \"translation. CoRR , abs/2308.06259.\", \"Yucheng Li, Bo Dong, Frank Guerin, and Chenghua Lin.\", \"2023b. Compressing context to enhance inferenceefficiency of large language models. In Proceedings\", \"ural Language Processing, EMNLP 2023, Singapore,\", \"December 6-10, 2023 , pages 6342–6353. Association\", \"Yuxin Liang, Zhuoyang Song, Hao Wang, and Jiax-\", \"mitigation. CoRR , abs/2401.15449.\", \"Tianqi Liu, Zhen Qin, Junru Wu, Jiaming Shen, Misha\", \"Khalman, Rishabh Joshi, Yao Zhao, Mohammad\", \"Saleh, Simon Baumgartner, Jialu Liu, Peter J. Liu,\", \"ence optimization through learning-to-rank. CoRR ,\", \"Antoine Louis, Gijs van Dijck, and Gerasimos Spanakis.\", \"2024. Interpretable long-form legal question answer-\", \"Intelligence, AAAI 2024, Thirty-Sixth Conference\", \"on Innovative Applications of Artificial Intelligence,\", \"IAAI 2024, Fourteenth Symposium on Educational\", \"Advances in Artificial Intelligence, EAAI 2014, Febru-\", \"ary 20-27, 2024, Vancouver, Canada , pages 22266–\", \"22275. AAAI Press.\", \"Joshua Maynez, Shashi Narayan, Bernd Bohnet, and\", \"Computational Linguistics, ACL 2020, Online, July\", \"5-10, 2020 , pages 1906–1919. Association for Com-\", \"Sewon Min, Danqi Chen, Luke Zettlemoyer, and Han-\", \"ing. CoRR , abs/1911.03868.\", \"Vaishali Pal, Manish Shrivastava, and Irshad Bhat. 2019.\", \"New Frontiers in Summarization , pages 1–9, Hong\", \"Kong, China. Association for Computational Linguis-\", \"Rafael Rafailov, Archit Sharma, Eric Mitchell, Christo-\", \"pher D. Manning, Stefano Ermon, and Chelsea Finn.\", \"2023. Direct preference optimization: Your language\", \"tems 2023, NeurIPS 2023, New Orleans, LA, USA,\", \"December 10 - 16, 2023 .\", \"Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay,\", \"Amnon Shashua, Kevin Leyton-Brown, and Yoav\", \"guage models. CoRR , abs/2302.00083.\", \"Hannah Rashkin, David Reitter, Gaurav Singh Tomar,\", \"Language Processing, ACL/IJCNLP 2021, (Volume 1:\", \"Long Papers), Virtual Event, August 1-6, 2021 , pages\", \"704–718. Association for Computational Linguistics.\", \"Parth Sarthi, Salman Abdullah, Aditi Tuli, Shubh\", \"Khanna, Anna Goldie, and Christopher D. Manning.\", \"2024. RAPTOR: recursive abstractive processing for\", \"tree-organized retrieval. CoRR , abs/2401.18059.\", \"John Schulman, Filip Wolski, Prafulla Dhariwal, Alec\", \"Radford, and Oleg Klimov. 2017. Proximal policy\", \"optimization algorithms. CoRR , abs/1707.06347.\", \"Freda Shi, Xinyun Chen, Kanishka Misra, Nathan\", \"Scales, David Dohan, Ed H. Chi, Nathanael Schärli,\", \"tional Conference on Machine Learning, ICML 2023,\", \"23-29 July 2023, Honolulu, Hawaii, USA , volume\", \"202 of Proceedings of Machine Learning Research ,\", \"Zhiqing Sun, Yikang Shen, Hongxin Zhang, Qinhong\", \"Zhou, Zhenfang Chen, David D. Cox, Yiming Yang,\", \"with principle-following reward models. CoRR ,\", \"Zhiqing Sun, Yikang Shen, Qinhong Zhou, Hongxin\", \"Zhang, Zhenfang Chen, David D. Cox, Yiming\", \"Yang, and Chuang Gan. 2023b. Principle-driven\", \"ence on Neural Information Processing Systems 2023,\", \"NeurIPS 2023, New Orleans, LA, USA, December 10\", \"Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-\", \"bert, Amjad Almahairi, Yasmine Babaei, Nikolay\", \"Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti\", \"Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton-\", \"Ferrer, Moya Chen, Guillem Cucurull, David Esiobu,\", \"Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,\", \"Cynthia Gao, Vedanuj Goswami, Naman Goyal, An-\", \"thony Hartshorn, Saghar Hosseini, Rui Hou, Hakan\", \"Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,\", \"Isabel Kloumann, Artem Korenev, Punit Singh Koura,\", \"Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-\", \"ana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-\", \"tinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-\", \"bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-\", \"stein, Rashi Rungta, Kalyan Saladi, Alan Schelten,\", \"Ruan Silva, Eric Michael Smith, Ranjan Subrama-\", \"nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-\", \"lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,\", \"Melanie Kambadur, Sharan Narang, Aurélien Ro-\", \"driguez, Robert Stojnic, Sergey Edunov, and Thomas\", \"tuned chat models. CoRR , abs/2307.09288.\", \"Xuanhui Wang, Cheng Li, Nadav Golbandi, Michael\", \"Bendersky, and Marc Najork. 2018. The lambdaloss\", \"on Information and Knowledge Management, CIKM\", \"2018, Torino, Italy, October 22-26, 2018 , pages 1313–\", \"1322. ACM.\", \"Zhiruo Wang, Jun Araki, Zhengbao Jiang, Md. Rizwan\", \"Parvez, and Graham Neubig. 2023. Learning to filter\", \"context for retrieval-augmented generation. CoRR ,\", \"Shitao Xiao, Zheng Liu, Peitian Zhang, and Niklas\", \"to advance general chinese embedding. CoRR ,\", \"Miao Xiong, Zhiyuan Hu, Xinyang Lu, Yifei Li, Jie Fu,\", \"Junxian He, and Bryan Hooi. 2023. Can llms express\", \"dence elicitation in llms. CoRR , abs/2306.13063.\", \"Benfeng Xu, Chunxu Zhao, Wenbin Jiang, Pengfei Zhu,\", \"Songtai Dai, Chao Pang, Zhuo Sun, Shuohuan Wang,\", \"8th Workshop on Representation Learning for NLP ,\", \"RepL4NLP@ACL 2023, Toronto, Canada, July 13,\", \"2023 , pages 54–64. Association for Computational\", \"Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Ben-\", \"gio, William W. Cohen, Ruslan Salakhutdinov, and\", \"for diverse, explainable multi-hop question answer-\", \"pirical Methods in Natural Language Processing,\", \"Brussels, Belgium, October 31 - November 4, 2018 ,\", \"Weizhe Yuan, Richard Yuanzhe Pang, Kyunghyun Cho,\", \"Xian Li, Sainbayar Sukhbaatar, Jing Xu, and Ja-\", \"Learning, ICML 2024, Vienna, Austria, July 21-27,\", \"2024 . OpenReview.net.\", \"Cyril Zakka, Rohan Shad, Akash Chaurasia, Alex R\", \"Dalal, Jennifer L Kim, Michael Moor, Robyn Fong,\", \"Curran Phillips, Kevin Alexander, Euan Ashley,\", \"guage models for clinical medicine. NEJM AI ,\", \"1(2):AIoa2300068.\", \"Yuheng Zha, Yichi Yang, Ruichen Li, and Zhiting Hu.\", \"2023. Alignscore: Evaluating factual consistency\", \"Computational Linguistics (Volume 1: Long Papers),\", \"ACL 2023, Toronto, Canada, July 9-14, 2023 , pages\", \"11328–11348. Association for Computational Lin-\", \"Peitian Zhang, Shitao Xiao, Zheng Liu, Zhicheng Dou,\", \"Xiaoying Zhang, Baolin Peng, Ye Tian, Jingyan Zhou,\", \"Lifeng Jin, Linfeng Song, Haitao Mi, and Helen\", \"ing hallucinations in llms via self-evaluation. CoRR ,\", \"Yaowei Zheng, Richong Zhang, Junhao Zhang, Yanhan\", \"Ye, Zheyan Luo, and Yongqiang Ma. 2024. Llamafac-\", \"models. CoRR , abs/2403.13372.\", \"periments on three benchmark datasets, i.e.,Natu-\", \"ralQuestions (NQ) (Kwiatkowski et al., 2019), Triv-\", \"iaQA (TQA) (Joshi et al., 2017), and HotpotQA\", \"(Yang et al., 2018), for evaluating our proposed\", \"the retrieved passages, we prompt the base extrac-\", \"extraction preferences of the base extractor, we\", \"the responses more varied. Specifically, we set top-\", \"p, top-k, temperature, and the repetition penalty\", \"as 1.0, 80, 1.0, and 1.0 respectively, for collecting\", \"diverse preference data, used to align the responses\", \"(Kingma and Ba, 2015) with β1= 0.9,β2= 0.999,\", \"1.5% warmup ratio and cosine scheduler. The batch\", \"size, gradient accumulation step, and number of\", \"epochs are set as 16, 2, and 2.0, respectively. Weleverage the parameter-efficient fine-tuning tech-\", \"nique, specifically LoRA (Hu et al., 2022), where\", \"work (Zheng et al., 2024) to implement all the pref-\", \"Context relevance details. In Section 2, we use\", \"quality of generation. To this end, we naturally\", \"scr= SBERT cosine(q, e), (10)\", \"where scr∈[−1,1]is the context relevance score;\", \"qandedenote the query and evidence, respectively.\", \"Silver faithfulness details. In Section 4.4, we de-\", \"vise a metric, silver faithfulness, to measure the\", \"narios. Specifically, we fed the mixture of the rele-\", \"irrelevant passages into the extractor. Then, we\", \"evidence as the premise and hypothesis, respec-\", \"tively, measuring how well the extractor is robust\", \"to irrelevant context, which can be formulated as:\", \"ssf=ALIGN SCORE (ˆp, e), e =˜E(·|q⊕˘P),\", \"(11)\", \"where ssf∈[0,1]is the silver faithfulness score; ˆp\", \"To assess the conciseness of the extracted evidence,\", \"ment, as shown in Table 4. Towards this end, we\", \"ally, we prepared a few-shot examples to encour-\", \"In Figure 6, we experiment to verify whether the\", \"9https://github.com/hiyouga/LLaMA-Factory .3039\", \"Question: What country used the Drachma as its currency, before switching to the Euro in 2001?\", \"Question: Californian rock band Lit recorded A Place in the Sun in 1995, but what’s their best known song?\", \"Full-length answer: The Californian rock band Lit recorded their album A Place in the Sun in 1995, and their best known\", \"Table 4: Three examples of full-length answers from the NQ, TQA, as well as HotpotQA datasets, respectively.\", \"[Instruction]\", \"[Here are three examples]\", \"[Question]: What profession does Nicholas Ray and Elia Kazan have in common?\", \"[Answer]: director\", \"[Full-length answer]: Nicholas Ray and Elia Kazan have the profession of director in common.\", \"[Question]: When is season seven of game of thrones coming out?\", \"[Answer]: July 16, 2017\", \"[Full-length answer]: Season seven of Game of Thrones is coming out on July 16, 2017.\", \"[Question]: What is the moon festival called in Chinese?\", \"[Answer]: Mid-Autumn Festival\", \"[Full-length answer]: The moon festival is called the Mid-Autumn Festival in Chinese.\", \"[Now complete the following]\", \"[Question]: When did the genre of installation art start to gain acceptance?\", \"[Answer]: in the 1970s\", \"[Full-length answer]:\", \"alignment optimization. Specifically, we generate\", \"uration as Section 3.1. Subsequently, we measure\", \"the oracle scores (§3.2), calculate the standard de-\", \"viation, and compute the average value. The ex-\", \"that of the base one in most cases. More precisely,\", \"seen greater improvements compared to the othertwo properties ( i.e.,faithfulness and conciseness),\", \"with an average improvement of 32.2%, showing\", \"can be divided into three stages, i.e.,(1) Evidence\", \"Extraction (line 3-6), (2) Expert Assessment (line\", \"7-10), as well as (3) Self-Alignment (line 11-14).3040\", \"(a) NQ dataset.\", \"(b) TQA dataset.\", \"(c) HotpotQA dataset.\", \"Figure 6: Model stability w.r.t. faithfulness, helpfulness, and conciseness. The bar represents the standard deviation\", \"results, while the line represents the stability improvement percent of the aligned model compared to the base model.\", \"We use FS, HS, and CS to denote the Faithfulness, Helpfulness, and Conciseness scores, respectively, for simplicity.\", \"Input: Trainig dataset with queries q, answers a, and retrieved passages P={pi}K\", \"1:Initialize the model parameter ˜EwithE\", \"2:foreachi∈[1, T]do\", \"3: #Stage1: Evidence Extraction\", \"4: Sample a mini-batch of ( q,a,P) query-answer-passage triples from the dataset.\", \"5: Get evidence candidates {ej}M\", \"6: Obtain uniformly distributed set {ej}N\", \"7: #Stage2: Expert Assessment\", \"8: Construct a QuadQARE for each evidence candidate < q, a, P, e > .\", \"9: Get the oracle scores (sf, sh, sc)for each evidence candidate with Eq. (2-4).\", \"10: Get the smoothing CoV-weighted score swith Eq. (5-7).\", \"11: #Stage3: Self-Alignment\", \"12: Get the lambda weight λw,lfor each preference pair (x, yw, yl)with Eq. (9).\", \"13: Compute the preference optimization loss LLPO with Eq. (8).\", \"14: Update the model parameter of ˜Eusing gradient descent.\", \"15:end for\", \"16:return ˜E.3041\"], \"error\": null}, \"7e8fa7fc\": {\"success\": true, \"paper_id\": \"7e8fa7fc\", \"url\": \"https://arxiv.org/pdf/2401.15391v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_7e8fa7fc.pdf\", \"extracted_info\": {\"title\": \"MultiHop-RAG: A Benchmark Dataset for Multi-Hop Retrieval-Augmented Generation\", \"authors\": [\"Not explicitly provided in the given content\"], \"abstract\": \"Retrieval-augmented generation (RAG) augments large language models (LLMs) by retrieving relevant information. Existing RAG methods perform unsatisfactorily in retrieving and answering multi-hop queries. The proposed MultiHop-RAG dataset aims to address these limitations and serve as a valuable resource for evaluating multi-hop retrieval and reasoning capabilities in LLMs.\", \"methodology\": \"The authors constructed the MultiHop-RAG dataset containing six different types of news articles. They designed multi-hop queries by identifying bridge-entities and bridge-topics across multiple documents. GPT-4 was used for claim generation, bridge generation, query formulation, and answer generation. Manual examination was conducted to ensure data quality. Multiple LLMs, including GPT-4, ChatGPT, Llama-2-70b-chat-hf, Mixtral-8x7B-Instruct, and Claude-2.1, were evaluated on the dataset to measure retrieval and response accuracy.\", \"results\": \"Evaluation results show varying performance across models. GPT-4 achieved the highest accuracy (retrieval: 0.56, response: 0.89), followed by Claude-2.1 (0.52, 0.56), ChatGPT (0.44, 0.57), Mixtral-8x7B-Instruct (0.32, 0.36), and Llama-2-70b-chat-hf (0.28, 0.32). The experiments indicate that current RAG implementations are inadequate for effectively handling multi-hop queries.\", \"conclusion\": \"The paper introduces MultiHop-RAG, a novel benchmark dataset specifically designed for multi-hop retrieval-augmented generation tasks. It addresses the gap in existing RAG benchmarks by focusing on complex multi-hop queries, providing high-quality annotated data, and enabling systematic evaluation of LLMs' multi-hop reasoning capabilities. This dataset is expected to facilitate advancements in multi-hop retrieval and reasoning research.\", \"figures\": null, \"tables\": null}, \"citations\": [\"Akari Asai, Sewon Min, Zexuan Zhong, and Danqi\", \"(Volume 6: Tutorial Abstracts) , pages 41–46.\", \"Sebastian Borgeaud, Arthur Mensch, Jordan Hoff-\", \"mann, Trevor Cai, Eliza Rutherford, Katie Milli-\", \"can, George Bm Van Den Driessche, Jean-Baptiste\", \"Lespiau, Bogdan Damoc, Aidan Clark, Diego\", \"De Las Casas, Aurelia Guy, Jacob Menick, Roman\", \"Ring, Tom Hennigan, Saffron Huang, Loren Mag-\", \"giore, Chris Jones, Albin Cassirer, Andy Brock,\", \"Michela Paganini, Geoffrey Irving, Oriol Vinyals,\", \"Simon Osindero, Karen Simonyan, Jack Rae, Erich\", \"Elsen, and Laurent Sifre. 2022. Improving language\", \"on Machine Learning , volume 162 of Proceedings\", \"of Machine Learning Research , pages 2206–2240.\", \"Jiawei Chen, Hongyu Lin, Xianpei Han, and Le Sun.\", \"2023. Benchmarking large language models in\", \"Shahul Es, Jithin James, Luis Espinosa-Anke, and\", \"Tianyu Gao, Howard Yen, Jiatong Yu, and Danqi Chen.\", \"2023. Enabling large language models to generate\", \"com/Significant-Gravitas/AutoGPT .Michael Günther, Jackmin Ong, Isabelle Mohr, Alaed-\", \"dine Abdessalem, Tanguy Abel, Mohammad Kalim\", \"Akram, Susana Guzman, Georgios Mastrapas, Saba\", \"Sturua, Bo Wang, Maximilian Werk, Nan Wang,\", \"Xanh Ho, Anh-Khoa Duong Nguyen, Saku Sugawara,\", \"national Conference on Computational Linguistics ,\", \"pages 6609–6625, Barcelona, Spain (Online). Inter-\", \"Albert Q. Jiang, Alexandre Sablayrolles, Antoine\", \"Roux, Arthur Mensch, Blanche Savary, Chris\", \"Bamford, Devendra Singh Chaplot, Diego de las\", \"Casas, Emma Bou Hanna, Florian Bressand, Gi-\", \"anna Lengyel, Guillaume Bour, Guillaume Lam-\", \"ple, Lélio Renard Lavaud, Lucile Saulnier, Marie-\", \"Anne Lachaux, Pierre Stock, Sandeep Subramanian,\", \"Sophia Yang, Szymon Antoniak, Teven Le Scao,\", \"Théophile Gervet, Thibaut Lavril, Thomas Wang,\", \"Timothée Lacroix, and William El Sayed. 2024. Mix-\", \"Yichen Jiang, Shikha Bordia, Zheng Zhong, Charles\", \"Dognin, Maneesh Singh, and Mohit Bansal. 2020.\", \"(EMNLP) .\", \"Ehsan Kamalloo, Xinyu Zhang, Odunayo Ogundepo,\", \"Nandan Thakur, David Alfonso-Hermelo, Mehdi\", \"Rezagholizadeh, and Jimmy Lin. 2023. Evaluat-\", \"Daniel Khashabi, Snigdha Chaturvedi, Michael Roth,\", \"Shyam Upadhyay, and Dan Roth. 2018. Looking\", \"(NAACL) .\", \"Yi Liu, Lianzhe Huang, Shicheng Li, Sishuo Chen, Hao\", \"Zhou, Fandong Meng, Jie Zhou, and Xu Sun. 2023.\", \"Jon Saad-Falcon, Omar Khattab, Christopher Potts, and\", \"Hongjin Su, Weijia Shi, Jungo Kasai, Yizhong Wang,\", \"Yushi Hu, Mari Ostendorf, Wen tau Yih, Noah A.\", \"Smith, Luke Zettlemoyer, and Tao Yu. 2023. One\", \"embedder, any task: Instruction-finetuned text em-\", \"James Thorne, Andreas Vlachos, Christos\", \"Christodoulopoulos, and Arpit Mittal. 2018.\", \"Hugo Touvron, Louis Martin, Kevin Stone, Peter Al-\", \"bert, Amjad Almahairi, Yasmine Babaei, Nikolay\", \"Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti\", \"Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton\", \"Ferrer, Moya Chen, Guillem Cucurull, David Esiobu,\", \"Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,\", \"Cynthia Gao, Vedanuj Goswami, Naman Goyal, An-\", \"thony Hartshorn, Saghar Hosseini, Rui Hou, Hakan\", \"Inan, Marcin Kardas, Viktor Kerkez, Madian Khabsa,\", \"Isabel Kloumann, Artem Korenev, Punit Singh Koura,\", \"Marie-Anne Lachaux, Thibaut Lavril, Jenya Lee, Di-\", \"ana Liskovich, Yinghai Lu, Yuning Mao, Xavier Mar-\", \"tinet, Todor Mihaylov, Pushkar Mishra, Igor Moly-\", \"bog, Yixin Nie, Andrew Poulton, Jeremy Reizen-\", \"stein, Rashi Rungta, Kalyan Saladi, Alan Schelten,\", \"Ruan Silva, Eric Michael Smith, Ranjan Subrama-\", \"nian, Xiaoqing Ellen Tan, Binh Tang, Ross Tay-\", \"lor, Adina Williams, Jian Xiang Kuan, Puxin Xu,\", \"Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan,\", \"Melanie Kambadur, Sharan Narang, Aurelien Ro-\", \"driguez, Robert Stojnic, Sergey Edunov, and Thomas\", \"David Wadden, Shanchuan Lin, Kyle Lo, Lucy Lu\", \"Wang, Madeleine van Zuylen, Arman Cohan, and\", \"Processing (EMNLP) , pages 7534–7550, Online. As-\", \"Liang Wang, Nan Yang, Xiaolong Huang, Binxing\", \"Jiao, Linjun Yang, Daxin Jiang, Rangan Majumder,\", \"Shitao Xiao, Zheng Liu, Peitian Zhang, and Niklas\", \"Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Ben-\", \"gio, William W. Cohen, Ruslan Salakhutdinov, and\", \"for diverse, explainable multi-hop question answer-\", \"Peitian Zhang, Shitao Xiao, Zheng Liu, Zhicheng Dou,\", \"Ming Zhong, Yang Liu, Da Yin, Yuning Mao, Yizhu\", \"Jiao, Pengfei Liu, Chenguang Zhu, Heng Ji, andJiawei Han. 2022. Towards a unified multi-\", \"claim generation, along with the corresponding top-\", \"ics and entities within these claims. Table 8, Table\", \"9, and Table 10 respectively show the prompts used\", \"for generating multi-hop queries of the inference,\", \"comparison, and temporal types.\", \"In this appendix, we present an example of each\", \"respective tables: Table 12 for Inference Queries,\", \"Table 13 for Comparison Queries, Table 14 for\", \"Temporal Queries, and Table 15 for Null Queries.\", \"for the evaluation of generation accuracy, while\", \"for assessing retrieval performance. Additionally,\", \"metadata such as the title, source, and publication\", \"A \\\"claim\\\" is a statement or assertion made within a text expressing a belief, opinion, or fact. Given\", \"evidence from the original context, please extract one claim and its associated topics.\", \"Note: The claim should not contain ambiguous references, such as ’he’,’ she,’ and’ it’, and should use\", \"complete names. If there are multiple topics, give the most dominant one. The target of the claim (one\", \"entity)is the specific individual, group, or organization that the statement or assertion within a text is\", \"representing the claim’s central argument concept. If there is no claim, please leave it blank. Please\", \"1. Find the Connection: The connection between claims is <target> , which is how these key pieces of\", \"2. Formulate the Question: Create a question that cannot be answered by relying on just one of the\", \"3. Ensure Coherence: Make sure the question flows logically from the combined information and is\", \"4. Use the keywords: <key set>\", \"as a comparative adjective, a statement of alignment, a simple yes or no. To generate a comparative\", \"question from claims, you need to use the following keywords: <key set>\", \"time points. If it is to compare the consistency, please clearly mention the news source and time in the\", \"question using <time frame> . If it is to compare sequences of reports, just clearly mention the news\", \"at least two news articles on <entity> , construct a multi-hop question that incorporates all the news\", \"sources. The source of the news should be stated in the question. Also, ensure that the answer to the\", \"Query: Which platform is at the center of discussions in articles from Music Business Worldwide,\", \"Polygon, and FOX News - Health, concerning the policing of AI-driven voice replication, the debate\", \"over \\\"reaction\\\" content, and being the most used app overnight by young people?\", \"Fact: During this period of discussion, YouTube has made a number of positive announcements\", \"Fact: The debate over \\\"reaction\\\" content on YouTube has been brewing for years, but a recent incident\", \"Title: Cell phone shocker as 97% of kids use their device during school hours and beyond, says study\", \"Fact: Overnight phone use was primarily spent engaging with the same media, although YouTube\", \"Title: Nike misses revenue expectations for the first time in two years, beats on earnings and gross\", \"billion, or 94 cents per share, compared with $1.47 billion, or 93 cents per share, a year earlier.\", \"Fact: The yield on the 10-year Treasury, which is the centrepiece of the bond market, pulled back from\", \"its highest level since 2007, down to 4.73 per cent from 4.80 per cent late on Tuesday.\", \"Title: Bears vs. Vikings live score, updates, highlights from NFL ’Monday Night Football’ game\", \"Fact: The Bears answer right back and sack Dobbs, with Sweat and Brisker in there to take him down.\", \"Fact: In his second season as HC, the defense has improved, but positive results are hard to come by\", \"Query: What is the first letter of the CEO’s last name in the news article from Bloomberg on TomTom,\"], \"error\": null}, \"d20ba321\": {\"success\": true, \"paper_id\": \"d20ba321\", \"url\": \"https://arxiv.org/pdf/2404.15939v3\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_d20ba321.pdf\", \"extracted_info\": {\"title\": \"Telco-RAG: A Retrieval-Augmented Generation Framework for 3GPP Telecommunications Standards\", \"authors\": [\"A. Vaswani\", \"N. Shazeer\", \"N. Parmar\", \"J. Uszkoreit\", \"L. Jones\", \"A. N. Gomez\", \"L. Kaiser\", \"I. Pol\"], \"abstract\": \"The application of Large Language Models (LLMs) and Retrieval-Augmented Generation (RAG) systems in the telecommunications domain presents unique challenges. This work introduces Telco-RAG, a specialized RAG framework designed to enhance LLM performance in processing 3GPP telecommunications standards. The framework aims to provide generally applicable guidelines to overcome common implementation challenges, contributing to the integration of AI in telecommunications.\", \"methodology\": \"The proposed Telco-RAG framework leverages Retrieval-Augmented Generation to improve LLM responses by incorporating external sources of information. The methodology includes: Glossary Enhancement to improve domain-specific terminology understanding; generating candidate answers using large embedding models; optimizing chunk size and context length for better accuracy; employing lexicon-enhanced queries; refining user queries; and integrating an NN Router for efficient retrieval of relevant 3GPP series. Experiments were conducted using datasets from 3GPP Rel.18 and TeleQnA MCQs.\", \"results\": \"Key results include: text-embedding-3-large model improved accuracy by 2.29%; optimal chunk size selection led to a 2.9% accuracy gain; lexicon-enhanced queries improved accuracy from 84.8% (Benchmark RAG) to 90.8% (Telco-RAG); refined queries yielded additional accuracy gains; NN Router outperformed GPT-3.5 and GPT-4 in relevant 3GPP series identification (k=1: 51.3% vs 19.9% and 30.4%, respectively); NN-enhanced RAG reduced RAM usage by 45%; overall accuracy improvements of 6.6% and 14.45% compared to GPT-3.5 with and without Benchmark RAG.\", \"conclusion\": \"The paper’s key contributions include: (1) introduction of Telco-RAG, a domain-specific RAG framework for telecommunications; (2) demonstration of effective methodologies for enhancing LLM performance through glossary enhancement, chunk size optimization, and lexicon-based query refinement; (3) integration of an NN Router for improved retrieval accuracy and efficiency; (4) substantial performance gains over baseline LLMs and existing RAG systems; and (5) guidelines for applying AI to complex, domain-specific technical standards in telecommunications.\", \"figures\": null, \"tables\": null}, \"citations\": [\"[1] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\", \"L. u. Kaiser, and I. Polosukhin, “Attention is all you need,” in Advances\", \"in neural information processing systems (NIPS) , 2017, pp. 5998–6008.\", \"[2] A. Maatouk, N. Piovesan, F. Ayed, A. D. Domenico, and M. Debbah,\", \"Industry,” IEEE Communications Magazine , pp. 1–7, 2024.\", \"[3] A. Maatouk, F. Ayed, N. Piovesan, A. De Domenico, M. Debbah,\", \"and Z.-Q. Luo, “TeleQnA: A Benchmark Dataset to Assess Large\", \"Language Models Telecommunications Knowledge,” arXiv preprint\", \"arXiv:2310.15051 , 2023.\", \"[4] N. C. Thompson, K. Greenewald, K. Lee, and G. F. Manso, “The com-\", \"putational limits of deep learning,” arXiv preprint arXiv:2007.05558 ,\", \"2020.\", \"[5] O. Ovadia, M. Brief, M. Mishaeli, and O. Elisha, “Fine-Tuning or\", \"Retrieval? Comparing Knowledge Injection in LLMs,” arXiv preprint\", \"arXiv:2312.05934 , 2024.[6] A. Balaguer, V . Benara, R. Cunha, R. Estev ˜ao, T. Hendry, D. Holstein,\", \"J. Marsman, N. Mecklenburg, S. Malvar, L. O. Nunes et al. , “RAG\", \"vs Fine-tuning: Pipelines, Tradeoffs, and a Case Study on Agriculture,”\", \"arXiv preprint arXiv:2401.08406 , 2024.\", \"[7] N. Piovesan, A. De Domenico, and F. Ayed, “Telecom language models:\", \"Personal, Indoor and Mobile Radio Communications (PIMRC) , 2024.\", \"[8] LlamaIndex, “Evaluating the Ideal Chunk Size for a\", \"RAG System Using LlamaIndex,” LlamaIndex Blog,\", \"2024. [Online]. Available: https://www.llamaindex.ai/blog/\", \"[9] P. Finardi, L. Avila, R. Castaldoni, P. Gengo, C. Larcher, M. Piau,\", \"P. Costa, and V . Carid ´a, “The Chronicles of RAG: The Retriever, the\", \"Chunk and the Generator,” arXiv preprint arXiv:2401.07883 , 2024.\", \"[10] C.-M. Chan, C. Xu, R. Yuan, H. Luo, W. Xue, Y . Guo, and J. Fu, “RQ-\", \"RAG: Learning to Refine Queries for Retrieval Augmented Generation,”\", \"inarXiv preprint arXiv:2404.00610 , 2024.\", \"[11] Banghao Chen, Zhaofeng Zhang, Nicolas Langren, Shengxin Zhu,\", \"Models: a comprehensive review,” arXiv preprint arXiv:2310.14735 ,\", \"2023.\", \"[12] S. Siriwardhana, R. Weerasekera, E. Wen, T. Kaluarachchi, R. Rana,\", \"and S. Nanayakkara, “Improving the Domain Adaptation of Retrieval\", \"swering,” Transactions of the Association for Computational Linguistics ,\", \"vol. 11, pp. 1–17, 01 2023.\", \"[13] J. Johnson, M. Douze, and H. J ´egou, “Faiss: Facebook ai similarity\", \"search,” https://github.com/facebookresearch/faiss, 2017.\", \"[14] 3GPP TSG SA, “TR 21.905, V ocabulary for 3GPP Specifications,”\", \"V17.2.0 , March 2024.\", \"[15] 3GPP, “Specifications by series.” [Online]. Available: https://www.\", \"3gpp.org/specifications-technologies/specifications-by-series\", \"[16] F. Gilardi, M. Alizadeh, and M. Kubli, “ChatGPT Outperforms Crowd-\", \"Workers for Text-Annotation Tasks,” Proceedings of the National\", \"Academy of Sciences , vol. 120, no. 30, 2023.\", \"[17] J. Gao, M. Galley, and L. Li, “Neural Approaches to Conversational\", \"AI,” in Annual Meeting of the Association for Computational Linguistics\", \"(ACL): Tutorial Abstracts , 2019.\", \"[18] OpenAI, “New embedding models and api updates,” https://openai.com/\", \"blog/new-embedding-models-and-api-updates, 2023, accessed: 2024-\", \"04-18.\", \"[19] A. Kusupati, G. Bhatt, A. Rege, M. Wallingford, A. Sinha, V . Ramanu-\", \"jan, W. Howard-Snyder, K. Chen, S. Kakade, P. Jain, and A. Farhadi,\", \"“Matryoshka Representation Learning,” in Advances in Neural Informa-\", \"tion Processing Systems (NeurIPS) , 2022.\"], \"error\": null}, \"2b07e563\": {\"success\": true, \"paper_id\": \"2b07e563\", \"url\": \"https://arxiv.org/pdf/2510.25518v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_2b07e563.pdf\", \"extracted_info\": {\"title\": \"Enhancing Retrieval-Augmented Generation in Specialized Fintech Domains via Agentic Architectures\", \"authors\": [\"V. Scotti\", \"M. J. Carman\"], \"abstract\": \"Retrieval-Augmented Generation (RAG) systems often face limitations in specialized domains such as fintech, where domain-specific ontologies and dense, complex data structures challenge retrieval precision and relevance. This paper proposes an agentic RAG framework that integrates hierarchical agents, automatic query enhancement, and cross-encoder re-ranking to improve retrieval robustness. Experimental results demonstrate that the agentic RAG system outperforms a baseline in retrieval precision and relevance, albeit with increased latency, suggesting promising directions for complex, domain-specific applications.\", \"methodology\": \"The study designs a hierarchical agent-driven RAG pipeline incorporating automatic query enhancement with continuous feedback, cross-encoder-based document re-ranking, and iterative retrieval sweeps. An evaluation dataset was constructed from an enterprise fintech knowledge base using LLM-driven synthetic data generation. The methodology involved comparing a baseline RAG (B-RAG) and agentic RAG (A-RAG) system across 85 questions, measuring retrieval accuracy (Hit@5), coverage, and semantic accuracy using both automated metrics and human-curated benchmarks.\", \"results\": \"The A-RAG system achieved a retrieval accuracy of 62.35% compared to the baseline's 54.12%, with improved semantic accuracy scores and better coverage in human-curated benchmarks. Sub-query decomposition and ontology navigation improved precision, though latency increased. The system demonstrated measurable gains in handling complex, multi-fragment queries and resolving ambiguities.\", \"conclusion\": \"This work contributes: (1) a modular agent-based RAG architecture tailored for specialized fintech domains; (2) integration of continuous feedback-driven query enhancement and cross-encoder re-ranking; (3) a secure, reproducible enterprise-scale evaluation methodology; (4) empirical evidence that agentic methods improve retrieval accuracy and semantic relevance in complex, domain-specific settings.\", \"figures\": null, \"tables\": null}, \"citations\": [\"[1] V . Scotti and M. J. Carman, “Llm support for real-time technical\", \"assistance,” inJoint European Conference on Machine Learning and\", \"Knowledge Discovery in Databases. Springer, 2024, pp. 388–393.\", \"[2] Cursor AI, “Cursor: The ai-first code editor,” https://www.cursor.so,\", \"2024, accessed: 2025-06-25.\", \"[3] OpenAI, “Chatgpt: Optimizing language models for dialogue,” https:\", \"//openai.com/blog/chatgpt, 2022, accessed: 2025-06-25.\", \"[4] E. Schuman, “88% of AI pilots fail to reach production — but that’s\", \"not all on IT,” https://www.cio.com/article/3850763/88-of-ai-pilots-fai\", \"l-to-reach-production-but-thats-not-all-on-it.html, Mar. 2025, accessed:\", \"2025-06-25.\", \"[5] A. Menshawy, Z. Nawaz, and M. Fahmy, “Navigating challenges and\", \"technical debt in large language models deployment,” inProceedings of\", \"the 4th Workshop on Machine Learning and Systems, 2024, pp. 192–199.\", \"[6] P. Giudici, “Fintech risk management: A research challenge for artificial\", \"intelligence in finance,”Frontiers in Artificial Intelligence, vol. V olume\", \"1 - 2018, 2018. [Online]. Available: https://www.frontiersin.org/journa\", \"[7] Mastercard, “Mdes for merchants (m4m): Mastercard digital enablement\", \"service for merchants,” https://www.mastercard.com/news/eemea/en/new\", \"-in-digital-payments-as-ecommerce-reaches-new-heights-in-the-uae/,\", \"2020, accessed: 2025-06-25.\", \"[8] ——, “Switchcore: Mastercard transaction switching platform,” https:\", \"html, 2025, accessed: 2025-06-25.\", \"[9] Y . Liu, D. Iter, Y . Xu, S. Wang, R. Xu, and C. Zhu, “G-eval: Nlg\", \"evaluation using gpt-4 with better human alignment,” 2023. [Online].\", \"[10] J. Chen, H. Lin, X. Han, and L. Sun, “Benchmarking large language\", \"models in retrieval-augmented generation,” inProceedings of the AAAI\", \"Conference on Artificial Intelligence, vol. 38, no. 16, 2024, pp. 17 754–\", \"17 762.\", \"[11] A. Singh, A. Ehtesham, S. Kumar, and T. T. Khoei, “Agentic retrieval-\", \"augmented generation: A survey on agentic rag,”arXiv preprint\", \"arXiv:2501.09136, 2025.\", \"[12] T. Nguyen, P. Chin, and Y .-W. Tai, “Ma-rag: Multi-agent retrieval-\", \"augmented generation via collaborative chain-of-thought reasoning,”\", \"arXiv preprint arXiv:2505.20096, 2025.\", \"[13] Pathway Community, “Adaptive agents for real-time rag: Domain-\", \"specific ai for legal, finance & healthcare,” https://pathway.com/bl\", \"og/adaptive-agents-rag/, 2025.\", \"[14] R. C. Barron, V . Grantcharov, S. Wanna, M. E. Eren, M. Bhattarai,\", \"N. Solovyev, G. Tompkins, C. Nicholas, K. . Rasmussen, C. Matuszek,\", \"and B. S. Alexandrov, “Domain-specific retrieval-augmented generation\", \"using vector stores, knowledge graphs, and tensor factorization,”arXiv\", \"preprint arXiv:2410.02721, 2024.\", \"[15] H. Daiya, “Leveraging large language models (llms) for enhanced risk\", \"monitoring in fintech,”IEEE Computer Society Tech News, 2024.\", \"[16] M. Broughton, “Large language models: How they help fintechs,” https:\", \"[17] Lumenova AI, “Ai in finance: The promise and risks of rag,” https:\", \"//www.lumenova.ai/blog/ai-finance-retrieval-augmented-generation/,\", \"2024.\", \"[18] P. H. Leal, “Building a financial education chatbot with retrieval-\", \"augmented generation (rag),” https://medium.com/@hlealpablo/bui\", \"n-rag-bf338aa2df09, 2023.\"], \"error\": null}, \"adb0a7cc\": {\"success\": true, \"paper_id\": \"adb0a7cc\", \"url\": \"https://arxiv.org/pdf/2409.03708v2\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_adb0a7cc.pdf\", \"extracted_info\": {\"title\": \"Retrieval-Augmented Generation for Response Prediction and Question Answering Systems\", \"authors\": [\"Rohan Anil\", \"Andrew M. Dai\", \"Orhan Firat\", \"Melvin Johnson\", \"Dmitry Lepikhin\", \"Alexandre Passos\", \"Siamak Shakeri\"], \"abstract\": \"Large Language Models (LLMs) have shown versatility in various Natural Language Processing (NLP) tasks. This work explores the integration of Retrieval-Augmented Generation (RAG) with LLMs to improve response prediction and question answering systems. The study investigates retrieval strategies, prompting methods, and their impact on RAG performance, as well as the comparative assistance RAG-based responses provide to human agents.\", \"methodology\": \"The research implements an end-to-end RAG framework integrating a Retriever and a Generator LLM. The process involves: (1) creating a comprehensive knowledge base from KB articles and historical query-response pairs; (2) using datasets such as MS-MARCO, SQuAD, and TriviaQA for training and evaluation; (3) testing multiple embedding techniques (USE, SBERT, Vertex AI) and retrieval methods (HNSW KNN, ScaNN); (4) generating responses using LLMs; (5) evaluating outputs through automated metrics and human-in-the-loop assessments using ChatGPT-3.5-turbo as an evaluator.\", \"results\": \"Vertex AI embeddings outperformed SBERT and USE in capturing complex semantics. RAG-based responses showed a 45% improvement in factual accuracy and a 27% reduction in hallucination rates compared to baselines. Automated and human evaluations confirmed that RAG integration improved response quality across datasets, with notable gains in MS-MARCO and SQuAD benchmarks.\", \"conclusion\": \"This study demonstrates the practical benefits and challenges of implementing RAG-based systems for response prediction and question answering. Key contributions include: (1) a comprehensive evaluation of embedding and retrieval strategies for RAG; (2) integration of LLMs with RAG for improved factual accuracy and reduced hallucinations; (3) validation of a human-in-the-loop approach to enhance system reliability; (4) empirical evidence showing RAG’s superiority over non-retrieval baselines in multiple QA datasets.\", \"figures\": null, \"tables\": null}, \"citations\": [], \"error\": null}, \"9890f30b\": {\"success\": true, \"paper_id\": \"9890f30b\", \"url\": \"https://arxiv.org/pdf/2402.07483v2\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_9890f30b.pdf\", \"extracted_info\": {\"title\": \"T-RAG: Lessons from the LLM Trenches\", \"authors\": [\"Masoomali Fatehkia\", \"Ji Kim Lucas\", \"Sanjay Chawla\"], \"abstract\": \"Large Language Models (LLMs) have shown remarkable language capabilities, fueling attempts to integrate them into organizational operations and decision-making. This paper discusses the development and evaluation of T-RAG, a system that combines fine-tuned LLMs with retrieval-augmented generation techniques to improve factual accuracy and relevance in domain-specific contexts.\", \"methodology\": \"The authors developed T-RAG by fine-tuning a base LLM on a domain-specific dataset using parameter-efficient fine-tuning methods such as LoRA. The system integrates a search and retrieval component with a vector database to provide relevant context to the LLM. They created evaluation datasets through expert-generated questions and answers, tested multiple configurations (with and without tree context for entity-related queries), and conducted performance evaluations using manual scoring and benchmark tests such as MMLU.\", \"results\": \"Results show that incorporating tree context significantly improves performance for entity-related questions, with T-RAG achieving 100% correctness in some configurations. Without tree context, performance slightly decreases but remains high. In \\\"Needle in a Haystack\\\" tests, T-RAG generally outperformed RAG, especially when relevant context was placed at the beginning or end of prompts. Fine-tuned models also performed better than base models on MMLU benchmarks.\", \"conclusion\": \"The key contributions include: (1) Development of T-RAG, a retrieval-augmented generation system optimized for domain-specific tasks; (2) Demonstration of the effectiveness of tree context for improving entity-related question answering; (3) Empirical evidence that context placement impacts retrieval performance; (4) Validation of parameter-efficient fine-tuning methods for enhancing LLM performance in specialized domains.\", \"figures\": null, \"tables\": null}, \"citations\": [\"[Agrawal et al.(2023a)] Garima Agrawal, Tharindu Kumarage, Zeyad Alghami, and Huan Liu. 2023a. Can Knowledge\", \"[Agrawal et al.(2023b)] Garima Agrawal, Kuntal Pal, Yuli Deng, Huan Liu, and Chitta Baral. 2023b. AISecKG:\", \"(CEUR Workshop Proceedings, Vol. 3433) , Andreas Martin, Hans-Georg Fill, Aurona Gerber, Knut Hinkelmann,\", \"Doug Lenat, Reinhard Stolle, and Frank van Harmelen (Eds.). CEUR, Hyatt Regency, San Francisco Airport.\", \"[Baek et al.(2023)] Jinheon Baek, Alham Fikri Aji, and Amir Saffari. 2023. Knowledge-Augmented Language Model\", \"Language Reasoning and Structured Explanations (NLRSE) , Bhavana Dalvi Mishra, Greg Durrett, Peter Jansen,\", \"Danilo Neves Ribeiro, and Jason Wei (Eds.). Association for Computational Linguistics, Toronto, Canada, 78–106.\", \"[Balaguer et al.(2024)] Angels Balaguer, Vinamra Benara, Renato Luiz de Freitas Cunha, Roberto de M. Estevão Filho,\", \"Todd Hendry, Daniel Holstein, Jennifer Marsman, Nick Mecklenburg, Sara Malvar, Leonardo O. Nunes, Rafael\", \"Padilha, Morris Sharp, Bruno Silva, Swati Sharma, Vijay Aski, and Ranveer Chandra. 2024. RAG vs Fine-tuning:\", \"Pipelines, Tradeoffs, and a Case Study on Agriculture. https://doi.org/10.48550/arXiv.2401.08406\", \"[Baldazzi et al.(2023)] Teodoro Baldazzi, Luigi Bellomarini, Stefano Ceri, Andrea Colombo, Andrea Gentili, and\", \"Reasoning: 7th International Joint Conference, RuleML+RR 2023, Oslo, Norway, September 18–20, 2023, Pro-\", \"ceedings . Springer-Verlag, Berlin, Heidelberg, 86–94. https://doi.org/10.1007/978-3-031-45072-3_6\", \"[Barnett et al.(2024)] Scott Barnett, Stefanus Kurniawan, Srikanth Thudumu, Zach Brannelly, and Mohamed Ab-\", \"[Chang et al.(2023)] Yupeng Chang, Xu Wang, Jindong Wang, Yuan Wu, Linyi Yang, Kaijie Zhu, Hao Chen, Xiaoyuan\", \"Yi, Cunxiang Wang, Yidong Wang, Wei Ye, Yue Zhang, Yi Chang, Philip S. Yu, Qiang Yang, and Xing Xie. 2023.\", \"[Chiang and Lee(2023)] Cheng-Han Chiang and Hung-yi Lee. 2023. Can Large Language Models Be an Alternative\", \"Linguistics (Volume 1: Long Papers) , Anna Rogers, Jordan Boyd-Graber, and Naoaki Okazaki (Eds.). Association\", \"for Computational Linguistics, Toronto, Canada, 15607–15631. https://doi.org/10.18653/v1/2023.\", \"[Cuconasu et al.(2024)] Florin Cuconasu, Giovanni Trappolini, Federico Siciliano, Simone Filice, Cesare Campagnano,\", \"Yoelle Maarek, Nicola Tonellotto, and Fabrizio Silvestri. 2024. The Power of Noise: Redefining Retrieval for\", \"[Dettmers et al.(2023)] Tim Dettmers, Artidoro Pagnoni, Ari Holtzman, and Luke Zettlemoyer. 2023. QLoRA: Efficient\", \"[Drori et al.(2023)] Iddo Drori, Sarah J. Zhang, Reece Shuttleworth, Sarah Zhang, Keith Tyser, Zad Chin, Pedro\", \"Lantigua, Saisamrit Surbehera, Gregory Hunter, Derek Austin, Leonard Tang, Yann Hicke, Sage Simhon, Sathwik\", \"Karnik, Darnell Granberry, and Madeleine Udell. 2023. From Human Days to Machine Seconds: Automatically\", \"on Knowledge Discovery and Data Mining (KDD ’23) . Association for Computing Machinery, New York, NY ,\", \"USA, 3947–3955. https://doi.org/10.1145/3580305.3599827\", \"13\", \"[Edge et al.(2024)] Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva Mody, Steven Truitt,\", \"[Fang et al.(2023)] Chuyu Fang, Chuan Qin, Qi Zhang, Kaichun Yao, Jingshuai Zhang, Hengshu Zhu, Fuzhen Zhuang,\", \"Data Mining (KDD ’23) . Association for Computing Machinery, New York, NY , USA, 3991–4002. https:\", \"[Gao et al.(2024)] Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, Qianyu\", \"Guo, Meng Wang, and Haofen Wang. 2024. Retrieval-Augmented Generation for Large Language Models: A\", \"[gkamradt(2023)] gkamradt. 2023. LLMTest Needle In A Haystack - Pressure Testing LLMs. https://github.\", \"[Guo et al.(2022)] Quan Guo, Shuai Cao, and Zhang Yi. 2022. A medical question answering system using large\", \"language models and knowledge graphs. International Journal of Intelligent Systems 37, 11 (2022), 8548–8564.\", \"[Guu et al.(2020a)] Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Mingwei Chang. 2020a. Retrieval\", \"Learning . PMLR, 3929–3938. https://proceedings.mlr.press/v119/guu20a.html ISSN: 2640-3498.\", \"[Guu et al.(2020b)] Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. 2020b. REALM:\", \"Learning (ICML’20, Vol. 119) . JMLR.org, 3929–3938.\", \"[Gómez-Rodríguez and Williams(2023)] Carlos Gómez-Rodríguez and Paul Williams. 2023. A Confederacy of Mod-\", \"Linguistics: EMNLP 2023 , Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Association for Computational\", \"Linguistics, Singapore, 14504–14528. https://doi.org/10.18653/v1/2023.findings-emnlp.966\", \"[Hamidi and Roberts(2023)] Alaleh Hamidi and Kirk Roberts. 2023. Evaluation of AI Chatbots for Patient-Specific\", \"[He et al.(2023)] Kai He, Rui Mao, Qika Lin, Yucheng Ruan, Xiang Lan, Mengling Feng, and Erik Cambria. 2023. A\", \"Survey of Large Language Models for Healthcare: from Data, Technology, and Applications to Accountability\", \"[Hendrycks et al.(2021)] Dan Hendrycks, Collin Burns, Steven Basart, Andy Zou, Mantas Mazeika, Dawn Song,\", \"48550/arXiv.2009.03300 arXiv:2009.03300 [cs].\", \"[Houlsby et al.(2019)] Neil Houlsby, Andrei Giurgiu, Stanislaw Jastrzebski, Bruna Morrone, Quentin De Laroussilhe,\", \"Andrea Gesmundo, Mona Attariyan, and Sylvain Gelly. 2019. Parameter-Efficient Transfer Learning for NLP.\", \"Research, Vol. 97) , Kamalika Chaudhuri and Ruslan Salakhutdinov (Eds.). PMLR, 2790–2799. https://\", \"[Howard and Ruder(2018)] Jeremy Howard and Sebastian Ruder. 2018. Universal Language Model Fine-tuning for\", \"(Volume 1: Long Papers) , Iryna Gurevych and Yusuke Miyao (Eds.). Association for Computational Linguistics,\", \"Melbourne, Australia, 328–339. https://doi.org/10.18653/v1/P18-1031\", \"[Hu et al.(2021)] Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang, Lu Wang,\", \"48550/arXiv.2106.09685 arXiv:2106.09685 [cs].\", \"[Huang et al.(2023)] Allen H. Huang, Hui Wang, and Yi Yang. 2023. FinBERT: A Large Language Model for Extract-\", \"ing Information from Financial Text*. Contemporary Accounting Research 40, 2 (2023), 806–841. https://doi.\", \"[Huang et al.(2022)] Jizhou Huang, Haifeng Wang, Yibo Sun, Yunsheng Shi, Zhengjie Huang, An Zhuo, and Shikun\", \"Association for Computing Machinery, New York, NY , USA, 3029–3039. https://doi.org/10.1145/\", \"3534678.3539021\", \"14\", \"[Kandpal et al.(2023)] Nikhil Kandpal, Haikang Deng, Adam Roberts, Eric Wallace, and Colin Raffel. 2023. Large\", \"Machine Learning (ICML’23, Vol. 202) . JMLR.org, Honolulu, Hawaii, USA, 15696–15707.\", \"[Lai et al.(2023)] Tin Lai, Yukun Shi, Zicong Du, Jiajie Wu, Ken Fu, Yichao Dou, and Ziqi Wang. 2023. Psy-LLM:\", \"[Lewis et al.(2020)] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal,\", \"Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe Kiela. 2020. Retrieval-\", \"Systems , V ol. 33. Curran Associates, Inc., 9459–9474. https://proceedings.neurips.cc/paper_files/\", \"[Lialin et al.(2023)] Vladislav Lialin, Vijeta Deshpande, and Anna Rumshisky. 2023. Scaling Down to Scale Up: A\", \"[Liu et al.(2023)] Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, and Chenguang Zhu. 2023. G-Eval:\", \"16634 arXiv:2303.16634 [cs].\", \"[Liventsev et al.(2023)] Vadim Liventsev, Anastasiia Grishina, Aki Härmä, and Leon Moonen. 2023. Fully Autonomous\", \"Conference (GECCO ’23) . Association for Computing Machinery, New York, NY , USA, 1146–1155. https:\", \"[Louis et al.(2023)] Antoine Louis, Gijs van Dijck, and Gerasimos Spanakis. 2023. Interpretable Long-Form Legal\", \"[Min et al.(2017)] Sewon Min, Minjoon Seo, and Hannaneh Hajishirzi. 2017. Question Answering through Transfer\", \"for Computational Linguistics (Volume 2: Short Papers) , Regina Barzilay and Min-Yen Kan (Eds.). Association\", \"for Computational Linguistics, Vancouver, Canada, 510–517. https://doi.org/10.18653/v1/P17-2081\", \"[Nellis and Cherney(2023)] Stephen Nellis and Max A. Cherney. 2023. US curbs AI chip exports from Nvidia and\", \"[OpenAI et al.(2023)] OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Flo-\", \"rencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, Red Avila, Igor\", \"Babuschkin, Suchir Balaji, Valerie Balcom, Paul Baltescu, Haiming Bao, Mo Bavarian, Jeff Belgum, Irwan Bello,\", \"Jake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg Boiko, Madelaine Boyd,\", \"Anna-Luisa Brakman, Greg Brockman, Tim Brooks, Miles Brundage, Kevin Button, Trevor Cai, Rosie Campbell,\", \"Andrew Cann, Brittany Carey, Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek\", \"Chen, Sully Chen, Ruby Chen, Jason Chen, Mark Chen, Ben Chess, Chester Cho, Casey Chu, Hyung Won Chung,\", \"Dave Cummings, Jeremiah Currier, Yunxing Dai, Cory Decareaux, Thomas Degry, Noah Deutsch, Damien Deville,\", \"Arka Dhar, David Dohan, Steve Dowling, Sheila Dunning, Adrien Ecoffet, Atty Eleti, Tyna Eloundou, David Farhi,\", \"Liam Fedus, Niko Felix, Simón Posada Fishman, Juston Forte, Isabella Fulford, Leo Gao, Elie Georges, Christian\", \"Gibson, Vik Goel, Tarun Gogineni, Gabriel Goh, Rapha Gontijo-Lopes, Jonathan Gordon, Morgan Grafstein,\", \"Scott Gray, Ryan Greene, Joshua Gross, Shixiang Shane Gu, Yufei Guo, Chris Hallacy, Jesse Han, Jeff Harris,\", \"Yuchen He, Mike Heaton, Johannes Heidecke, Chris Hesse, Alan Hickey, Wade Hickey, Peter Hoeschele, Brandon\", \"Houghton, Kenny Hsu, Shengli Hu, Xin Hu, Joost Huizinga, Shantanu Jain, Shawn Jain, Joanne Jang, Angela\", \"Jiang, Roger Jiang, Haozhun Jin, Denny Jin, Shino Jomoto, Billie Jonn, Heewoo Jun, Tomer Kaftan, Łukasz Kaiser,\", \"Ali Kamali, Ingmar Kanitscheider, Nitish Shirish Keskar, Tabarak Khan, Logan Kilpatrick, Jong Wook Kim,\", \"Christina Kim, Yongjik Kim, Hendrik Kirchner, Jamie Kiros, Matt Knight, Daniel Kokotajlo, Łukasz Kondraciuk,\", \"Andrew Kondrich, Aris Konstantinidis, Kyle Kosic, Gretchen Krueger, Vishal Kuo, Michael Lampe, Ikai Lan,\", \"Teddy Lee, Jan Leike, Jade Leung, Daniel Levy, Chak Ming Li, Rachel Lim, Molly Lin, Stephanie Lin, Mateusz\", \"Litwin, Theresa Lopez, Ryan Lowe, Patricia Lue, Anna Makanju, Kim Malfacini, Sam Manning, Todor Markov,\", \"Yaniv Markovski, Bianca Martin, Katie Mayer, Andrew Mayne, Bob McGrew, Scott Mayer McKinney, Christine\", \"McLeavey, Paul McMillan, Jake McNeil, David Medina, Aalok Mehta, Jacob Menick, Luke Metz, Andrey\", \"Mishchenko, Pamela Mishkin, Vinnie Monaco, Evan Morikawa, Daniel Mossing, Tong Mu, Mira Murati, Oleg\", \"Murk, David Mély, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak, Arvind Neelakantan, Richard Ngo, Hyeonwoo\", \"Noh, Long Ouyang, Cullen O’Keefe, Jakub Pachocki, Alex Paino, Joe Palermo, Ashley Pantuliano, Giambattista\", \"Parascandolo, Joel Parish, Emy Parparita, Alex Passos, Mikhail Pavlov, Andrew Peng, Adam Perelman, Filipe\", \"15\", \"de Avila Belbute Peres, Michael Petrov, Henrique Ponde de Oliveira Pinto, Michael, Pokorny, Michelle Pokrass,\", \"Vitchyr Pong, Tolly Powell, Alethea Power, Boris Power, Elizabeth Proehl, Raul Puri, Alec Radford, Jack Rae,\", \"Aditya Ramesh, Cameron Raymond, Francis Real, Kendra Rimbach, Carl Ross, Bob Rotsted, Henri Roussez, Nick\", \"Ryder, Mario Saltarelli, Ted Sanders, Shibani Santurkar, Girish Sastry, Heather Schmidt, David Schnurr, John\", \"Schulman, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah Shoker, Pranav Shyam, Szymon\", \"Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin, Katarina Slama, Ian Sohl, Benjamin Sokolowsky, Yang Song,\", \"Natalie Staudacher, Felipe Petroski Such, Natalie Summers, Ilya Sutskever, Jie Tang, Nikolas Tezak, Madeleine\", \"Thompson, Phil Tillet, Amin Tootoonchian, Elizabeth Tseng, Preston Tuggle, Nick Turley, Jerry Tworek, Juan\", \"Felipe Cerón Uribe, Andrea Vallone, Arun Vijayvergiya, Chelsea V oss, Carroll Wainwright, Justin Jay Wang,\", \"Alvin Wang, Ben Wang, Jonathan Ward, Jason Wei, C. J. Weinmann, Akila Welihinda, Peter Welinder, Jiayi\", \"Weng, Lilian Weng, Matt Wiethoff, Dave Willner, Clemens Winter, Samuel Wolrich, Hannah Wong, Lauren\", \"Workman, Sherwin Wu, Jeff Wu, Michael Wu, Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qiming Yuan, Wojciech\", \"Zaremba, Rowan Zellers, Chong Zhang, Marvin Zhang, Shengjia Zhao, Tianhao Zheng, Juntang Zhuang, William\", \"Zhuk, and Barret Zoph. 2023. GPT-4 Technical Report. https://doi.org/10.48550/arXiv.2303.08774\", \"[Ram et al.(2023)] Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown,\", \"[Su et al.(2023)] Hongjin Su, Weijia Shi, Jungo Kasai, Yizhong Wang, Yushi Hu, Mari Ostendorf, Wen-tau Yih,\", \"Noah A. Smith, Luke Zettlemoyer, and Tao Yu. 2023. One Embedder, Any Task: Instruction-Finetuned Text\", \"Embeddings. In Findings of the Association for Computational Linguistics: ACL 2023 , Anna Rogers, Jordan Boyd-\", \"Graber, and Naoaki Okazaki (Eds.). Association for Computational Linguistics, Toronto, Canada, 1102–1121.\", \"[Touvron et al.(2023)] Hugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei,\", \"Nikolay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, Dan Bikel, Lukas Blecher, Cristian Canton\", \"Ferrer, Moya Chen, Guillem Cucurull, David Esiobu, Jude Fernandes, Jeremy Fu, Wenyin Fu, Brian Fuller,\", \"Cynthia Gao, Vedanuj Goswami, Naman Goyal, Anthony Hartshorn, Saghar Hosseini, Rui Hou, Hakan Inan,\", \"Marcin Kardas, Viktor Kerkez, Madian Khabsa, Isabel Kloumann, Artem Korenev, Punit Singh Koura, Marie-Anne\", \"Lachaux, Thibaut Lavril, Jenya Lee, Diana Liskovich, Yinghai Lu, Yuning Mao, Xavier Martinet, Todor Mihaylov,\", \"Pushkar Mishra, Igor Molybog, Yixin Nie, Andrew Poulton, Jeremy Reizenstein, Rashi Rungta, Kalyan Saladi,\", \"Alan Schelten, Ruan Silva, Eric Michael Smith, Ranjan Subramanian, Xiaoqing Ellen Tan, Binh Tang, Ross Taylor,\", \"Adina Williams, Jian Xiang Kuan, Puxin Xu, Zheng Yan, Iliyan Zarov, Yuchen Zhang, Angela Fan, Melanie\", \"Kambadur, Sharan Narang, Aurelien Rodriguez, Robert Stojnic, Sergey Edunov, and Thomas Scialom. 2023.\", \"[Vaswani et al.(2017)] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\", \"Łukasz Kaiser, and Illia Polosukhin. 2017. Attention is All you Need. In Advances in Neural Information\", \"Processing Systems , V ol. 30. Curran Associates, Inc. https://proceedings.neurips.cc/paper_files/\", \"[Wang et al.(2023)] Yidong Wang, Zhuohao Yu, Zhengran Zeng, Linyi Yang, Cunxiang Wang, Hao Chen, Chaoya\", \"Jiang, Rui Xie, Jindong Wang, Xing Xie, Wei Ye, Shikun Zhang, and Yue Zhang. 2023. PandaLM: An Automatic\", \"05087 arXiv:2306.05087 [cs].\", \"[Wu et al.(2023)] Yike Wu, Nan Hu, Sheng Bi, Guilin Qi, Jie Ren, Anhuan Xie, and Wei Song. 2023. Retrieve-\", \"[Xia et al.(2022)] Fei Xia, Bin Li, Yixuan Weng, Shizhu He, Kang Liu, Bin Sun, Shutao Li, and Jun Zhao. 2022.\", \"the 2022 Conference on Empirical Methods in Natural Language Processing: System Demonstrations , Wanxiang\", \"Che and Ekaterina Shutova (Eds.). Association for Computational Linguistics, Abu Dhabi, UAE, 148–158.\", \"[Xiao et al.(2022)] Shitao Xiao, Zheng Liu, Yingxia Shao, Tao Di, Bhuvan Middha, Fangzhao Wu, and Xing Xie.\", \"2022. Training Large-Scale News Recommenders with Pretrained Language Models in the Loop. In Proceedings\", \"Computing Machinery, New York, NY , USA, 4215–4225. https://doi.org/10.1145/3534678.3539120\", \"16\", \"[Xu et al.(2023)] Lingling Xu, Haoran Xie, Si-Zhao Joe Qin, Xiaohui Tao, and Fu Lee Wang. 2023. Parameter-\", \"[Xu et al.(2024)] Peng Xu, Wei Ping, Xianchao Wu, Lawrence McAfee, Chen Zhu, Zihan Liu, Sandeep Subramanian,\", \"Evelina Bakhturina, Mohammad Shoeybi, and Bryan Catanzaro. 2024. Retrieval meets Long Context Large\", \"[Yang et al.(2023)] Fangkai Yang, Pu Zhao, Zezhong Wang, Lu Wang, Jue Zhang, Mohit Garg, Qingwei Lin, Saravan\", \"Rajmohan, and Dongmei Zhang. 2023. Empower Large Language Model to Perform Better on Industrial\", \"[Ye et al.(2023)] Hongbin Ye, Tong Liu, Aijia Zhang, Wei Hua, and Weiqiang Jia. 2023. Cognitive Mirage: A\", \"[Zhang et al.(2024)] Yikai Zhang, Junlong Li, and Pengfei Liu. 2024. Extending LLMs’ Context Window with 100\", \"[Zhang et al.(2023)] Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo Zhao,\", \"Yu Zhang, Yulong Chen, Longyue Wang, Anh Tuan Luu, Wei Bi, Freda Shi, and Shuming Shi. 2023. Siren’s\", \"[Zhao et al.(2023)] Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang, Xiaolei Wang, Yupeng Hou, Yingqian Min,\", \"Beichen Zhang, Junjie Zhang, Zican Dong, Yifan Du, Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao Jiang,\", \"Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen. 2023. A Survey of\", \"17\", \"As an AI assistant, your task is To generate question types, questions, answers, and source text for answers that\", \"comprehensively cover a given text and present them in a table format, considering various question types such as\", \"dialogs, conversations, conversations summary, conversations fact check, fact check, True or False, summary, quiz,\", \"review, Fill in the Blank, Short Answer, Yes or No, Matrix, compound questions, etc., follow these steps:\", \"1. Read the given text: Carefully read the text to understand its content and context.\", \"2.Identify key information: Look for definitions, metrics, facts, figures, events, or statements that can be\", \"used to create questions, ensuring that all parts of the text are covered.\", \"3.Determine question types: Based on the key information, decide which question types would be most\", \"suitable for the text (dialogs, conversations, conversations summary, conversations fact check, fact check,\", \"True or False, summary, quiz, review, Fill in the Blank, Short Answer, Yes or No, Matrix, compound\", \"questions, classify question, etc.).\", \"4.Generate questions: Create questions according to the chosen question types, ensuring they are clear,\", \"concise, and aligned with the question type. Make sure the questions cover the entire text.\", \"5. Locate answers: Find the corresponding answers for the questions within the text.\", \"6.Obtain source text: Replicate the essential text sections that offer the solutions to the queries, functioning\", \"7. Design a table: Create a table with columns for question type, question, answer, and source text.\", \"8.Populate the table: Fill the table with the generated question types, questions, answers, and the extracted\", \"9.Review and revise: Double-check the table for accuracy, comprehensiveness, and make any necessary\", \"18\", \"As an AI assistant, your task is To generate a Q&A conversation between a user and an assistant using a given text,\", \"1.Read and understand the text: Carefully read the given text and make sure you understand the key points,\", \"facts, and ideas presented in it.\", \"2.Identify potential questions: Based on your understanding of the text, think of possible questions that a\", \"3.Formulate clear and concise answers: For each question, draft a clear and concise answer based on the\", \"information provided in the text. Make sure your answers are accurate, informative, and directly address\", \"4.Organize the conversation: Arrange the questions and answers into a logical order, creating a smooth flow\", \"provides an answer, followed by another question and answer, and so on. Ensure that there are at least 2-3\", \"5.Check for clarity and coherence: Review the conversation to ensure that it is clear, coherent, and easy to\", \"Text: \\\"A healthy diet consists of various food groups, such as fruits, vegetables, whole grains, lean proteins, and\", \"healthy fats. Consuming a balanced diet can help maintain a healthy weight, support the immune system, and\", \"Assistant: A healthy diet includes various food groups, such as fruits, vegetables, whole grains, lean proteins, and\", \"Assistant: A healthy diet supports the immune system by providing essential vitamins, minerals, and antioxidants\", \"for optimal body function and reducing the intake of harmful substances like saturated fats, trans fats, and added\", \"sugars. A healthy diet can help prevent conditions such as heart disease, diabetes, and certain types of cancer.\", \"As an AI assistant, your task is To generate question types, questions, answers, and source text for answers that\", \"comprehensively cover a given text and sample questions present them in a table format, follow these steps:\", \"1. Read the given text: Carefully read the text to understand its content and context.\", \"19\", \"2.Identify key information: Look for definitions, metrics, facts, figures, events, or statements that can be\", \"used to create questions, ensuring that all parts of the text are covered.\", \"3.Generate questions: Create questions according to the chosen question types, ensuring they are clear,\", \"concise, and aligned with the question type. Make sure the questions cover the entire text.\", \"4. Locate answers: Find the corresponding answers for the questions within the text.\", \"5.Obtain source text: Replicate the essential text sections that offer the solutions to the queries, functioning\", \"6. Design a table: Create a table with columns for question type, question, answer, and source text.\", \"7.Populate the table: Fill the table with the generated question types, questions, answers, and the extracted\", \"8.Review and revise: Double-check the table for accuracy, comprehensiveness, and make any necessary\", \"•What are the categories of <entity group name>, and could you provide examples of entities falling under\", \"•Who are the stakeholders that must abide by the principles outlined in the Governance Manual, according\", \"20\", \"Remember to generate a variety of question types, questions, answers, and source text, and aim for a total of 10\", \"As a <organization document name> assistant, Your job is provide with accurate information exclusively based on\", \"1.Carefully analyze the question to comprehend what is being asked. Pay attention to the keywords, indirect\", \"cues, intentions, and specific details mentioned in the question.\", \"2.Find relevant information within the <organization document name> and provided context to construct\", \"your answer. If the given context is not suitable, do not use it.\", \"3.Support your answer with facts or information from the <organization document name> and provided\", \"context. If the given context is not relevant, do not need to use it.\", \"4. Organize the main points in a concise and clear manner.\", \"5. DO NOT create answers that aren’t in the <organization document name>.\", \"6. Provide brief and clear response to the question, focusing on main point ONLY .\", \"7. If you can’t answer a question, politely state that you’re unable to do so.\", \"Please take note that <organization acronym> and <organization name> have identical meanings. Additionally,\", \"phrases such as \\\"types\\\", \\\"departments\\\", \\\"entities\\\", \\\"categories\\\", \\\"positions\\\", \\\"groups\\\", \\\"units\\\", \\\"classifications\\\" and\", \"\\\"directorates\\\" might also suggest the same idea. Furthermore, any significant keywords like \\\"All\\\" or \\\"comprehen-\", \"Remember, as an AI assistant, it is vital to provide precise and dependable information based on the <organization\", \"i f l e n ( temp ) > 1 and t . f i n d ( ’ , ’ ) < 0 and t . f i n d ( ’& ’) <0:\", \"21\", \"p a t t e r n s . append ( { \\\" l a b e l \\\" : \\\"UNHCRORG\\\" , \\\" p a t t e r n \\\" : t e m p _ p a t t e r n ,\", \"{\\\" l a b e l \\\" : \\\"UNHCRORG\\\" , \\\" p a t t e r n \\\" : t . lower ( ) ,\", \"d e f s e a r c h _ e n t i t y _ i n f o ( t r e e , nlp , s e a r c h ) :\", \"s e a r c h _ c o n t e x t . append ( g e t _ n o d e _ i n f o ( t r e e , span . i d _ ) )\", \"22\"], \"error\": null}, \"cd0257a9\": {\"success\": false, \"paper_id\": \"cd0257a9\", \"url\": \"https://github.com/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/branches\\\" class=\\\"prc-Button-ButtonBase-9n-Xk OverviewContent-module__Button--bbZn8\\\" data-loading=\\\"false\\\" data-size=\\\"medium\\\" data-variant=\\\"invisible\\\"><span data-component=\\\"buttonContent\\\" data-align=\\\"center\\\" class=\\\"prc-Button-ButtonContent-Iohp5\\\"><span data-component=\\\"leadingVisual\\\" class=\\\"prc-Button-Visual-YNt2F prc-Button-VisualWrap-E4cnq\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-git-branch\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z\\\"></path></svg></span><span data-component=\\\"text\\\" class=\\\"prc-Button-Label-FWkx3\\\">Branches</span></span></a><a type=\\\"button\\\" href=\\\"/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/tags\\\" class=\\\"prc-Button-ButtonBase-9n-Xk OverviewContent-module__Button--bbZn8\\\" data-loading=\\\"false\\\" data-size=\\\"medium\\\" data-variant=\\\"invisible\\\"><span data-component=\\\"buttonContent\\\" data-align=\\\"center\\\" class=\\\"prc-Button-ButtonContent-Iohp5\\\"><span data-component=\\\"leadingVisual\\\" class=\\\"prc-Button-Visual-YNt2F prc-Button-VisualWrap-E4cnq\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-tag\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.752 1.752 0 0 1 1 7.775Zm1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2Z\\\"></path></svg></span><span data-component=\\\"text\\\" class=\\\"prc-Button-Label-FWkx3\\\">Tags</span></span></a></div><div class=\\\"OverviewContent-module__Box_5--wttWN\\\"><a type=\\\"button\\\" aria-label=\\\"Go to Branches page\\\" href=\\\"/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/branches\\\" class=\\\"prc-Button-ButtonBase-9n-Xk OverviewContent-module__Button_1--AQow7\\\" data-loading=\\\"false\\\" data-no-visuals=\\\"true\\\" data-size=\\\"medium\\\" data-variant=\\\"invisible\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-git-branch\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"M9.5 3.25a2.25 2.25 0 1 1 3 2.122V6A2.5 2.5 0 0 1 10 8.5H6a1 1 0 0 0-1 1v1.128a2.251 2.251 0 1 1-1.5 0V5.372a2.25 2.25 0 1 1 1.5 0v1.836A2.493 2.493 0 0 1 6 7h4a1 1 0 0 0 1-1v-.628A2.25 2.25 0 0 1 9.5 3.25Zm-6 0a.75.75 0 1 0 1.5 0 .75.75 0 0 0-1.5 0Zm8.25-.75a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5ZM4.25 12a.75.75 0 1 0 0 1.5.75.75 0 0 0 0-1.5Z\\\"></path></svg></a><a type=\\\"button\\\" aria-label=\\\"Go to Tags page\\\" href=\\\"/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/tags\\\" class=\\\"prc-Button-ButtonBase-9n-Xk OverviewContent-module__Button_1--AQow7\\\" data-loading=\\\"false\\\" data-no-visuals=\\\"true\\\" data-size=\\\"medium\\\" data-variant=\\\"invisible\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-tag\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"M1 7.775V2.75C1 1.784 1.784 1 2.75 1h5.025c.464 0 .91.184 1.238.513l6.25 6.25a1.75 1.75 0 0 1 0 2.474l-5.026 5.026a1.75 1.75 0 0 1-2.474 0l-6.25-6.25A1.752 1.752 0 0 1 1 7.775Zm1.5 0c0 .066.026.13.073.177l6.25 6.25a.25.25 0 0 0 .354 0l5.025-5.025a.25.25 0 0 0 0-.354l-6.25-6.25a.25.25 0 0 0-.177-.073H2.75a.25.25 0 0 0-.25.25ZM6 5a1 1 0 1 1 0 2 1 1 0 0 1 0-2Z\\\"></path></svg></a></div></div><div class=\\\"OverviewContent-module__Box_6--tJpBe\\\"><div class=\\\"OverviewContent-module__Box_7--x594V\\\"><div class=\\\"OverviewContent-module__Box_8--TjDBQ\\\"><!--$--><div class=\\\"Box-sc-62in7e-0 OverviewContent-module__FileResultsList--ZnbCo\\\"><span class=\\\"TextInput__StyledTextInput-sc-ttxlvl-0 d-flex FileResultsList-module__FilesSearchBox--fSAh3 TextInput-wrapper prc-components-TextInputWrapper-Hpdqi prc-components-TextInputBaseWrapper-wY-n0\\\" data-leading-visual=\\\"true\\\" data-trailing-visual=\\\"true\\\" aria-busy=\\\"false\\\"><span class=\\\"TextInput-icon\\\" id=\\\"_R_535ab_\\\" aria-hidden=\\\"true\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-search\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"M10.68 11.74a6 6 0 0 1-7.922-8.982 6 6 0 0 1 8.982 7.922l3.04 3.04a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215ZM11.5 7a4.499 4.499 0 1 0-8.997 0A4.499 4.499 0 0 0 11.5 7Z\\\"></path></svg></span><input type=\\\"text\\\" aria-label=\\\"Go to file\\\" role=\\\"combobox\\\" aria-controls=\\\"file-results-list\\\" aria-expanded=\\\"false\\\" aria-haspopup=\\\"dialog\\\" autoCorrect=\\\"off\\\" spellCheck=\\\"false\\\" placeholder=\\\"Go to file\\\" aria-describedby=\\\"_R_535ab_ _R_535abH1_\\\" data-component=\\\"input\\\" class=\\\"prc-components-Input-IwWrt\\\" value=\\\"\\\"/><span class=\\\"TextInput-icon\\\" id=\\\"_R_535abH1_\\\" aria-hidden=\\\"true\\\"></span></span></div><!--/$--></div><div class=\\\"OverviewContent-module__Box_9--kxlwV\\\"><button type=\\\"button\\\" class=\\\"prc-Button-ButtonBase-9n-Xk\\\" data-loading=\\\"false\\\" data-no-visuals=\\\"true\\\" data-size=\\\"medium\\\" data-variant=\\\"default\\\"><span data-component=\\\"buttonContent\\\" data-align=\\\"center\\\" class=\\\"prc-Button-ButtonContent-Iohp5\\\"><span data-component=\\\"text\\\" class=\\\"prc-Button-Label-FWkx3\\\">Go to file</span></span></button></div></div><button type=\\\"button\\\" aria-haspopup=\\\"true\\\" aria-expanded=\\\"false\\\" tabindex=\\\"0\\\" class=\\\"prc-Button-ButtonBase-9n-Xk\\\" data-loading=\\\"false\\\" data-size=\\\"medium\\\" data-variant=\\\"primary\\\" id=\\\"_R_75ab_\\\"><span data-component=\\\"buttonContent\\\" data-align=\\\"center\\\" class=\\\"prc-Button-ButtonContent-Iohp5\\\"><span data-component=\\\"leadingVisual\\\" class=\\\"prc-Button-Visual-YNt2F prc-Button-VisualWrap-E4cnq\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-code hide-sm\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"m11.28 3.22 4.25 4.25a.75.75 0 0 1 0 1.06l-4.25 4.25a.749.749 0 0 1-1.275-.326.749.749 0 0 1 .215-.734L13.94 8l-3.72-3.72a.749.749 0 0 1 .326-1.275.749.749 0 0 1 .734.215Zm-6.56 0a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042L2.06 8l3.72 3.72a.749.749 0 0 1-.326 1.275.749.749 0 0 1-.734-.215L.47 8.53a.75.75 0 0 1 0-1.06Z\\\"></path></svg></span><span data-component=\\\"text\\\" class=\\\"prc-Button-Label-FWkx3\\\">Code</span><span data-component=\\\"trailingVisual\\\" class=\\\"prc-Button-Visual-YNt2F prc-Button-VisualWrap-E4cnq\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-triangle-down\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"m4.427 7.427 3.396 3.396a.25.25 0 0 0 .354 0l3.396-3.396A.25.25 0 0 0 11.396 7H4.604a.25.25 0 0 0-.177.427Z\\\"></path></svg></span></span></button><div class=\\\"OverviewContent-module__Box_10--UMc9C\\\"><button data-component=\\\"IconButton\\\" type=\\\"button\\\" aria-haspopup=\\\"true\\\" aria-expanded=\\\"false\\\" tabindex=\\\"0\\\" class=\\\"prc-Button-ButtonBase-9n-Xk prc-Button-IconButton-fyge7\\\" data-loading=\\\"false\\\" data-no-visuals=\\\"true\\\" data-size=\\\"medium\\\" data-variant=\\\"default\\\" aria-labelledby=\\\"_R_7p5ab_\\\" id=\\\"_R_95ab_\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-kebab-horizontal\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"M8 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3ZM1.5 9a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Zm13 0a1.5 1.5 0 1 0 0-3 1.5 1.5 0 0 0 0 3Z\\\"></path></svg></button><span class=\\\"prc-TooltipV2-Tooltip-tLeuB\\\" data-direction=\\\"n\\\" aria-hidden=\\\"true\\\" id=\\\"_R_7p5ab_\\\">Open more actions menu</span></div></div></div><div class=\\\"OverviewContent-module__Box_11--QeUk1\\\"><div data-hpc=\\\"true\\\"><button hidden=\\\"\\\" data-testid=\\\"focus-next-element-button\\\" data-hotkey=\\\"j\\\"></button><button hidden=\\\"\\\" data-testid=\\\"focus-previous-element-button\\\" data-hotkey=\\\"k\\\"></button><h2 class=\\\"sr-only ScreenReaderHeading-module__userSelectNone--vlUbc prc-Heading-Heading-MtWFE\\\" data-testid=\\\"screen-reader-heading\\\" id=\\\"folders-and-files\\\">Folders and files</h2><table class=\\\"Table-module__Box--KyMHK\\\" aria-labelledby=\\\"folders-and-files\\\"><thead class=\\\"DirectoryContent-module__OverviewHeaderRow--FlrUZ Table-module__Box_1--DkRqs\\\"><tr class=\\\"Table-module__Box_2--l1wjV\\\"><th colSpan=\\\"2\\\" class=\\\"DirectoryContent-module__Box--y3Nvf\\\"><span class=\\\"text-bold\\\">Name</span></th><th colSpan=\\\"1\\\" class=\\\"DirectoryContent-module__Box_1--xeAhp\\\"><span class=\\\"text-bold\\\">Name</span></th><th class=\\\"hide-sm\\\"><div class=\\\"width-fit prc-Truncate-Truncate-2G1eo\\\" data-inline=\\\"true\\\" title=\\\"Last commit message\\\" style=\\\"--truncate-max-width:125px\\\"><span class=\\\"text-bold\\\">Last commit message</span></div></th><th colSpan=\\\"1\\\" class=\\\"DirectoryContent-module__Box_2--h912w\\\"><div class=\\\"width-fit prc-Truncate-Truncate-2G1eo\\\" data-inline=\\\"true\\\" title=\\\"Last commit date\\\" style=\\\"--truncate-max-width:125px\\\"><span class=\\\"text-bold\\\">Last commit date</span></div></th></tr></thead><tbody><tr class=\\\"DirectoryContent-module__Box_3--zI0N1\\\"><td colSpan=\\\"3\\\" class=\\\"bgColor-muted p-1 rounded-top-2\\\"><div class=\\\"LatestCommit-module__Box--Fimpo\\\"><h2 class=\\\"sr-only ScreenReaderHeading-module__userSelectNone--vlUbc prc-Heading-Heading-MtWFE\\\" data-testid=\\\"screen-reader-heading\\\">Latest commit</h2><div style=\\\"width:120px\\\" class=\\\"Skeleton Skeleton--text\\\" data-testid=\\\"loading\\\"> </div><div class=\\\"d-flex flex-shrink-0 gap-2\\\"><div data-testid=\\\"latest-commit-details\\\" class=\\\"d-none d-sm-flex flex-items-center\\\"></div><div class=\\\"d-flex gap-2\\\"><h2 class=\\\"sr-only ScreenReaderHeading-module__userSelectNone--vlUbc prc-Heading-Heading-MtWFE\\\" data-testid=\\\"screen-reader-heading\\\">History</h2><a href=\\\"/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/commits/main/\\\" class=\\\"prc-Button-ButtonBase-9n-Xk d-none d-lg-flex LinkButton-module__code-view-link-button--thtqc flex-items-center fgColor-default\\\" data-loading=\\\"false\\\" data-size=\\\"small\\\" data-variant=\\\"invisible\\\"><span data-component=\\\"buttonContent\\\" data-align=\\\"center\\\" class=\\\"prc-Button-ButtonContent-Iohp5\\\"><span data-component=\\\"leadingVisual\\\" class=\\\"prc-Button-Visual-YNt2F prc-Button-VisualWrap-E4cnq\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-history\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"m.427 1.927 1.215 1.215a8.002 8.002 0 1 1-1.6 5.685.75.75 0 1 1 1.493-.154 6.5 6.5 0 1 0 1.18-4.458l1.358 1.358A.25.25 0 0 1 3.896 6H.25A.25.25 0 0 1 0 5.75V2.104a.25.25 0 0 1 .427-.177ZM7.75 4a.75.75 0 0 1 .75.75v2.992l2.028.812a.75.75 0 0 1-.557 1.392l-2.5-1A.751.751 0 0 1 7 8.25v-3.5A.75.75 0 0 1 7.75 4Z\\\"></path></svg></span><span data-component=\\\"text\\\" class=\\\"prc-Button-Label-FWkx3\\\"><span class=\\\"fgColor-default\\\">14 Commits</span></span></span></a><div class=\\\"d-sm-none\\\"></div><div class=\\\"d-flex d-lg-none\\\"><span role=\\\"tooltip\\\" aria-label=\\\"14 Commits\\\" id=\\\"history-icon-button-tooltip\\\" class=\\\"prc-Tooltip-Tooltip-JLsri prc-Tooltip-Tooltip--n-SqCQ- tooltipped-n\\\"><a aria-label=\\\"View commit history for this file.\\\" href=\\\"/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/commits/main/\\\" class=\\\"prc-Button-ButtonBase-9n-Xk LinkButton-module__code-view-link-button--thtqc flex-items-center fgColor-default\\\" data-loading=\\\"false\\\" data-size=\\\"small\\\" data-variant=\\\"invisible\\\" aria-describedby=\\\"history-icon-button-tooltip\\\"><span data-component=\\\"buttonContent\\\" data-align=\\\"center\\\" class=\\\"prc-Button-ButtonContent-Iohp5\\\"><span data-component=\\\"leadingVisual\\\" class=\\\"prc-Button-Visual-YNt2F prc-Button-VisualWrap-E4cnq\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-history\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"m.427 1.927 1.215 1.215a8.002 8.002 0 1 1-1.6 5.685.75.75 0 1 1 1.493-.154 6.5 6.5 0 1 0 1.18-4.458l1.358 1.358A.25.25 0 0 1 3.896 6H.25A.25.25 0 0 1 0 5.75V2.104a.25.25 0 0 1 .427-.177ZM7.75 4a.75.75 0 0 1 .75.75v2.992l2.028.812a.75.75 0 0 1-.557 1.392l-2.5-1A.751.751 0 0 1 7 8.25v-3.5A.75.75 0 0 1 7.75 4Z\\\"></path></svg></span></span></a></span></div></div></div></div></td></tr><tr class=\\\"react-directory-row undefined\\\" id=\\\"folder-row-0\\\"><td class=\\\"react-directory-row-name-cell-small-screen\\\" colSpan=\\\"2\\\"><div class=\\\"react-directory-filename-column\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-file color-fg-muted\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\\\"></path></svg><div class=\\\"overflow-hidden\\\"><div class=\\\"react-directory-filename-cell\\\"><div class=\\\"react-directory-truncate\\\"><a title=\\\"LLM_RAG_Project_1.ipynb\\\" aria-label=\\\"LLM_RAG_Project_1.ipynb, (File)\\\" class=\\\"Link--primary\\\" href=\\\"/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/blob/main/LLM_RAG_Project_1.ipynb\\\" data-discover=\\\"true\\\">LLM_RAG_Project_1.ipynb</a></div></div></div></div></td><td class=\\\"react-directory-row-name-cell-large-screen\\\" colSpan=\\\"1\\\"><div class=\\\"react-directory-filename-column\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-file color-fg-muted\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\\\"></path></svg><div class=\\\"overflow-hidden\\\"><div class=\\\"react-directory-filename-cell\\\"><div class=\\\"react-directory-truncate\\\"><a title=\\\"LLM_RAG_Project_1.ipynb\\\" aria-label=\\\"LLM_RAG_Project_1.ipynb, (File)\\\" class=\\\"Link--primary\\\" href=\\\"/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/blob/main/LLM_RAG_Project_1.ipynb\\\" data-discover=\\\"true\\\">LLM_RAG_Project_1.ipynb</a></div></div></div></div></td><td class=\\\"react-directory-row-commit-cell\\\"><div class=\\\"Skeleton Skeleton--text\\\"> </div></td><td><div class=\\\"Skeleton Skeleton--text\\\"> </div></td></tr><tr class=\\\"react-directory-row undefined\\\" id=\\\"folder-row-1\\\"><td class=\\\"react-directory-row-name-cell-small-screen\\\" colSpan=\\\"2\\\"><div class=\\\"react-directory-filename-column\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-file color-fg-muted\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\\\"></path></svg><div class=\\\"overflow-hidden\\\"><div class=\\\"react-directory-filename-cell\\\"><div class=\\\"react-directory-truncate\\\"><a title=\\\"README.md\\\" aria-label=\\\"README.md, (File)\\\" class=\\\"Link--primary\\\" href=\\\"/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/blob/main/README.md\\\" data-discover=\\\"true\\\">README.md</a></div></div></div></div></td><td class=\\\"react-directory-row-name-cell-large-screen\\\" colSpan=\\\"1\\\"><div class=\\\"react-directory-filename-column\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-file color-fg-muted\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\\\"></path></svg><div class=\\\"overflow-hidden\\\"><div class=\\\"react-directory-filename-cell\\\"><div class=\\\"react-directory-truncate\\\"><a title=\\\"README.md\\\" aria-label=\\\"README.md, (File)\\\" class=\\\"Link--primary\\\" href=\\\"/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/blob/main/README.md\\\" data-discover=\\\"true\\\">README.md</a></div></div></div></div></td><td class=\\\"react-directory-row-commit-cell\\\"><div class=\\\"Skeleton Skeleton--text\\\"> </div></td><td><div class=\\\"Skeleton Skeleton--text\\\"> </div></td></tr><tr class=\\\"react-directory-row undefined\\\" id=\\\"folder-row-2\\\"><td class=\\\"react-directory-row-name-cell-small-screen\\\" colSpan=\\\"2\\\"><div class=\\\"react-directory-filename-column\\\"><svg aria-hidden=\\\"true\\\" focusable=\\\"false\\\" class=\\\"octicon octicon-file color-fg-muted\\\" viewBox=\\\"0 0 16 16\\\" width=\\\"16\\\" height=\\\"16\\\" fill=\\\"currentColor\\\" display=\\\"inline-block\\\" overflow=\\\"visible\\\" style=\\\"vertical-align:text-bottom\\\"><path d=\\\"M2 1.75C2 .784 2.784 0 3.75 0h6.586c.464 0 .909.184 1.237.513l2.914 2.914c.329.328.513.773.513 1.237v9.586A1.75 1.75 0 0 1 13.25 16h-9.5A1.75 1.75 0 0 1 2 14.25Zm1.75-.25a.25.25 0 0 0-.25.25v12.5c0 .138.112.25.25.25h9.5a.25.25 0 0 0 .25-.25V6h-2.75A1.75 1.75 0 0 1 9 4.25V1.5Zm6.75.062V4.25c0 .138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z\\\"></path></svg><div class=\\\"overflow-hidden\\\"><div class=\\\"react-directory-filename-cell\\\"><div class=\\\"react-directory-truncate\\\"><a title=\\\"Technical_Report_with_code.pdf\", \"pdf_path\": null, \"extracted_info\": null, \"error\": \"download failed: request failed: 414 Client Error: Request-URI Too Large for url: https://github.com/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/branches%22%20class=%22prc-Button-ButtonBase-9n-Xk%20OverviewContent-module__Button--bbZn8%22%20data-loading=%22false%22%20data-size=%22medium%22%20data-variant=%22invisible%22%3E%3Cspan%20data-component=%22buttonContent%22%20data-align=%22center%22%20class=%22prc-Button-ButtonContent-Iohp5%22%3E%3Cspan%20data-component=%22leadingVisual%22%20class=%22prc-Button-Visual-YNt2F%20prc-Button-VisualWrap-E4cnq%22%3E%3Csvg%20aria-hidden=%22true%22%20focusable=%22false%22%20class=%22octicon%20octicon-git-branch%22%20viewBox=%220%200%2016%2016%22%20width=%2216%22%20height=%2216%22%20fill=%22currentColor%22%20display=%22inline-block%22%20overflow=%22visible%22%20style=%22vertical-align:text-bottom%22%3E%3Cpath%20d=%22M9.5%203.25a2.25%202.25%200%201%201%203%202.122V6A2.5%202.5%200%200%201%2010%208.5H6a1%201%200%200%200-1%201v1.128a2.251%202.251%200%201%201-1.5%200V5.372a2.25%202.25%200%201%201%201.5%200v1.836A2.493%202.493%200%200%201%206%207h4a1%201%200%200%200%201-1v-.628A2.25%202.25%200%200%201%209.5%203.25Zm-6%200a.75.75%200%201%200%201.5%200%20.75.75%200%200%200-1.5%200Zm8.25-.75a.75.75%200%201%200%200%201.5.75.75%200%200%200%200-1.5ZM4.25%2012a.75.75%200%201%200%200%201.5.75.75%200%200%200%200-1.5Z%22%3E%3C/path%3E%3C/svg%3E%3C/span%3E%3Cspan%20data-component=%22text%22%20class=%22prc-Button-Label-FWkx3%22%3EBranches%3C/span%3E%3C/span%3E%3C/a%3E%3Ca%20type=%22button%22%20href=%22/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/tags%22%20class=%22prc-Button-ButtonBase-9n-Xk%20OverviewContent-module__Button--bbZn8%22%20data-loading=%22false%22%20data-size=%22medium%22%20data-variant=%22invisible%22%3E%3Cspan%20data-component=%22buttonContent%22%20data-align=%22center%22%20class=%22prc-Button-ButtonContent-Iohp5%22%3E%3Cspan%20data-component=%22leadingVisual%22%20class=%22prc-Button-Visual-YNt2F%20prc-Button-VisualWrap-E4cnq%22%3E%3Csvg%20aria-hidden=%22true%22%20focusable=%22false%22%20class=%22octicon%20octicon-tag%22%20viewBox=%220%200%2016%2016%22%20width=%2216%22%20height=%2216%22%20fill=%22currentColor%22%20display=%22inline-block%22%20overflow=%22visible%22%20style=%22vertical-align:text-bottom%22%3E%3Cpath%20d=%22M1%207.775V2.75C1%201.784%201.784%201%202.75%201h5.025c.464%200%20.91.184%201.238.513l6.25%206.25a1.75%201.75%200%200%201%200%202.474l-5.026%205.026a1.75%201.75%200%200%201-2.474%200l-6.25-6.25A1.752%201.752%200%200%201%201%207.775Zm1.5%200c0%20.066.026.13.073.177l6.25%206.25a.25.25%200%200%200%20.354%200l5.025-5.025a.25.25%200%200%200%200-.354l-6.25-6.25a.25.25%200%200%200-.177-.073H2.75a.25.25%200%200%200-.25.25ZM6%205a1%201%200%201%201%200%202%201%201%200%200%201%200-2Z%22%3E%3C/path%3E%3C/svg%3E%3C/span%3E%3Cspan%20data-component=%22text%22%20class=%22prc-Button-Label-FWkx3%22%3ETags%3C/span%3E%3C/span%3E%3C/a%3E%3C/div%3E%3Cdiv%20class=%22OverviewContent-module__Box_5--wttWN%22%3E%3Ca%20type=%22button%22%20aria-label=%22Go%20to%20Branches%20page%22%20href=%22/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/branches%22%20class=%22prc-Button-ButtonBase-9n-Xk%20OverviewContent-module__Button_1--AQow7%22%20data-loading=%22false%22%20data-no-visuals=%22true%22%20data-size=%22medium%22%20data-variant=%22invisible%22%3E%3Csvg%20aria-hidden=%22true%22%20focusable=%22false%22%20class=%22octicon%20octicon-git-branch%22%20viewBox=%220%200%2016%2016%22%20width=%2216%22%20height=%2216%22%20fill=%22currentColor%22%20display=%22inline-block%22%20overflow=%22visible%22%20style=%22vertical-align:text-bottom%22%3E%3Cpath%20d=%22M9.5%203.25a2.25%202.25%200%201%201%203%202.122V6A2.5%202.5%200%200%201%2010%208.5H6a1%201%200%200%200-1%201v1.128a2.251%202.251%200%201%201-1.5%200V5.372a2.25%202.25%200%201%201%201.5%200v1.836A2.493%202.493%200%200%201%206%207h4a1%201%200%200%200%201-1v-.628A2.25%202.25%200%200%201%209.5%203.25Zm-6%200a.75.75%200%201%200%201.5%200%20.75.75%200%200%200-1.5%200Zm8.25-.75a.75.75%200%201%200%200%201.5.75.75%200%200%200%200-1.5ZM4.25%2012a.75.75%200%201%200%200%201.5.75.75%200%200%200%200-1.5Z%22%3E%3C/path%3E%3C/svg%3E%3C/a%3E%3Ca%20type=%22button%22%20aria-label=%22Go%20to%20Tags%20page%22%20href=%22/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/tags%22%20class=%22prc-Button-ButtonBase-9n-Xk%20OverviewContent-module__Button_1--AQow7%22%20data-loading=%22false%22%20data-no-visuals=%22true%22%20data-size=%22medium%22%20data-variant=%22invisible%22%3E%3Csvg%20aria-hidden=%22true%22%20focusable=%22false%22%20class=%22octicon%20octicon-tag%22%20viewBox=%220%200%2016%2016%22%20width=%2216%22%20height=%2216%22%20fill=%22currentColor%22%20display=%22inline-block%22%20overflow=%22visible%22%20style=%22vertical-align:text-bottom%22%3E%3Cpath%20d=%22M1%207.775V2.75C1%201.784%201.784%201%202.75%201h5.025c.464%200%20.91.184%201.238.513l6.25%206.25a1.75%201.75%200%200%201%200%202.474l-5.026%205.026a1.75%201.75%200%200%201-2.474%200l-6.25-6.25A1.752%201.752%200%200%201%201%207.775Zm1.5%200c0%20.066.026.13.073.177l6.25%206.25a.25.25%200%200%200%20.354%200l5.025-5.025a.25.25%200%200%200%200-.354l-6.25-6.25a.25.25%200%200%200-.177-.073H2.75a.25.25%200%200%200-.25.25ZM6%205a1%201%200%201%201%200%202%201%201%200%200%201%200-2Z%22%3E%3C/path%3E%3C/svg%3E%3C/a%3E%3C/div%3E%3C/div%3E%3Cdiv%20class=%22OverviewContent-module__Box_6--tJpBe%22%3E%3Cdiv%20class=%22OverviewContent-module__Box_7--x594V%22%3E%3Cdiv%20class=%22OverviewContent-module__Box_8--TjDBQ%22%3E%3C!--$--%3E%3Cdiv%20class=%22Box-sc-62in7e-0%20OverviewContent-module__FileResultsList--ZnbCo%22%3E%3Cspan%20class=%22TextInput__StyledTextInput-sc-ttxlvl-0%20d-flex%20FileResultsList-module__FilesSearchBox--fSAh3%20TextInput-wrapper%20prc-components-TextInputWrapper-Hpdqi%20prc-components-TextInputBaseWrapper-wY-n0%22%20data-leading-visual=%22true%22%20data-trailing-visual=%22true%22%20aria-busy=%22false%22%3E%3Cspan%20class=%22TextInput-icon%22%20id=%22_R_535ab_%22%20aria-hidden=%22true%22%3E%3Csvg%20aria-hidden=%22true%22%20focusable=%22false%22%20class=%22octicon%20octicon-search%22%20viewBox=%220%200%2016%2016%22%20width=%2216%22%20height=%2216%22%20fill=%22currentColor%22%20display=%22inline-block%22%20overflow=%22visible%22%20style=%22vertical-align:text-bottom%22%3E%3Cpath%20d=%22M10.68%2011.74a6%206%200%200%201-7.922-8.982%206%206%200%200%201%208.982%207.922l3.04%203.04a.749.749%200%200%201-.326%201.275.749.749%200%200%201-.734-.215ZM11.5%207a4.499%204.499%200%201%200-8.997%200A4.499%204.499%200%200%200%2011.5%207Z%22%3E%3C/path%3E%3C/svg%3E%3C/span%3E%3Cinput%20type=%22text%22%20aria-label=%22Go%20to%20file%22%20role=%22combobox%22%20aria-controls=%22file-results-list%22%20aria-expanded=%22false%22%20aria-haspopup=%22dialog%22%20autoCorrect=%22off%22%20spellCheck=%22false%22%20placeholder=%22Go%20to%20file%22%20aria-describedby=%22_R_535ab_%20_R_535abH1_%22%20data-component=%22input%22%20class=%22prc-components-Input-IwWrt%22%20value=%22%22/%3E%3Cspan%20class=%22TextInput-icon%22%20id=%22_R_535abH1_%22%20aria-hidden=%22true%22%3E%3C/span%3E%3C/span%3E%3C/div%3E%3C!--/$--%3E%3C/div%3E%3Cdiv%20class=%22OverviewContent-module__Box_9--kxlwV%22%3E%3Cbutton%20type=%22button%22%20class=%22prc-Button-ButtonBase-9n-Xk%22%20data-loading=%22false%22%20data-no-visuals=%22true%22%20data-size=%22medium%22%20data-variant=%22default%22%3E%3Cspan%20data-component=%22buttonContent%22%20data-align=%22center%22%20class=%22prc-Button-ButtonContent-Iohp5%22%3E%3Cspan%20data-component=%22text%22%20class=%22prc-Button-Label-FWkx3%22%3EGo%20to%20file%3C/span%3E%3C/span%3E%3C/button%3E%3C/div%3E%3C/div%3E%3Cbutton%20type=%22button%22%20aria-haspopup=%22true%22%20aria-expanded=%22false%22%20tabindex=%220%22%20class=%22prc-Button-ButtonBase-9n-Xk%22%20data-loading=%22false%22%20data-size=%22medium%22%20data-variant=%22primary%22%20id=%22_R_75ab_%22%3E%3Cspan%20data-component=%22buttonContent%22%20data-align=%22center%22%20class=%22prc-Button-ButtonContent-Iohp5%22%3E%3Cspan%20data-component=%22leadingVisual%22%20class=%22prc-Button-Visual-YNt2F%20prc-Button-VisualWrap-E4cnq%22%3E%3Csvg%20aria-hidden=%22true%22%20focusable=%22false%22%20class=%22octicon%20octicon-code%20hide-sm%22%20viewBox=%220%200%2016%2016%22%20width=%2216%22%20height=%2216%22%20fill=%22currentColor%22%20display=%22inline-block%22%20overflow=%22visible%22%20style=%22vertical-align:text-bottom%22%3E%3Cpath%20d=%22m11.28%203.22%204.25%204.25a.75.75%200%200%201%200%201.06l-4.25%204.25a.749.749%200%200%201-1.275-.326.749.749%200%200%201%20.215-.734L13.94%208l-3.72-3.72a.749.749%200%200%201%20.326-1.275.749.749%200%200%201%20.734.215Zm-6.56%200a.751.751%200%200%201%201.042.018.751.751%200%200%201%20.018%201.042L2.06%208l3.72%203.72a.749.749%200%200%201-.326%201.275.749.749%200%200%201-.734-.215L.47%208.53a.75.75%200%200%201%200-1.06Z%22%3E%3C/path%3E%3C/svg%3E%3C/span%3E%3Cspan%20data-component=%22text%22%20class=%22prc-Button-Label-FWkx3%22%3ECode%3C/span%3E%3Cspan%20data-component=%22trailingVisual%22%20class=%22prc-Button-Visual-YNt2F%20prc-Button-VisualWrap-E4cnq%22%3E%3Csvg%20aria-hidden=%22true%22%20focusable=%22false%22%20class=%22octicon%20octicon-triangle-down%22%20viewBox=%220%200%2016%2016%22%20width=%2216%22%20height=%2216%22%20fill=%22currentColor%22%20display=%22inline-block%22%20overflow=%22visible%22%20style=%22vertical-align:text-bottom%22%3E%3Cpath%20d=%22m4.427%207.427%203.396%203.396a.25.25%200%200%200%20.354%200l3.396-3.396A.25.25%200%200%200%2011.396%207H4.604a.25.25%200%200%200-.177.427Z%22%3E%3C/path%3E%3C/svg%3E%3C/span%3E%3C/span%3E%3C/button%3E%3Cdiv%20class=%22OverviewContent-module__Box_10--UMc9C%22%3E%3Cbutton%20data-component=%22IconButton%22%20type=%22button%22%20aria-haspopup=%22true%22%20aria-expanded=%22false%22%20tabindex=%220%22%20class=%22prc-Button-ButtonBase-9n-Xk%20prc-Button-IconButton-fyge7%22%20data-loading=%22false%22%20data-no-visuals=%22true%22%20data-size=%22medium%22%20data-variant=%22default%22%20aria-labelledby=%22_R_7p5ab_%22%20id=%22_R_95ab_%22%3E%3Csvg%20aria-hidden=%22true%22%20focusable=%22false%22%20class=%22octicon%20octicon-kebab-horizontal%22%20viewBox=%220%200%2016%2016%22%20width=%2216%22%20height=%2216%22%20fill=%22currentColor%22%20display=%22inline-block%22%20overflow=%22visible%22%20style=%22vertical-align:text-bottom%22%3E%3Cpath%20d=%22M8%209a1.5%201.5%200%201%200%200-3%201.5%201.5%200%200%200%200%203ZM1.5%209a1.5%201.5%200%201%200%200-3%201.5%201.5%200%200%200%200%203Zm13%200a1.5%201.5%200%201%200%200-3%201.5%201.5%200%200%200%200%203Z%22%3E%3C/path%3E%3C/svg%3E%3C/button%3E%3Cspan%20class=%22prc-TooltipV2-Tooltip-tLeuB%22%20data-direction=%22n%22%20aria-hidden=%22true%22%20id=%22_R_7p5ab_%22%3EOpen%20more%20actions%20menu%3C/span%3E%3C/div%3E%3C/div%3E%3C/div%3E%3Cdiv%20class=%22OverviewContent-module__Box_11--QeUk1%22%3E%3Cdiv%20data-hpc=%22true%22%3E%3Cbutton%20hidden=%22%22%20data-testid=%22focus-next-element-button%22%20data-hotkey=%22j%22%3E%3C/button%3E%3Cbutton%20hidden=%22%22%20data-testid=%22focus-previous-element-button%22%20data-hotkey=%22k%22%3E%3C/button%3E%3Ch2%20class=%22sr-only%20ScreenReaderHeading-module__userSelectNone--vlUbc%20prc-Heading-Heading-MtWFE%22%20data-testid=%22screen-reader-heading%22%20id=%22folders-and-files%22%3EFolders%20and%20files%3C/h2%3E%3Ctable%20class=%22Table-module__Box--KyMHK%22%20aria-labelledby=%22folders-and-files%22%3E%3Cthead%20class=%22DirectoryContent-module__OverviewHeaderRow--FlrUZ%20Table-module__Box_1--DkRqs%22%3E%3Ctr%20class=%22Table-module__Box_2--l1wjV%22%3E%3Cth%20colSpan=%222%22%20class=%22DirectoryContent-module__Box--y3Nvf%22%3E%3Cspan%20class=%22text-bold%22%3EName%3C/span%3E%3C/th%3E%3Cth%20colSpan=%221%22%20class=%22DirectoryContent-module__Box_1--xeAhp%22%3E%3Cspan%20class=%22text-bold%22%3EName%3C/span%3E%3C/th%3E%3Cth%20class=%22hide-sm%22%3E%3Cdiv%20class=%22width-fit%20prc-Truncate-Truncate-2G1eo%22%20data-inline=%22true%22%20title=%22Last%20commit%20message%22%20style=%22--truncate-max-width:125px%22%3E%3Cspan%20class=%22text-bold%22%3ELast%20commit%20message%3C/span%3E%3C/div%3E%3C/th%3E%3Cth%20colSpan=%221%22%20class=%22DirectoryContent-module__Box_2--h912w%22%3E%3Cdiv%20class=%22width-fit%20prc-Truncate-Truncate-2G1eo%22%20data-inline=%22true%22%20title=%22Last%20commit%20date%22%20style=%22--truncate-max-width:125px%22%3E%3Cspan%20class=%22text-bold%22%3ELast%20commit%20date%3C/span%3E%3C/div%3E%3C/th%3E%3C/tr%3E%3C/thead%3E%3Ctbody%3E%3Ctr%20class=%22DirectoryContent-module__Box_3--zI0N1%22%3E%3Ctd%20colSpan=%223%22%20class=%22bgColor-muted%20p-1%20rounded-top-2%22%3E%3Cdiv%20class=%22LatestCommit-module__Box--Fimpo%22%3E%3Ch2%20class=%22sr-only%20ScreenReaderHeading-module__userSelectNone--vlUbc%20prc-Heading-Heading-MtWFE%22%20data-testid=%22screen-reader-heading%22%3ELatest%20commit%3C/h2%3E%3Cdiv%20style=%22width:120px%22%20class=%22Skeleton%20Skeleton--text%22%20data-testid=%22loading%22%3E%C2%A0%3C/div%3E%3Cdiv%20class=%22d-flex%20flex-shrink-0%20gap-2%22%3E%3Cdiv%20data-testid=%22latest-commit-details%22%20class=%22d-none%20d-sm-flex%20flex-items-center%22%3E%3C/div%3E%3Cdiv%20class=%22d-flex%20gap-2%22%3E%3Ch2%20class=%22sr-only%20ScreenReaderHeading-module__userSelectNone--vlUbc%20prc-Heading-Heading-MtWFE%22%20data-testid=%22screen-reader-heading%22%3EHistory%3C/h2%3E%3Ca%20href=%22/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/commits/main/%22%20class=%22prc-Button-ButtonBase-9n-Xk%20d-none%20d-lg-flex%20LinkButton-module__code-view-link-button--thtqc%20flex-items-center%20fgColor-default%22%20data-loading=%22false%22%20data-size=%22small%22%20data-variant=%22invisible%22%3E%3Cspan%20data-component=%22buttonContent%22%20data-align=%22center%22%20class=%22prc-Button-ButtonContent-Iohp5%22%3E%3Cspan%20data-component=%22leadingVisual%22%20class=%22prc-Button-Visual-YNt2F%20prc-Button-VisualWrap-E4cnq%22%3E%3Csvg%20aria-hidden=%22true%22%20focusable=%22false%22%20class=%22octicon%20octicon-history%22%20viewBox=%220%200%2016%2016%22%20width=%2216%22%20height=%2216%22%20fill=%22currentColor%22%20display=%22inline-block%22%20overflow=%22visible%22%20style=%22vertical-align:text-bottom%22%3E%3Cpath%20d=%22m.427%201.927%201.215%201.215a8.002%208.002%200%201%201-1.6%205.685.75.75%200%201%201%201.493-.154%206.5%206.5%200%201%200%201.18-4.458l1.358%201.358A.25.25%200%200%201%203.896%206H.25A.25.25%200%200%201%200%205.75V2.104a.25.25%200%200%201%20.427-.177ZM7.75%204a.75.75%200%200%201%20.75.75v2.992l2.028.812a.75.75%200%200%201-.557%201.392l-2.5-1A.751.751%200%200%201%207%208.25v-3.5A.75.75%200%200%201%207.75%204Z%22%3E%3C/path%3E%3C/svg%3E%3C/span%3E%3Cspan%20data-component=%22text%22%20class=%22prc-Button-Label-FWkx3%22%3E%3Cspan%20class=%22fgColor-default%22%3E14%20Commits%3C/span%3E%3C/span%3E%3C/span%3E%3C/a%3E%3Cdiv%20class=%22d-sm-none%22%3E%3C/div%3E%3Cdiv%20class=%22d-flex%20d-lg-none%22%3E%3Cspan%20role=%22tooltip%22%20aria-label=%2214%20Commits%22%20id=%22history-icon-button-tooltip%22%20class=%22prc-Tooltip-Tooltip-JLsri%20prc-Tooltip-Tooltip--n-SqCQ-%20tooltipped-n%22%3E%3Ca%20aria-label=%22View%20commit%20history%20for%20this%20file.%22%20href=%22/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/commits/main/%22%20class=%22prc-Button-ButtonBase-9n-Xk%20LinkButton-module__code-view-link-button--thtqc%20flex-items-center%20fgColor-default%22%20data-loading=%22false%22%20data-size=%22small%22%20data-variant=%22invisible%22%20aria-describedby=%22history-icon-button-tooltip%22%3E%3Cspan%20data-component=%22buttonContent%22%20data-align=%22center%22%20class=%22prc-Button-ButtonContent-Iohp5%22%3E%3Cspan%20data-component=%22leadingVisual%22%20class=%22prc-Button-Visual-YNt2F%20prc-Button-VisualWrap-E4cnq%22%3E%3Csvg%20aria-hidden=%22true%22%20focusable=%22false%22%20class=%22octicon%20octicon-history%22%20viewBox=%220%200%2016%2016%22%20width=%2216%22%20height=%2216%22%20fill=%22currentColor%22%20display=%22inline-block%22%20overflow=%22visible%22%20style=%22vertical-align:text-bottom%22%3E%3Cpath%20d=%22m.427%201.927%201.215%201.215a8.002%208.002%200%201%201-1.6%205.685.75.75%200%201%201%201.493-.154%206.5%206.5%200%201%200%201.18-4.458l1.358%201.358A.25.25%200%200%201%203.896%206H.25A.25.25%200%200%201%200%205.75V2.104a.25.25%200%200%201%20.427-.177ZM7.75%204a.75.75%200%200%201%20.75.75v2.992l2.028.812a.75.75%200%200%201-.557%201.392l-2.5-1A.751.751%200%200%201%207%208.25v-3.5A.75.75%200%200%201%207.75%204Z%22%3E%3C/path%3E%3C/svg%3E%3C/span%3E%3C/span%3E%3C/a%3E%3C/span%3E%3C/div%3E%3C/div%3E%3C/div%3E%3C/div%3E%3C/td%3E%3C/tr%3E%3Ctr%20class=%22react-directory-row%20undefined%22%20id=%22folder-row-0%22%3E%3Ctd%20class=%22react-directory-row-name-cell-small-screen%22%20colSpan=%222%22%3E%3Cdiv%20class=%22react-directory-filename-column%22%3E%3Csvg%20aria-hidden=%22true%22%20focusable=%22false%22%20class=%22octicon%20octicon-file%20color-fg-muted%22%20viewBox=%220%200%2016%2016%22%20width=%2216%22%20height=%2216%22%20fill=%22currentColor%22%20display=%22inline-block%22%20overflow=%22visible%22%20style=%22vertical-align:text-bottom%22%3E%3Cpath%20d=%22M2%201.75C2%20.784%202.784%200%203.75%200h6.586c.464%200%20.909.184%201.237.513l2.914%202.914c.329.328.513.773.513%201.237v9.586A1.75%201.75%200%200%201%2013.25%2016h-9.5A1.75%201.75%200%200%201%202%2014.25Zm1.75-.25a.25.25%200%200%200-.25.25v12.5c0%20.138.112.25.25.25h9.5a.25.25%200%200%200%20.25-.25V6h-2.75A1.75%201.75%200%200%201%209%204.25V1.5Zm6.75.062V4.25c0%20.138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z%22%3E%3C/path%3E%3C/svg%3E%3Cdiv%20class=%22overflow-hidden%22%3E%3Cdiv%20class=%22react-directory-filename-cell%22%3E%3Cdiv%20class=%22react-directory-truncate%22%3E%3Ca%20title=%22LLM_RAG_Project_1.ipynb%22%20aria-label=%22LLM_RAG_Project_1.ipynb,%20(File)%22%20class=%22Link--primary%22%20href=%22/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/blob/main/LLM_RAG_Project_1.ipynb%22%20data-discover=%22true%22%3ELLM_RAG_Project_1.ipynb%3C/a%3E%3C/div%3E%3C/div%3E%3C/div%3E%3C/div%3E%3C/td%3E%3Ctd%20class=%22react-directory-row-name-cell-large-screen%22%20colSpan=%221%22%3E%3Cdiv%20class=%22react-directory-filename-column%22%3E%3Csvg%20aria-hidden=%22true%22%20focusable=%22false%22%20class=%22octicon%20octicon-file%20color-fg-muted%22%20viewBox=%220%200%2016%2016%22%20width=%2216%22%20height=%2216%22%20fill=%22currentColor%22%20display=%22inline-block%22%20overflow=%22visible%22%20style=%22vertical-align:text-bottom%22%3E%3Cpath%20d=%22M2%201.75C2%20.784%202.784%200%203.75%200h6.586c.464%200%20.909.184%201.237.513l2.914%202.914c.329.328.513.773.513%201.237v9.586A1.75%201.75%200%200%201%2013.25%2016h-9.5A1.75%201.75%200%200%201%202%2014.25Zm1.75-.25a.25.25%200%200%200-.25.25v12.5c0%20.138.112.25.25.25h9.5a.25.25%200%200%200%20.25-.25V6h-2.75A1.75%201.75%200%200%201%209%204.25V1.5Zm6.75.062V4.25c0%20.138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z%22%3E%3C/path%3E%3C/svg%3E%3Cdiv%20class=%22overflow-hidden%22%3E%3Cdiv%20class=%22react-directory-filename-cell%22%3E%3Cdiv%20class=%22react-directory-truncate%22%3E%3Ca%20title=%22LLM_RAG_Project_1.ipynb%22%20aria-label=%22LLM_RAG_Project_1.ipynb,%20(File)%22%20class=%22Link--primary%22%20href=%22/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/blob/main/LLM_RAG_Project_1.ipynb%22%20data-discover=%22true%22%3ELLM_RAG_Project_1.ipynb%3C/a%3E%3C/div%3E%3C/div%3E%3C/div%3E%3C/div%3E%3C/td%3E%3Ctd%20class=%22react-directory-row-commit-cell%22%3E%3Cdiv%20class=%22Skeleton%20Skeleton--text%22%3E%C2%A0%3C/div%3E%3C/td%3E%3Ctd%3E%3Cdiv%20class=%22Skeleton%20Skeleton--text%22%3E%C2%A0%3C/div%3E%3C/td%3E%3C/tr%3E%3Ctr%20class=%22react-directory-row%20undefined%22%20id=%22folder-row-1%22%3E%3Ctd%20class=%22react-directory-row-name-cell-small-screen%22%20colSpan=%222%22%3E%3Cdiv%20class=%22react-directory-filename-column%22%3E%3Csvg%20aria-hidden=%22true%22%20focusable=%22false%22%20class=%22octicon%20octicon-file%20color-fg-muted%22%20viewBox=%220%200%2016%2016%22%20width=%2216%22%20height=%2216%22%20fill=%22currentColor%22%20display=%22inline-block%22%20overflow=%22visible%22%20style=%22vertical-align:text-bottom%22%3E%3Cpath%20d=%22M2%201.75C2%20.784%202.784%200%203.75%200h6.586c.464%200%20.909.184%201.237.513l2.914%202.914c.329.328.513.773.513%201.237v9.586A1.75%201.75%200%200%201%2013.25%2016h-9.5A1.75%201.75%200%200%201%202%2014.25Zm1.75-.25a.25.25%200%200%200-.25.25v12.5c0%20.138.112.25.25.25h9.5a.25.25%200%200%200%20.25-.25V6h-2.75A1.75%201.75%200%200%201%209%204.25V1.5Zm6.75.062V4.25c0%20.138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z%22%3E%3C/path%3E%3C/svg%3E%3Cdiv%20class=%22overflow-hidden%22%3E%3Cdiv%20class=%22react-directory-filename-cell%22%3E%3Cdiv%20class=%22react-directory-truncate%22%3E%3Ca%20title=%22README.md%22%20aria-label=%22README.md,%20(File)%22%20class=%22Link--primary%22%20href=%22/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/blob/main/README.md%22%20data-discover=%22true%22%3EREADME.md%3C/a%3E%3C/div%3E%3C/div%3E%3C/div%3E%3C/div%3E%3C/td%3E%3Ctd%20class=%22react-directory-row-name-cell-large-screen%22%20colSpan=%221%22%3E%3Cdiv%20class=%22react-directory-filename-column%22%3E%3Csvg%20aria-hidden=%22true%22%20focusable=%22false%22%20class=%22octicon%20octicon-file%20color-fg-muted%22%20viewBox=%220%200%2016%2016%22%20width=%2216%22%20height=%2216%22%20fill=%22currentColor%22%20display=%22inline-block%22%20overflow=%22visible%22%20style=%22vertical-align:text-bottom%22%3E%3Cpath%20d=%22M2%201.75C2%20.784%202.784%200%203.75%200h6.586c.464%200%20.909.184%201.237.513l2.914%202.914c.329.328.513.773.513%201.237v9.586A1.75%201.75%200%200%201%2013.25%2016h-9.5A1.75%201.75%200%200%201%202%2014.25Zm1.75-.25a.25.25%200%200%200-.25.25v12.5c0%20.138.112.25.25.25h9.5a.25.25%200%200%200%20.25-.25V6h-2.75A1.75%201.75%200%200%201%209%204.25V1.5Zm6.75.062V4.25c0%20.138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z%22%3E%3C/path%3E%3C/svg%3E%3Cdiv%20class=%22overflow-hidden%22%3E%3Cdiv%20class=%22react-directory-filename-cell%22%3E%3Cdiv%20class=%22react-directory-truncate%22%3E%3Ca%20title=%22README.md%22%20aria-label=%22README.md,%20(File)%22%20class=%22Link--primary%22%20href=%22/happymondaynkanta/LLM-Web-RAG-Pipeline-Intelligent-Website-Knowledge-Assistant/blob/main/README.md%22%20data-discover=%22true%22%3EREADME.md%3C/a%3E%3C/div%3E%3C/div%3E%3C/div%3E%3C/div%3E%3C/td%3E%3Ctd%20class=%22react-directory-row-commit-cell%22%3E%3Cdiv%20class=%22Skeleton%20Skeleton--text%22%3E%C2%A0%3C/div%3E%3C/td%3E%3Ctd%3E%3Cdiv%20class=%22Skeleton%20Skeleton--text%22%3E%C2%A0%3C/div%3E%3C/td%3E%3C/tr%3E%3Ctr%20class=%22react-directory-row%20undefined%22%20id=%22folder-row-2%22%3E%3Ctd%20class=%22react-directory-row-name-cell-small-screen%22%20colSpan=%222%22%3E%3Cdiv%20class=%22react-directory-filename-column%22%3E%3Csvg%20aria-hidden=%22true%22%20focusable=%22false%22%20class=%22octicon%20octicon-file%20color-fg-muted%22%20viewBox=%220%200%2016%2016%22%20width=%2216%22%20height=%2216%22%20fill=%22currentColor%22%20display=%22inline-block%22%20overflow=%22visible%22%20style=%22vertical-align:text-bottom%22%3E%3Cpath%20d=%22M2%201.75C2%20.784%202.784%200%203.75%200h6.586c.464%200%20.909.184%201.237.513l2.914%202.914c.329.328.513.773.513%201.237v9.586A1.75%201.75%200%200%201%2013.25%2016h-9.5A1.75%201.75%200%200%201%202%2014.25Zm1.75-.25a.25.25%200%200%200-.25.25v12.5c0%20.138.112.25.25.25h9.5a.25.25%200%200%200%20.25-.25V6h-2.75A1.75%201.75%200%200%201%209%204.25V1.5Zm6.75.062V4.25c0%20.138.112.25.25.25h2.688l-.011-.013-2.914-2.914-.013-.011Z%22%3E%3C/path%3E%3C/svg%3E%3Cdiv%20class=%22overflow-hidden%22%3E%3Cdiv%20class=%22react-directory-filename-cell%22%3E%3Cdiv%20class=%22react-directory-truncate%22%3E%3Ca%20title=%22Technical_Report_with_code.pdf\"}, \"cb08622a\": {\"success\": true, \"paper_id\": \"cb08622a\", \"url\": \"https://arxiv.org/pdf/2504.01346v4\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_cb08622a.pdf\", \"extracted_info\": {\"title\": \"RAGOVERTABLES: Hierarchical Memory Index, Multi-Stage Retrieval, and Benchmarking\", \"authors\": [\"Jiaru Zou\", \"Dongqi Fu\", \"Sirui Chen\", \"Xinrui He\", \"Zihao Li\", \"Yada Zhu\", \"Jiawei Han\", \"Jingrui He\"], \"abstract\": \"Retrieval-Augmented Generation (RAG) enhances Large Language Models (LLMs) by integrating them with efficient retrieval and reasoning over large-scale table corpora. This paper presents a holistic comparison of table retrieval methods, RAG methods, and table-to-graph representation learning approaches, introducing T-RAG, which achieves leading accuracy, recall, and runtime performance. Additionally, the authors establish the first large-scale multi-table question answering benchmark, MultiTableQA, to evaluate cross-table reasoning capabilities.\", \"methodology\": \"The proposed T-RAG framework combines two core techniques: (1) Hierarchical Memory Index — organizing large-scale table corpora into a hypergraph using multi-way feature extraction (semantic, structural, heuristic) and clustering; (2) Multi-Stage Retrieval — coarse-grained multi-way retrieval to filter irrelevant tables followed by fine-grained subgraph retrieval to narrow down relevant tables. The retrieved tables are then processed with a graph-aware prompting method to enable downstream LLMs to perform effective tabular reasoning. The methodology is evaluated on the MultiTableQA benchmark, which includes TFV, Single-hop TQA, and Multi-hop TQA tasks, and compared against baselines from table retrieval, RAG-based, table-to-graph representation, and table prompting methods.\", \"results\": \"T-RAG achieves state-of-the-art performance across all tasks in MultiTableQA, with accuracy improvements ranging from 1.2% to 11.4% and recall gains from 1.5% to 12.5% compared to baselines. It yields an average 11.2% improvement in downstream LLM cross-table QA performance over the strongest baselines (Table-E5, TAPAS). On the Spider dataset, T-RAG generalizes well, outperforming baselines by up to 6.5% in accuracy. Efficiency analysis shows significant reduction in candidate tables after coarse-grained retrieval (up to 99.9% reduction), leading to faster inference times. Ablation studies confirm the importance of graph-aware prompting and hierarchical reasoning components.\", \"conclusion\": \"Key contributions include: (1) Introduction of T-RAG, a novel RAG framework with hierarchical memory indexing and multi-stage retrieval tailored for large-scale table corpora; (2) Development of a hypergraph-based table-to-graph construction method leveraging multi-way feature extraction; (3) Proposal of a graph-aware prompting strategy to enhance LLM tabular reasoning; (4) Creation of MultiTableQA, the first large-scale multi-table QA benchmark; (5) Comprehensive evaluation demonstrating T-RAG’s superior accuracy, recall, runtime efficiency, and generalizability across datasets and LLMs; (6) Empirical evidence that multi-way retrieval and graph-aware prompting significantly improve cross-table reasoning performance.\", \"figures\": null, \"tables\": null}, \"citations\": [\"Marah Abdin, Jyoti Aneja, Hany Awadalla, Ahmed Awadallah, Ammar Ahmad Awan, Nguyen Bach,\", \"Amit Bahree, Arash Bakhtiari, Jianmin Bao, Harkirat Behl, et al. Phi-3 technical report: A highly\", \"capable language model locally on your phone.arXiv preprint arXiv:2404.14219, 2024.\", \"Garima Agrawal, Tharindu Kumarage, Zeyad Alghamdi, and Huan Liu. Can knowledge graphs\", \"reduce hallucinations in llms?: A survey.arXiv preprint arXiv:2311.07914, 2023.\", \"Rami Aly, Zhijiang Guo, Michael Schlichtkrull, James Thorne, Andreas Vlachos, Christos\", \"Christodoulopoulos, Oana Cocarascu, and Arpit Mittal. Feverous: Fact extraction and verifi-\", \"cation over unstructured and structured information.arXiv preprint arXiv:2106.05707, 2021.\", \"Reid Andersen, Fan R. K. Chung, and Kevin J. Lang. Local graph partitioning using pagerank vectors.\", \"In47th Annual IEEE Symposium on Foundations of Computer Science, FOCS 2006, Berkeley,\", \"California, USA, October 21-24, 2006, Proceedings, pages 475–486. IEEE Computer Society,\", \"2006. doi: 10.1109/FOCS.2006.44. URLhttps://doi.org/10.1109/FOCS.2006.44.\", \"Anthropic. Claude 3.5 sonnet, 2024. URL https://www.anthropic.com/news/\", \"Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and Hannaneh Hajishirzi. Self-rag: Learning to\", \"retrieve, generate, and critique through self-reflection. InThe Twelfth International Conference on\", \"Learning Representations, 2023.\", \"Huanhuan Cao, Daxin Jiang, Jian Pei, Qi He, Zhen Liao, Enhong Chen, and Hang Li. Context-aware\", \"10\", \"SIGKDD international conference on Knowledge discovery and data mining, pages 875–883,\", \"2008.\", \"Pei Chen, Soumajyoti Sarkar, Leonard Lausen, Balasubramaniam Srinivasan, Sheng Zha, Ruihong\", \"Huang, and George Karypis. Hytrel: Hypergraph-enhanced tabular data representation learning.\", \"Advances in Neural Information Processing Systems, 36:32173–32193, 2023.\", \"Wenhu Chen, Hongmin Wang, Jianshu Chen, Yunkai Zhang, Hong Wang, Shiyang Li, Xiyou Zhou,\", \"preprint arXiv:1909.02164, 2019.\", \"Wenhu Chen, Hanwen Zha, Zhiyu Chen, Wenhan Xiong, Hong Wang, and William Wang. Hy-\", \"arXiv:2004.07347, 2020.\", \"Eunsol Choi, Jennimaria Palomaki, Matthew Lamm, Tom Kwiatkowski, Dipanjan Das, and Michael\", \"Computational Linguistics, 9:447–461, 2021.\", \"Xiang Deng, Huan Sun, Alyssa Lees, You Wu, and Cong Yu. Turl: Table understanding through\", \"representation learning.ACM SIGMOD Record, 51(1):33–40, 2022.\", \"Vijay Prakash Dwivedi, Charilaos I. Kanatsoulis, Shenyang Huang, and Jure Leskovec. Relational\", \"deep learning: Challenges, foundations and next-generation architectures.CoRR, abs/2506.16654,\", \"2025. doi: 10.48550/ARXIV .2506.16654. URL https://doi.org/10.48550/arXiv.\", \"2506.16654.\", \"Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva Mody, Steven Truitt, and\", \"CoRR, abs/2404.16130, 2024a. doi: 10.48550/ARXIV .2404.16130. URL https://doi.org/\", \"10.48550/arXiv.2404.16130.\", \"Darren Edge, Ha Trinh, Newman Cheng, Joshua Bradley, Alex Chao, Apurva Mody, Steven Truitt,\", \"arXiv preprint arXiv:2404.16130, 2024b.\", \"Matthias Fey, Weihua Hu, Kexin Huang, Jan Eric Lenssen, Rishabh Ranjan, Joshua Robinson, Rex\", \"Ying, Jiaxuan You, and Jure Leskovec. Relational deep learning: Graph representation learning on\", \"relational databases.arXiv preprint arXiv:2312.04615, 2023.\", \"Matthias Fey, Weihua Hu, Kexin Huang, Jan Eric Lenssen, Rishabh Ranjan, Joshua Robinson,\", \"Rex Ying, Jiaxuan You, and Jure Leskovec. Position: Relational deep learning - graph rep-\", \"chine Learning, ICML 2024, Vienna, Austria, July 21-27, 2024. OpenReview.net, 2024. URL\", \"Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun,\", \"Qianyu Guo, Meng Wang, and Haofen Wang. Retrieval-augmented generation for large language\", \"models: A survey.CoRR, abs/2312.10997, 2023. doi: 10.48550/ARXIV .2312.10997. URL\", \"Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad\", \"Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, et al. The llama 3 herd of\", \"models.arXiv preprint arXiv:2407.21783, 2024.\", \"Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu,\", \"Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in llms\", \"via reinforcement learning.arXiv preprint arXiv:2501.12948, 2025.\", \"Bernal Jimenez Gutierrez, Yiheng Shu, Yu Gu, Michihiro Yasunaga, and Yu Su. Hipporag: Neuro-\", \"biologically inspired long-term memory for large language models. In Amir Globersons, Lester\", \"Mackey, Danielle Belgrave, Angela Fan, Ulrich Paquet, Jakub M. Tomczak, and Cheng Zhang,\", \"editors,Advances in Neural Information Processing Systems 38: Annual Conference on Neural\", \"11\", \"Information Processing Systems 2024, NeurIPS 2024, Vancouver, BC, Canada, December 10 -\", \"15, 2024, 2024. URL http://papers.nips.cc/paper_files/paper/2024/hash/\", \"6ddc001d07ca4f319af96a3024f6dbd1-Abstract-Conference.html.\", \"Bernal Jiménez Gutiérrez, Yiheng Shu, Weijian Qi, Sizhe Zhou, and Yu Su. From RAG to memory:\", \"Non-parametric continual learning for large language models.CoRR, abs/2502.14802, 2025.\", \"14802.\", \"Haoyu Han, Yu Wang, Harry Shomer, Kai Guo, Jiayuan Ding, Yongjia Lei, Mahantesh Halappanavar,\", \"Ryan A. Rossi, Subhabrata Mukherjee, Xianfeng Tang, Qi He, Zhigang Hua, Bo Long, Tong\", \"Zhao, Neil Shah, Amin Javari, Yinglong Xia, and Jiliang Tang. Retrieval-augmented generation\", \"with graphs (graphrag).CoRR, abs/2501.00309, 2025. doi: 10.48550/ARXIV .2501.00309. URL\", \"Xinrui He, Yikun Ban, Jiaru Zou, Tianxin Wei, Curtiss B Cook, and Jingrui He. Llm-forest:\", \"arXiv:2410.21520, 2024.\", \"Jonathan Herzig, Paweł Krzysztof Nowak, Thomas Müller, Francesco Piccinno, and Julian Mar-\", \"arXiv:2004.02349, 2020.\", \"Jonathan Herzig, Thomas Müller, Syrine Krichene, and Julian Martin Eisenschlos. Open domain\", \"question answering over tables via dense retrieval.arXiv preprint arXiv:2103.12011, 2021.\", \"Aaron Hurst, Adam Lerer, Adam P Goucher, Adam Perelman, Aditya Ramesh, Aidan Clark, AJ Os-\", \"trow, Akila Welihinda, Alan Hayes, Alec Radford, et al. Gpt-4o system card.arXiv preprint\", \"arXiv:2410.21276, 2024.\", \"Hiroshi Iida, Dung Thai, Varun Manjunatha, and Mohit Iyyer. Tabbie: Pretrained representations of\", \"tabular data.arXiv preprint arXiv:2105.02584, 2021.\", \"Mohit Iyyer, Wen-tau Yih, and Ming-Wei Chang. Search-based neural structured learning for\", \"Computational Linguistics (Volume 1: Long Papers), pages 1821–1831, 2017.\", \"Gautier Izacard, Mathilde Caron, Lucas Hosseini, Sebastian Riedel, Piotr Bojanowski, Armand\", \"Joulin, and Edouard Grave. Unsupervised dense information retrieval with contrastive learning.\", \"arXiv preprint arXiv:2112.09118, 2021.\", \"Aaron Jaech, Adam Kalai, Adam Lerer, Adam Richardson, Ahmed El-Kishky, Aiden Low, Alec\", \"Helyar, Aleksander Madry, Alex Beutel, Alex Carney, et al. Openai o1 system card.arXiv preprint\", \"arXiv:2412.16720, 2024.\", \"Kezhi Kong, Jiani Zhang, Zhengyuan Shen, Balasubramaniam Srinivasan, Chuan Lei, Christos\", \"Faloutsos, Huzefa Rangwala, and George Karypis. Opentab: Advancing large language models as\", \"open-domain table reasoners.arXiv preprint arXiv:2402.14361, 2024.\", \"Geon Lee, Fanchen Bu, Tina Eliassi-Rad, and Kijung Shin. A survey on hypergraph mining: Patterns,\", \"tools, and generators.CoRR, abs/2401.08878, 2024. doi: 10.48550/ARXIV .2401.08878. URL\", \"Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal,\", \"Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. Retrieval-augmented genera-\", \"tion for knowledge-intensive nlp tasks.Advances in Neural Information Processing Systems, 33:\", \"9459–9474, 2020.\", \"Mufei Li, Siqi Miao, and Pan Li. Simple is effective: The roles of graphs and large language models\", \"in knowledge-graph-based retrieval-augmented generation.ICLR, 2025.\", \"Shuaiqi Liu, Jiannong Cao, Ruosong Yang, and Zhiyuan Wen. Long text and multi-table summariza-\", \"tion: Dataset and method.arXiv preprint arXiv:2302.03815, 2023.\", \"12\", \"Lingrui Mei, Jiayu Yao, Yuyao Ge, Yiwei Wang, Baolong Bi, Yujun Cai, Jiazhi Liu, Mingyu Li,\", \"Zhong-Zhi Li, Duzhen Zhang, Chenlin Zhou, Jiayi Mao, Tianze Xia, Jiafeng Guo, and Shenghua\", \"Liu. A survey of context engineering for large language models.CoRR, abs/2507.13334, 2025.\", \"13334.\", \"Ali Mohammadjafari, Anthony S Maida, and Raju Gottumukkala. From natural language to sql:\", \"Review of llm-based text-to-sql systems.arXiv preprint arXiv:2410.01066, 2024.\", \"through table decomposition.arXiv preprint arXiv:2404.10150, 2024.\", \"Vaishali Pal, Andrew Yates, Evangelos Kanoulas, and Maarten de Rijke. Multitabqa: Generating\", \"tabular answers for multi-table question answering.arXiv preprint arXiv:2305.12820, 2023.\", \"Panupong Pasupat and Percy Liang. Compositional semantic parsing on semi-structured tables, 2015.\", \"Boci Peng, Yun Zhu, Yongchao Liu, Xiaohe Bo, Haizhou Shi, Chuntao Hong, Yan Zhang, and Siliang\", \"Tang. Graph retrieval-augmented generation: A survey.arXiv preprint arXiv:2408.08921, 2024.\", \"Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown, and\", \"for Computational Linguistics, 11:1316–1331, 2023.\", \"arXiv:1908.10084, 2019.\", \"Discovery in Databases: European Conference, ECML PKDD 2016, Riva del Garda, Italy,\", \"September 19-23, 2016, Proceedings, Part II 16, pages 674–689. Springer, 2016.\", \"Keshav Santhanam, Omar Khattab, Jon Saad-Falcon, Christopher Potts, and Matei Zaharia. Colbertv2:\", \"Effective and efficient retrieval via lightweight late interaction.arXiv preprint arXiv:2112.01488,\", \"2021.\", \"Parth Sarthi, Salman Abdullah, Aditi Tuli, Shubh Khanna, Anna Goldie, and Christopher D. Manning.\", \"tional Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024.\", \"OpenReview.net, 2024. URLhttps://openreview.net/forum?id=GN921JHCRw.\", \"Kwangwook Seo, Donguk Kwon, and Dongha Lee. Mt-raig: Novel benchmark and evaluation\", \"arXiv:2502.11735, 2025.\", \"Shamane Siriwardhana, Rivindu Weerasekera, Elliott Wen, Tharindu Kaluarachchi, Rajib Rana, and\", \"Linguistics, 11:1–17, 2023.\", \"Yuan Sui, Jiaru Zou, Mengyu Zhou, Xinyi He, Lun Du, Shi Han, and Dongmei Zhang. Tap4llm:\", \"Table provider on sampling, augmenting, and packing semi-structured data for large language\", \"model reasoning.arXiv preprint arXiv:2312.09039, 2023.\", \"Chang-You Tai, Ziru Chen, Tianshu Zhang, Xiang Deng, and Huan Sun. Exploring chain-of-thought\", \"style prompting for text-to-sql.arXiv preprint arXiv:2305.14215, 2023.\", \"Nan Tang, Ju Fan, Fangyi Li, Jianhong Tu, Xiaoyong Du, Guoliang Li, Sam Madden, and Mourad\", \"preparation.arXiv preprint arXiv:2012.02469, 2020.\", \"preprint arXiv:1705.06504, 2017.\", \"13\", \"Robert Van Rooij. Vagueness and linguistics. InVagueness: A guide, pages 123–170. Springer, 2011.\", \"Cunxiang Wang, Xiaoze Liu, Yuanhao Yue, Xiangru Tang, Tianhang Zhang, Cheng Jiayang, Yunzhi\", \"Yao, Wenyang Gao, Xuming Hu, Zehan Qi, Yidong Wang, Linyi Yang, Jindong Wang, Xing Xie,\", \"Zheng Zhang, and Yue Zhang. Survey on factuality in large language models: Knowledge, retrieval\", \"and domain-specificity.CoRR, abs/2310.07521, 2023a. doi: 10.48550/ARXIV .2310.07521. URL\", \"Fei Wang, Zhewei Xu, Pedro Szekely, and Muhao Chen. Robust (controlled) table-to-text generation\", \"with structure-aware equivariance learning.arXiv preprint arXiv:2205.03972, 2022a.\", \"Liang Wang, Nan Yang, Xiaolong Huang, Binxing Jiao, Linjun Yang, Daxin Jiang, Rangan Majumder,\", \"arXiv:2212.03533, 2022b.\", \"Tianshu Wang, Xiaoyang Chen, Hongyu Lin, Xianpei Han, Le Sun, Hao Wang, and Zhenyu Zeng.\", \"Simitsis, Bettina Kemme, Anna Queralt, Oscar Romero, and Petar Jovanovic, editors,Proceedings\", \"28th International Conference on Extending Database Technology, EDBT 2025, Barcelona, Spain,\", \"March 25-28, 2025, pages 707–721. OpenProceedings.org, 2025. doi: 10.48786/EDBT.2025.57.\", \"Zhiruo Wang, Jun Araki, Zhengbao Jiang, Md Rizwan Parvez, and Graham Neubig. Learning to filter\", \"context for retrieval-augmented generation.arXiv preprint arXiv:2311.08377, 2023b.\", \"Zilong Wang, Hao Zhang, Chun-Liang Li, Julian Martin Eisenschlos, Vincent Perot, Zifeng Wang,\", \"Lesly Miculicich, Yasuhisa Fujii, Jingbo Shang, Chen-Yu Lee, et al. Chain-of-table: Evolving\", \"tables in the reasoning chain for table understanding.arXiv preprint arXiv:2401.04398, 2024.\", \"Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny\", \"Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models.Advances in\", \"neural information processing systems, 35:24824–24837, 2022.\", \"Jian Wu, Linyi Yang, Dongyuan Li, Yuliang Ji, Manabu Okumura, and Yue Zhang. Mmqa: Evaluating\", \"Learning Representations, 2025.\", \"Fangyuan Xu, Weijia Shi, and Eunsol Choi. Recomp: Improving retrieval-augmented lms with\", \"compression and selective augmentation.arXiv preprint arXiv:2310.04408, 2023.\", \"An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan Li,\", \"Dayiheng Liu, Fei Huang, Haoran Wei, et al. Qwen2. 5 technical report.arXiv preprint\", \"arXiv:2412.15115, 2024.\", \"Edward Yeo, Yuxuan Tong, Morry Niu, Graham Neubig, and Xiang Yue. Demystifying long\", \"chain-of-thought reasoning in llms.arXiv preprint arXiv:2502.03373, 2025.\", \"Pengcheng Yin, Graham Neubig, Wen-tau Yih, and Sebastian Riedel. Tabert: Pretraining for joint\", \"understanding of textual and tabular data.arXiv preprint arXiv:2005.08314, 2020.\", \"Minji Yoon, Woojeong Jin, and U Kang. Fast and accurate random walk with restart on dynamic\", \"graphs with guarantees. InProceedings of the 2018 World Wide Web Conference, pages 409–418,\", \"2018.\", \"Tao Yu, Rui Zhang, Kai Yang, Michihiro Yasunaga, Dongxu Wang, Zifan Li, James Ma, Irene Li,\", \"Qingning Yao, Shanelle Roman, et al. Spider: A large-scale human-labeled dataset for complex\", \"and cross-domain semantic parsing and text-to-sql task.arXiv preprint arXiv:1809.08887, 2018.\", \"Xiaohan Yu, Pu Jian, and Chong Chen. Tablerag: A retrieval augmented generation framework for\", \"heterogeneous document reasoning.CoRR, abs/2506.10380, 2025. doi: 10.48550/ARXIV .2506.\", \"10380. URLhttps://doi.org/10.48550/arXiv.2506.10380.\", \"Tianshu Zhang, Xiang Yue, Yifei Li, and Huan Sun. Tablellama: Towards open large generalist\", \"models for tables.arXiv preprint arXiv:2311.09206, 2023a.\", \"14\", \"Zhebin Zhang, Xinyu Zhang, Yuanhang Ren, Saijiang Shi, Meng Han, Yongkang Wu, Ruofei Lai,\", \"InProceedings of the 2023 Conference on Empirical Methods in Natural Language Processing,\", \"Yilun Zhao, Yunxiang Li, Chenying Li, and Rui Zhang. Multihiertt: Numerical reasoning over multi\", \"hierarchical tabular and textual data.arXiv preprint arXiv:2206.01347, 2022.\", \"Jiaru Zou, Yikun Ban, Zihao Li, Yunzhe Qi, Ruizhong Qiu, Ling Yang, and Jingrui He. Transformer\", \"copilot: Learning from the mistake log in llm fine-tuning.arXiv preprint arXiv:2505.16270, 2025.\", \"15\", \"16\", \"ity; however, we refer to it as a representative score to highlight the specific role in our setting: quatify\", \"how well one node serves as a representative,semantically or structurally, for another under a given\", \"in a vector space, our use emphasizes task-specific interpretability, where high representative scores\", \"Now, follow the provided information and instructions below.\", \"•Given the query, figure out and find the most relevant tables (normally 1–3 tables) from the set of table\", \"• Once you have identified the relevant tables, follow step two to answer the query.\", \"<table1>, <table2>, ... (Example in HTML format)\", \"{ \\\"source_node\\\": \\\"Table 1\\\", \\\"target_node\\\": \\\"Table 2\\\", \\\"relationship\\\":\", \"{\\\"type\\\":\\\"similarity\\\", \\\"score\\\":0.674}} ...\", \"claim/query are true or false. Work through the problem step by step,\", \"and then return a 0 if it’s false, or 1 if it’s true. Only return\", \"0 or 1 without any other information. (Example Instruction for TFV\", \"•Your output MUST conclude two components: the chain-of-thought (CoT) steps to reach the final answer,\", \"•For the CoT component, you MUST enclose your reasoning between <reasoning> and\", \"•For the final answer component, you MUST enclose your answer between <answer> and</answer>\", \"•If you still cannot find the answer from the given tables and your pretrained knowledge, then output your\", \"17\", \"from single-table resources, such as Spider or Wiki-Table, into joint table sets, and then employing\", \"human experts or automated annotators (e.g., LLMs) to design queries based on these clusters.\", \"As illustrated in Figure 4 (up), the common dataset construction method has several drawbacks:\", \"(i) Sparsity of similar-topic table sets:In our preliminary experiments, we clustered tables using\", \"either primary/foreign key relationships or semantic cosine similarity of table schemas. However,\", \"even within the same topical category, tables often exhibit substantial heterogeneity. For instance,\", \"under the clustered category of “NFL Games\\\", one table’s content is about “player information\\\" and\", \"require reasoning across multiple tables with human experts or LLMs is highly resource-intensive,\", \"(e.g., LLMs) for multi-table queries often introduces bias, as both the queries and their ground-truth\", \"labels are model-generated. This divergence may compromise the realism of RAG settings, which\", \"To overcome these challenges, we reframe the data construction process bydecomposing source\", \"tablesandcombining queries. As illustrated in Figure 4 (down), our strategy guarantees that the\", \"resulting sub-tables, all derived from a single root table, maintain an intrinsic relationship, while the\", \"(a) Table Decomposition\", \"(b) Query Combination\", \"18\", \"based on the given tabular data. In our benchmark, we label an entailed (supported) claim as “1”\", \"and a refuted claim as “0”, depending on the evidence found within the tables.\", \"mation from a single table cell. However, identifying the correct cell often requires the LLMs\", \"information, as illustrated in the example figure.\", \"cells, often across different rows, columns, or tables. The final answer typically consists of a list of\", \"(2012 )2013 one year\", \"(1993)defunctone year\", \"( 2012 ) 2013 one year\", \"Answer: December 16, 2011\", \"1Patrick Makau\", \"6 Ricardo Serrano [5]2:13.32\", \"8 Simon Munyutu [6]2:14.20Athlete Born Year\", \"[5]: Ricardo Serrano  ( born 29 October 1980 ) is a\", \"[1]: Position  The ranking position on Berlin marathon hold in 2011\", \"Answer: [“Ricardo Serrano”, “6”]\", \"19\", \"multiple retrieved tables. In our experiments, we choose common table retrieval methods including\", \"DTR (Herzig et al., 2021), Table-Contriever (Izacard et al., 2021), Table-E5 (Wang et al., 2022b)\", \"and Table-LLaMA (Zhang et al., 2023a) as our baseline methods.\", \"retriever identifies relevant tables from a large corpus, which are then passed to the generator\", \"response in retrieved evidence, making it particularly effective for knowledge-intensive tasks. In\", \"our experiments, we utilize In-context RALM (Ram et al., 2023) (Abbreviated as RALM) and\", \"ColBERTv2 (Santhanam et al., 2021) (Abbreviated as ColBERT) as our baseline methods.\", \"feature representation approaches, as compared to our method described in Section 3.1. Specifically,\", \"we compare with single feature extraction methods (e.g., semantic, structural, or heuristic features\", \"alone), tabular representation learning models such as TAPAS (Herzig et al., 2020) and TaBERT\", \"(Yin et al., 2020), as well as table summarization methods such as Lattice (Wang et al., 2022a).\", \"representations, these methods enable LLMs to effectively reason over tabular inputs. In our\", \"experiments, we choose TAP4LLM (Sui et al., 2023) as our baseline method as it includes multiple\", \"plug-and-play table sampling, augmentation, and packing methods inside.\", \"both open- and closed-source LLMs. Specifically, for closed-source models, we employ Claude-3-\", \"5-Sonnet-2024-10-22 (Anthropic, 2024) (abbreviated as Claude-3.5-Sonnet), GPT-4o-2024-08-06\", \"(Hurst et al., 2024) (abbreviated as GPT-4o), and GPT-40-mini-2024-07-18 (Hurst et al., 2024)\", \"(abbreviated as GPT-4o-mini). For open-source models, we utilize the LLaMA3 families (Grattafiori\", \"et al., 2024) including LLaMA-3.1-8B-Instruct, LLaMA-3.1-70B-Instruct, and LLaMA-3.2-3B-\", \"Instruct, Phi-3.5-mini-Instruct (Abdin et al., 2024), and Qwen-2.5-7B-Instruct (Yang et al., 2024).\", \"In our experiment settings, we omit all “Instruct\\\" in the model names for brevity. For the model\", \"parameter setups, we set the temperature to 0.1, max output tokens to 4096, and top-p to 0.95.\", \"Baseline Implementation.For the Table Retrieval and RAG-based baselines, we first linearize the\", \"retrievers to the resulting table sequences, retrieving the top 10, 20, and 50 relevant tables to serve\", \"as the final input for downstream LLMs. For all Table-to-Graph baseline methods, we encode each\", \"table into an embedding representation using the respective approach, compute a similarity matrix\", \"from these embeddings, and then apply personalized PageRank to retrieve the final set of table nodes,\", \"as described in our method. For all other baselines, we strictly follow the publicly available code\", \"implementations corresponding to each method. For the downstream LLMs reasoning, we use the\", \"20\", \"Table 3 presents the overall downstream performance of T-RAG. For comparison, we also report the\", \"downstream results of the strongest baselines, including Table-E5 (as shown in Table 7) and TAPAS\", \"(as shown in Table 8). From the results, we observe that the superior retrieval capability of T-RAG\", \"to-graph representation methods. However, we also find that increasing the number of final retrieved\", \"tables can sometimes lead to performance degradation, indicating that improved retrieval metrics do\", \"report the EM@50 results.“G\\\" Stands for the Graph Information Insertion part, “H\\\" stands for the\", \"Graph-aware Prompting.To demonstrate the effectiveness of our graph-aware prompting, we\", \"formation Insertion and hierarchical Long CoT generation components, as shown in Table 9. The\", \"21\", \"final.In Tables 2 and 3, we evaluate the performance of T-RAG using different numbers\", \"of final retrieved tables, denoted as V∗\", \"final. For better demonstration, Figure 6 illustrates the retrieval\", \"downstream tasks, GPT-4o demonstrates enhanced performance with a larger number of tables,\", \"useful information from additional tables, while smaller models may struggle with lengthy prompts\", \"Table 10 presents the comparison results, reporting the accuracy (i.e., the proportion of sub-tables\", \"that using fewer clusters yields higher accuracy, but it also results in a substantial increase in the\", \"number of tables per cluster. Moreover, setting the top- ktypical nodes too low or too high can lead to\", \"performance degradation or overfitting, respectively. Based on these observations, we adopt K= 10\", \"22\", \"all three tabular reasoning tasks, which aligns with several previous PageRank studies (Rozenshtein\", \"and Gionis, 2016; Yoon et al., 2018). However, the optimal value of τvaries depending on the task\", \"due to differences in sparsity and scalability among our constructed graphs. Consequently, we tuned\", \"τover the range[0,1]to determine its most effective setting.\", \"experiment, all other hyperparameters remain fixed. We compare the retrieval accuracy and recall.\", \"23\"], \"error\": null}, \"74313379\": {\"success\": true, \"paper_id\": \"74313379\", \"url\": \"https://arxiv.org/pdf/2412.12881v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_74313379.pdf\", \"extracted_info\": {\"title\": \"RAG-Star: Retrieval-Augmented Verification for Multi-Hop Reasoning in Large Language Models\", \"authors\": [\"Akari Asai\", \"Zeqiu Wu\", \"Yizhong Wang\", \"Avirup Sil\", \"Hannaneh Hajishirzi\"], \"abstract\": \"Existing large language models (LLMs) show exceptional problem-solving capabilities but often struggle with complex multi-hop reasoning tasks when relying solely on internal knowledge. Tree-based search methods primarily depend on internal reasoning steps, limiting their effectiveness. RAG-Star proposes a retrieval-augmented verification framework that integrates both query-aware and answer-aware reward mechanisms to improve reasoning performance, addressing limitations in previous RAG and reasoning approaches.\", \"methodology\": \"The proposed RAG-Star framework combines external retrieval with a verification mechanism using Monte Carlo Tree Search (MCTS). It retrieves top-K relevant documents from an external corpus (e.g., Wikipedia 2017 dump abstracts) and evaluates reasoning paths using query-aware and answer-aware rewards. The backpropagation step updates expected rewards based on rollout results, reducing the need for expensive full rollouts. Baselines include vanilla prompting (direct prompting, Chain-of-Thought, standard RAG) and improved RAG methods (Iterative RAG, Judge-then-retrieve, Generate-then-retrieve). Experiments were conducted on four multi-hop QA datasets: HotpotQA, 2WikiMultihopQA, MusiQue, and StrategyQA, using Llama-3.1-8B-Instruct and GPT-4o models.\", \"results\": \"RAG-Star outperformed all baselines across most metrics in four datasets. For Llama-3.1-8B, it achieved up to 18.98% improvement over baselines; for GPT-4o, up to 16.19%. On StrategyQA, RAG-Star achieved CEM 84.0 and F1 68.3 for GPT-4o, and CEM 75.0 and F1 73.3 for Llama-3.1-8B. Ablation studies showed that removing query or answer scoring reduced performance, confirming the importance of each component. Performance improved with increased simulation numbers in MCTS.\", \"conclusion\": \"RAG-Star introduces a novel retrieval-augmented verification approach that effectively consolidates external and internal knowledge for multi-hop reasoning. Key contributions include: (1) integrating query-aware and answer-aware rewards into MCTS for reasoning verification; (2) reducing computational cost by avoiding full rollouts; (3) demonstrating significant performance gains over existing RAG and reasoning methods across multiple datasets and LLM architectures; (4) providing empirical evidence of the effectiveness of each framework component through ablation studies.\", \"figures\": null, \"tables\": null}, \"citations\": [\"Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and\", \"retrieve, generate, and critique through self-reflection.\", \"Representations, ICLR 2024, Vienna, Austria, May\", \"7-11, 2024 . OpenReview.net.\", \"Sebastian Borgeaud, Arthur Mensch, Jordan Hoff-\", \"mann, Trevor Cai, Eliza Rutherford, Katie Milli-\", \"can, George Bm Van Den Driessche, Jean-Baptiste\", \"Lespiau, Bogdan Damoc, Aidan Clark, et al. 2022.\", \"chine learning , pages 2206–2240. PMLR.\", \"Bradley C. A. Brown, Jordan Juravsky, Ryan Saul\", \"Ehrlich, Ronald Clark, Quoc V . Le, Christopher Ré,\", \"pling. CoRR , abs/2407.21787.\", \"Tom B. Brown, Benjamin Mann, Nick Ryder, Melanie\", \"Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\", \"Neelakantan, Pranav Shyam, Girish Sastry, Amanda\", \"Askell, Sandhini Agarwal, Ariel Herbert-V oss,\", \"Gretchen Krueger, Tom Henighan, Rewon Child,Aditya Ramesh, Daniel M. Ziegler, Jeffrey Wu,\", \"Clemens Winter, Christopher Hesse, Mark Chen, Eric\", \"Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\", \"Jack Clark, Christopher Berner, Sam McCandlish,\", \"Alec Radford, Ilya Sutskever, and Dario Amodei.\", \"2020. Language models are few-shot learners. In Ad-\", \"ing Systems 2020, NeurIPS 2020, December 6-12,\", \"2020, virtual .\", \"Jifan Chen, Shih-Ting Lin, and Greg Durrett. 2019.\", \"CoRR , abs/1910.02610.\", \"Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia,\", \"Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun, and Haofen\", \"Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot,\", \"Dan Roth, and Jonathan Berant. 2021. Did aristotle\", \"Linguistics , 9:346–361.\", \"Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasu-\", \"pat, and Mingwei Chang. 2020. Retrieval augmented\", \"ference on Machine Learning , pages 3929–3938.\", \"Peter E. Hart, Nils J. Nilsson, and Bertram Raphael.\", \"1968. A formal basis for the heuristic determina-\", \"Cybern. , 4(2):100–107.\", \"Xanh Ho, Anh-Khoa Duong Nguyen, Saku Sugawara,\", \"Conference on Computational Linguistics, COLING\", \"2020, Barcelona, Spain (Online), December 8-13,\", \"2020 , pages 6609–6625. International Committee on\", \"Linguistics: ACL 2023, Toronto, Canada, July 9-14,\", \"2023 , pages 1049–1065. Association for Computa-\", \"Zhen Huang, Zengzhi Wang, Shijie Xia, Xuefeng Li,\", \"Haoyang Zou, Ruijie Xu, Run-Ze Fan, Lyumanshan\", \"Ye, Ethan Chern, Yixin Ye, Yikai Zhang, Yuqing\", \"Yang, Ting Wu, Binjie Wang, Shichao Sun, Yang\", \"Xiao, Yiyuan Li, Fan Zhou, Steffi Chern, Yiwei\", \"Qin, Yan Ma, Jiadi Su, Yixiu Liu, Yuxiang Zheng,\", \"Shaoting Zhang, Dahua Lin, Yu Qiao, and Pengfei\", \"CoRR , abs/2406.12753.\", \"Daniel Kahneman. 2011. Thinking, fast and slow. Far-\", \"rar, Straus and Giroux .\", \"Vladimir Karpukhin, Barlas O ˘guz, Sewon Min, Patrick\", \"Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and\", \"ECML 2006, 17th European Conference on Machine\", \"Learning, Berlin, Germany, September 18-22, 2006,\", \"Proceedings , volume 4212 of Lecture Notes in Com-\", \"puter Science , pages 282–293. Springer.\", \"Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio\", \"Petroni, Vladimir Karpukhin, Naman Goyal, Hein-\", \"rich Küttler, Mike Lewis, Wen-tau Yih, Tim Rock-\", \"täschel, et al. 2020a. Retrieval-augmented generation\", \"ral Information Processing Systems , 33:9459–9474.\", \"Patrick S. H. Lewis, Ethan Perez, Aleksandra Pik-\", \"tus, Fabio Petroni, Vladimir Karpukhin, Naman\", \"Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih,\", \"Tim Rocktäschel, Sebastian Riedel, and Douwe\", \"2020, NeurIPS 2020, December 6-12, 2020, virtual .\", \"Hunter Lightman, Vineet Kosaraju, Yuri Burda, Harri-\", \"son Edwards, Bowen Baker, Teddy Lee, Jan Leike,\", \"John Schulman, Ilya Sutskever, and Karl Cobbe.\", \"2024. Let’s verify step by step. In The Twelfth In-\", \"ternational Conference on Learning Representations,\", \"ICLR 2024, Vienna, Austria, May 7-11, 2024 . Open-\", \"Qing Lyu, Shreya Havaldar, Adam Stein, Li Zhang,\", \"Delip Rao, Eric Wong, Marianna Apidianaki, and\", \"guistics, IJCNLP 2023 -Volume 1: Long Papers,\", \"Nusa Dua, Bali, November 1 - 4, 2023 , pages 305–\", \"329. Association for Computational Linguistics.\", \"Amrith Setlur, Chirag Nagpal, Adam Fisch, Xinyang\", \"Geng, Jacob Eisenstein, Rishabh Agarwal, Alekh\", \"Agarwal, Jonathan Berant, and Aviral Kumar.\", \"2024. Rewarding progress: Scaling automated pro-\", \"David Silver, Aja Huang, Chris J. Maddison, Arthur\", \"Guez, Laurent Sifre, George van den Driessche, Ju-\", \"lian Schrittwieser, Ioannis Antonoglou, Vedavyas\", \"Panneershelvam, Marc Lanctot, Sander Dieleman,Dominik Grewe, John Nham, Nal Kalchbrenner, Ilya\", \"Sutskever, Timothy P. Lillicrap, Madeleine Leach,\", \"Koray Kavukcuoglu, Thore Graepel, and Demis Has-\", \"ral networks and tree search. Nat., 529(7587):484–\", \"489.\", \"David Silver, Thomas Hubert, Julian Schrittwieser, Ioan-\", \"nis Antonoglou, Matthew Lai, Arthur Guez, Marc\", \"Lanctot, Laurent Sifre, Dharshan Kumaran, Thore\", \"Graepel, Timothy P. Lillicrap, Karen Simonyan, and\", \"algorithm. CoRR , abs/1712.01815.\", \"Charlie Snell, Jaehoon Lee, Kelvin Xu, and Aviral Ku-\", \"CoRR , abs/2408.03314.\", \"Ideas (blog) , 13(1):38.\", \"Mirac Suzgun, Nathan Scales, Nathanael Schärli, Se-\", \"bastian Gehrmann, Yi Tay, Hyung Won Chung,\", \"Aakanksha Chowdhery, Quoc V . Le, Ed H. Chi,\", \"Denny Zhou, and Jason Wei. 2023. Challenging\", \"putational Linguistics: ACL 2023, Toronto, Canada,\", \"July 9-14, 2023 , pages 13003–13051. Association for\", \"Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot,\", \"Trans. Assoc. Comput. Linguistics , 10:539–554.\", \"Chaojie Wang, Yanchen Deng, Zhiyi Lv, Zeng Liang,\", \"Jujie He, Shuicheng Yan, and Bo An. 2024a. Q*:\", \"ative planning. CoRR , abs/2406.14283.\", \"Fei Wang, Xingchen Wan, Ruoxi Sun, Jiefeng Chen,\", \"Liang Wang, Nan Yang, and Furu Wei. 2023.\", \"ing, EMNLP 2023, Singapore, December 6-10, 2023 ,\", \"Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\", \"Bosma, Brian Ichter, Fei Xia, Ed H. Chi, Quoc V . Le,\", \"ing Systems 2022, NeurIPS 2022, New Orleans, LA,\", \"USA, November 28 - December 9, 2022 .\", \"Shitao Xiao, Zheng Liu, Peitian Zhang, and Niklas\", \"Shicheng Xu, Liang Pang, Huawei Shen, Xueqi Cheng,\", \"ACM on Web Conference 2024, WWW 2024, Singa-\", \"pore, May 13-17, 2024 , pages 1362–1373. ACM.\", \"Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Ben-\", \"gio, William W. Cohen, Ruslan Salakhutdinov, and\", \"for diverse, explainable multi-hop question answer-\", \"pirical Methods in Natural Language Processing,\", \"Brussels, Belgium, October 31 - November 4, 2018 ,\", \"Shunyu Yao, Dian Yu, Jeffrey Zhao, Izhak Shafran,\", \"Thomas L. Griffiths, Yuan Cao, and Karthik\", \"Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak\", \"Shafran, Karthik Narasimhan, and Yuan Cao. 2022.\", \"Eric Zelikman, Georges Harik, Yijia Shao, Varuna\", \"Jayasiri, Nick Haber, and Noah D. Goodman. 2024.\", \"to think before speaking. CoRR , abs/2403.09629.\", \"Di Zhang, Jianbo Wu, Jingdi Lei, Tong Che, Jiatong\", \"Li, Tong Xie, Xiaoshui Huang, Shufei Zhang, Marco\", \"Pavone, Yuqiang Li, et al. 2024. Llama-berry: Pair-\", \"Ruochen Zhao, Xingxuan Li, Shafiq Joty, Chengwei\", \"Qin, and Lidong Bing. 2023a. Verify-and-edit: A\", \"1: Long Papers), ACL 2023, Toronto, Canada, July\", \"9-14, 2023 , pages 5823–5840. Association for Com-\", \"Wayne Xin Zhao, Kun Zhou, Junyi Li, Tianyi Tang,\", \"Xiaolei Wang, Yupeng Hou, Yingqian Min, Be-\", \"ichen Zhang, Junjie Zhang, Zican Dong, Yifan Du,\", \"Chen Yang, Yushuo Chen, Zhipeng Chen, Jinhao\", \"Jiang, Ruiyang Ren, Yifan Li, Xinyu Tang, Zikang\", \"Liu, Peiyu Liu, Jian-Yun Nie, and Ji-Rong Wen.\", \"2023b. A survey of large language models. CoRR ,\", \"Xinyu Zhu, Junjie Wang, Lin Zhang, Yuxiang Zhang,\", \"Yongfeng Huang, Ruyi Gan, Jiaxing Zhang, and Yu-\", \"Long Papers), ACL 2023, Toronto, Canada, July 9-14,\", \"2023 , pages 4471–4485. Association for Computa-\"], \"error\": null}, \"4aea00ae\": {\"success\": true, \"paper_id\": \"4aea00ae\", \"url\": \"https://arxiv.org/pdf/2511.22858v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_4aea00ae.pdf\", \"extracted_info\": {\"title\": \"Essential Components for Retrieval-Augmented Generation-based LLMs in Medical Litigation Support\", \"authors\": [\"Not specified\"], \"abstract\": \"This study discusses the essential components that a Retrieval-Augmented Generation (RAG)-based large language model (LLM) should have, with a focus on ensuring factual accuracy, attribution, and faithfulness in generated responses.\", \"methodology\": \"The paper reviews existing literature on RAG, Data Attribution (DA), and response faithfulness evaluation methods. It proposes approaches such as explicit constraints through prompting, chain-of-verification steps, and filtering outputs based on predefined scope. The study focuses on designing a RAG-based LLM pipeline tailored for medical litigation support in Japan.\", \"results\": \"The work identifies key challenges in ensuring generated responses remain faithful to retrieved context, particularly in domains requiring precise time-sensitive information such as medical and legal fields. It outlines potential solutions including enhanced attribution mechanisms and verification steps.\", \"conclusion\": \"The key contributions include: (1) outlining requirements for RAG-based LLMs in legal-medical contexts; (2) proposing methods to improve faithfulness and attribution in generated responses; (3) suggesting evaluation metrics for factual accuracy; and (4) presenting a roadmap for future implementation and experimentation.\", \"figures\": null, \"tables\": null}, \"citations\": [\"[1]F. Petroni, T. Rocktäschel, S. Riedel, P. Lewis, A. Bakhtin, Y. Wu, A. Miller, Language Models as\", \"Knowledge Bases?, in: Proc. of the EMNLP-IJCNLP 2019, 2019.\", \"[2]J. Wei, Y. Tay, R. Bommasani, C. Raffel, B. Zoph, S. Borgeaud, D. Yogatama, M. Bosma, D. Zhou,\", \"D. Metzler, E. H. Chi, T. Hashimoto, O. Vinyals, P. Liang, J. Dean, W. Fedus, Emergent abilities of\", \"large language models, Transactions on Machine Learning Research (TMLR) (2022) 2835–8856.\", \"[3]V. Magesh, F. Surani, M. Dahl, M. Suzgun, C. D. Manning, D. E. Ho, Hallucination-Free? Assessing\", \"the Reliability of Leading AI Legal Research Tools, Journal of Empirical Legal Studies 22 (2025)\", \"216–242.\", \"[4]Y.-W. Chu, K. Zhang, C. Malon, M. R. Min, Reducing Hallucinations of Medical Multimodal Large\", \"Language Models with Visual Retrieval-Augmented Generation , in: Proc. of the AAAI 2025, 2025.\", \"[5]G. Okanari, Saibankan no shichi riyou no kinshi (the prohibition of judge ’s use of private\", \"knowledge), Hougaku Zasshi :(Journal of Law) of Osaka City University 68 (2021) 1 – 66.\", \"[6]E. Sugiyama, Saibankan niyoru senmonchishiki no shushu to riyou (collection and use of expert\", \"knowledge by the judge, symposium: The discipline of civil judges in the exercise of their powers),\", \"[7]Y. Shirai, Mijukuji Moumakusyou to Ishi no Kashitu (Misdiagnosis of retinopathy of prematurity\", \"and Doctor ’s Negligence), Hanrei kara Manabu Minji-Jijitsu Nintei: Jurisuto Zoukan (Special\", \"[8]A. Albalak, Y. Elazar, S. M. Xie, S. Longpre, N. Lambert, X. Wang, N. Muennighoff, B. Hou, L. Pan,\", \"H. Jeong, C. Raffel, S. Chang, T. Hashimoto, W. Y. Wang, A Survey on Data Selection for Language\", \"Models, arXiv:2402.16827, 2024.\", \"[9]K. Li, O. Patel, F. Viégas, H. Pfister, M. Wattenberg, Inference-Time Intervention: Eliciting Truthful\", \"Answers from a Language Model, in: Proc. of the NeurIPS 2023, 2023.\", \"[10] P. Manakul, A. Liusie, M. Gales, SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection\", \"for Generative Large Language Models, in: Proc. of the EMNLP 2023, 2023.\", \"[11] X. Zhang, B. Peng, Y. Tian, J. Zhou, L. Jin, L. Song, H. Mi, H. Meng, Self-Alignment for Factuality:\", \"Mitigating Hallucinations in LLMs via Self-Evaluation, in: Proc. of the ACL 2024, 2024.\", \"[12] Y. Wang, R. G. Reddy, Z. M. Mujahid, A. Arora, A. Rubashevskii, J. Geng, O. M. Afzal, L. Pan,\", \"N. Borenstein, A. Pillai, I. Augenstein, I. Gurevych, P. Nakov, Factcheck-Bench: Fine-Grained\", \"Evaluation Benchmark for Automatic Fact-checkers, in: Proc. of the Findings of the EMNLP 2024,\", \"2024.\", \"[13] P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler, M. Lewis, W. tau Yih,\", \"T. Rocktäschel, S. Riedel, D. Kiela, Retrieval-Augmented Generation for Knowledge-Intensive NLP\", \"Tasks, in: Proc. of the NIPS 2020, 2020.\", \"[14] Y. Gao, Y. Xiong, X. Gao, K. Jia, J. Pan, Y. Bi, Y. Dai, J. Sun, M. Wang, H. Wang, Retrieval-Augmented\", \"Generation for Large Language Models: A Survey, arXiv:2312.10997, 2023.\", \"[15] S. T. I. Tonmoy, S. M. M. Zaman, V. Jain, A. Rani, V. Rawte, A. Chadha, A. Das, A Comprehensive\", \"Survey of Hallucination Mitigation Techniques in Large Language Models, arXiv:2401.01313, 2024.\", \"[16] P. Lewis, E. Perez, A. Piktus, F. Petroni, V. Karpukhin, N. Goyal, H. Küttler, M. Lewis, W. tau Yih,\", \"T. Rocktäschel, S. Riedel, D. Kiela, Reducing Hallucination in Structured Outputs via Retrieval-\", \"Augmented Generation, in: Proc. of the NAACL 2024, 2024.\", \"[17] W. Zhang, J. Zhang, Hallucination Mitigation for Retrieval-Augmented Large Language Models: A\", \"Review, Mathematics 13 (2025).\", \"[18] G. Pruthi, F. Liu, S. Kale, M. Sundararajan, Estimating Training Data Influence by Tracing Gradient\", \"Descent, in: Proc. of the NeurIPS 2020, 2020.\", \"[19] T. A. Chang, D. Rajagopal, T. Bolukbasi, L. Dixon, I. Tenney, Scalable Influence and Fact Tracing\", \"for Large Language Model Pretraining, in: Proc. of the ICLR 2025, 2025.\"], \"error\": null}, \"eba894bc\": {\"success\": true, \"paper_id\": \"eba894bc\", \"url\": \"https://arxiv.org/pdf/2502.13957v2\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_eba894bc.pdf\", \"extracted_info\": {\"title\": \"RAG-Gym: A Unified Framework for Optimizing Agentic Retrieval-Augmented Generation\", \"authors\": [\"Not specified in provided content\"], \"abstract\": \"Retrieval-augmented generation (RAG) has shown great promise for knowledge-intensive tasks and information retrieval. However, existing agentic RAG methods often depend on ad-hoc prompt engineering and lack a unified optimization framework. We introduce RAG-Gym, a comprehensive framework for fine-grained process-level supervision and systematic evaluation of optimization methods for agentic RAG. We present the optimized agent Re2Search++, which surpasses recent methods like Search-R1 by a relative increase of 3.2% to 11.6% in average F1, and achieves even greater gains on unseen datasets. We also examine the impact of different reward sources on agent performance.\", \"methodology\": \"The study introduces RAG-Gym, a framework for process-level supervision and evaluation in agentic RAG. It formulates knowledge-intensive question answering tasks into structured optimization problems. Multiple training algorithms are explored, including supervised fine-tuning (SFT), direct preference optimization (DPO), and proximal policy optimization (PPO). The Re2Search and Re2Search++ agents are developed using fine-grained process rewards, with reward sources including GPT-4o annotations, rollout-based methods, and Llama-based annotations. Experiments are conducted on four datasets (HotpotQA, 2WikiMultihopQA, Bamboogle, MedQA) in both zero-shot and tuned settings, with comparisons against state-of-the-art methods such as Search-R1 and R1-Searcher.\", \"results\": \"Re2Search consistently outperforms other agents in zero-shot and tuned settings, achieving +3.2% to 11.6% average F1 improvement over baselines, and +8.5% to 24.7% on unseen datasets. Re2Search++ surpasses Search-R1 and R1-Searcher in average performance, demonstrating robustness and generalizability compared to RL-based outcome supervision methods. GPT-4o annotated reward models yield the highest performance and best alignment with human preferences (85.85% agreement). Scaling studies show performance improvements with increased training data and inference-time sampling.\", \"conclusion\": \"Introduced RAG-Gym as a unified, extensible framework for optimizing agentic RAG with process-level supervision; developed Re2Search++ agent achieving state-of-the-art performance; demonstrated superiority of fine-grained process rewards over outcome supervision; provided detailed analysis of reward sources; validated robustness and generalizability across domains and datasets; established systematic evaluation protocols for agentic RAG optimization.\", \"figures\": null, \"tables\": null}, \"citations\": [\"[1]Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni\", \"Aleman, Diogo Almeida, Janko Altenschmidt, Sam Altman, Shyamal Anadkat, et al. Gpt-4\", \"technical report. arXiv preprint arXiv:2303.08774 , 2023.\", \"[2]Victor Akinwande, Yiding Jiang, Dylan Sam, and J Zico Kolter. Understanding prompt\", \"engineering may not require rethinking generalization. arXiv preprint arXiv:2310.03957 , 2023.\", \"[3]Chenxin An, Ming Zhong, Zhichao Geng, Jianqiang Yang, and Xipeng Qiu. Retrievalsum: A\", \"retrieval enhanced framework for abstractive summarization. arXiv preprint arXiv:2109.07943 ,\", \"2021.\", \"[4]Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and Hannaneh Hajishirzi. Self-rag: Learn-\", \"ing to retrieve, generate, and critique through self-reflection. In The Twelfth International\", \"Conference on Learning Representations, ICLR 2024, Vienna, Austria, May 7-11, 2024 . Open-\", \"Review.net, 2024. URL https://openreview.net/forum?id=hSyW5go0v8 .\", \"[5]Amanda Askell, Yuntao Bai, Anna Chen, Dawn Drain, Deep Ganguli, Tom Henighan, Andy\", \"Jones, Nicholas Joseph, Ben Mann, Nova DasSarma, et al. A general language assistant as a\", \"laboratory for alignment. arXiv preprint arXiv:2112.00861 , 2021.\", \"[6]Yuntao Bai, Andy Jones, Kamal Ndousse, Amanda Askell, Anna Chen, Nova DasSarma, Dawn\", \"Drain, Stanislav Fort, Deep Ganguli, Tom Henighan, et al. Training a helpful and harmless\", \"assistant with reinforcement learning from human feedback. arXiv preprint arXiv:2204.05862 ,\", \"2022.\", \"[7]Sebastian Borgeaud, Arthur Mensch, Jordan Hoffmann, Trevor Cai, Eliza Rutherford, Katie\", \"Millican, George Bm Van Den Driessche, Jean-Baptiste Lespiau, Bogdan Damoc, Aidan Clark,\", \"conference on machine learning , pages 2206–2240. PMLR, 2022.\", \"[8]Mingyang Chen, Tianpeng Li, Haoze Sun, Yijie Zhou, Chenzheng Zhu, Haofen Wang, Jeff Z\", \"Pan, Wen Zhang, Huajun Chen, Fan Yang, et al. Research: Learning to reason with search for\", \"llms via reinforcement learning. arXiv preprint arXiv:2503.19470 , 2025.\", \"[9]Mingyue Cheng, Yucong Luo, Jie Ouyang, Qi Liu, Huijie Liu, Li Li, Shuo Yu, Bohou Zhang,\", \"Jiawei Cao, Jie Ma, et al. A survey on knowledge-oriented retrieval-augmented generation.\", \"arXiv preprint arXiv:2503.10677 , 2025.\", \"[10] Hyung Won Chung, Le Hou, Shayne Longpre, Barret Zoph, Yi Tay, William Fedus, Yunxuan\", \"Li, Xuezhi Wang, Mostafa Dehghani, Siddhartha Brahma, et al. Scaling instruction-finetuned\", \"language models. Journal of Machine Learning Research , 25(70):1–53, 2024.\", \"[11] Gordon V Cormack, Charles LA Clarke, and Stefan Buettcher. Reciprocal rank fusion outper-\", \"ACM SIGIR conference on Research and development in information retrieval , pages 758–759,\", \"2009.\", \"[12] Guanting Dong, Chenghao Zhang, Mengjie Deng, Yutao Zhu, Zhicheng Dou, and Ji-Rong Wen.\", \"Progressive multimodal reasoning via active retrieval. arXiv preprint arXiv:2412.14835 , 2024.\", \"10\", \"[13] Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian, Ahmad Al-Dahle,\", \"Aiesha Letman, Akhil Mathur, Alan Schelten, Amy Yang, Angela Fan, et al. The llama 3 herd\", \"of models. arXiv preprint arXiv:2407.21783 , 2024.\", \"[14] Kawin Ethayarajh, Winnie Xu, Niklas Muennighoff, Dan Jurafsky, and Douwe Kiela. Kto:\", \"Model alignment as prospect theoretic optimization. arXiv preprint arXiv:2402.01306 , 2024.\", \"[15] Feiteng Fang, Yuelin Bai, Shiwen Ni, Min Yang, Xiaojun Chen, and Ruifeng Xu. Enhancing\", \"arXiv preprint arXiv:2405.20978 , 2024.\", \"[16] Jiayi Fu, Xuandong Zhao, Chengyuan Yao, Heng Wang, Qi Han, and Yanghua Xiao. Reward\", \"shaping to mitigate reward hacking in rlhf. arXiv preprint arXiv:2502.18770 , 2025.\", \"[17] Jingsheng Gao, Linxu Li, Weiyuan Li, Yuzhuo Fu, and Bin Dai. Smartrag: Jointly learn\", \"rag-related tasks from the environment feedback. arXiv preprint arXiv:2410.18141 , 2024.\", \"[18] Yunfan Gao, Yun Xiong, Xinyu Gao, Kangxiang Jia, Jinliu Pan, Yuxi Bi, Yi Dai, Jiawei Sun,\", \"preprint arXiv:2312.10997 , 2023.\", \"[19] Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu,\", \"Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in\", \"llms via reinforcement learning. arXiv preprint arXiv:2501.12948 , 2025.\", \"[20] Binglan Han, Teo Susnjak, and Anuradha Mathrani. Automating systematic literature reviews\", \"with retrieval-augmented generation: A comprehensive overview. Applied Sciences , 14(19):\", \"9103, 2024.\", \"[21] Xanh Ho, Anh-Khoa Duong Nguyen, Saku Sugawara, and Akiko Aizawa. Constructing a\", \"28th International Conference on Computational Linguistics , pages 6609–6625, 2020.\", \"[22] Sheryl Hsu, Omar Khattab, Chelsea Finn, and Archit Sharma. Grounding by trying: Llms with\", \"reinforcement learning-enhanced retrieval. arXiv preprint arXiv:2410.23214 , 2024.\", \"[23] Edward J Hu, Yelong Shen, Phillip Wallis, Zeyuan Allen-Zhu, Yuanzhi Li, Shean Wang,\", \"Lu Wang, and Weizhu Chen. Lora: Low-rank adaptation of large language models. arXiv\", \"preprint arXiv:2106.09685 , 2021.\", \"[24] Jian Hu, Xibin Wu, Zilin Zhu, Weixun Wang, Dehao Zhang, Yu Cao, et al. Openrlhf: An\", \"easy-to-use, scalable and high-performance rlhf framework. arXiv preprint arXiv:2405.11143 ,\", \"2024.\", \"[25] Gautier Izacard and Édouard Grave. Leveraging passage retrieval with generative models for\", \"Chapter of the Association for Computational Linguistics: Main Volume , pages 874–880, 2021.\", \"[26] Gautier Izacard, Patrick Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick, Jane\", \"Dwivedi-Yu, Armand Joulin, Sebastian Riedel, and Edouard Grave. Atlas: Few-shot learning\", \"with retrieval augmented language models. Journal of Machine Learning Research , 24(251):\", \"1–43, 2023.\", \"[27] Soyeong Jeong, Jinheon Baek, Sukmin Cho, Sung Ju Hwang, and Jong-Cheol Park. Adaptive-\", \"Linguistics: Human Language Technologies , pages 7036–7050. Association for Computational\", \"[28] Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan Su, Yan Xu, Etsuko Ishii, Ye Jin Bang,\", \"Andrea Madotto, and Pascale Fung. Survey of hallucination in natural language generation.\", \"ACM Computing Surveys , 55(12):1–38, 2023.\", \"11\", \"[29] Pengcheng Jiang, Lang Cao, Ruike Zhu, Minhao Jiang, Yunyi Zhang, Jimeng Sun, and Jiawei\", \"arXiv:2502.10996 , 2025.\", \"[30] Pengcheng Jiang, Jiacheng Lin, Lang Cao, Runchu Tian, SeongKu Kang, Zifeng Wang, Jimeng\", \"Sun, and Jiawei Han. Deepretrieval: Hacking real search engines and retrievers with large\", \"language models via reinforcement learning. arXiv preprint arXiv:2503.00223 , 2025.\", \"[31] Zhengbao Jiang, Frank F Xu, Luyu Gao, Zhiqing Sun, Qian Liu, Jane Dwivedi-Yu, Yiming Yang,\", \"Jamie Callan, and Graham Neubig. Active retrieval augmented generation. In Proceedings of\", \"the 2023 Conference on Empirical Methods in Natural Language Processing , pages 7969–7992,\", \"2023.\", \"[32] Ziyan Jiang, Xueguang Ma, and Wenhu Chen. Longrag: Enhancing retrieval-augmented\", \"generation with long-context llms. arXiv preprint arXiv:2406.15319 , 2024.\", \"[33] Bowen Jin, Hansi Zeng, Zhenrui Yue, Jinsung Yoon, Sercan Arik, Dong Wang, Hamed Za-\", \"mani, and Jiawei Han. Search-r1: Training llms to reason and leverage search engines with\", \"reinforcement learning. arXiv preprint arXiv:2503.09516 , 2025.\", \"[34] Di Jin, Eileen Pan, Nassim Oufattole, Wei-Hung Weng, Hanyi Fang, and Peter Szolovits. What\", \"medical exams. Applied Sciences , 11(14):6421, 2021.\", \"[35] Qiao Jin, Won Kim, Qingyu Chen, Donald C Comeau, Lana Yeganova, W John Wilbur, and\", \"for zero-shot biomedical information retrieval. Bioinformatics , 39(11):btad651, 2023.\", \"[36] Zhuoran Jin, Hongbang Yuan, Tianyi Men, Pengfei Cao, Yubo Chen, Kang Liu, and Jun\", \"preference alignment. arXiv preprint arXiv:2412.13746 , 2024.\", \"[37] Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov,\", \"Danqi Chen, and Wen-tau Yih. Dense passage retrieval for open-domain question answering.\", \"(EMNLP) , pages 6769–6781, 2020.\", \"[38] Tushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, and\", \"InThe Eleventh International Conference on Learning Representations, ICLR 2023, Kigali,\", \"Rwanda, May 1-5, 2023 . OpenReview.net, 2023. URL https://openreview.net/forum?\", \"[39] Jakub Lála, Odhran O’Donoghue, Aleksandar Shtedritski, Sam Cox, Samuel G Rodriques, and\", \"preprint arXiv:2312.07559 , 2023.\", \"[40] Divya Lamba. The role of prompt engineering in improving language understanding and\", \"generation. International Journal For Multidisciplinary Research , 2024. URL https://api.\", \"[41] Guido Lang and Tan Gürpinar. Ai-powered learning support: A study of retrieval-augmented\", \"Journal , 23(2), 2025.\", \"[42] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman\", \"Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, et al. Retrieval-augmented\", \"Systems , 33:9459–9474, 2020.\", \"[43] Dongheng Li, Yongchang Hao, and Lili Mou. Llmr: Knowledge distillation with a large\", \"Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024) , pages\", \"10657–10664, 2024.\", \"12\", \"[44] Xiaoxi Li, Guanting Dong, Jiajie Jin, Yuyao Zhang, Yujia Zhou, Yutao Zhu, Peitian Zhang, and\", \"arXiv:2501.05366 , 2025.\", \"[45] Xingxuan Li, Weiwen Xu, Ruochen Zhao, Fangkai Jiao, Shafiq Joty, and Lidong Bing. Can we\", \"challenging tasks. arXiv preprint arXiv:2410.01428 , 2024.\", \"[46] Hunter Lightman, Vineet Kosaraju, Yuri Burda, Harrison Edwards, Bowen Baker, Teddy\", \"Lee, Jan Leike, John Schulman, Ilya Sutskever, and Karl Cobbe. Let’s verify step by step.\", \"InThe Twelfth International Conference on Learning Representations, ICLR 2024, Vienna,\", \"Austria, May 7-11, 2024 . OpenReview.net, 2024. URL https://openreview.net/forum?\", \"[47] Fei Liu et al. Learning to summarize from human feedback. In Proceedings of the 58th Annual\", \"Meeting of the Association for Computational Linguistics , pages 583–592, 2020.\", \"[48] Siru Liu, Allison B McCoy, and Adam Wright. Improving large language model applications\", \"in biomedicine with retrieval-augmented generation: a systematic review, meta-analysis, and\", \"clinical development guidelines. Journal of the American Medical Informatics Association ,\", \"[49] Hao Ma, Tianyi Hu, Zhiqiang Pu, Liu Boyin, Xiaolin Ai, Yanyan Liang, and Min Chen. Coevolv-\", \"learning. Advances in Neural Information Processing Systems , 37:15497–15525, 2024.\", \"[50] Yu Meng, Mengzhou Xia, and Danqi Chen. Simpo: Simple preference optimization with a\", \"reference-free reward. Advances in Neural Information Processing Systems , 37:124198–124235,\", \"2024.\", \"[51] Thang Nguyen, Peter Chin, and Yu-Wing Tai. Reward-rag: Enhancing rag with reward driven\", \"supervision. arXiv preprint arXiv:2410.03780 , 2024.\", \"[52] Long Ouyang, Jeffrey Wu, Xu Jiang, Diogo Almeida, Carroll Wainwright, Pamela Mishkin,\", \"Chong Zhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to\", \"follow instructions with human feedback. Advances in neural information processing systems ,\", \"35:27730–27744, 2022.\", \"[53] Nicholas Pipitone and Ghita Houir Alami. Legalbench-rag: A benchmark for retrieval-\", \"augmented generation in the legal domain. arXiv preprint arXiv:2408.10343 , 2024.\", \"[54] Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A Smith, and Mike Lewis.\", \"Association for Computational Linguistics: EMNLP 2023 , pages 5687–5711, 2023.\", \"[55] Cheng Qian, Emre Can Acikgoz, Qi He, Hongru Wang, Xiusi Chen, Dilek Hakkani-Tür, Gokhan\", \"Tur, and Heng Ji. Toolrl: Reward is all tool learning needs. arXiv preprint arXiv:2504.13958 ,\", \"2025.\", \"[56] Rafael Rafailov, Archit Sharma, Eric Mitchell, Christopher D Manning, Stefano Ermon, and\", \"Advances in Neural Information Processing Systems , 36:53728–53741, 2023.\", \"[57] Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay, Amnon Shashua, Kevin Leyton-Brown,\", \"Association for Computational Linguistics , 11:1316–1331, 2023.\", \"[58] Stephen Robertson, Hugo Zaragoza, et al. The probabilistic relevance framework: Bm25 and\", \"beyond. Foundations and Trends® in Information Retrieval , 3(4):333–389, 2009.\", \"[59] Satya S Sahoo, Joseph M Plasek, Hua Xu, Özlem Uzuner, Trevor Cohen, Meliha Yetisgen,\", \"Hongfang Liu, Stéphane Meystre, and Yanshan Wang. Large language models for biomedicine:\", \"foundations, opportunities, challenges, and best practices. Journal of the American Medical\", \"Informatics Association , page ocae074, 2024.\", \"13\", \"[60] John Schulman, Filip Wolski, Prafulla Dhariwal, Alec Radford, and Oleg Klimov. Proximal\", \"policy optimization algorithms. arXiv preprint arXiv:1707.06347 , 2017.\", \"[61] Zhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, and Weizhu Chen.\", \"InFindings of the Association for Computational Linguistics: EMNLP 2023 , pages 9248–9274,\", \"2023.\", \"[62] Zhihong Shao, Peiyi Wang, Qihao Zhu, Runxin Xu, Junxiao Song, Xiao Bi, Haowei Zhang,\", \"Mingchuan Zhang, YK Li, Y Wu, et al. Deepseekmath: Pushing the limits of mathematical\", \"reasoning in open language models. arXiv preprint arXiv:2402.03300 , 2024.\", \"[63] Yucheng Shi, Tianze Yang, Canyu Chen, Quanzheng Li, Tianming Liu, Xiang Li, and Ninghao\", \"arXiv preprint arXiv:2502.13233 , 2025.\", \"[64] Zhengliang Shi, Shuo Zhang, Weiwei Sun, Shen Gao, Pengjie Ren, Zhumin Chen, and Zhaochun\", \"(Volume 1: Long Papers) , pages 7339–7353, 2024.\", \"[65] Noah Shinn, Federico Cassano, Ashwin Gopinath, Karthik Narasimhan, and Shunyu Yao.\", \"Processing Systems , 36, 2024.\", \"[66] Kurt Shuster, Spencer Poff, Moya Chen, Douwe Kiela, and Jason Weston. Retrieval augmenta-\", \"Linguistics: EMNLP 2021 , pages 3784–3803, 2021.\", \"[67] Joar Skalse, Nikolaus Howe, Dmitrii Krasheninnikov, and David Krueger. Defining and\", \"characterizing reward gaming. Advances in Neural Information Processing Systems , 35:9460–\", \"9471, 2022.\", \"[68] Michael D Skarlinski, Sam Cox, Jon M Laurent, James D Braza, Michaela Hinks, Michael J\", \"Hammerling, Manvitha Ponnapati, Samuel G Rodriques, and Andrew D White. Language\", \"agents achieve superhuman synthesis of scientific knowledge. arXiv preprint arXiv:2409.13740 ,\", \"2024.\", \"[69] Huatong Song, Jinhao Jiang, Yingqian Min, Jie Chen, Zhipeng Chen, Wayne Xin Zhao, Lei Fang,\", \"learning. arXiv preprint arXiv:2503.05592 , 2025.\", \"[70] Hari Subramonyam, Divy Thakkar, Andrew Ku, Juergen Dieber, and Anoop K Sinha. Prototyp-\", \"Systems , pages 1–22, 2025.\", \"[71] Zhongxiang Sun, Qipeng Wang, Weijie Yu, Xiaoxue Zang, Kai Zheng, Jun Xu, Xiao Zhang,\", \"Song Yang, and Han Li. Rearter: Retrieval-augmented reasoning with trustworthy process\", \"rewarding. arXiv preprint arXiv:2501.07861 , 2025.\", \"[72] Jakub Swacha and Michał Gracel. Retrieval-augmented generation (rag) chatbots for education:\", \"A survey of applications. Applied Sciences , 15(8):4234, 2025.\", \"[73] Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. Interleaving\", \"(Volume 1: Long Papers) , pages 10014–10037, 2023.\", \"[74] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\", \"Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. Advances in neural information\", \"processing systems , 30, 2017.\", \"14\", \"[75] Leandro von Werra, Younes Belkada, Lewis Tunstall, Edward Beeching, Tristan Thrush, Nathan\", \"Lambert, Shengyi Huang, Kashif Rasul, and Quentin Gallouédec. Trl: Transformer reinforce-\", \"ment learning. https://github.com/huggingface/trl , 2020.\", \"[76] Keheng Wang, Feiyu Duan, Sirui Wang, Peiguang Li, Yunsen Xian, Chuantao Yin, Wenge\", \"Rong, and Zhang Xiong. Knowledge-driven cot: Exploring faithful reasoning in llms for\", \"knowledge-intensive question answering. arXiv preprint arXiv:2308.13259 , 2023.\", \"[77] Peiyi Wang, Lei Li, Zhihong Shao, Runxin Xu, Damai Dai, Yifei Li, Deli Chen, Yu Wu, and\", \"(Volume 1: Long Papers) , pages 9426–9439, 2024.\", \"[78] Yuxia Wang, Minghan Wang, Muhammad Arslan Manzoor, Fei Liu, Georgi Georgiev, Rocktim\", \"Das, and Preslav Nakov. Factuality of large language models: A survey. In Proceedings of the\", \"2024 Conference on Empirical Methods in Natural Language Processing , pages 19519–19529,\", \"2024.\", \"[79] Zihao Wang, Anji Liu, Haowei Lin, Jiaqi Li, Xiaojian Ma, and Yitao Liang. Rat: Retrieval\", \"arXiv:2403.05313 , 2024.\", \"[80] Zilong Wang, Zifeng Wang, Long Le, Huaixiu Steven Zheng, Swaroop Mishra, Vincent Perot,\", \"Yuwei Zhang, Anush Mattapalli, Ankur Taly, Jingbo Shang, et al. Speculative rag: Enhancing\", \"retrieval augmented generation through drafting. arXiv preprint arXiv:2407.08223 , 2024.\", \"[81] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le,\", \"Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models.\", \"Advances in neural information processing systems , 35:24824–24837, 2022.\", \"[82] Zhepei Wei, Wei-Lin Chen, and Yu Meng. InstructRAG: Instructing retrieval-augmented\", \"Learning Representations , 2025. URL https://openreview.net/forum?id=P1qhkp8gQT .\", \"[83] Nirmalie Wiratunga, Ramitha Abeyratne, Lasal Jayawardena, Kyle Martin, Stewart Massie,\", \"Ikechukwu Nkisi-Orji, Ruvan Weerasinghe, Anne Liret, and Bruno Fleisch. Cbr-rag: case-\", \"International Conference on Case-Based Reasoning , pages 445–460. Springer, 2024.\", \"[84] Shitao Xiao, Zheng Liu, Peitian Zhang, and Niklas Muennighoff. C-pack: Packaged resources\", \"to advance general chinese embedding, 2023.\", \"[85] Guangzhi Xiong, Qiao Jin, Zhiyong Lu, and Aidong Zhang. Benchmarking retrieval-augmented\", \"2024 , pages 6233–6251, 2024.\", \"[86] Guangzhi Xiong, Qiao Jin, Xiao Wang, Minjia Zhang, Zhiyong Lu, and Aidong Zhang. Im-\", \"Biocomputing 2025: Proceedings of the Pacific Symposium , pages 199–214. World Scientific,\", \"2024.\", \"[87] Haoran Xu, Amr Sharaf, Yunmo Chen, Weiting Tan, Lingfeng Shen, Benjamin Van Durme, Ken-\", \"ton Murray, and Young Jin Kim. Contrastive preference optimization: Pushing the boundaries\", \"of llm performance in machine translation. In International Conference on Machine Learning ,\", \"pages 55204–55224. PMLR, 2024.\", \"[88] Ran Xu, Hui Liu, Sreyashi Nag, Zhenwei Dai, Yaochen Xie, Xianfeng Tang, Chen Luo, Yang\", \"Li, Joyce C Ho, Carl Yang, et al. Simrag: Self-improving retrieval-augmented generation for\", \"adapting large language models to specialized domains. arXiv preprint arXiv:2410.17952 ,\", \"2024.\", \"15\", \"[89] Ran Xu, Wenqi Shi, Yue Yu, Yuchen Zhuang, Yanqiao Zhu, May Dongmei Wang, Joyce C.\", \"Ho, Chao Zhang, and Carl Yang. BMRetriever: Tuning large language models as better\", \"biomedical text retrievers. In Yaser Al-Onaizan, Mohit Bansal, and Yun-Nung Chen, editors,\", \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing ,\", \"pages 22234–22254, Miami, Florida, USA, November 2024. Association for Computational\", \"2024.emnlp-main.1241/ .\", \"[90] Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhutdinov,\", \"and Christopher D. Manning. HotpotQA: A dataset for diverse, explainable multi-hop question\", \"answering. In Ellen Riloff, David Chiang, Julia Hockenmaier, and Jun’ichi Tsujii, editors,\", \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing ,\", \"pages 2369–2380, Brussels, Belgium, October-November 2018. Association for Computational\", \"[91] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan\", \"on Learning Representations (ICLR) , 2023.\", \"[92] Tian Yu, Shaolei Zhang, and Yang Feng. Auto-rag: Autonomous retrieval-augmented generation\", \"[93] Oussama Zekri, Ambroise Odonnat, Abdelhakim Benechehab, Linus Bleistein, Nicolas Boullé,\", \"and Ievgen Redko. Large language models as markov chains. arXiv preprint arXiv:2410.02724 ,\", \"2024.\", \"[94] Hanning Zhang, Juntong Song, Juno Zhu, Yuanhao Wu, Tong Zhang, and Cheng Niu. Rag-\", \"reward: Optimizing rag with reward modeling and rlhf. arXiv preprint arXiv:2501.13264 ,\", \"2025.\", \"[95] Peitian Zhang, Shitao Xiao, Zheng Liu, Zhicheng Dou, and Jian-Yun Nie. Retrieve anything to\", \"augment large language models. arXiv preprint arXiv:2310.07554 , 2023.\", \"[96] Tianjun Zhang, Shishir G Patil, Naman Jain, Sheng Shen, Matei Zaharia, Ion Stoica, and\", \"arXiv:2403.10131 , 2024.\", \"[97] Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu, Tingchen Fu, Xinting Huang, Enbo\", \"Zhao, Yu Zhang, Yulong Chen, et al. Siren’s song in the ai ocean: a survey on hallucination in\", \"large language models. arXiv preprint arXiv:2309.01219 , 2023.\", \"[98] Zhenru Zhang, Chujie Zheng, Yangzhen Wu, Beichen Zhang, Runji Lin, Bowen Yu, Dayiheng\", \"Liu, Jingren Zhou, and Junyang Lin. The lessons of developing process reward models in\", \"mathematical reasoning. arXiv preprint arXiv:2501.07301 , 2025.\", \"16\", \"Despite the strengths of RAG-Gym, several limitations remain. First, our framework relies on\", \"Second, as with other reward modeling approaches, there is an inherent risk of reward hacking: agents\", \"may learn to exploit imperfections or biases in the reward model, optimizing for the reward signal\", \"rather than genuine task performance [ 67,16]. Third, while our experiments focus on knowledge-\", \"intensive question answering, the generalizability of RAG-Gym to other task types (e.g., dialogue,\", \"summarization, or planning) remains to be systematically evaluated.\", \"RAG, several promising directions remain for future work. First, developing more scalable and\", \"cost-effective annotation strategies for process reward modeling is essential, especially for complex or\", \"significant gains in our experiments (Table 4), new approaches are needed to facilitate efficient and\", \"high-quality process reward collection. Second, the design and training of process reward judges can\", \"be further refined to improve robustness and reduce susceptibility to reward hacking. Third, extending\", \"as dialogue will help assess its generalizability and reveal new challenges, particularly in settings\", \"guage agents, which has the potential for wide-ranging societal benefits and risks. By enabling\", \"high-quality intermediate steps with process-level supervsion, our framework can improve the relia-\", \"bility of AI assistants in knowledge-intensive domains such as education [ 72,41], healthcare [ 48,86],\", \"scientific research [ 20,39,68], and legal analysis [ 83,53]. Also, process-level actor tuning and\", \"critic-guided inference may help reduce hallucinations and increase transparency, supporting more\", \"However, these advances also raise important considerations. The reliance on high-quality process\", \"systematic errors. Reward hacking remains a risk, as agents may learn to exploit weaknesses in the\", \"reward model, potentially leading to unintended behaviors or misinformation.\", \"In this section, we provide detailed descriptions of the datasets used in our experiments, including\", \"HotpotQA [90], 2WikiMultihopQA [21], Bamboogle [54], and MedQA [34].\", \"HotpotQA. HotpotQA is a large-scale, multi-hop question-answering dataset that requires rea-\", \"documents, allowing evaluation of models’ ability to filter relevant information effectively. As the\", \"validation set (7,405 instances) as previous research did [ 91,44]. The last 1,000 validation questions\", \"were selected for the agent evaluation on HotpotQA. The first 1,000 questions were used as the\", \"2WikiMultihopQA. 2WikiMultihopQA is another multi-hop question-answering dataset con-\", \"across different Wikipedia pages, ensuring a diverse range of factual and inferential challenges. The\", \"last 1000 questions in the development set (12,576 question in total) were used for agent evaluation.\", \"reasoning and adversarial robustness. It consists of 2-hop questions written by researchers, where\", \"17\", \"systems. Unlike automatically generated datasets like 2WikiMultihopQA and Musique, Bamboogle\", \"questions do not follow fixed templates, increasing their variability. We used the whole test set with\", \"125 questions for the evaluation of agents on Bamboogle.\", \"English split of MedQA with 1,273 USMLE-style test questions. A subset of 1,000 questions was\", \"sampled from the training set (10,178 questions) for the optimization of various agents.\", \"Direct. The Direct agent represents the simplest baseline, where the language model is prompted\", \"to output the predicted answer immediately, without any explicit intermediate reasoning or search\", \"steps. This approach tests the model’s ability to answer questions in a single step, relying solely on\", \"reasoning process before producing the final answer, but still does so in a single iteration. The agent\", \"is prompted to articulate its reasoning explicitly, which can help with complex questions by making\", \"the model’s thought process transparent and potentially improving answer accuracy. However, CoT\", \"retrieval step. At the first iteration, the agent issues the original question as a search query to retrieve\", \"relevant documents. In the subsequent step, it reasons about the updated state, which includes the\", \"retrieved information, and generates a predicted answer. This approach leverages external knowledge\", \"natural language reasoning with actions, such as issuing search queries or providing answers. At each\", \"step, the agent reasons about the current state and decides whether to search for more information or\", \"to answer the question. This enables multi-step, interactive information-seeking and supports more\", \"summarization step before reasoning. For each search query, the agent reasons about the retrieved\", \"documents and briefly summarize the useful information as the direct answer to the search query,\", \"replaces the use of raw documents with structured summaries, potentially improving reasoning\", \"In our experiments, we selected Llama-3.1-8B-Instruct [ 13] as the base LLM for the implementations\", \"of various language agents, due to its context length of 128k tokens and its availability of open-source\", \"parameters. The critic is also trained based on the same Llama-3.1-8B-Instruct, same as the actor.\", \"(Figure 2) and the generalizability of RAG-Gym (Table 3) to other LLMs.\", \"To evaluate intermediate reasoning and search steps in RAG-Gym, we design a process reward\", \"18\", \"•If the retrieval history already contains sufficient information, answering should be the preferred\", \"•Queries should also be precise, actionable, and foundational to solving the question while avoiding\", \"• Queries should introduce new, useful information rather than repeating past searches.\", \"These criteria ensure that queries are efficient, targeted, and contribute meaningfully to constructing\", \"The data collection pipeline begins with trajectory sampling, where the language agent generates a se-\", \"quence of actions based on its current policy. At each step in the trajectory, multiple candidate actions\", \"are proposed, and the best action is selected according to predefined evaluation criteria. To streamline\", \"the annotation process and ensure consistency, we employ a ranking-based evaluation framework\", \"rather than assigning numerical scores. The selected action is then executed, and the trajectory\", \"To ensure quality, only sampled trajectories that result in a correct final answer are retained, as\", \"challenges of slow and costly human annotation, we leverage LLMs such as GPT-4o to annotate\", \"the sampled trajectories. As demonstrated in our experiments (Table 4), annotations generated by\", \"GPT-4o exhibit high reliability, closely aligning with domain expert judgments. This approach\", \"enables scalable and efficient data collection, making it feasible to gather high-quality process reward\", \"randomly sampling action candidates at each time step and using an external annotator (e.g., GPT-4o)\", \"For the implementation of the IR environment, we select Wikipedia as the supporting corpus for the\", \"retrieval of relevant information for questions from HotpotQA, 2WikiMultihopQA, and Bamboogle.\", \"For the environment of solving MedQA questions, we use a combination of medical textbooks and\", \"StatPearls which were pre-processed in MedRAG [ 85]. For all tasks, we used both lexical and\", \"BGE-Base [ 84] were used for HotpotQA, 2WikiMultihopQA, and Bamboogle, while in MedQA, we\", \"For the actor tuning, we employed Low-Rank Adaptation (LoRA) [ 23] in the implementaion of\", \"19\", \"were implemented using the TRL package [ 75]. For proximal policy optimization (PPO), we used\", \"the OpenRLHF package [ 24] with full-parameter tuning. Detailed hyperparameter settings for SFT,\", \"DPO, and PPO can be found in our source code. For the tuning of Search-o1 and Re2Search agents,\", \"All results of zero-shot learning (ZSL), supervised fine-tuning (SFT), direct preference optimization\", \"(DPO), and proximal policy optimization (PPO) are generated with a temperature of 0.0. For the\", \"evaluation of agents with a critic, we employed a temperature of 1.0 with 10 different actions sampled\", \"1.Input: Original question Q, actor πθ, critic rϕ, number of candidate actions N, maximum steps\", \"T, information retrieval function IR.\", \"2.Initialize stateS←(Q, H 1=∅).\", \"3.Fort= 1toT:\", \"(a) Generate Ncandidate actions: aq,···, aN∼πf(θ)(·|S).\", \"(b) Compute process rewards and select the best action: a∗←arg max a∈{a1,···,aN}rϕ(S, a).\", \"(c)Ifa∗is a search query:\", \"ii. Update state: S←(Q, H t+1=Ht∪ {(a∗, D)}).\", \"(d)Ifa∗is a final answer:\", \"4.End For\", \"In addition to the results presented in Table 2, we further analyzed the number of search queries\", \"generated by Re2Search agents across different datasets. Table 5 reports the minimum, maximum,\", \"and mean number of search queries issued. The maximum value is capped at 10, reflecting the upper\", \"limit of iterations allowed per question in our experiments. The results show that tuned agents (SFT,\", \"DPO, and PPO) consistently generate more search queries than the zero-shot agent (ZSL), indicating\", \"that fine-tuning encourages more extensive information-seeking behavior, which aligns with their\", \"Table 5: Minimum, maximum, and mean number of search queries generated by Re2Search agents\", \"20\", \"We analyze the reasoning and search behaviors of RAG, ReAct, Search-o1, and Re2Search using an\", \"example from the Bamboogle dataset. As shown in Figure 7, given the question “What was the father\", \"of the last surviving Canadian father of Confederation?\\\", the three agents show distinct behaviors\", \"The RAG agent directly passes the question as a search query without decomposition, relying entirely\", \"intermediate facts. ReAct and Search-o1 improve upon this by engaging in stepwise query reasoning,\", \"issuing a search query. However, the generated query, “List of Canadian fathers of Confederation”,\", \"In contrast, Re2Search explicitly integrates answer reasoning with search. It first constructs a potential\", \"answer, identifying an unverified claim that William Lyon Mackenzie King is among the last surviving\", \"Canadian fathers of Confederation. Recognizing the missing evidence, it formulates a targeted query,\", \"“Who is the last surviving Canadian father of Confederation?”, to resolve the uncertainty. This\", \"approach ensures that retrieval is aligned with answer construction, minimizing unnecessary queries\", \"1.  Need to identify the\", \"2.  Start by searching for\", \"2. Mackenzie King's\", \"Similarly, when presented with a complex medical question from MedQA, the distinct approaches of\", \"the agents are evident. The RAG agent, as before, directly uses a truncated version of the lengthy\", \"input as its search query, which is unlikely to yield specific, actionable information. ReAct and\", \"Search-o1 engage in query reasoning, first hypothesizing that these symptoms suggest a possible\", \"serotonin syndrome. While this is more targeted than RAG, Re2Search demonstrates a more refined\", \"patient’s existing conditions and the suspected syndrome, it generates a highly specific query about\", \"the relationship between constipation, fibromyalgia, and cholinergic syndrome. This demonstrates\", \"answer, thereby improving the precision of its information retrieval in a complex diagnostic scenario.\", \"21\", \"(a) RAG (b) ReAct / Search-o1\", \"between constipation,\", \"fibromyalgia, and cholinergic\", \"malaise and severe diarrhea ... rhinorrhea, lacrimation, and piloerection ... pupils are dilated ...  scars are\", \"To illustrate how the trained critic improves decision-making, we examine a case from the MedQA\", \"For the generation of the first action, the agent initially generates a broad and less actionable query\", \"about heart failure, which, while relevant, does not directly contribute to identifying the correct\", \"medication. Meanwhile, it also provides another candidate action with the query “What are common\", \"classes of oral anti-diabetic medications?\\\", which leads to retrieving a structured list of relevant drug\", \"As the reasoning progresses, the process reward model continues to refine action selection, identifying\", \"the agent toward correctly inferring that the medication is most likely to be Biguanides (metformin),\", \"models enhance decision quality by selecting queries that effectively bridge knowledge gaps, leading\", \"22\", \"improves with rest. While she could previously walk to the nearby store for her groceries, she now has to\", \"receptor, B.Closure of ATP-sensitive K-channels in the pancreatic beta-cell, C.Increased gene expression of\", \"GLUT-4, D.Glucagon-like peptide-1 receptor agonist\", \"[Candidate 1 – Reasoning] ...\", \"[Candidate 1 – Action]\", \"Query : What is the primary concern with the patient’s condition, specifically whether heart failure is\", \"[Candidate 2 – Reasoning]\", \"1. The patient presents with worsening shortness of breath, increasing abdominal distention, and gross\", \"ascites. These symptoms, along with visibly engorged periumbilical veins and bilateral pitting edema, are\", \"2. The patient’s history of diabetes, which is compliant with medication, suggests that her anti-diabetic\", \"3. Considering the patient’s age (60 years) and symptoms, it is unlikely that she is taking a glucagon-like\", \"peptide-1 (GLP-1) receptor agonist, which is typically used in younger patients with type 2 diabetes and has\", \"4. With the remaining options, ’Binding to the alpha subunit of the insulin receptor’ and ’Closure of\", \"ATP-sensitive K-channels in the pancreatic beta-cell’, we can narrow down the possibilities. ’Binding to the\", \"alpha subunit of the insulin receptor’ is more characteristic of insulin receptor agonists or insulin itself, which\", \"is unlikely given the patient’s age and the oral nature of her medication. Therefore, ’Closure ofATP-sensitive\", \"5. This mechanism is consistent with the sulfonylureas class ofmedications, which are commonly used in\", \"[Candidate 2 – Action]\", \"[+ Documents]\", \"Common classes of oral anti-diabetic medications include: 1. Sulfonylureas, 2. Dipeptidyl Peptidase IV\", \"(DPP IV) inhibitors (gliptins), 3. Thiazolidinediones, 4. Meglitinides, 5. Sodium-glucose co-transporter 2\", \"(SGLT 2) inhibitors, 6. Alpha-glucosidase inhibitors, 7. Biguanides (metformin).\", \"[Candidate 1 – Reasoning] ...\", \"[Candidate 1 – Action]\", \"[Candidate 2 – Reasoning] ...\", \"[Candidate 2 – Action]\", \"[+ Documents]\", \"(AMPK) and reduce hepatic glucose production.\", \"[Candidate 1 – Reasoning] ...[Candidate 1 – Action] Answer : B/thumbs-down\", \"[Candidate 2 – Reasoning] ...[Candidate 2 – Action] Answer : C/thumbs-up\", \"23\", \"Answer the follow-up query succinctly, using only the information from the documents. When\", \"the documents do not provide sufficient information, explicitly point this out instead of making\", \"1. **### Step-by-step Reasoning**:\", \"2. **### Unverified Claim Identification**:\", \"- If yes, summarize the first piece of missing information as an atomic query to search in an\", \"- If no, clearly state that no further query is needed.\", \"3. **### Structured Output**:\", \"“predicted_answer\\\": “Provide a single letter (for multiple-choice questions), digit, word, or\", \"“generated_query\\\": “Provide an entity, question, or statement to be searched in an external\", \"knowledge base. Output \\\\“None\\\\\\\" if no query is generated.\\\",\", \"24\", \"1. **Sufficiency Check**:\", \"question. If not, the proposed action to “Answer” is inappropriate.\", \"- Prioritize queries that gather specific, missing information essential to solving the question.\", \"- If the history already contains all necessary information, then “Answer” is the most\", \"appropriate action, and the correct answer should be ranked highest.\", \"2. **Utility Check**:\", \"- Queries must be precise, actionable, and directly relevant to solving the question.\", \"3. **Redundancy Check**:\", \"25\"], \"error\": null}, \"7a470757\": {\"success\": true, \"paper_id\": \"7a470757\", \"url\": \"https://arxiv.org/pdf/2409.18313v5\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_7a470757.pdf\", \"extracted_info\": {\"title\": \"Embodied-RAG: A Framework for Retrieval-Augmented Generation from Embodied Experiences\", \"authors\": [\"P. Lewis\", \"D. Kiela\", \"S. Y. Min\", \"Yonatan\", \"Khanna\", \"Roozbeh\"], \"abstract\": \"There is no limit to how much a robot might explore and learn, but all of that knowledge needs to be searchable and actionable. Within language research, data is highly correlated, and perception requires abstraction. To address these challenges, we introduce Embodied-RAG, a framework that enhances foundational retrieval-augmented generation methods for embodied experiences, enabling search and action across varying levels of query abstraction.\", \"methodology\": \"The proposed Embodied-RAG framework constructs a hierarchical semantic memory from embodied observations using a bottom-up memory building process, organizing topological maps into semantic forests. Retrieval is performed in a dual-level manner, combining top-down abstraction with lower-level detail retrieval. The system modifies RAG’s relevancy scoring inspired by Tree-of-Thoughts, integrating spatial and semantic similarity metrics. Experiments compare Embodied-RAG against Naive-RAG, GraphRAG, and LightRAG using explicit, implicit, and global queries on E-image and E-multimodal datasets.\", \"results\": \"Embodied-RAG consistently outperforms baseline methods across all query types and metrics, achieving higher retrieval probabilities (P(Q|A) and P(Q|A,L)), shorter navigation path lengths, and faster graph memory building times (7.38× faster than GraphRAG and 9.76× faster than LightRAG). It demonstrates strong performance in both retrieval and navigation tasks, with significant gains in implicit and global query handling.\", \"conclusion\": \"Embodied-RAG provides an efficient, nonparametric embodied memory system capable of handling queries at multiple abstraction levels, outperforming existing RAG-based methods in speed and accuracy. It offers a scalable approach for integrating large nonparametric embodied memories into generalist robot agents, paving the way for more flexible and semantically rich robotic operations.\", \"figures\": null, \"tables\": null}, \"citations\": [\"[1] P. Lewis, D. Kiela et al. , “Retrieval-augmented generation for\", \"knowledge-intensive nlp tasks,” 2021.\", \"[2] A. Asai, S. Min, Z. Zhong, and D. Chen, “Acl 2023 tutorial: Retrieval-\", \"based language models and applications,” ACL 2023 , 2023.\", \"[3] J. Chen, H. Lin, X. Han, and L. Sun, “Benchmarking large language\", \"models in retrieval-augmented generation,” 2023.\", \"[4] N. Hughes et al. , “Hydra: A real-time spatial perception system for 3d\", \"scene graph construction and optimization,” RSS, 2022.\", \"[5] D. Edge, H. Trinh, N. Cheng, J. Bradley, A. Chao, A. Mody, S. Truitt,\", \"and J. Larson, “From local to global: A graph rag approach to query-\", \"focused summarization,” arXiv preprint arXiv:2404.16130 , 2024.\", \"[6] Z. Guo, L. Xia, Y . Yu, T. Ao, and C. Huang, “Lightrag: Simple\", \"and fast retrieval-augmented generation,” 2024. [Online]. Available:\", \"[7] O. Ram, Y . Levine, I. Dalmedigos, D. Muhlgay, A. Shashua, K. Leyton-\", \"Brown, and Y . Shoham, “In-context retrieval-augmented language\", \"models,” 2023. [Online]. Available: https://arxiv.org/abs/2302.00083\", \"[8] W. Fan, Y . Ding, L. Ning, S. Wang, H. Li, D. Yin, T.-S.\", \"Chua, and Q. Li, “A survey on rag meeting llms: Towards\", \"retrieval-augmented large language models,” 2024. [Online]. Available:\", \"[9] Y . Gao, Y . Xiong, X. Gao, K. Jia, J. Pan, Y . Bi, Y . Dai,\", \"J. Sun, M. Wang, and H. Wang, “Retrieval-augmented generation\", \"for large language models: A survey,” 2024. [Online]. Available:\", \"[10] L. Gao, X. Ma, J. Lin, and J. Callan, “Precise zero-shot dense\", \"retrieval without relevance labels,” 2022. [Online]. Available: https:\", \"[11] C.-M. Chan, C. Xu, R. Yuan, H. Luo, W. Xue, Y . Guo, and J. Fu,\", \"“Rq-rag: Learning to refine queries for retrieval augmented generation,”\", \"2024. [Online]. Available: https://arxiv.org/abs/2404.00610\", \"[12] S. Y . Min, D. S. Chaplot, P. Ravikumar, Y . Bisk, and R. Salakhutdinov,\", \"“Film: Following instructions in language with modular methods,” ICLR ,\", \"2021.\", \"[13] S. Y . Min, Yonatan et al. , “Don’t copy the teacher: Data and model\", \"challenges in embodied dialogue,” EMNLP , 2022.\", \"[14] Chaplot, R. R et al. , “Object goal navigation using goal-oriented\", \"semantic exploration,” NeurIPS , vol. 33, 2020.\", \"[15] N. M. M. Shafiullah, C. Paxton, L. Pinto, S. Chintala, and A. Szlam,\", \"“Clip-fields: Weakly supervised semantic fields for robotic memory,”\", \"arXiv: Arxiv-2210.05663 , 2022.\", \"[16] C. Huang, O. Mees, A. Zeng, and W. Burgard, “Visual language maps\", \"for robot navigation,” in Proceedings of the ICRA , London, UK, 2023.\", \"[17] M. Chang, T. Gervet, M. Khanna, S. Yenamandra, D. Shah, S. Y . Min,\", \"K. Shah, C. Paxton, S. Gupta, D. Batra et al. , “Goat: Go to any thing,”\", \"arXiv:2311.06430 , 2023.\", \"[18] S. K. Ramakrishnan, D. S. Chaplot, Z. Al-Halah, J. Malik, and\", \"K. Grauman, “Poni: Potential functions for objectgoal navigation with\", \"interaction-free learning,” in ICCV , 2022, pp. 18 890–18 900.\", \"[19] S. Y . Min, Y .-H. H. Tsai, W. Ding, A. Farhadi, R. Salakhutdinov,\", \"Y . Bisk, and J. Zhang, “Self-supervised object goal navigation with in-\", \"situ finetuning,” in 2023 IROS . IEEE, 2023, pp. 7119–7126.\", \"[20] Li, Fuchun et al. , “Embodied semantic scene graph generation,” in\", \"CoRL , A. Faust, D. Hsu, and G. Neumann, Eds. PMLR, 2022.\", \"[21] K. Rana et al. , “Sayplan: Grounding large language models using 3d\", \"scene graphs for scalable task planning,” in CoRL , 2023.\", \"[22] A. Hornung, K. M. Wurm, M. Bennewitz, C. Stachniss, and W. Burgard,\", \"octrees,” Autonomous robots , vol. 34, pp. 189–206, 2013.\", \"[23] L. Zhang, L. Wei, P. Shen, W. Wei, G. Zhu, and J. Song, “Semantic\", \"slam based on object detection and improved octomap,” IEEE Access ,\", \"vol. 6, pp. 75 545–75 559, 2018.\", \"[24] K. Zheng, A. Paul, and S. Tellex, “Asystem for generalized 3d multi-\", \"object search,” in 2023 ICRA . IEEE, 2023, pp. 1638–1644.\", \"[25] K. Liu, Z. Fan, M. Liu, and S. Zhang, “Object-aware semantic mapping\", \"of indoor scenes using octomap,” in 2019 Chinese Control Conference\", \"(CCC) . IEEE, 2019, pp. 8671–8676.\", \"[26] P. Anderson, A. Chang, D. S. Chaplot, A. Dosovitskiy, S. Gupta,\", \"V . Koltun, J. Kosecka, J. Malik, R. Mottaghi, M. Savva et al. , “On evalu-\", \"ation of embodied navigation agents,” arXiv preprint arXiv:1807.06757 ,\", \"2018.\", \"[27] L. Mezghan, S. Sukhbaatar, T. Lavril, O. Maksymets, D. Batra, P. Bo-\", \"janowski, and K. Alahari, “Memory-augmented reinforcement learning\", \"for image-goal navigation,” in 2022 IROS . IEEE, 2022, pp. 3316–3323.[28] Y . Zhu, R. Mottaghi, E. Kolve, J. J. Lim, A. Gupta, L. Fei-Fei, and\", \"A. Farhadi, “Target-driven visual navigation in indoor scenes using deep\", \"reinforcement learning,” in 2017 ICRA . IEEE, 2017, pp. 3357–3364.\", \"[29] J. Krantz, S. Lee, J. Malik, D. Batra, and D. S. Chaplot, “Instance-\", \"instances,” CVPR , 2022.\", \"[30] J. Gu, E. Stefani, Q. Wu, J. Thomason, and X. E. Wang, “Vision-and-\", \"language navigation: A survey of tasks, methods, and future directions,”\", \"arXiv:2203.12667 , 2022.\", \"[31] Khanna, Roozbeh et al. , “Goat-bench: A benchmark for multi-modal\", \"lifelong navigation,” arXiv:2404.06609 , 2024.\", \"[32] A. Das, S. Datta, G. Gkioxari, S. Lee, D. Parikh, and D. Batra,\", \"“Embodied question answering,” in CVPR , 2018, pp. 1–10.\", \"[33] Padalkar et al. , “Open x-embodiment: Robotic learning datasets and rt-x\", \"models,” arXiv:2310.08864 , 2023.\", \"[34] L. Yu, X. Chen, G. Gkioxari, M. Bansal, T. L. Berg, and D. Batra,\", \"“Multi-target embodied question answering,” in ICCV , 2019, p. 6309.\", \"[35] S. Tan, M. Ge, D. Guo, H. Liu, and F. Sun, “Knowledge-based\", \"embodied question answering,” IEEE Transactions on Pattern Analysis\", \"and Machine Intelligence , 2023.\", \"[36] Zhong, Tat-Seng et al. , “Video question answering: Datasets, algorithms\", \"and challenges,” arXiv:2203.01225 , 2022.\", \"[37] H. Yang, L. Chaisorn, Y . Zhao, S.-Y . Neo, and T.-S. Chua, “Videoqa:\", \"question answering on news video,” in Proceedings of the eleventh ACM\", \"international conference on Multimedia , 2003, pp. 632–641.\", \"[38] Castro, Rada et al. , “Lifeqa: A real-life dataset for video question\", \"answering,” in LREC , 2020.\", \"[39] J. Xiao, X. Shang, A. Yao, and T.-S. Chua, “Next-qa: Next phase of\", \"question-answering to explaining temporal actions,” in ICCV , 2021.\", \"[40] P. H. Sneath and R. R. Sokal, Numerical Taxonomy: The Principles and\", \"Practice of Numerical Classification . W.H. Freeman, 1973.\", \"[41] D. M ¨ullner, “Modern hierarchical, agglomerative clustering algorithms,”\", \"ArXiv , vol. abs/1109.2378, 2011. [Online]. Available: https://api.\", \"[42] S. Yao, D. Yu, J. Zhao, I. Shafran, T. Griffiths, Y . Cao, and\", \"K. Narasimhan, “Tree of thoughts: Deliberate problem solving with large\", \"language models,” NeurIPS , vol. 36, 2024.\", \"[43] S. Shah, D. Dey, C. Lovett, and A. Kapoor, “Airsim: High-fidelity visual\", \"and physical simulation for autonomous vehicles,” in FSR, 2018.\"], \"error\": null}, \"13a17071\": {\"success\": true, \"paper_id\": \"13a17071\", \"url\": \"https://arxiv.org/pdf/1204.0186v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_13a17071.pdf\", \"extracted_info\": {\"title\": \"Semantic-Sensitive Web Vector Model and Boosted Term Frequency–Inverse Document Frequency for Improved Information Retrieval\", \"authors\": [\"Not specified\"], \"abstract\": \"With the advent of the Internet, a new era of digital information exchange has begun. Information Retrieval (IR) focuses on storing, searching, and retrieving data efficiently. Traditional Boolean methods are unsuitable for document weighting, and TF-IDF does not consider synonyms, leading to missed relevant results. This paper proposes a Semantic-Sensitive Web Vector Model (SWVM) combined with a Boosted Term Frequency–Inverse Document Frequency (BTF-IDF) scheme to improve retrieval accuracy by incorporating synonyms and boosting term weights based on their HTML tag context.\", \"methodology\": \"The study compares the classical Vector Space Model (VSM) with TF-IDF weighting against the proposed SWVM with BTF-IDF. The process involves: (1) collecting 100 IT-related web documents, (2) preprocessing and tokenizing text, (3) identifying synonyms, (4) applying boosted term frequency calculations based on HTML tag importance, (5) converting documents into SWVM vectors, and (6) indexing results into a relational database. Retrieval performance is evaluated using cosine similarity between query and document vectors.\", \"results\": \"Using traditional VSM with TF-IDF yielded a cosine similarity of 0.33, indicating a weak match between query and document. The proposed SWVM with BTF-IDF significantly increased term weights by incorporating synonyms and HTML tag boosts, leading to improved retrieval accuracy. For example, \\\"Optimize\\\" achieved a BTF-IDF score of 100.32 compared to 1.52 in TF-IDF, and \\\"Performance\\\" increased from 0.32 to 11.84. Overall, the proposed approach demonstrated stronger matches and more relevant retrieval results.\", \"conclusion\": \"The paper introduces a novel SWVM model and BTF-IDF weighting scheme that address limitations of traditional TF-IDF by incorporating semantic sensitivity through synonyms and contextual HTML tag boosting. This method enhances retrieval accuracy, improves relevance ranking, and demonstrates measurable performance gains over classical approaches. Future work will explore expanding synonym databases and refining boosting values for different HTML contexts.\", \"figures\": null, \"tables\": null}, \"citations\": [\"[1] Berry, M . and Browne, M ., 2005.  “Understanding Search Engines: Mathematical Modeling and\", \"Text Retrieval ”, 2nd ed, SIAM .\", \"[2] Deitel, Deitel, and Nieto, 2002. “ Internet & World Wide Web How to Program ”, 2nd ed,\", \"[3] Dumais, S.T, 1991. “Improving the retrieval of information from external sources”, Behavior\", \"Research Methods, Instruments and Computers , No. 23, pp. 229 -236.\", \"[4] Garcia, E. , 2006. “ The Classic Vector Space Model Description, Advantages and Limitations of\", \"the C lassic Vector Space Model ”, [online] http://www.miislita.com/term -vector/term -vector -\", \"3.html.\", \"[5] Jurafsky  D., Martin J., 2008. “Speech and Language Processing”, 2nd ed, Prentice Hall .\", \"[6] Kolda, T . G., 1997. “ Limited -Memory Matrix Methods with Applications ”, Appli ed\", \"Mathematics Program , University of M aryland at College Park, pp. 59 -68.\", \"[7] Luhn, H. , 1957.  “A statistical approach of mechanized encoding and searching of literary\", \"information ”, IBM Journal of research and development , Vol. 1, No. 4, pp . 309 -317.\", \"[8] Polettini , N., 2004. “The Vector Space Model in Information Retrieval - Term Weighting\", \"[9] Salton G. and Buckley, C., 1988. “Term Weighting Approaches in Automatic Text Retrieval”,\", \"Processing and Management: an International Journal , Vol. 24, No. 5, pp. 513-523.\", \"[10] Salton, G. and McGill, M. J. , 1983. “ Introduction to Modern  Information Retrieval ”, McGraw -\", \"[11] Salton, G ., Wong, A. , and Yang , C.S., 1975.  “A Vector Space Model for A utomatic  Indexing ”,\", \"Communications of the ACM , Vol. 18 No .11, p p. 613-620.\", \"[12] Salton, G ., Wong, A. , and Yang , C.S., 1975.  “A V ector Space Model for I nformation\", \"Retrieval ”, Journal of the American Society for Information Science , Vol. 18, No. 11, pp. 613-\", \"620.\", \"[13] Singhal, A , 2001 . “Modern Information Retrieval: A Brief Overview ”, Bulletin of the IEEE\", \"Computer Society Technical Committee on Data Engineering , Vol. 24, No. 4, pp. 35-43.\", \"[14] Spark Jones, K. , 1972.  “A statistical interpr etation of term specificity and its application in\", \"retrieval ”, Journal of documentation , Vol. 28, No. 1, pp . 1-21.\"], \"error\": null}, \"9faf6b9f\": {\"success\": true, \"paper_id\": \"9faf6b9f\", \"url\": \"https://arxiv.org/pdf/1404.7099v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_9faf6b9f.pdf\", \"extracted_info\": {\"title\": \"Bibliometric-enhanced Information Retrieval (BIR 2014) Workshop Overview\", \"authors\": [\"M.K. Abbasi\", \"I. Frommholz\"], \"abstract\": \"This paper introduces the first Bibliometric-enhanced Information Retrieval (BIR 2014) workshop, which focuses on integrating bibliometric methods such as citation analysis, Bradfordizing, and network analysis into information retrieval (IR) systems. The aim is to explore how statistical modelling of scholarly communication can improve retrieval effectiveness beyond traditional text-based methods.\", \"methodology\": \"The authors employ bibliometric techniques, including citation analysis and linguistic analysis of article sections (Introduction, Methods, Results, Discussion), to identify patterns in verb usage and scholarly communication. These patterns are proposed for use in future citation classifiers to enhance IR ranking methods.\", \"results\": \"The study reveals distinct distributions of verb usage across standard sections of scholarly articles, suggesting potential for improving citation-based ranking. Preliminary evaluations indicate that bibliometric-enhanced approaches can complement traditional text-based retrieval methods.\", \"conclusion\": \"The paper contributes by (1) introducing the BIR workshop as a platform for combining bibliometrics and IR, (2) proposing linguistic analysis of scholarly writing as a tool for citation classification, and (3) advocating for ranked document lists based on bibliometric data rather than solely text relevance.\", \"figures\": null, \"tables\": null}, \"citations\": [\"1. Abbasi, M.K., Frommholz, I.: Exploiting Information Needs and Bibliographi cs\", \"on Bibliometric -enhanced Information Retrieval. pp. 21 –28 , Amsterdam, The\", \"2. Bertin, M., Atanassova, I.: A Study of Lexical Distribution in Citation Conte xts\", \"enhanced Information Retrieval. pp. 5 –12 , Amsterdam, The Netherlands (2014).\", \"3. Carevic, Z., Schaer, P.: On the Connection Between Citation -based and Topical\", \"Workshop on Bibliometric -enhanced Information Retrieval. pp. 37 –44 , Amste r-\", \"dam, The Netherlands (2014).\", \"4. Van Eck, N.J., Waltman, L.: Systematic retrieval of scientific literature based on\", \"Workshop on Bibliometric -enhanced Information Retrieval. pp. 13 –20 , Amste r-\", \"dam, The Netherlands (2014).\", \"5. Jack, K. et al.: {{citation needed}}: Filling in Wikipedia’s Citatio n Shaped Holes.\", \"al. pp. 45 –52 , Amsterdam, The Netherlands (2014).\", \"6. Mayr, P. et al.: Bibliometric -enhanced Information Retrieval. In: et al. de Rijke,\", \"M. (ed.) 36th European Co nference on IR Research, ECIR 2014, Amsterdam, The\", \"Netherlands, April 13 -16, 2014. pp. 798 –801 Springer International Publishing\", \"(2014).\", \"7. Zhao, H., Hu, X.: Language Model Document Priors based on Citation and Co -\", \"Information Retrieval. pp. 29 –36 , Amsterdam, The Netherlands (2014).\"], \"error\": null}, \"8c094ab1\": {\"success\": true, \"paper_id\": \"8c094ab1\", \"url\": \"https://arxiv.org/pdf/1601.04605v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_8c094ab1.pdf\", \"extracted_info\": {\"title\": \"Dynamic Information Retrieval Theory and Application to Multi-Page Search\", \"authors\": [\"Not explicitly provided in the given text\"], \"abstract\": \"The paper develops a theoretical framework for Dynamic Information Retrieval (DIR), building on existing static frameworks such as the Probability Ranking Principle (PRP) and Interactive Information Retrieval (IIR). It discusses the limitations of these static models and proposes a dynamic approach that adapts to user interactions over time, particularly in multi-page search scenarios. The framework is compared against existing models to highlight its potential benefits and trade-offs.\", \"methodology\": \"The authors first review and compare existing IR frameworks (PRP, IIR-PRP) to establish a baseline. They then define the components of the DIR framework, including actions, relevance, utility, time, observations, and probabilities. The framework is applied to the Multi-Page Search (MPS) problem, with experiments conducted using datasets from Web Track, Robust (AQUAINT), and ClueWeb09 Diversity Track. Multiple ranking algorithms (PRP, IIR-PRP-MPS, S-MPS, IIR-MPS, DIR-MPS) are implemented using relevance scoring techniques from the Indri search engine. Performance is evaluated using metrics such as NDCG, MAP, ERR, sAP, and sDCG, with statistical significance testing.\", \"results\": \"Experimental results show that DIR-MPS can outperform static frameworks in scenarios where diversification and personalization are important, such as the ClueWeb09 Diversity Track, achieving higher second-page utility. However, in datasets without strong diversification needs (Web Track, Robust), PRP and IIR-PRP remain highly effective. DIR-MPS tends to sacrifice first-page performance to improve later pages, which is beneficial in exploratory search but less so in precision-focused tasks.\", \"conclusion\": \"The key contributions of the paper are: (1) the first formal definition of a dynamic IR framework that incorporates user interaction over time; (2) application of the framework to the multi-page search problem; (3) empirical comparison of dynamic, static, and interactive IR models across multiple datasets; (4) demonstration that dynamic optimization can improve long-term search utility in diversification-heavy scenarios; and (5) identification of trade-offs between immediate ranking performance and long-term user satisfaction.\", \"figures\": null, \"tables\": null}, \"citations\": [], \"error\": null}, \"e99dd106\": {\"success\": true, \"paper_id\": \"e99dd106\", \"url\": \"https://arxiv.org/pdf/1501.02646v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_e99dd106.pdf\", \"extracted_info\": {\"title\": \"Bridging Bibliometrics and Information Retrieval: BIR 2015 Workshop\", \"authors\": [\"M. K. Abbasi\", \"I. Frommholz\"], \"abstract\": \"This workshop brings together experts from bibliometrics, scientometrics, and informetrics to share methods, discuss current research problems, and explore common interests. It aims to foster collaboration between communities traditionally seen as distinct, building on prior experiences to enhance research synergies.\", \"methodology\": \"The workshop format includes presentations of methods from each community, reporting on ongoing research problems, brainstorming sessions, and discussions on alternative ranking methods based on citation analysis to improve information retrieval.\", \"results\": \"The workshop facilitated lively discussions, identified shared research interests, explored possibilities for enhanced IR through bibliometric methods, and contributed to building a sustainable bridge between bibliometrics and IR.\", \"conclusion\": \"The key contributions include fostering interdisciplinary collaboration between bibliometrics and IR communities, exploring citation-based ranking methods for improved IR, and initiating future actions and special issues to continue the integration of these fields.\", \"figures\": null, \"tables\": null}, \"citations\": [\"1. Abbasi, M. K., & Frommholz, I. (2015). Cluster -based Polyrepresentation as Science\", \"1478 -1\", \"2. Jack, K., López -García, P., Hristakeva, M., & Kern, R. (2014). {{citat ion needed}}: Fil l-\", \"al, ECIR. Amsterdam. Retrieved from http://ceur -ws.org/Vol -1143/paper6.pdf\", \"3. Mayr, P., Schaer, P., Scharnhorst, A., & Mutschke, P. (2014 b). Editorial for the Bibli o-\", \"metric -enhanced Information Retrieval Workshop at ECIR 2014. In P. Mayr et al. (Ed.),\", \"1–4). Amsterdam, NL. Retrieved from http://ceur -ws.org/Vol -1143/editorial. pdf\", \"4. Mayr, P., & Scharnhorst, A. (2015). Scientometrics and Information Retrieval - weak -\", \"5. Mayr, P., Scharnhorst, A., Larsen, B., Schaer, P., & Mutschke, P. (2014 a). Bibliometric -\", \"enhanced Inform ation Retrieval. In M. et al. de Rijke (Ed.), 36th European Conference on\", \"IR Research, ECIR 2014, Amsterdam, The Netherlands, April 13 -16, 2014. Proceedings\", \"(pp. 798 –801). Springer International Publishing. doi:10.1007/978 -3-319-06028 -6_99\", \"6. Mutschke, P., Ma yr, P., Schaer, P., & Sure, Y. (2011). Science models as value -added\", \"services for scholarly information systems. Scientometrics, 89(1), 349 –364.\", \"7. White, H. D., & McCain, K. W. (1998). Visualizing a discipline: An author co -citation\", \"analysis of information science, 1972 –1995. Journal of the American Society for Info r-\", \"mation Science, 49, 327 –355.\", \"8. Wolfram, D. (2015). The Symbiotic Relationship Between Information Retrieval and\"], \"error\": null}, \"3ba9c444\": {\"success\": true, \"paper_id\": \"3ba9c444\", \"url\": \"https://arxiv.org/pdf/1606.06137v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_3ba9c444.pdf\", \"extracted_info\": {\"title\": \"Proactive Information Retrieval for Contextual Recommendations during Writing Tasks\", \"authors\": [\"K. Athukorala\", \"A. Medlar\", \"K. Ilves\", \"D. Glowacka\"], \"abstract\": \"We describe a method for proactive information retrieval targeted at retrieving relevant information during a writing task. The system estimates the current task and user needs, predicts potential next steps based on user input, and retrieves relevant documents unobtrusively. The approach uses Long Short-Term Memory (LSTM) networks for query expansion and compares performance against a user intent model based on a multi-armed bandit algorithm.\", \"methodology\": \"The proposed method uses LSTM-based text prediction to expand queries with probable next words derived from the current written context. A comparison method estimates user intent using a multi-armed bandit model, expanding queries with terms of high tf-idf values from related documents. Simulated experiments were conducted using abstracts from the Computer Science branch of the arXiv dataset (15M words, 10k vocabulary). Performance was evaluated in exploratory and known-item search tasks, comparing LSTM-based expansion, intent model expansion, and a baseline using only the written input.\", \"results\": \"Results show that both query expansion methods improve retrieval precision in exploratory search tasks compared to the baseline. LSTM-based expansion performs better when context size is large (n > 10), while the intent model performs better with small context sizes. The methods are complementary, with LSTM degrading performance for small contexts but excelling with longer contexts. Known-item search performance also improved with increased context size.\", \"conclusion\": \"The key contributions include: (1) introducing an LSTM-based query expansion method for proactive information retrieval during writing tasks; (2) demonstrating that LSTM predictions improve retrieval precision when sufficient context is available; (3) showing that a user intent model complements LSTM by performing better with limited context; (4) proposing a generalizable context-gathering approach applicable to multiple sources beyond writing tasks; and (5) developing an experimental user interface for unobtrusive proactive recommendations.\", \"figures\": null, \"tables\": null}, \"citations\": [], \"error\": null}, \"2101f1cd\": {\"success\": true, \"paper_id\": \"2101f1cd\", \"url\": \"https://arxiv.org/pdf/2503.17876v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_2101f1cd.pdf\", \"extracted_info\": {\"title\": \"Retrieval-Augmented Generation Framework for Medical Consultation with Terminology-Enhanced Information Retrieval and Emotional In-Context Learning\", \"authors\": [\"Ilan S Schwartz\", \"Katherine E Link\", \"Roxana Daneshjou\", \"Nicolás Cortés-Penfield\", \"Piet van\", \"Deeksha Varshney\", \"Aizan Zafar\", \"Niranshu Kumar Behera\", \"Asif Ekbal\", \"Ming Yang\", \"Jinglu Jiang\", \"Melody Y. Kiang\", \"Fangyun Yuan\"], \"abstract\": \"Recent advancements in Large Language Models (LLMs) have marked significant progress in understanding and responding to medical inquiries. Comprehensive experiments demonstrate the proposed method’s effectiveness in extending the context window length of existing LLMs, improving accuracy and relevance in medical dialogue generation.\", \"methodology\": \"The proposed framework integrates two core components: (1) Terminology-Enhanced Information Retrieval (TEIR), which improves query understanding beyond literal keyword matching by leveraging contextual and domain-specific terminology; and (2) Emotional In-Context Learning (EICL), which incorporates emotional dimensions into generated responses through Emotionally Attuned Generation and suffix-tuning methods. The approach maintains language model parameters unchanged while transforming continuous tasks into discrete training data, ensuring both technical precision and empathetic response generation.\", \"results\": \"The framework was evaluated on 803,564 medical consultation data entries using BLEU-5 and ROUGE-2/L metrics. Patient satisfaction studies showed higher satisfaction rates compared to baseline models: DoctorGLM (5.67%), ChatGPT-3.5 (7.17%), ChatGLM-6B (2.83%), with the proposed model achieving superior scores. BLEU-1 improved from 24.68 to 26.12, and GLEU from 8.07 to 8.23 over state-of-the-art models. Ablation studies confirmed that both TEIR and EICL significantly enhance performance in complex Chinese medical consultation tasks.\", \"conclusion\": \"The research introduces a novel retrieval-augmented generation framework that combines TEIR and EICL to deliver more accurate, context-aware, and emotionally attuned medical responses. It demonstrates substantial improvements over existing models in both technical metrics and patient satisfaction, representing a pivotal step toward more sophisticated, responsive, and empathetic AI-driven healthcare solutions.\", \"figures\": null, \"tables\": null}, \"citations\": [\"[1] Ilan S Schwartz, Katherine E Link, Roxana Daneshjou, and Nicol´ as Cort´ es-\", \"fectious diseases consultation. Clinical Infectious Diseases , page ciad633,\", \"2023.\", \"[2] Yuxin Wang and Shunda Du. Time to rebuild the doctor-patient relation-\", \"ship in china. Hepatobiliary Surgery and Nutrition , 12(2):235, 2023.\", \"[3] Hussain A Younis, Taiseer Abdalla Elfadil Eisa, Maged Nasser,\", \"Thaeer Mueen Sahib, Ameen A Noor, Osamah Mohammed Alyasiri, Sani\", \"Salisu, Israa M Hayder, and Hameed AbdulKareem Younis. A system-\", \"healthcare: Applications, considerations, limitations, motivation and chal-\", \"lenges. Diagnostics , 14(1):109, 2024.\", \"[4] Per Engelseth, BE White, Ingunn Mundal, Trude Fløystad Eines, and\", \"ture of healthcare services. Health and Technology , 11:193–209, 2021.\", \"[5] Ian L Alberts, Lorenzo Mercolli, Thomas Pyka, George Prenosil, Kuangyu\", \"Shi, Axel Rominger, and Ali Afshar-Oromieh. Large language models (llm)\", \"of nuclear medicine and molecular imaging , 50(6):1549–1552, 2023.\", \"[6] Abdulmotaleb El Saddik and Sara Ghaboura. The integration of chatgpt\", \"[7] Maksut Senbekov, Timur Saliev, Zhanar Bukeyeva, Aigul Almabayeva,\", \"Marina Zhanaliyeva, Nazym Aitenova, Yerzhan Toishibekov, Ildar\", \"Fakhradiyev, et al. The recent progress and applications of digital tech-\", \"applications , 2020, 2020.\", \"[8] Changyu Wang, Siru Liu, Hao Yang, Jiulin Guo, Yuxuan Wu, and Jialin\", \"Medical Internet Research , 25:e48009, 2023.\", \"[9] Jonah Kenei. Supporting Information Retrieval From Clinical Narrative\", \"Texts Using Text Classification and Visualization Techniques . PhD thesis,\", \"University of Nairobi, 2022.\", \"[10] Tin Kam Ho, Yen-Fu Luo, and Rodrigo Capobianco Guido. Explainability\", \"survey of representative works. IEEE Signal Processing Magazine , 39(4):96–\", \"106, 2022.\", \"[11] Piet van der Keylen, Johanna Tomandl, Katharina Wollmann, Ralph\", \"Moehler, Mario Sofroniou, Andy Maun, Sebastian Voigt-Radloff, and Luca\", \"research , 22(12):e18816, 2020.\", \"[12] Yubing Ren, Yanan Cao, Ping Guo, Fang Fang, Wei Ma, and Zheng Lin.\", \"tational Linguistics , 2023.\", \"[13] Xinke Jiang, Ruizhe Zhang, Yongxin Xu, Rihong Qiu, Yue Fang, Zhiyuan\", \"Wang, Jinyi Tang, Hongxin Ding, Xu Chu, Junfeng Zhao, and Yasha Wang.\", \"language models, 2023.\", \"[14] Yunxiang Li, Zihan Li, Kai Zhang, Ruilong Dan, Steve Jiang, and You\", \"model meta-ai (llama) using medical domain knowledge, 2023.\", \"[15] Ping Yu, Hua Xu, Xia Hu, and Chao Deng. Leveraging generative ai and\", \"tion. In Healthcare , volume 11, page 2776. MDPI, 2023.\", \"[16] Elizabeth Ford, John A Carroll, Helen E Smith, Donia Scott, and Jackie A\", \"Medical Informatics Association , 23(5):1007–1015, 2016.\", \"[17] Gary Malet, Felix Munoz, Richard Appleyard, and William Hersh. A model\", \"data”. Journal of the American Medical Informatics Association , 6(2):163–\", \"172, 1999.\", \"[18] Zhebin Zhang, Xinyu Zhang, Yuanhang Ren, Saijiang Shi, Meng Han,\", \"Yongkang Wu, Ruofei Lai, and Zhao Cao. Iag: Induction-augmented gen-\", \"2023 Conference on Empirical Methods in Natural Language Processing ,\", \"[19] Deeksha Varshney, Aizan Zafar, Niranshu Kumar Behera, and Asif Ekbal.\", \"Scientific Reports , 13(1):3310, 2023.\", \"[20] Wouter van Atteveldt, Mariken A.C.G. van der Velden, and Mark Boukes.\", \"The validity of sentiment analysis: Comparing manual annotation, crowd-\", \"coding, dictionary approaches, and machine learning algorithms. Commu-\", \"nication Methods and Measures , 15:121 – 140, 2021.\", \"[21] Ming Yang, Jinglu Jiang, Melody Y. Kiang, and Fangyun Yuan. Re-\", \"consultation service continuance decision. Information Systems Frontiers ,\", \"24:983 – 1007, 2021.\", \"[22] Ali Al-laith, Muhammad Shahbaz, Hind Alaskar, and Asim Rehmat.\", \"large arabic text corpus. Applied Sciences , 2021.\", \"[23] Zhihua Wen, Zhiliang Tian, Zhen Huang, Yuxin Yang, Zexin Jian,\", \"Changjian Wang, and Dongsheng li. Grace: Gradient-guided controllable\", \"retrieval for augmenting attribute-based text generation. pages 8377–8398,\", \"01 2023.\", \"16 J. Tang et al.\", \"[24] Yan Wan, Ziqing Peng, Yalu Wang, Yifan Zhang, Jinping Gao, and Baojun\", \"Internet Res. , 31:2055–2075, 2021.\", \"[25] Risha Gidwani, Cathina T. Nguyen, Alexis Kofoed, Catherine Carragee,\", \"Tracy A Rydel, Ian Nelligan, Amelia L Sattler, Megan Mahoney, and Steven\", \"Lin. Impact of scribes on physician satisfaction, patient satisfaction, and\", \"Medicine , 15:427 – 433, 2017.\", \"[26] Jinglu Jiang, Ann Frances Cameron, and Ming Yang. Analysis of massive\", \"return: Observational data mining study. JMIR Medical Informatics , 8,\", \"2020.\", \"[27] Honglin Xiong, Sheng Wang, Yitao Zhu, Zihao Zhao, Yuxiao Liu, Linlin\", \"Huang, Qian Wang, and Dinggang Shen. Doctorglm: Fine-tuning your chi-\", \"nese doctor is not a herculean task. ArXiv , abs/2304.01097, 2023.\", \"[28] Mustafa Said Yıldız. Comparing response performances of chatgpt-3.5,\", \"chatgpt-4 and bard to health-related questions: Comprehensiveness, accu-\", \"racy and being up-to-date. SSRN Electronic Journal , 2023.\", \"[29] Bang Yang, Asif Raza, Yuexian Zou, and Tong Zhang. Customizing general-\", \"purpose foundation models for medical report generation, 2023.\", \"[30] Junyu Lu, Di Zhang, Xiaojun Wu, Xinyu Gao, Ruyi Gan, Jiaxing Zhang,\", \"Yan Song, and Pingjian Zhang. Ziya-visual: Bilingual large vision-language\", \"model via multi-task instruction tuning. ArXiv , abs/2310.08166, 2023.\", \"[31] Hongbo Zhang, Junying Chen, Feng Jiang, Fei Yu, Zhihong Chen, Jianquan\", \"Li, Guimin Chen, Xiangbo Wu, Zhiyi Zhang, Qingying Xiao, Xiang Wan,\", \"Benyou Wang, and Haizhou Li. Huatuogpt, towards taming language model\"], \"error\": null}, \"8e826f4f\": {\"success\": true, \"paper_id\": \"8e826f4f\", \"url\": \"https://arxiv.org/pdf/2404.08628v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_8e826f4f.pdf\", \"extracted_info\": {\"title\": \"Document Accessibility: Evaluating the Access Afforded to a Document by the Retrieval System\", \"authors\": [\"L. Azzopardi\", \"V. Vinay\"], \"abstract\": \"This paper introduces the concept of accessibility from the field of transportation planning and adapts it to the context of Information Retrieval (IR). Accessibility, originally defined as a measure of potential opportunities in transportation and land use, is applied here to evaluate how easily documents can be accessed within an IR system.\", \"methodology\": \"The study draws on established accessibility measures from transportation planning, specifically gravity-based and cumulative-based methods, and adapts them to quantify document accessibility in IR systems. The methodology involves defining accessibility in IR, selecting appropriate measurement techniques, and applying them to assess retrievability of documents within a collection.\", \"results\": \"The paper demonstrates that accessibility measures can be successfully adapted to IR, providing a novel abstraction for quantifying and detecting varying levels of document accessibility imposed by retrieval systems. This approach enables identification of disparities in retrievability across documents.\", \"conclusion\": \"The main contributions are: (1) introduction of the concept of accessibility into the IR domain; (2) proposal of methods to measure accessibility of documents; (3) adaptation of transportation-based accessibility measures to IR; (4) providing a framework to quantify and detect differences in document retrievability within collections.\", \"figures\": null, \"tables\": null}, \"citations\": [\"1. L. Azzopardi and V. Vinay. Document accessibility: Evalu ating the access aﬀorded\", \"Evaluation in Information Retrieval , pages 52–60, March 2008.\", \"2. L. Azzopardi and V. Vinay. Retrievability: an evaluation measure for higher order\", \"tion and Knowledge Management , CIKM ’08, page 561–570, 2008.\", \"3. R. Baeza-Yates, A. Gionis, F. Junqueira, V. Murdock, V. Pl achouras, and F. Sil-\", \"SIGIR conference , pages 183–190, 2007.\", \"4. P. Bailey, N. Craswell, and D. Hawking. Chart of darkness: Mapping a large\", \"intranet. Technical report, CSIRO Mathematical and Inform ation Sciences, 2000.\", \"5. S. Buttcher and C. L. A. Clarke. A document-centric approa ch to static index\", \"Information and Knowledge Management , 2006.\", \"6. W. S. Cooper. Expected search length: A single measure of r etrieval eﬀectiveness\", \"for Information Science , 19(1):30–41, 1968.\", \"7. X. Dong, M. E. Ben-Akiva, J. L. Bowman, and J. L. Walker. Mov ing from trip-\", \"based to activity-based measures of accessibility. Transportation research. Part A,\", \"Policy and practice , 40(2):163–180, 2006.\", \"8. I. Fajardo, J. J. Canas, L. Salmeron, and J. Abascal. Impro ving deaf users’ acces-\", \"Behaviour and Information Technology , 25(6):455–467(13), 2006.\", \"9. S. Garcia, H. E. Williams, and A. Cannane. Access-ordered indexes. In Twenty-\", \"Seveth Australasian Computer Science Conference (ACSC200 4), pages 7–14, 2004.\", \"10. W. Hansen. How accessibility shape land use. Journal of the American Institute\", \"of Planners , 25(2):73–76, 1959.\", \"11. D. Hawking. Challenges in enterprise search. In ADC ’04: Proceedings of the 15th\", \"Australasian database conference , pages 15–24, Darlinghurst, Australia, Australia,\", \"2004. Australian Computer Society, Inc.\", \"12. H. Neuburger. User beneﬁt in the evaluation of transport and land use plans.\", \"Journal of Transport Economics and Policy , 5:52–75, 1971.\", \"13. T. Upstill, N. Craswell, and D. Hawking. Buying bestsell ers online: A case study\", \"in search & searchability. In 7th Australasian Document Computing Symposium ,\", \"Sydney, Australia, 2002.\", \"14. C. J. van Rijsbergen. Information Retrieval . Butterworths, London, second edition\", \"15. M. Wachs and T. G. Kumagai. Physiscal accessibility as a s ocial indicator. So-\", \"cioeconomic Planning Science , 7:327–456, 1973.\", \"16. I. H. Witten, A. Moﬀat, and B. T. C. Managing Gigabytes: Compressing and\", \"Indexing Documents and Images . Morgan Kaufmann Publishing, San Franciso,\", \"second edition edition, 1999.\"], \"error\": null}, \"654c0488\": {\"success\": true, \"paper_id\": \"654c0488\", \"url\": \"https://arxiv.org/pdf/1811.08772v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_654c0488.pdf\", \"extracted_info\": {\"title\": \"Overcoming Low-Utility Facets for Complex Answer Retrieval\", \"authors\": [\"N. Goharian\", \"O. Frieder\", \"Sean MacAvaney\", \"Kai Hui\", \"Andrew Yates\"], \"abstract\": \"Many questions cannot be answered simply; their answers must include numerous nuanced details and additional context. Complex Answer Retrieval (CAR) is the retrieval of such answers, which often consist of multiple facets. This work addresses the challenge of low-utility facets—facets that are difficult to match in retrieval systems—by proposing enhancements to neural ranking models to improve performance in CAR tasks.\", \"methodology\": \"The study focuses on enhancing the PACRR neural ranking model for CAR by integrating contextual vectors (heading position, heading frequency, heading independence) and knowledge graph similarity features. The methodology involves generating a custom knowledge graph from the CAR dataset, training PACRR with BM25 re-ranked results, and evaluating using both manual and automatic relevance judgments from the TREC CAR dataset. Various configurations of the enhanced PACRR model are compared against the baseline PACRR and BM25 rankings using metrics such as nDCG.\", \"results\": \"The enhanced PACRR models consistently outperform the unmodified PACRR and BM25 baselines, particularly for queries with low-utility facets. Improvements include up to +7.2% in certain evaluation metrics. Configurations with heading position and heading frequency contextual vectors yield the most significant gains, while knowledge graph features offer mixed results. Statistical significance is observed in several configurations compared to the baseline.\", \"conclusion\": \"This work is one of the first comprehensive studies on CAR, identifying low-utility facets as a key challenge and demonstrating that targeted neural ranking model enhancements can improve retrieval performance. The proposed methods—contextual vectors and knowledge graph similarity—provide valuable insights for future CAR research, particularly in handling nuanced and complex queries.\", \"figures\": null, \"tables\": null}, \"citations\": [\"1. Auer S., Bizer C., Kobilarov G., Lehmann J., Cyganiak R., Ives Z. G.\", \"(2007) DBpedia: A nucleus for a web of open data. In: ISWC/ASWC\", \"2. Bollacker K. D., Evans C., Paritosh P., Sturge T., Taylor J. (2008) Free-\", \"3. Bordes A., Usunier N., García-Durán A., Weston J., Yakhnenko O. (2013)\", \"4. DaiZ.,XiongC.,CallanJ.P.,LiuZ.(2018)Convolutionalneuralnetworks\", \"5. DaiberJ.,JakobM.,HokampC.,MendesP.N.(2013)Improvingeﬃciency\", \"6. Dalton J., Dietz L., Allan J. (2014) Entity query feature expansion using\", \"knowledge base links. In: SIGIR 2014, ACM\", \"7. Dietz L., Gamari B. (2017) TREC CAR: A data set for complex answer\", \"8. Dietz L., Verma M., Radlinski F., Craswell N. (2017) TREC complex\", \"9. Guo J., Fan Y., Ai Q., Croft W. B. (2016) A deep relevance matching\", \"10. Heilman J. M., West A. G. (2015) Wikipedia and medicine: quantifying\", \"readership, editors, and the signiﬁcance of natural language. Journal of\", \"11. Huang P.-S., He X., Gao J., Deng L., Acero A., Heck L. (2013) Learning\", \"12. Hui K., Yates A., Berberich K., de Melo G. (2017) PACRR: A position-\", \"13. Hui K., Yates A., Berberich K., de Melo G. (2018) Co-PACRR: A context-\", \"22 Sean MacAvaney et al.\", \"14. Levy O., Goldberg Y. (2014) Dependency-based word embeddings. In:\", \"15. Lin X., Lam W. (2017) CUIS team for TREC 2017 CAR track. In: TREC\", \"2017\", \"16. MacAvaneyS.,HuiK.,YatesA.(2017)Anapproachforweakly-supervised\", \"17. MacAvaney S., Yates A., Hui K. (2017) Contextualized PACRR for com-\", \"18. MacAvaney S., Yates A., Cohan A., Soldaini L., Hui K., Goharian N.,\", \"19. Maldonado R., Taylor S., Harabagiu S. M. (2017) UTD HLTRI at TREC\", \"2017: Complex answer retrieval track. In: TREC 2017\", \"20. Metzler D., Croft W. B. (2005) A markov random ﬁeld model for term\", \"21. Mitra B., Diaz F., Craswell N. (2017) Learning to match using local and\", \"22. Nanni F., Mitra B., Magnusson M., Dietz L. (2017) Benchmark for com-\", \"23. Nickel M., Rosasco L., Poggio T. A. (2016) Holographic embeddings of\", \"24. Nogueira R., Cho K. (2017) Task-oriented query reformulation with rein-\", \"25. Nogueira R., Cho K., Patel U., Chabot V. (2017) New york university\", \"26. PangL.,LanY.,GuoJ.,XuJ.,ChengX.(2016)AstudyofMatchPyramid\", \"27. Pang L., Lan Y., Guo J., Xu J., Xu J., Cheng X. (2017) DeepRank: A\", \"28. Sakai T., Kando N. (2008) On information retrieval metrics designed for\", \"11(5):447–470\", \"29. Schuhmacher M., Dietz L., Ponzetto S. P. (2015) Ranking entities for web\", \"30. Singh A. (2012) Entity based q&a retrieval. In: EMNLP-CoNLL\", \"31. Singh S., Subramanya A., Pereira F., McCallum A. (2012) Wikilinks:\", \"wikipedia. University of Massachusetts, Amherst, Tech Rep UM-CS-2012\", \"15\", \"32. Wang Z., Zhang J., Feng J., Chen Z. (2014) Knowledge graph embedding\", \"33. Xiong C., Callan J. (2015) Query expansion with Freebase. In: ICTIR\", \"2015, ACM\", \"34. Xiong C., Dai Z., Callan J., Liu Z., Power R. (2017) End-to-End Neural\", \"Ad-hoc Ranking with Kernel Pooling. In: SIGIR 2017, ACM\", \"35. tau Yih W., Chang M.-W., He X., Gao J. (2015) Semantic parsing via\"], \"error\": null}, \"44f513e7\": {\"success\": true, \"paper_id\": \"44f513e7\", \"url\": \"https://arxiv.org/pdf/2210.09877v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_44f513e7.pdf\", \"extracted_info\": {\"title\": \"Using Wikipedia Concepts for Proactive Information Retrieval\", \"authors\": [\"S. Bulathwela\", \"M. Pérez-Ortiz\", \"E. Yilmaz\", \"J. Shawe-Taylor\"], \"abstract\": \"Extracting useful information from the user history to clearly understand informational needs is a challenging task due to contextual dependencies and noise. This paper explores the use of Wikipedia concepts to refine query and document representations, aiming to improve relevance prediction in information retrieval systems.\", \"methodology\": \"The study employs probabilistic retrieval models (BM25 and DPH) and integrates Wikipedia concepts into query-document matching. Named Entity Recognition (NER) is used to extract entities, which are then augmented or replaced with Wikipedia concepts. Experiments compare baseline models with proposed models incorporating Wikipedia features, evaluating ranking performance and relevance prediction through statistical tests and similarity measures.\", \"results\": \"Experiments show that Wikipedia concepts improve relevance prediction and ranking performance compared to baselines. Augmenting NER-based entities with Wikipedia concepts yields better results than replacing them entirely. Jaccard similarity analysis confirms that overlap of Wikipedia concepts between queries and relevant documents is a strong relevance signal. Proposed models such as Ent_Wiki_rel achieve higher performance metrics than traditional BM25 and DPH.\", \"conclusion\": \"This work demonstrates that Wikipedia concepts can effectively enhance proactive search and relevance prediction in information retrieval systems. Key contributions include: (1) validating the usefulness of Wikipedia concepts as relevance signals; (2) showing that augmenting NER entities with Wikipedia concepts improves ranking performance; (3) highlighting the potential of query context for keyword disambiguation; and (4) providing empirical evidence supporting concept-based user models for zero-effort queries.\", \"figures\": null, \"tables\": null}, \"citations\": [\"[1]S. Bulathwela, M. Pérez-Ortiz, E. Yilmaz, J. Shawe-Taylor, Towards an integrative educa-\", \"tional recommender for lifelong learners, in: AAAI Conference on Artificial Intelligence,\", \"[2]W. Jiang, Z. A. Pardos, Q. Wei, Goal-based course recommendation, in: Proceedings of\", \"International Conference on Learning Analytics & Knowledge, 2019.\", \"[3]S. Bulathwela, M. Pérez-Ortiz, E. Yilmaz, J. Shawe-Taylor, Power to the learner: To-\", \"wards human-intuitive and integrative recommendations with open educational resources,\", \"[4]S. Bulathwela, M. Pérez-Ortiz, E. Yilmaz, J. Shawe-Taylor, Truelearn: A family of bayesian\", \"algorithms to match lifelong learners to open educational resources, in: AAAI Conference\", \"on Artificial Intelligence, AAAI 20, 2020.\", \"[5]G. Sidiropoulos, S. Vakulenko, E. Kanoulas, On the impact of speech recognition errors in\", \"passage retrieval for spoken question answering, arXiv preprint arXiv:2209.12944 (2022).\", \"[6]S. Bulathwela, M. Pérez-Ortiz, C. Halloway, J. Shawe-Taylor, Could ai democratise edu-\", \"cation? socio-technical imaginaries of an edtech revolution, in: In Proc. of the NeurIPS\", \"Workshop on Machine Learning for the Developing World (ML4D), 2021.\", \"[7]H. K. Azad, A. Deepak, A new approach for query expansion using wikipedia and wordnet,\", \"[8]J. A. Nasir, I. Varlamis, S. Ishfaq, A knowledge-based semantic framework for query\", \"expansion, Information processing & management 56 (2019) 1605–1617.\", \"[9]R. Jones, B. Carterette, A. Clifton, M. Eskevich, G. J. Jones, J. Karlgren, A. Pappu, S. Reddy,\", \"Y. Yu, Trec 2020 podcasts track overview, arXiv preprint arXiv:2103.15953 (2021).\", \"[10] Y. Lv, C. Zhai, When documents are very long, bm25 fails!, in: Proceedings of the\", \"34th international ACM SIGIR conference on Research and development in Information\", \"Retrieval, 2011, pp. 1103–1104.\", \"[11] G. Amati, Frequentist and bayesian approach to information retrieval, in: European\", \"Conference on Information Retrieval, Springer, 2006, pp. 13–24.\", \"[12] Y. Yu, J. Karlgren, H. Bonab, A. Clifton, M. I. Tanveer, R. Jones, Spotify at the trec 2020\", \"podcasts track: Segment retrieval, in: Proceedings of the Twenty-Ninth Text REtrieval\", \"Conference (TREC 2020), 2020.\", \"[13] P. Galušcáková, S. Nair, D. W. Oard, Combine and re-rank: The university of maryland at\", \"[14] Y. Moriya, G. J. Jones, Dcu-adapt at the trec 2020 podcasts track., in: TREC, 2020.\", \"[15] A. Arampatzis, J. Kamps, A study of query length, in: Proceedings of the 31st annual\", \"international ACM SIGIR conference on Research and development in information retrieval,\", \"2008, pp. 811–812.\", \"[16] P. Sen, Proactive information retrieval, Ph.D. thesis, Dublin City University, 2021.\", \"[17] G. H. Torbati, A. Yates, G. Weikum, Personalized entity search by sparse and scrutable\", \"user profiles, in: Proceedings of the 2020 Conference on Human Information Interaction\", \"and Retrieval, 2020, pp. 427–431.\", \"[18] L. Yang, Q. Guo, Y. Song, S. Meng, M. Shokouhi, K. McDonald, W. B. Croft, Modeling\", \"user interests for zero-query ranking, in: European Conference on Information Retrieval,\", \"Springer, 2016, pp. 171–184.\", \"[19] S. Bulathwela, M. Perez-Ortiz, E. Novak, E. Yilmaz, J. Shawe-Taylor, Peek: A large dataset\", \"of learner engagement with educational videos, in: Proc. of RecSys Workshop on Online\", \"Recommender Systems and User Modeling (ORSUM’21), 2021. URL: https://arxiv.org/abs/\", \"2109.03154.\", \"[20] F. Zarrinkalam, S. Faralli, G. Piao, E. Bagheri, Extracting, mining and predicting users’\", \"[21] R. Syed, K. Collins-Thompson, Retrieval algorithms optimized for human learning, in:\", \"Proc. of Int. Conf. on Research and Development in Information Retrieval (SIGIR), 2017.\", \"[22] G. Piao, J. G. Breslin, Analyzing mooc entries of professionals on linkedin for user modeling\", \"and personalized mooc recommendations, in: Proceedings of the 2016 Conference on User\", \"Modeling Adaptation and Personalization, UMAP ’16, 2016.\", \"[23] F. Zarrinkalam, H. Fani, E. Bagheri, M. Kahani, Predicting users’ future interests on twitter,\", \"in: European Conference on Information Retrieval, Springer, 2017, pp. 464–476.\", \"[24] A. T. Corbett, J. R. Anderson, Knowledge tracing: Modeling the acquisition of procedural\", \"knowledge, User Modeling and User-Adapted Interaction 4 (1994).\", \"[25] J. Brank, G. Leban, M. Grobelnik, Annotating documents with relevant wikipedia concepts,\", \"in: Proc. of Slovenian KDD Conf. on Data Mining and Data Warehouses (SiKDD), 2017.\", \"[26] A. Clifton, A. Pappu, S. Reddy, Y. Yu, J. Karlgren, B. Carterette, R. Jones, The spotify\", \"podcast dataset, arXiv preprint arXiv:2004.04270 (2020).\", \"[27] C. Macdonald, N. Tonellotto, Declarative experimentation in information retrieval using\", \"PyTerrier, in: Proceedings of the 2020 ACM SIGIR on International Conference on Theory\", \"of Information Retrieval, ACM, 2020. doi: 10.1145/3409256.3409829 .\", \"[28] S. Bulathwela, S. Kreitmayer, M. Pérez-Ortiz, What’s in it for me? augmenting rec-\", \"ommended learning resources with navigable annotations, in: Proceedings of the 25th\", \"International Conference on Intelligent User Interfaces Companion, IUI 20, 2020.\", \"[29] E. Hirsch, A. Eirew, O. Shapira, A. Caciularu, A. Cattan, O. Ernst, R. Pasunuru, H. Ronen,\", \"M. Bansal, I. Dagan, iFacetSum: Coreference-based interactive faceted summarization for\", \"multi-document exploration, in: Proceedings of the 2021 Conference on Empirical Methods\", \"in Natural Language Processing: System Demonstrations, Association for Computational\", \"Linguistics, Online and Punta Cana, Dominican Republic, 2021, pp. 283–297. URL: https:\"], \"error\": null}, \"3fe091fd\": {\"success\": true, \"paper_id\": \"3fe091fd\", \"url\": \"https://arxiv.org/pdf/2403.13468v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_3fe091fd.pdf\", \"extracted_info\": {\"title\": \"DESIRE-ME: Domain-Specialized Retrieval with Mixture-of-Experts for Open-Domain Question Answering\", \"authors\": [\"Kasela et al.\"], \"abstract\": \"Open-domain question answering requires retrieval systems capable of handling diverse and varied questions, providing accurate answers across multiple domains. This work introduces DESIRE-ME, a retrieval model that leverages a Mixture-of-Experts (MoE) architecture with supervised gating to dynamically weight domain-specialized retrievers, improving semantic understanding and retrieval accuracy.\", \"methodology\": \"The proposed DESIRE-ME model integrates a Mixture-of-Experts framework into dense retrieval systems. Each expert (specializer) is trained for domain-specific contextualization, while a supervised gating mechanism predicts the query's domain and assigns weights to the experts' outputs. The model is evaluated on multiple datasets (NQ, HotpotQA, FEVER, and Climate-FEVER) using standard IR metrics (MAP@100, MRR@100, R@100, NDCG@10, NDCG@3, P@1). Baselines include BM25, COCO-DR, Contriever, fine-tuned versions, and a random gating variant (RND-G). Experiments compare DESIRE-ME performance against these baselines.\", \"results\": \"Across all datasets, DESIRE-ME consistently outperforms baseline dense retrieval models. On NQ, it achieves up to +6% in NDCG@10 and +22% in P@1 over base models. On HotpotQA, it improves COCO-DR and Contriever baselines by 6% and 9% in NDCG@10, respectively. On FEVER, DESIRE-ME yields up to +9% in NDCG@10. Climate-FEVER results show DESIRE-ME's adaptability to domain-shifted queries, with notable gains over baselines. Improvements are statistically significant in most cases.\", \"conclusion\": \"1. Introduction of DESIRE-ME, a novel MoE-based dense retrieval approach for open-domain Q&A. 2. Supervised gating mechanism that predicts query domain and adaptively weights domain-specialized retrievers. 3. Demonstrated consistent performance improvements across multiple datasets and retrieval architectures. 4. Shown robustness to domain shifts, as evidenced by Climate-FEVER results. 5. Provided a framework that enhances semantic understanding in retrieval tasks through domain contextualization.\", \"figures\": null, \"tables\": null}, \"citations\": [\"1. Bassani, E.: ranx: A blazing-fast python library for ranking evaluation and compar-\", \"ison. In: Hagen, M., Verberne, S., Macdonald, C., Seifert, C., Balog, K., Nørv˚ ag,\", \"K., Setty, V. (eds.) Advances in Information Retrieval - 44th European Confer-\", \"ence on IR Research, ECIR 2022, Stavanger, Norway, April 10-14, 2022, Pro-\", \"ceedings, Part II. Lecture Notes in Computer Science, vol. 13186, pp. 259–264.\", \"Springer (2022). https://doi.org/10.1007/978-3-030-99739-7 30, https://doi.org/\", \"10.1007/978-3-030-99739-7 30\", \"2. Bassani, E.: Ranxhub: An online repository for information retrieval runs.\", \"’23, Association for Computing Machinery, New York, NY, USA (2023).\", \"https://doi.org/10.1145/3539618.3591823, https://doi.org/10.1145/3539618.\", \"3591823\", \"3. Collobert, R., Bengio, S., Bengio, Y.: A parallel mixture of svms for\", \"very large scale problems. In: Dietterich, T., Becker, S., Ghahramani,\", \"MIT Press (2001), https://proceedings.neurips.cc/paper files/paper/2001/file/\", \"36ac8e558ac7690b6f44e2cb5ef93322-Paper.pdf\", \"4. Dai, D., Jiang, W.J., Zhang, J., Peng, W., Lyu, Y., Sui, Z., Chang, B., Zhu, Y.:\", \"(2022), https://api.semanticscholar.org/CorpusID:248218762\", \"5. Dauphin, Y.N., Fan, A., Auli, M., Grangier, D.: Language modeling with gated\", \"convolutional networks. In: Precup, D., Teh, Y.W. (eds.) Proceedings of the 34th\", \"Research, vol. 70, pp. 933–941. PMLR (06–11 Aug 2017), https://proceedings.mlr.\", \"6. Diggelmann, T., Boyd-Graber, J., Bulian, J., Ciaramita, M., Leippold, M.:\", \"7. Eigen, D., Ranzato, M., Sutskever, I.: Learning factored representations in a deep\", \"8. Fedus, W., Zoph, B., Shazeer, N.: Switch transformers: Scaling to trillion parameter\", \"9. Gaur, N., Farris, B., Haghani, P., Leal, I., Moreno, P.J., Prasad, M., Ram-\", \"abhadran, B., Zhu, Y.: Mixture of informed experts for multilingual speech\", \"tics, Speech and Signal Processing (ICASSP). pp. 6234–6238 (June 2021).\", \"10. Gururangan, S., Lewis, M., Holtzman, A., Smith, N.A., Zettlemoyer, L.: Demix\", \"11. Hashemi, H., Zhuang, Y., Kothur, S.S.R., Prasad, S., Meij, E., Croft, W.B.: Dense\", \"12. Houlsby, N., Giurgiu, A., Jastrzebski, S., Morrone, B., De Laroussilhe, Q., Ges-\", \"mundo, A., Attariyan, M., Gelly, S.: Parameter-efficient transfer learning for NLP.\", \"13. Izacard, G., Caron, M., Hosseini, L., Riedel, S., Bojanowski, P., Joulin, A., Grave,\", \"https://doi.org/10.48550/ARXIV.2112.09118, https://arxiv.org/abs/2112.09118\", \"14. Jacobs, R.A., Jordan, M.I., Nowlan, S.J., Hinton, G.E.: Adaptive mix-\", \"tures of local experts. Neural Computation 3(1), 79–87 (March 1991).\", \"15. Jordan, M.I., Jacobs, R.A.: Hierarchical mixtures of experts and\", \"the em algorithm. Neural Computation 6(2), 181–214 (1994).\", \"16. Khattab, O., Zaharia, M.: Colbert: Efficient and effective passage search via con-\", \"p. 39–48. SIGIR ’20, Association for Computing Machinery, New York, NY,\", \"USA (2020). https://doi.org/10.1145/3397271.3401075, https://doi.org/10.1145/\", \"3397271.3401075\", \"17. Kwiatkowski, T., Palomaki, J., Redfield, O., Collins, M., Parikh, A., Alberti, C.,\", \"Epstein, D., Polosukhin, I., Kelcey, M., Devlin, J., Lee, K., Toutanova, K.N., Jones,\", \"L., Chang, M.W., Dai, A., Uszkoreit, J., Le, Q., Petrov, S.: Natural questions: a\", \"18. Li, M., Li, M., Xiong, K., Lin, J.: Multi-task dense retrieval via model un-\", \"ation for Computational Linguistics, Punta Cana, Dominican Republic (Nov\", \"2021). https://doi.org/10.18653/v1/2021.findings-emnlp.26, https://aclanthology.\", \"19. Mitra, B., Craswell, N.: An introduction to neural information retrieval.\", \"Foundations and Trends ®in Information Retrieval 13(1), 1–126 (2018).\", \"https://doi.org/10.1561/1500000061, http://dx.doi.org/10.1561/1500000061\", \"20. Mun, J., Lee, K., Shin, J., Han, B.: Learning to specialize with knowl-\", \"edge distillation for visual question answering. In: Bengio, S., Wallach,\", \"H., Larochelle, H., Grauman, K., Cesa-Bianchi, N., Garnett, R. (eds.) Ad-\", \"ciates, Inc. (2018), https://proceedings.neurips.cc/paper files/paper/2018/file/\", \"0f2818101a7ac4b96ceeba38de4b934c-Paper.pdf\", \"21. Nogueira, R., Yang, W., Lin, J., Cho, K.: Document expansion by query prediction\", \"(2019)\", \"22. Puigcerver, J., Riquelme, C., Mustafa, B., Houlsby, N.: From sparse to soft mixtures\", \"23. Robertson, S.E., Walker, S., Jones, S., Hancock-Beaulieu, M., Gatford, M.: Okapi\", \"at TREC-3. In: Harman, D.K. (ed.) Proceedings of The Third Text REtrieval Con-\", \"ference, TREC 1994, Gaithersburg, Maryland, USA, November 2-4, 1994. NIST\", \"Special Publication, vol. 500-225, pp. 109–126. National Institute of Standards and\", \"Technology (NIST) (1994), http://trec.nist.gov/pubs/trec3/papers/city.ps.gz\", \"24. Rosa, G.M., Bonifacio, L., Jeronymo, V., Abonizio, H., Fadaee, M., Lotufo, R.,\", \"Nogueira, R.: No parameter left behind: How distillation and model size affect\", \"25. Shazeer, N., Mirhoseini, A., Maziarz, K., Davis, A., Le, Q., Hinton, G., Dean, J.:\", \"(2017)\", \"26. Thakur, N., Reimers, N., R¨ uckl´ e, A., Srivastava, A., Gurevych, I.: BEIR: A het-\", \"16 Kasela et al.\", \"and Benchmarks Track (Round 2) (2021), https://openreview.net/forum?id=\", \"27. Thorne, J., Vlachos, A., Christodoulopoulos, C., Mittal, A.: FEVER: a large-scale\", \"guistics: Human Language Technologies, Volume 1 (Long Papers). pp. 809–819.\", \"Association for Computational Linguistics, New Orleans, Louisiana (Jun 2018).\", \"https://doi.org/10.18653/v1/N18-1074, https://aclanthology.org/N18-1074\", \"28. Yang, Z., Qi, P., Zhang, S., Bengio, Y., Cohen, W., Salakhutdinov, R., Man-\", \"ning, C.D.: HotpotQA: A dataset for diverse, explainable multi-hop question an-\", \"tics, Brussels, Belgium (Oct-Nov 2018). https://doi.org/10.18653/v1/D18-1259,\", \"29. Yu, Y., Xiong, C., Sun, S., Zhang, C., Overwijk, A.: Coco-dr: Combating distribu-\", \"30. Zhou, Y., Lei, T., Liu, H., Du, N., Huang, Y., Zhao, V., Dai, A.M., Le, Q.V.,\", \"Laudon, J., et al.: Mixture-of-experts with expert choice routing. Advances in\", \"Neural Information Processing Systems 35, 7103–7114 (2022)\"], \"error\": null}, \"ec73fc98\": {\"success\": false, \"paper_id\": \"ec73fc98\", \"url\": \"https://sapient.pro/_next/static/chunks/webpack-8f2f3a22d4058924.js\\\"/><script src=\\\"/_next/static/chunks/4bd1b696-30718bd562604751.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/8261-87b8c652f4859a63.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/main-app-bb2c9f756d1b5869.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/5692-72f59cbd0b2d4e1c.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/372-451cb83d29080205.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/2425-439c7bb72af23a79.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/1610-347058d2d6f072f3.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/2255-4738241640ea2919.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/8171-cddb9006621c7c00.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/5920-07a1fcdb22c875d8.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/8050-6fe88ce55f02cc11.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/47-eff6aa59faf62008.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/9568-fae9ea3a1f7a897e.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/8762-904b9dccec4bdcbe.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/9379-b268cb89893422b9.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/6005-ebaace4f89cd1040.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/7733-f85527123dbb52bd.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/app/(pages)/blog/%5BfirstRoute%5D/page-fdb8479ab01af442.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/app/layout-b137356a30e39ace.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/app/error-65374cf82c16a100.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/app/not-found-75717f0b381a5717.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/160b575a-21c0702096c443fe.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/13b76428-d0865967e61b6767.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/6429-39f4a61cddb917a1.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/7040-a126503cb486062f.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/1325-c421be758bae2d4b.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/2602-4efe96ee0869cd95.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/7871-7eabec075b2300c6.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/app/(pages)/layout-0627809657c81bf2.js\\\" async=\\\"\\\"></script><script src=\\\"/_next/static/chunks/app/(pages)/page-7ab8cf56416bc535.js\\\" async=\\\"\\\"></script><link rel=\\\"preload\\\" href=\\\"https://tag.clearbitscripts.com/v1/pk\\\\_f50bf055ee2830aedf119b8ace4bc540/tags.js\\\" as=\\\"script\\\"/><title>NER: Overview, Techniques, Methods, and Implementation Guide | SapientPro</title><meta name=\\\"description\\\" content=\\\"Learn the basics of named entity recognition, its use cases, and how it works in natural language processing (NLP).\\\"/><link rel=\\\"manifest\\\" href=\\\"/manifest.webmanifest\\\"/><link rel=\\\"canonical\\\" href=\\\"https://sapient.pro/blog/named-entity-recognition-implementation-tips\\\"/><meta property=\\\"og:title\\\" content=\\\"NER: Overview, Techniques, Methods, and Implementation Guide | SapientPro\\\"/><meta property=\\\"og:description\\\" content=\\\"Learn the basics of named entity recognition, its use cases, and how it works in natural language processing (NLP).\\\"/><meta property=\\\"og:url\\\" content=\\\"https://sapient.pro/blog/named-entity-recognition-implementation-tips\\\"/><meta property=\\\"og:site_name\\\" content=\\\"SapientPro\\\"/><meta property=\\\"og:locale\\\" content=\\\"en_US\\\"/><meta property=\\\"og:image\\\" content=\\\"https://sapientpro.fra1.digitaloceanspaces.com/1c43931be7e6058e1569acd847be3460.jpg\\\"/><meta property=\\\"og:type\\\" content=\\\"website\\\"/><meta name=\\\"twitter:card\\\" content=\\\"summary_large_image\\\"/><meta name=\\\"twitter:creator\\\" content=\\\"@sapientpro\\\"/><meta name=\\\"twitter:title\\\" content=\\\"NER: Overview, Techniques, Methods, and Implementation Guide | SapientPro\\\"/><meta name=\\\"twitter:description\\\" content=\\\"Learn the basics of named entity recognition, its use cases, and how it works in natural language processing (NLP).\\\"/><meta name=\\\"twitter:image\\\" content=\\\"https://sapientpro.fra1.digitaloceanspaces.com/1c43931be7e6058e1569acd847be3460.jpg\\\"/><link rel=\\\"icon\\\" href=\\\"/favicon.ico\\\" type=\\\"image/x-icon\\\" sizes=\\\"48x48\\\"/><link rel=\\\"icon\\\" href=\\\"/icon.png?c21dbdf8726499f9\\\" type=\\\"image/png\\\" sizes=\\\"160x160\\\"/><link rel=\\\"apple-touch-icon\\\" href=\\\"/apple-icon.png?d13d4c1b561cc588\\\" type=\\\"image/png\\\" sizes=\\\"180x180\\\"/><script src=\\\"/_next/static/chunks/polyfills-42372ed130431b0a.js\\\" noModule=\\\"\\\"></script></head><body><div hidden=\\\"\\\"><!--$--><!--/$--></div><header class=\\\"Header_header__MwWvM Header_header_absolute__x4DUv\\\"><a aria-label=\\\"Get back to main page\\\" class=\\\"Header_logo__V9h3K\\\" href=\\\"/\\\"><div class=\\\"Logo_logo__zBwGf\\\" style=\\\"width:100px;height:32px\\\"><svg><use width=\\\"100\\\" height=\\\"32\\\" xlink:href=\\\"/media/logo.svg#logo\\\" href=\\\"/media/logo.svg#logo\\\"></use></svg></div></a><div class=\\\"Header_header__rightBlock__YuLgy\\\"><nav class=\\\"Menu_menu__N68p_\\\"><ul class=\\\"Menu_menu__list__NkMaT\\\"><li id=\\\"headedNavItem-1\\\" class=\\\"Menu_menu__item__Ze9KX\\\"><button type=\\\"button\\\" class=\\\"Menu_menuItem__lORev Menu_linkless__XjyKx\\\">Services<svg class=\\\"Menu_dropdownIcon__A4roo\\\"><use xlink:href=\\\"/media/angle_down.svg#angleDown\\\" href=\\\"/media/angle_down.svg#angleDown\\\"></use></svg><div class=\\\"Submenu_submenuWrapper__F9bWI Menu_submenuWrapper__SQlb2\\\"><section class=\\\"Submenu_submenu__4X1GF Menu_submenu__VGcRf Submenu_isVisible__vc3Zx\\\"><ul class=\\\"Submenu_submenu__mainlist__OEZcO\\\"><li></li><li class=\\\"Submenu_submenu__mainlist__item__7VGcv\\\"><ul class=\\\"Submenu_submenu__sublist__NLlB7\\\"><li><div class=\\\"Submenu_submenu__sublist__item__z1vTi\\\"><div class=\\\"Submenu_imageWrapper__nMh6K\\\"><div class=\\\"Submenu_image__cH19Y\\\"><img alt=\\\"submenu icon\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent\\\" src=\\\"https://sapientpro.fra1.digitaloceanspaces.com/63ac20be9e26fbf5da726aa0f6441139.svg\\\"/></div></div><div><a class=\\\"Submenu_title__ceSEA\\\" href=\\\"/legacy-software-modernization-services\\\">Legacy Software Modernization</a></div></div></li><li><div class=\\\"Submenu_submenu__sublist__item__z1vTi\\\"><div class=\\\"Submenu_imageWrapper__nMh6K\\\"><div class=\\\"Submenu_image__cH19Y\\\"><img alt=\\\"submenu icon\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent\\\" src=\\\"https://sapientpro.fra1.digitaloceanspaces.com/cc6f2e1fe7df157b60eaa254cdac5721.svg\\\"/></div></div><div><a class=\\\"Submenu_title__ceSEA\\\" href=\\\"/web-development-services\\\">Web 3.0 Development</a></div></div></li><li><div class=\\\"Submenu_submenu__sublist__item__z1vTi\\\"><div class=\\\"Submenu_imageWrapper__nMh6K\\\"><div class=\\\"Submenu_image__cH19Y\\\"><img alt=\\\"submenu icon\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent\\\" src=\\\"https://sapientpro.fra1.digitaloceanspaces.com/c87d62e9b8a55c2708a4ba2ba1489935.svg\\\"/></div></div><div><a class=\\\"Submenu_title__ceSEA\\\" href=\\\"/custom-software-development\\\">Custom Software Development </a></div></div></li><li><div class=\\\"Submenu_submenu__sublist__item__z1vTi\\\"><div class=\\\"Submenu_imageWrapper__nMh6K\\\"><div class=\\\"Submenu_image__cH19Y\\\"><img alt=\\\"submenu icon\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent\\\" src=\\\"https://sapientpro.fra1.digitaloceanspaces.com/1fcf391753fad4c59a797d4cf4438530.svg\\\"/></div></div><div><a class=\\\"Submenu_title__ceSEA\\\" href=\\\"/business-digitalization-solutions\\\">Business Digitalization</a></div></div></li><li><div class=\\\"Submenu_submenu__sublist__item__z1vTi\\\"><div class=\\\"Submenu_imageWrapper__nMh6K\\\"><div class=\\\"Submenu_image__cH19Y\\\"><img alt=\\\"submenu icon\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent\\\" src=\\\"https://sapientpro.fra1.digitaloceanspaces.com/ed786473dd7f304528d1226e9e98dbea.svg\\\"/></div></div><div><a class=\\\"Submenu_title__ceSEA\\\" href=\\\"/big-data-and-scraping-services\\\">BigData and Scraping</a></div></div></li></ul></li><li class=\\\"Submenu_submenu__mainlist__item__7VGcv\\\"><ul class=\\\"Submenu_submenu__sublist__NLlB7\\\"><li><div class=\\\"Submenu_submenu__sublist__item__z1vTi\\\"><div class=\\\"Submenu_imageWrapper__nMh6K\\\"><div class=\\\"Submenu_image__cH19Y\\\"><img alt=\\\"submenu icon\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent\\\" src=\\\"https://sapientpro.fra1.digitaloceanspaces.com/da7c2ffd03d6bfe325b052a6cea90ba1.svg\\\"/></div></div><div><a class=\\\"Submenu_title__ceSEA\\\" href=\\\"/software-development-for-startups\\\">Startups Launching</a></div></div></li><li><div class=\\\"Submenu_submenu__sublist__item__z1vTi\\\"><div class=\\\"Submenu_imageWrapper__nMh6K\\\"><div class=\\\"Submenu_image__cH19Y\\\"><img alt=\\\"submenu icon\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent\\\" src=\\\"https://sapientpro.fra1.digitaloceanspaces.com/Services_Icon_2_1_6d37e4e23b.svg\\\"/></div></div><div><a class=\\\"Submenu_title__ceSEA\\\" href=\\\"/ui-ux-design-services\\\">UI/UX Design Services</a></div></div></li><li><div class=\\\"Submenu_submenu__sublist__item__z1vTi\\\"><div class=\\\"Submenu_imageWrapper__nMh6K\\\"><div class=\\\"Submenu_image__cH19Y\\\"><img alt=\\\"submenu icon\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent\\\" src=\\\"https://sapientpro.fra1.digitaloceanspaces.com/6c5df13ffb3ac21667c42ed4eb141be6.svg\\\"/></div></div><div><a class=\\\"Submenu_title__ceSEA\\\" href=\\\"/saas-development\\\">SaaS Development </a></div></div></li><li><div class=\\\"Submenu_submenu__sublist__item__z1vTi\\\"><div class=\\\"Submenu_imageWrapper__nMh6K\\\"><div class=\\\"Submenu_image__cH19Y\\\"><img alt=\\\"submenu icon\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent\\\" src=\\\"https://sapientpro.fra1.digitaloceanspaces.com/3e3d0656915b4d8d5479f5b21774cc14.svg\\\"/></div></div><div><a class=\\\"Submenu_title__ceSEA\\\" href=\\\"/ecommerce-development-services\\\">E-commerce Development</a></div></div></li><li><div class=\\\"Submenu_submenu__sublist__item__z1vTi\\\"><div class=\\\"Submenu_imageWrapper__nMh6K\\\"><div class=\\\"Submenu_image__cH19Y\\\"><img alt=\\\"submenu icon\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent\\\" src=\\\"https://sapientpro.fra1.digitaloceanspaces.com/71af5d77fc049335a840785c4df5b87b.svg\\\"/></div></div><div><a class=\\\"Submenu_title__ceSEA\\\" href=\\\"/ai-development-services\\\">AI-driven Solutions</a></div></div></li></ul></li></ul></section></div></button></li><li id=\\\"headedNavItem-10\\\" class=\\\"Menu_menu__item__Ze9KX\\\"><a class=\\\"Menu_menuItem__lORev\\\" href=\\\"/cases\\\">Cases</a></li><li id=\\\"headedNavItem-15\\\" class=\\\"Menu_menu__item__Ze9KX\\\"><a class=\\\"Menu_menuItem__lORev\\\" href=\\\"/company\\\">Company</a></li><li id=\\\"headedNavItem-1\\\" class=\\\"Menu_menu__item__Ze9KX\\\"><a class=\\\"Menu_menuItem__lORev\\\" href=\\\"/blog\\\">Blog</a></li><li id=\\\"headedNavItem-11\\\" class=\\\"Menu_menu__item__Ze9KX\\\"><a class=\\\"Menu_menuItem__lORev\\\" href=\\\"/contacts\\\">Contacts</a></li><li id=\\\"headedNavItem-6\\\" class=\\\"Menu_menu__item__Ze9KX\\\"><button type=\\\"button\\\" class=\\\"Menu_menuItem__lORev Menu_linkless__XjyKx Menu_dropdownButton__AheqL\\\">Career<svg class=\\\"Menu_dropdownIcon__A4roo\\\"><use xlink:href=\\\"/media/angle_down.svg#angleDown\\\" href=\\\"/media/angle_down.svg#angleDown\\\"></use></svg><div class=\\\"DropdownMenu_dropdown__GymYD Menu_dropdown__GwiQD\\\"><a class=\\\"DropdownMenu_link__pgZ4G\\\" href=\\\"/career/vacancies\\\"><div class=\\\"DropdownMenu_link__icon__3DwsB\\\"><img alt=\\\"Vacancies\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent\\\" src=\\\"https://sapientpro.fra1.digitaloceanspaces.com/cbe572143c839c95f74007a19671ca97.svg\\\"/></div>Vacancies</a><a class=\\\"DropdownMenu_link__pgZ4G\\\" href=\\\"/career/education\\\"><div class=\\\"DropdownMenu_link__icon__3DwsB\\\"><img alt=\\\"Education\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent\\\" src=\\\"https://sapientpro.fra1.digitaloceanspaces.com/dc1c85ce7203d624f1d0a60608b306f1.svg\\\"/></div>Education</a></div></button></li></ul></nav><button type=\\\"button\\\" aria-label=\\\"search\\\" class=\\\"Header_searchButton__tLL_S\\\" name=\\\"Search\\\"><svg><use xlink:href=\\\"/media/search.svg#searchSVG\\\" href=\\\"/media/search.svg#searchSVG\\\"></use></svg></button><button type=\\\"button\\\" class=\\\"ThemeToggle_toggle__KXKLn\\\"><div class=\\\"ThemeToggle_circle__gfBDv\\\"><img alt=\\\"particles\\\" loading=\\\"lazy\\\" width=\\\"16\\\" height=\\\"16\\\" decoding=\\\"async\\\" data-nimg=\\\"1\\\" class=\\\"ThemeToggle_particles__uQsJU\\\" style=\\\"color:transparent\\\" srcSet=\\\"/_next/image?url=%2Fmedia%2FthemeToggle%2FthemeParticles-dark.webp&amp;w=16&amp;q=75 1x, /_next/image?url=%2Fmedia%2FthemeToggle%2FthemeParticles-dark.webp&amp;w=32&amp;q=75 2x\\\" src=\\\"/_next/image?url=%2Fmedia%2FthemeToggle%2FthemeParticles-dark.webp&amp;w=32&amp;q=75\\\"/><img alt=\\\"shadow\\\" loading=\\\"lazy\\\" width=\\\"16\\\" height=\\\"16\\\" decoding=\\\"async\\\" data-nimg=\\\"1\\\" class=\\\"ThemeToggle_particles__shadow__Ap5A2\\\" style=\\\"color:transparent\\\" src=\\\"/media/themeToggle/themeShadow-dark.svg\\\"/></div></button></div><button aria-label=\\\"Toggle menu\\\" type=\\\"button\\\" class=\\\"Header_menuButton__0azx_\\\"><div class=\\\"Header_menuButton__line__x3Q44\\\"></div><div class=\\\"Header_menuButton__line__x3Q44\\\"></div></button></header><main class=\\\"Article_article__Njabh\\\"><section class=\\\"Article_hero__X7BaQ\\\"><div class=\\\"container\\\"><div class=\\\"ArticleBreadcrumbs_breadcrumbs__1jiWc\\\"><a class=\\\"ArticleBreadcrumbs_breadcrumb__hwLTB\\\" href=\\\"/blog\\\">Blog</a><svg class=\\\"ArticleBreadcrumbs_arrowIcon__Y2Cea\\\"><use href=\\\"/media/angle_down.svg#angleDown\\\" xlink:href=\\\"/media/angle_down.svg#angleDown\\\"></use></svg><a class=\\\"ArticleBreadcrumbs_breadcrumb__hwLTB\\\" href=\\\"/blog/category/reviews\\\">Techs’ reviews</a><svg class=\\\"ArticleBreadcrumbs_arrowIcon__Y2Cea\\\"><use href=\\\"/media/angle_down.svg#angleDown\\\" xlink:href=\\\"/media/angle_down.svg#angleDown\\\"></use></svg><a class=\\\"ArticleBreadcrumbs_breadcrumb__hwLTB ArticleBreadcrumbs_active__YMqNN\\\" href=\\\"/blog/named-entity-recognition-implementation-tips\\\">Named Entity Recognition: Mechanism, Methods, Use Cases, and Implementation Tips</a><svg class=\\\"ArticleBreadcrumbs_arrowIcon__Y2Cea\\\"><use href=\\\"/media/angle_down.svg#angleDown\\\" xlink:href=\\\"/media/angle_down.svg#angleDown\\\"></use></svg></div><div class=\\\"Article_titleBlock__kvIpz\\\"><h1 class=\\\"Article_title__VtXM_\\\"><a type=\\\"button\\\" class=\\\"Button_button__nbDXA Article_titleButton__6F_vg Button_outlined__mOu3b Button_withIcon__JksZi Button_withIcon_left__zz_uA\\\" href=\\\"/blog\\\">All<div class=\\\"Button_icon__BGcBT\\\" style=\\\"width:24px;height:24px\\\"><svg><use xlink:href=\\\"/media/arrow-left-bold.svg#arrowLeft\\\" href=\\\"/media/arrow-left-bold.svg#arrowLeft\\\"></use></svg></div></a> <span>Named Entity Recognition: Mechanism, Methods, Use Cases, and Implementation Tips</span></h1></div><div class=\\\"Article_articleDetails__Tjv1Q\\\"><p class=\\\"Article_articleInfo__N5Aar\\\"><span class=\\\"Article_articleInfo__updated__3Jpb8\\\">Updated:</span><span class=\\\"Article_articleInfo__date__ul54n\\\">April 28, 2025</span><span>15 min read</span></p><div class=\\\"Article_authorBlock__ipWmC\\\"><div class=\\\"AuthorCard_author__6xxtE\\\"><a class=\\\"AuthorCard_author__avatar__nH9od\\\" style=\\\"width:48px;height:48px\\\" href=\\\"/blog/author/Max\\\"><img alt=\\\"Max Tatarchenko\\\" loading=\\\"lazy\\\" decoding=\\\"async\\\" data-nimg=\\\"fill\\\" style=\\\"position:absolute;height:100%;width:100%;left:0;top:0;right:0;bottom:0;color:transparent;background-size:cover;background-position:50% 50%;background-repeat:no-repeat;background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns=&#x27;http://www.w3.org/2000/svg&#x27; %3E%3Cfilter id=&#x27;b&#x27; color-interpolation-filters=&#x27;sRGB&#x27;%3E%3CfeGaussianBlur stdDeviation=&#x27;20&#x27;/%3E%3CfeColorMatrix values=&#x27;1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 100 -1&#x27; result=&#x27;s&#x27;/%3E%3CfeFlood x=&#x27;0&#x27; y=&#x27;0&#x27; width=&#x27;100%25&#x27; height=&#x27;100%25&#x27;/%3E%3CfeComposite operator=&#x27;out&#x27; in=&#x27;s&#x27;/%3E%3CfeComposite in2=&#x27;SourceGraphic&#x27;/%3E%3CfeGaussianBlur stdDeviation=&#x27;20&#x27;/%3E%3C/filter%3E%3Cimage width=&#x27;100%25&#x27; height=&#x27;100%25&#x27; x=&#x27;0&#x27; y=&#x27;0&#x27; preserveAspectRatio=&#x27;none&#x27; style=&#x27;filter: url(%23b);&#x27; href=&#x27;data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEASABIAAD/2wBDAAUDBAQEAwUEBAQFBQUGBwwIBwcHBw8LCwkMEQ8SEhEPERETFhwXExQaFRERGCEYGh0dHx8fExciJCIeJBweHx7/2wBDAQUFBQcGBw4ICA4eFBEUHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh7/wAARCAAKAAoDAREAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAABgQH/8QAIBAAAgIBAwUAAAAAAAAAAAAAAQIDEQASEyEEFEFhof/EABYBAQEBAAAAAAAAAAAAAAAAAAIBA//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oADAMBAAIRAxEAPwDXJJITFvqSgdLbULqvPzLUg5LKjSue2ha2JsR8HFUVxs2vp11GtscXmZDk7MJ5ACQAxoX7xC//2Q==&#x27;/%3E%3C/svg%3E&quot;)\\\" sizes=\\\"100vw\\\" srcSet=\\\"/_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2Fimage_29_1fa9833b8d.webp&amp;w=640&amp;q=75 640w, /_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2Fimage_29_1fa9833b8d.webp&amp;w=750&amp;q=75 750w, /_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2Fimage_29_1fa9833b8d.webp&amp;w=828&amp;q=75 828w, /_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2Fimage_29_1fa9833b8d.webp&amp;w=1080&amp;q=75 1080w, /_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2Fimage_29_1fa9833b8d.webp&amp;w=1200&amp;q=75 1200w, /_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2Fimage_29_1fa9833b8d.webp&amp;w=1920&amp;q=75 1920w, /_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2Fimage_29_1fa9833b8d.webp&amp;w=2048&amp;q=75 2048w, /_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2Fimage_29_1fa9833b8d.webp&amp;w=3840&amp;q=75 3840w\\\" src=\\\"/_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2Fimage_29_1fa9833b8d.webp&amp;w=3840&amp;q=75\\\"/></a><div class=\\\"AuthorCard_author__content__p18vL\\\"><a class=\\\"AuthorCard_author__name__6f1Iq\\\" href=\\\"/blog/author/Max\\\">Max Tatarchenko</a><p class=\\\"AuthorCard_author__info__Sb3ke\\\">CTO</p></div></div></div></div><div class=\\\"Article_firstEllipse__Z1OxB\\\"></div><div class=\\\"Article_secondEllipse__0bCgJ\\\"></div></div></section><div class=\\\"container\\\"><section class=\\\"Article_main__v_hZi\\\"><aside class=\\\"Article_aside__1zKJ2\\\"><div class=\\\"Article_asideSticky__SjNnf\\\"><nav class=\\\"Article_articleMenuWrapper__72zxu\\\"><div class=\\\"Article_articleMenu__03hi8\\\"><button type=\\\"button\\\" class=\\\"Article_articleAnchor__1HoGo\\\"><span class=\\\"Article_sectionNumber__PX9Wo\\\">1</span><p>Intro</p></button><button type=\\\"button\\\" class=\\\"Article_articleAnchor__1HoGo\\\"><span class=\\\"Article_sectionNumber__PX9Wo\\\">2</span><p>What Is Named Entity Recognition?</p></button><button type=\\\"button\\\" class=\\\"Article_articleAnchor__1HoGo\\\"><span class=\\\"Article_sectionNumber__PX9Wo\\\">3</span><p>NER Benefits &amp; Challenges?</p></button><button type=\\\"button\\\" class=\\\"Article_articleAnchor__1HoGo\\\"><span class=\\\"Article_sectionNumber__PX9Wo\\\">4</span><p>How Named-entity Recognition Works?</p></button><button type=\\\"button\\\" class=\\\"Article_articleAnchor__1HoGo\\\"><span class=\\\"Article_sectionNumber__PX9Wo\\\">5</span><p>Named Entity Recognition Techniques</p></button><button type=\\\"button\\\" class=\\\"Article_articleAnchor__1HoGo\\\"><span class=\\\"Article_sectionNumber__PX9Wo\\\">6</span><p>NER Methodologies</p></button><button type=\\\"button\\\" class=\\\"Article_articleAnchor__1HoGo\\\"><span class=\\\"Article_sectionNumber__PX9Wo\\\">7</span><p>Use Cases for Named Entity Recognition</p></button><button type=\\\"button\\\" class=\\\"Article_articleAnchor__1HoGo\\\"><span class=\\\"Article_sectionNumber__PX9Wo\\\">8</span><p>NER Examples</p></button><button type=\\\"button\\\" class=\\\"Article_articleAnchor__1HoGo\\\"><span class=\\\"Article_sectionNumber__PX9Wo\\\">9</span><p>How to Implement Named Entity Recognition </p></button><button type=\\\"button\\\" class=\\\"Article_articleAnchor__1HoGo\\\"><span class=\\\"Article_sectionNumber__PX9Wo\\\">10</span><p>Recent Trends in Named Entity Recognition (NER) and Its Future</p></button><button type=\\\"button\\\" class=\\\"Article_articleAnchor__1HoGo\\\"><span class=\\\"Article_sectionNumber__PX9Wo\\\">11</span><p>Summary</p></button></div></nav><div class=\\\"Article_socialBar__JZfBi\\\"><p class=\\\"Article_socialBar__title__ohqqE\\\">Share this article</p><div class=\\\"Article_socialBar__content__BL8wn\\\"><a href=\\\"https://twitter.com/intent/tweet?url=https://sapient.pro/blog/named-entity-recognition-implementation-tips&amp;mini=true&amp;text=Named Entity Recognition: Mechanism, Methods, Use Cases, and Implementation Tips\\\" class=\\\"Article_social__tk25G\\\" target=\\\"_blank\\\" aria-label=\\\"Twitter\\\" rel=\\\"noreferrer\\\"><svg><use xlink:href=\\\"/media/socials/twitter.svg#twitterSVG\\\" href=\\\"/media/socials/twitter.svg#twitterSVG\\\"></use></svg></a><a href=\\\"https://www.linkedin.com/shareArticle?url=https://sapient.pro/blog/named-entity-recognition-implementation-tips&amp;mini=true\\\" class=\\\"Article_social__tk25G\\\" target=\\\"_blank\\\" aria-label=\\\"LinkedIn\\\" rel=\\\"noreferrer\\\"><svg><use xlink:href=\\\"/media/socials/linkedin.svg#linkedinSVG\\\" href=\\\"/media/socials/linkedin.svg#linkedinSVG\\\"></use></svg></a><a href=\\\"https://telegram.me/share/https://sapient.pro?url=https://sapient.pro/blog/named-entity-recognition-implementation-tips&amp;text=Named Entity Recognition: Mechanism, Methods, Use Cases, and Implementation Tips\\\" class=\\\"Article_social__tk25G\\\" target=\\\"_blank\\\" aria-label=\\\"Telegram\\\" rel=\\\"noreferrer\\\"><svg><use xlink:href=\\\"/media/socials/telegram.svg#telegramSVG\\\" href=\\\"/media/socials/telegram.svg#telegramSVG\\\"></use></svg></a><a href=\\\"https://www.facebook.com/sharer/sharer.php?u=https://sapient.pro/blog/named-entity-recognition-implementation-tips&amp;quote=Named Entity Recognition: Mechanism, Methods, Use Cases, and Implementation Tips\\\" class=\\\"Article_social__tk25G\\\" target=\\\"_blank\\\" aria-label=\\\"Facebook\\\" rel=\\\"noreferrer\\\"><svg><use xlink:href=\\\"/media/socials/facebook.svg#facebookSVG\\\" href=\\\"/media/socials/facebook.svg#facebookSVG\\\"></use></svg></a></div></div></div></aside><div class=\\\"Article_mainContent__eMCzN\\\"><div class=\\\"Article_articleContent__yMQdW\\\"><div class=\\\"Article_contentStyles__FOoh1 Article_contentStyles__withoutPaddingTopForFirstH2__LejJ1\\\"><p>Businesses are all about automation now, using chatbots and voice assistants to do tasks that previously required people. Machine learning and natural language processing (NLP) have become essential. For example, <a href=\\\"https://technologymagazine.com/top10/top-10-companies-advancing-natural-language-processing\\\" target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\">Google Cloud&#x27;s NLP platform</a> uses Google machine learning to help users understand and gain insights from unstructured texts. </p><p>According to a<a href=\\\"https://www.marketsandmarkets.com/Market-Reports/natural-language-processing-nlp-825.html\\\" target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\"> MarketsandMarkets</a> report, the NLP market is expected to reach $68.1 billion by 2028, with Named Entity Recognition (NER) being a key driver of this growth. Since about<a href=\\\"https://mitsloan.mit.edu/ideas-made-to-matter/tapping-power-unstructured-data\\\" target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\"> 80–90%</a> of all data is unorganized, tools like NER are necessary for finding meaningful information.</p></div><div class=\\\"Article_contentStyles__FOoh1\\\" data-id=\\\"1798\\\"><h2>Intro</h2><div class=\\\"\\\"><p>NER is popular because it can automatically find and categorize key information from large pieces of text. This allows organizations to easily extract needed data from customer interactions, financial reports, legal contracts, social media, etc.</p><p>This guide provides all the information about Named Entity Recognition. You'll learn how NER works, what&nbsp;named entity recognition custom entities are, discover its use cases, and learn&nbsp;how to build named entity recognition model.</p></div></div><div class=\\\"Article_contentStyles__FOoh1\\\" data-id=\\\"1799\\\"><h2>What Is Named Entity Recognition?</h2><div class=\\\"\\\"><p>Named entity recognition means&nbsp;a technique in natural language processing used to recognize specific types of entities in a text, like names, places, dates, and organizations.&nbsp;Named entity recognition history began in 1996. NER mostly used rule-based methods and ontologies at that time. By 2007, NER models started to adopt machine learning to engineer features.&nbsp;</p><p>&nbsp;</p><p>Implementation of deep learning has greatly improved NER. Deep learning&nbsp;models for named entity recognition&nbsp;are more flexible and can manage different domains and new data by using characters, sub-words, and word embeddings.</p><p>&nbsp;</p><p>Machines can process large amounts of text and extract key information in organized&nbsp;named entity recognition categories. By identifying specific entities within the text, NER changes how we manage and use written information.</p></div><figure class=\\\"Article_imageBlock__JlKMT\\\"><div class=\\\"Article_image__QmZ2p\\\"><img alt=\\\"NER on New York Times Dataset\\\" loading=\\\"lazy\\\" width=\\\"1296\\\" height=\\\"1394\\\" decoding=\\\"async\\\" data-nimg=\\\"1\\\" style=\\\"color:transparent;background-size:cover;background-position:50% 50%;background-repeat:no-repeat;background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns=&#x27;http://www.w3.org/2000/svg&#x27; viewBox=&#x27;0 0 1296 1394&#x27;%3E%3Cfilter id=&#x27;b&#x27; color-interpolation-filters=&#x27;sRGB&#x27;%3E%3CfeGaussianBlur stdDeviation=&#x27;20&#x27;/%3E%3CfeColorMatrix values=&#x27;1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 100 -1&#x27; result=&#x27;s&#x27;/%3E%3CfeFlood x=&#x27;0&#x27; y=&#x27;0&#x27; width=&#x27;100%25&#x27; height=&#x27;100%25&#x27;/%3E%3CfeComposite operator=&#x27;out&#x27; in=&#x27;s&#x27;/%3E%3CfeComposite in2=&#x27;SourceGraphic&#x27;/%3E%3CfeGaussianBlur stdDeviation=&#x27;20&#x27;/%3E%3C/filter%3E%3Cimage width=&#x27;100%25&#x27; height=&#x27;100%25&#x27; x=&#x27;0&#x27; y=&#x27;0&#x27; preserveAspectRatio=&#x27;none&#x27; style=&#x27;filter: url(%23b);&#x27; href=&#x27;data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEASABIAAD/2wBDAAUDBAQEAwUEBAQFBQUGBwwIBwcHBw8LCwkMEQ8SEhEPERETFhwXExQaFRERGCEYGh0dHx8fExciJCIeJBweHx7/2wBDAQUFBQcGBw4ICA4eFBEUHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh7/wAARCAAKAAoDAREAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAABgQH/8QAIBAAAgIBAwUAAAAAAAAAAAAAAQIDEQASEyEEFEFhof/EABYBAQEBAAAAAAAAAAAAAAAAAAIBA//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oADAMBAAIRAxEAPwDXJJITFvqSgdLbULqvPzLUg5LKjSue2ha2JsR8HFUVxs2vp11GtscXmZDk7MJ5ACQAxoX7xC//2Q==&#x27;/%3E%3C/svg%3E&quot;)\\\" srcSet=\\\"/_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2FDark_1_727de2f7a4.webp&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2FDark_1_727de2f7a4.webp&amp;w=3840&amp;q=75 2x\\\" src=\\\"/_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2FDark_1_727de2f7a4.webp&amp;w=3840&amp;q=75\\\"/></div><figcaption>NER on New York Times Dataset</figcaption></figure></div><div class=\\\"Article_contentStyles__FOoh1\\\" data-id=\\\"1800\\\"><h2>NER Benefits &amp; Challenges?</h2><div class=\\\"\\\"><p>Named entity recognition has several great benefits, but also some limitations. We’ll explain both to you.</p><h3>Advantages of Using NER</h3><p>The main advantage of NER is that it helps us find important details in large amounts of textual data, like articles, social media posts, websites, and research papers. Let’s check out some more benefits of NER:</p><ul><li><strong>Enhanced user experience</strong>: NER improves customer experience by providing better search results and personalized recommendations.</li><li><strong>Simple analysis of data and trends</strong>: NER makes it easier to analyze data to identify tendencies.&nbsp;&nbsp;</li><li><strong>Automated workflows</strong>:&nbsp;NER automates processes, which helps save our time and resources.</li></ul><h3>Any Limitations of NER?</h3><p>Now let's look at some&nbsp;named entity recognition challenges:</p><ul><li><strong>Context misunderstanding</strong>:&nbsp;algorithms often struggle to understand context because words get meaning from the surrounding text. For example, the word \\\"Bat\\\" can mean a flying animal or a baseball tool (depending on the context).</li><li><strong>Language variation</strong>:&nbsp;human language includes slang, dialects, and regional differences, which can make it harder to understand words that are common in one place but not in another.</li><li><strong>Data sparsity</strong>: machine learning models need a lot of labeled data to identify entities. This can be difficult to find, especially for rare languages or specialized areas.</li></ul></div></div><div class=\\\"Article_contentStyles__FOoh1\\\" data-id=\\\"1801\\\"><h2>How Named-entity Recognition Works?</h2><div class=\\\"\\\"><p>Named&nbsp;Entity Recognition&nbsp;<a href=\\\"https://sapient.pro/natural-language-processing-services\\\" target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\">NLP&nbsp;</a>uses unique algorithms with grammar rules and statistical models to find and tag names in text. It identifies categories like people, locations, dates, percentages,&nbsp; organizations, and currency amounts. These categories often use abbreviations, such as LOC for location, PER for person, and ORG for organization.</p><p>Once the&nbsp;named entity recognition best model&nbsp;can work with labeled text data, it automatically analyzes new text, identifies named entities, and sorts them into categories.&nbsp;</p><p>After identifying the information, a tool collects details about these entities and creates a machine-readable document. Other tools can then use this document to extract additional information.</p></div><figure class=\\\"Article_imageBlock__JlKMT\\\"><div class=\\\"Article_image__QmZ2p\\\"><img alt=\\\"article image\\\" loading=\\\"lazy\\\" width=\\\"1296\\\" height=\\\"1216\\\" decoding=\\\"async\\\" data-nimg=\\\"1\\\" style=\\\"color:transparent;background-size:cover;background-position:50% 50%;background-repeat:no-repeat;background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns=&#x27;http://www.w3.org/2000/svg&#x27; viewBox=&#x27;0 0 1296 1216&#x27;%3E%3Cfilter id=&#x27;b&#x27; color-interpolation-filters=&#x27;sRGB&#x27;%3E%3CfeGaussianBlur stdDeviation=&#x27;20&#x27;/%3E%3CfeColorMatrix values=&#x27;1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 100 -1&#x27; result=&#x27;s&#x27;/%3E%3CfeFlood x=&#x27;0&#x27; y=&#x27;0&#x27; width=&#x27;100%25&#x27; height=&#x27;100%25&#x27;/%3E%3CfeComposite operator=&#x27;out&#x27; in=&#x27;s&#x27;/%3E%3CfeComposite in2=&#x27;SourceGraphic&#x27;/%3E%3CfeGaussianBlur stdDeviation=&#x27;20&#x27;/%3E%3C/filter%3E%3Cimage width=&#x27;100%25&#x27; height=&#x27;100%25&#x27; x=&#x27;0&#x27; y=&#x27;0&#x27; preserveAspectRatio=&#x27;none&#x27; style=&#x27;filter: url(%23b);&#x27; href=&#x27;data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEASABIAAD/2wBDAAUDBAQEAwUEBAQFBQUGBwwIBwcHBw8LCwkMEQ8SEhEPERETFhwXExQaFRERGCEYGh0dHx8fExciJCIeJBweHx7/2wBDAQUFBQcGBw4ICA4eFBEUHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh7/wAARCAAKAAoDAREAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAABgQH/8QAIBAAAgIBAwUAAAAAAAAAAAAAAQIDEQASEyEEFEFhof/EABYBAQEBAAAAAAAAAAAAAAAAAAIBA//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oADAMBAAIRAxEAPwDXJJITFvqSgdLbULqvPzLUg5LKjSue2ha2JsR8HFUVxs2vp11GtscXmZDk7MJ5ACQAxoX7xC//2Q==&#x27;/%3E%3C/svg%3E&quot;)\\\" srcSet=\\\"/_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2FDark_2_ba6b1ca0e0.webp&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2FDark_2_ba6b1ca0e0.webp&amp;w=3840&amp;q=75 2x\\\" src=\\\"/_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2FDark_2_ba6b1ca0e0.webp&amp;w=3840&amp;q=75\\\"/></div></figure></div><div class=\\\"Article_contentStyles__FOoh1\\\" data-id=\\\"1802\\\"><h2>Named Entity Recognition Techniques</h2><div class=\\\"\\\"><p>To develop the best model for named entity recognition, the text must go through various steps like tokenization and tagging. In tagging, each word in a sentence is labeled with tags like “Person” or “Location”.&nbsp; We’ll explain what techniques NER uses:&nbsp;</p><h3>IO Tagging</h3><p>In this simple tagging method, each word in a sentence is tagged as “inside” (I) if it's part of an entity or “outside” (O) if it's not.</p><p>In the sentence “Sara is going to London,” the words “Sara” and “London” are tagged as entities (I tag), while the words \\\"is,\\\" \\\"going,\\\" and \\\"to\\\" are not entities (O tag).</p><p>This method has limitations, especially with tagging consecutive entities of the same type.</p><h3>BIO / IOB Tagging</h3><p>IOB is a widely used tagging method. This system labels each word to show if it is at the beginning (B) of a named entity, inside (I) of a named entity, or outside (O) of any named entity.</p><p>In the sentence “Sara is going to London,” “Sara” is marked as “B-PER” to show it's the start of a person's name, while “London” is tagged as “I-LOC” because it's a place.</p><h3>IOE Tagging</h3><p>This approach is similar to IOB, but it uses an&nbsp;E tag&nbsp;to mark the end of an entity instead of the beginning.</p><h3>BILOU Tagging</h3><p>BILOU is a more detailed version of the BIO labeling system that detects entities. It includes two extra labels, Last (L) and Unit (U), to improve&nbsp;ner metrics accuracy, especially with longer entities.</p><p>In a sentence like “Steve Jobs was born in San Francisco,” BILOU tagging would be: Steve —&nbsp;&nbsp;B-PER (beginning of a Person entity), Jobs —&nbsp;&nbsp;L-PER (last token of a Person entity), was —&nbsp;&nbsp;O (outside any named entity), born —&nbsp;&nbsp;O, in —&nbsp;&nbsp;O, San Francisco —&nbsp;&nbsp;U-LOC (Location).</p><h3>Conditional Random Fields (CRFs)</h3><p>CRFs are statistical tools that help make structured predictions. They consider the context and relationships between nearby tokens. CRFs are quite practical for custom named entity recognition, which involve labeling sequences.</p><p>In the sentence “Samsung announced the new Galaxy Buds in California,” Samsung is marked as an organization (B-ORG), Galaxy Buds as a product (B-PROD), and California as a location (B-LOC). CRFs use the context and relationships between words to identify these distinctions.</p></div></div><div class=\\\"Article_contentStyles__FOoh1\\\" data-id=\\\"1803\\\"><h2>NER Methodologies</h2><div class=\\\"\\\"><p>Named entity recognition data augmentation uses different methodologies to help identify and classify names and other specific entities in large texts. Let's see what they are.</p><h3>Named Entity Recognition Methods Based on Rules</h3><p>Rule-based methods often use linguistic patterns, expressions, or dictionaries. They are effective in tasks like extracting standard medical terms from clinical notes. Yet, rule-based techniques can't handle a large&nbsp;named entity recognition dataset because they follow fixed rules.</p><h3>Statistical Methods</h3><p>Statistical methods, like&nbsp; Conditional Random Fields (CRF) and Hidden Markov Models (HMM), use probabilities learned from training data to indicate named entities. These methods work well with lots of labeled data because they can adapt to different types of text.&nbsp;</p><h3>Machine Learning Methods&nbsp;</h3><p><a href=\\\"https://sapient.pro/blog/best-programming-languages-for-machine-learning\\\">Machine learning techniques&nbsp;</a>use algorithms like support vector machines and decision trees to learn from labeled data and predict specific named entities. These techniques help run large datasets and complex patterns.&nbsp;</p><h3>Deep Learning Methods</h3><p>Deep learning methods are the latest development that uses neural networks. Techniques like Recurrent Neural Networks (RNNs) and transformers are popular because they can handle long-term text patterns. These methods work great for big tasks with lots of training data, but they require a lot of computing power.</p><h3>Hybrid Methodologies</h3><p>No single method works for every situation in NER. So, this led to the development of hybrid methods. They use a mix of rules, stats, and machine learning to get the best of each. For example, rule-based methods can work with specific entities in a particular field, while machine learning or deep learning is better for identifying more general entities.</p></div></div><div class=\\\"Article_contentStyles__FOoh1\\\" data-id=\\\"1804\\\"><h2>Use Cases for Named Entity Recognition</h2><div class=\\\"\\\"><p>NER has changed how different businesses and industries operate by efficiently processing large datasets. Here are some key&nbsp;named entity recognition use cases.</p><h3>News Search</h3><p>News companies create online content daily. NER helps automatically identify the who, what, when, where, and why in news and other articles. It highlights key details and helps understand the context better.&nbsp;</p><p>If you're searching for information about a celebrity or a particular event, NER can categorize articles based on the entities they mention. For example, if you want to find news about Mark Zuckerberg, an NER-powered platform can suggest articles that mention “Mark Zuckerberg” or “Facebook,” even if these terms aren't in the headlines.</p><h3>Chatbots</h3><p>Chatbots use NER to understand user questions. By identifying key information, like names or places, they can accurately respond. For example, if a person asks a chatbot to find a fast casual restaurant in the City Hall Park, NER helps the chatbot identify entities such as the type of food (fast casual), the type of place (restaurants), and the location (City Hall Park).</p><h3>Scientific research</h3><p>An online journal or publication platform hosts millions of research papers and academic articles. With possibly hundreds of papers on the same topic, organizing this information can be quite challenging. For example, with about 100,000 publications on Machine Learning, tagging them by key topics makes it easy to find articles on how two-layer neural networks learn.</p><h3>Legal documentation</h3><p>Legal documents, especially contracts, provide important information about the parties and specifics like duration and scope. Tracking these details is a must to manage contracts and avoid accidental renewals. NER automatically finds key details like names and dates in long documents.</p><h3>Pharmaceuticals and healthcare</h3><p>The healthcare system has about<a href=\\\"https://pmc.ncbi.nlm.nih.gov/articles/PMC6372467/#:~:text=The%20big%20problem%20of%20healthcare,image%2C%20signal%2C%20etc.)\\\" target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\"> 80% of unstructured medical data.&nbsp;</a>NER helps identify and organize medical information like treatments, drugs, diseases, tests, and medication names in different documents. For example, tagging promotional materials makes it easier for medical representatives to find and share the most relevant information with healthcare professionals.</p><h3>Cybersecurity</h3><p>NER helps companies detect potential threats in network logs and other security data. The tool detects suspicious URLs, IP addresses, filenames, and usernames. This makes the network more secure and helps with safety investigations.</p><h3>Finance</h3><p>In finance, NER helps identify trends and improve risk assessments. It not only manages financial data like loans and earnings reports, but also analyzes company mentions on social media. This also helps to track events that might affect stock prices.</p><h3>Social Media</h3><p>Businesses use NER in social media analysis because it helps them find mentions of their brands, products, or competitors in conversations. This information helps improve brand reputation and create more targeted marketing strategies.</p></div><figure class=\\\"Article_imageBlock__JlKMT\\\"><div class=\\\"Article_image__QmZ2p\\\"><img alt=\\\"article image\\\" loading=\\\"lazy\\\" width=\\\"1296\\\" height=\\\"1386\\\" decoding=\\\"async\\\" data-nimg=\\\"1\\\" style=\\\"color:transparent;background-size:cover;background-position:50% 50%;background-repeat:no-repeat;background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns=&#x27;http://www.w3.org/2000/svg&#x27; viewBox=&#x27;0 0 1296 1386&#x27;%3E%3Cfilter id=&#x27;b&#x27; color-interpolation-filters=&#x27;sRGB&#x27;%3E%3CfeGaussianBlur stdDeviation=&#x27;20&#x27;/%3E%3CfeColorMatrix values=&#x27;1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 100 -1&#x27; result=&#x27;s&#x27;/%3E%3CfeFlood x=&#x27;0&#x27; y=&#x27;0&#x27; width=&#x27;100%25&#x27; height=&#x27;100%25&#x27;/%3E%3CfeComposite operator=&#x27;out&#x27; in=&#x27;s&#x27;/%3E%3CfeComposite in2=&#x27;SourceGraphic&#x27;/%3E%3CfeGaussianBlur stdDeviation=&#x27;20&#x27;/%3E%3C/filter%3E%3Cimage width=&#x27;100%25&#x27; height=&#x27;100%25&#x27; x=&#x27;0&#x27; y=&#x27;0&#x27; preserveAspectRatio=&#x27;none&#x27; style=&#x27;filter: url(%23b);&#x27; href=&#x27;data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEASABIAAD/2wBDAAUDBAQEAwUEBAQFBQUGBwwIBwcHBw8LCwkMEQ8SEhEPERETFhwXExQaFRERGCEYGh0dHx8fExciJCIeJBweHx7/2wBDAQUFBQcGBw4ICA4eFBEUHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh7/wAARCAAKAAoDAREAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAABgQH/8QAIBAAAgIBAwUAAAAAAAAAAAAAAQIDEQASEyEEFEFhof/EABYBAQEBAAAAAAAAAAAAAAAAAAIBA//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oADAMBAAIRAxEAPwDXJJITFvqSgdLbULqvPzLUg5LKjSue2ha2JsR8HFUVxs2vp11GtscXmZDk7MJ5ACQAxoX7xC//2Q==&#x27;/%3E%3C/svg%3E&quot;)\\\" srcSet=\\\"/_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2FDark_3_bef01613af.webp&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2FDark_3_bef01613af.webp&amp;w=3840&amp;q=75 2x\\\" src=\\\"/_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2FDark_3_bef01613af.webp&amp;w=3840&amp;q=75\\\"/></div></figure></div><div class=\\\"Article_contentStyles__FOoh1\\\" data-id=\\\"1805\\\"><h2>NER Examples</h2><div class=\\\"\\\"><p>Named Entity Recognition lets systems understand the context of words. For example, it allows a search engine to know if “Apple” means the company or the fruit, depending on the sentence.</p><p><a href=\\\"https://sapient.pro/ai-development-services\\\" target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\">AI-driven solutions&nbsp;</a>like chatbots and virtual assistants also use NER to specify key entities in user questions, like names, places, or dates. So they can give more precise answers.</p><p>To understand how NER works, let's look at an example where it identifies entities like people, organizations, locations, and dates in a text. Consider this passage:</p><p><strong>Martin Eberhard and Marc Tarpenning&nbsp;</strong><a href=\\\"https://www.forbes.com/sites/qai/2022/09/29/tesla-a-history-of-innovation-and-headaches/\\\" target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\"><strong>founded Tesla Motors</strong></a><strong> in July 2003, in San Carlos, California, U.S.</strong></p><p>With NER, we would identify these words:</p><ul><li><strong>Person</strong>: Martin Eberhard, Marc Tarpenning;</li><li><strong>Organization</strong>:&nbsp;Tesla Motors;</li><li><strong>Location</strong>: San Carlos, California;</li><li><strong>Date</strong>: July 1, 2003.</li></ul><p>NER identifies the specific entities that interest you. You define these named entity recognition types&nbsp;and then find the matching words in the text for each category.</p></div><figure class=\\\"Article_imageBlock__JlKMT\\\"><div class=\\\"Article_image__QmZ2p\\\"><img alt=\\\"article image\\\" loading=\\\"lazy\\\" width=\\\"1296\\\" height=\\\"360\\\" decoding=\\\"async\\\" data-nimg=\\\"1\\\" style=\\\"color:transparent;background-size:cover;background-position:50% 50%;background-repeat:no-repeat;background-image:url(&quot;data:image/svg+xml;charset=utf-8,%3Csvg xmlns=&#x27;http://www.w3.org/2000/svg&#x27; viewBox=&#x27;0 0 1296 360&#x27;%3E%3Cfilter id=&#x27;b&#x27; color-interpolation-filters=&#x27;sRGB&#x27;%3E%3CfeGaussianBlur stdDeviation=&#x27;20&#x27;/%3E%3CfeColorMatrix values=&#x27;1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 100 -1&#x27; result=&#x27;s&#x27;/%3E%3CfeFlood x=&#x27;0&#x27; y=&#x27;0&#x27; width=&#x27;100%25&#x27; height=&#x27;100%25&#x27;/%3E%3CfeComposite operator=&#x27;out&#x27; in=&#x27;s&#x27;/%3E%3CfeComposite in2=&#x27;SourceGraphic&#x27;/%3E%3CfeGaussianBlur stdDeviation=&#x27;20&#x27;/%3E%3C/filter%3E%3Cimage width=&#x27;100%25&#x27; height=&#x27;100%25&#x27; x=&#x27;0&#x27; y=&#x27;0&#x27; preserveAspectRatio=&#x27;none&#x27; style=&#x27;filter: url(%23b);&#x27; href=&#x27;data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEASABIAAD/2wBDAAUDBAQEAwUEBAQFBQUGBwwIBwcHBw8LCwkMEQ8SEhEPERETFhwXExQaFRERGCEYGh0dHx8fExciJCIeJBweHx7/2wBDAQUFBQcGBw4ICA4eFBEUHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh7/wAARCAAKAAoDAREAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAABgQH/8QAIBAAAgIBAwUAAAAAAAAAAAAAAQIDEQASEyEEFEFhof/EABYBAQEBAAAAAAAAAAAAAAAAAAIBA//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oADAMBAAIRAxEAPwDXJJITFvqSgdLbULqvPzLUg5LKjSue2ha2JsR8HFUVxs2vp11GtscXmZDk7MJ5ACQAxoX7xC//2Q==&#x27;/%3E%3C/svg%3E&quot;)\\\" srcSet=\\\"/_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2FDark_4_6aa3963993.webp&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2FDark_4_6aa3963993.webp&amp;w=3840&amp;q=75 2x\\\" src=\\\"/_next/image?url=https%3A%2F%2Fsapientpro.fra1.digitaloceanspaces.com%2FDark_4_6aa3963993.webp&amp;w=3840&amp;q=75\\\"/></div></figure></div><div class=\\\"Article_contentStyles__FOoh1\\\" data-id=\\\"1806\\\"><h2>How to Implement Named Entity Recognition </h2><div class=\\\"\\\"><p>Implementing NER involves 8 key steps. Let's go through them so you can better understand how the process works.</p><h3>Step #1: Setting Goals</h3><p>Decide which entities to recognize, like people and places, and how you'll use NER, such as for extracting information.</p><h3>Step #2: Data preparation</h3><p>Start by collecting the data with the entities you need. Use tools like SpaCy Prodigy or datasets like CoNLL-03 to tag them. Next, clean and preprocess the data to fix any issues with punctuation or special characters.</p><h3>Step #3: Deciding on Approach</h3><p>Choose from different methods like:</p><ul><li>Rule-based approaches that use set rules for certain tasks;</li><li>Machine Learning techniques, such as Conditional Random Fields (CRFs);</li><li>Deep learning tools.</li></ul><h3>Step #4: Building the Model</h3><p>Pick a library like SpaCy or Transformers. You can train a model from the beginning or adjust an existing one for your special needs.</p><h3>Step #5: Model Assessment</h3><p>Measure how well your model performs using metrics like precision, recall, and F1 score. Also, test it on various datasets to ensure it works properly with new data.</p><h3>Step #6: Deployment and Integration</h3><p>Integrate the NER model into your application and make sure it works with other tools and processes.</p><h3>Step #7: Maintenance</h3><p>Regularly check the model performance in real-world situations and update it as needed.</p><h3>Step #8: Solving Challenges</h3><p>In this last phase, manage any uncertainties and differences in identifying entities. You can adjust the model to fit the language and requirements of your field.</p><p>&nbsp;</p><p>Using an&nbsp;<a href=\\\"https://www.ibm.com/topics/api\\\" target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\">API&nbsp;</a>can make it much easier to set up&nbsp;named entity recognition software. These APIs are available online or as local tools that offer NER features. For example,&nbsp;Stanford Named Entity Recognizer is a popular Java tool used for extracting entities. It uses Conditional Random Fields (CRF) and comes with a pre-trained&nbsp;named entity recognition model&nbsp;to identify entities.</p><p>&nbsp;</p><p>If you’re interested in&nbsp;how to do named entity recognition in Python, the&nbsp;Natural Language Toolkit (NLTK) is a helpful open-source tool for processing human language data. It's easy to use and works with over 100 pre-trained&nbsp;large language models for named entity recognition. NLTK offers tools for tasks like named entity recognition classification, stemming, tokenization, parsing, tagging, and understanding meaning. It includes a named entity recognizer (`ne_chunk`) and can be used with the Stanford NER in Python.</p></div></div><div class=\\\"Article_contentStyles__FOoh1\\\" data-id=\\\"1807\\\"><h2>Recent Trends in Named Entity Recognition (NER) and Its Future</h2><div class=\\\"\\\"><p>Let's check out some predictions for the future of Named Entity Recognition (NER).</p><p>&nbsp;</p><p>First, experts believe pairing named entity recognition with knowledge graphs, large databases that show how different entities are connected, will improve its performance. This could make NER more precise and help discover new entities more easily.</p><p>&nbsp;</p><p>Next, named entity recognition could play a more significant role in voice assistants and chatbots, like ChatGPT. Recent stats show that&nbsp;<a href=\\\"https://cases.media/en/article/the-chatbot-market-in-2024-forecasts-and-latest-statistics\\\" target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\">67% of clients use chatbots</a> for customer support, while chatbots manage 64% of routine requests.&nbsp;</p><p>&nbsp;</p><p>As these technologies become more popular, it's important to identify specific parts of speech or text to understand what users want and give the right response. If a customer asks the chatbot, \\\"I lost my phone in London yesterday. Can you help me block my number?\\\" a NER system will identify a phone as a PRODUCT, London as a LOCATION, and yesterday as a DATE.&nbsp;</p><p>&nbsp;</p><p>A chatbot will be able to quickly share location services and temporarily block a customer's number. This will make support service faster and more efficient.</p><p>&nbsp;</p><p>Finally, as big data,&nbsp;<a href=\\\"https://sapient.pro/blog/how-to-build-ai-software\\\" target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\">artificial intelligence</a>, and the Internet of Things expand, companies will use named entity recognition for cybersecurity and fraud detection. NER can interpret large amounts of data to find potential threats, which helps protect people and companies from cyberattacks.&nbsp;</p><p>&nbsp;</p><p><a href=\\\"https://www.scitepress.org/Papers/2019/73142/73142.pdf\", \"pdf_path\": null, \"extracted_info\": null, \"error\": \"download failed: request failed: 404 Client Error: Not Found for url: https://sapient.pro/_next/static/chunks/webpack-8f2f3a22d4058924.js%22/%3E%3Cscript%20src=%22/_next/static/chunks/4bd1b696-30718bd562604751.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/8261-87b8c652f4859a63.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/main-app-bb2c9f756d1b5869.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/5692-72f59cbd0b2d4e1c.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/372-451cb83d29080205.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/2425-439c7bb72af23a79.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/1610-347058d2d6f072f3.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/2255-4738241640ea2919.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/8171-cddb9006621c7c00.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/5920-07a1fcdb22c875d8.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/8050-6fe88ce55f02cc11.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/47-eff6aa59faf62008.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/9568-fae9ea3a1f7a897e.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/8762-904b9dccec4bdcbe.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/9379-b268cb89893422b9.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/6005-ebaace4f89cd1040.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/7733-f85527123dbb52bd.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/app/(pages)/blog/%5BfirstRoute%5D/page-fdb8479ab01af442.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/app/layout-b137356a30e39ace.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/app/error-65374cf82c16a100.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/app/not-found-75717f0b381a5717.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/160b575a-21c0702096c443fe.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/13b76428-d0865967e61b6767.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/6429-39f4a61cddb917a1.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/7040-a126503cb486062f.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/1325-c421be758bae2d4b.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/2602-4efe96ee0869cd95.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/7871-7eabec075b2300c6.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/app/(pages)/layout-0627809657c81bf2.js%22%20async=%22%22%3E%3C/script%3E%3Cscript%20src=%22/_next/static/chunks/app/(pages)/page-7ab8cf56416bc535.js%22%20async=%22%22%3E%3C/script%3E%3Clink%20rel=%22preload%22%20href=%22https:/tag.clearbitscripts.com/v1/pk%5C_f50bf055ee2830aedf119b8ace4bc540/tags.js%22%20as=%22script%22/%3E%3Ctitle%3ENER:%20Overview,%20Techniques,%20Methods,%20and%20Implementation%20Guide%20%7C%20SapientPro%3C/title%3E%3Cmeta%20name=%22description%22%20content=%22Learn%20the%20basics%20of%20named%20entity%20recognition,%20its%20use%20cases,%20and%20how%20it%20works%20in%20natural%20language%20processing%20(NLP).%22/%3E%3Clink%20rel=%22manifest%22%20href=%22/manifest.webmanifest%22/%3E%3Clink%20rel=%22canonical%22%20href=%22https:/sapient.pro/blog/named-entity-recognition-implementation-tips%22/%3E%3Cmeta%20property=%22og:title%22%20content=%22NER:%20Overview,%20Techniques,%20Methods,%20and%20Implementation%20Guide%20%7C%20SapientPro%22/%3E%3Cmeta%20property=%22og:description%22%20content=%22Learn%20the%20basics%20of%20named%20entity%20recognition,%20its%20use%20cases,%20and%20how%20it%20works%20in%20natural%20language%20processing%20(NLP).%22/%3E%3Cmeta%20property=%22og:url%22%20content=%22https:/sapient.pro/blog/named-entity-recognition-implementation-tips%22/%3E%3Cmeta%20property=%22og:site_name%22%20content=%22SapientPro%22/%3E%3Cmeta%20property=%22og:locale%22%20content=%22en_US%22/%3E%3Cmeta%20property=%22og:image%22%20content=%22https:/sapientpro.fra1.digitaloceanspaces.com/1c43931be7e6058e1569acd847be3460.jpg%22/%3E%3Cmeta%20property=%22og:type%22%20content=%22website%22/%3E%3Cmeta%20name=%22twitter:card%22%20content=%22summary_large_image%22/%3E%3Cmeta%20name=%22twitter:creator%22%20content=%22@sapientpro%22/%3E%3Cmeta%20name=%22twitter:title%22%20content=%22NER:%20Overview,%20Techniques,%20Methods,%20and%20Implementation%20Guide%20%7C%20SapientPro%22/%3E%3Cmeta%20name=%22twitter:description%22%20content=%22Learn%20the%20basics%20of%20named%20entity%20recognition,%20its%20use%20cases,%20and%20how%20it%20works%20in%20natural%20language%20processing%20(NLP).%22/%3E%3Cmeta%20name=%22twitter:image%22%20content=%22https:/sapientpro.fra1.digitaloceanspaces.com/1c43931be7e6058e1569acd847be3460.jpg%22/%3E%3Clink%20rel=%22icon%22%20href=%22/favicon.ico%22%20type=%22image/x-icon%22%20sizes=%2248x48%22/%3E%3Clink%20rel=%22icon%22%20href=%22/icon.png?c21dbdf8726499f9%22%20type=%22image/png%22%20sizes=%22160x160%22/%3E%3Clink%20rel=%22apple-touch-icon%22%20href=%22/apple-icon.png?d13d4c1b561cc588%22%20type=%22image/png%22%20sizes=%22180x180%22/%3E%3Cscript%20src=%22/_next/static/chunks/polyfills-42372ed130431b0a.js%22%20noModule=%22%22%3E%3C/script%3E%3C/head%3E%3Cbody%3E%3Cdiv%20hidden=%22%22%3E%3C!--$--%3E%3C!--/$--%3E%3C/div%3E%3Cheader%20class=%22Header_header__MwWvM%20Header_header_absolute__x4DUv%22%3E%3Ca%20aria-label=%22Get%20back%20to%20main%20page%22%20class=%22Header_logo__V9h3K%22%20href=%22/%22%3E%3Cdiv%20class=%22Logo_logo__zBwGf%22%20style=%22width:100px;height:32px%22%3E%3Csvg%3E%3Cuse%20width=%22100%22%20height=%2232%22%20xlink:href=%22/media/logo.svg#logo%22%20href=%22/media/logo.svg%23logo%22%3E%3C/use%3E%3C/svg%3E%3C/div%3E%3C/a%3E%3Cdiv%20class=%22Header_header__rightBlock__YuLgy%22%3E%3Cnav%20class=%22Menu_menu__N68p_%22%3E%3Cul%20class=%22Menu_menu__list__NkMaT%22%3E%3Cli%20id=%22headedNavItem-1%22%20class=%22Menu_menu__item__Ze9KX%22%3E%3Cbutton%20type=%22button%22%20class=%22Menu_menuItem__lORev%20Menu_linkless__XjyKx%22%3EServices%3Csvg%20class=%22Menu_dropdownIcon__A4roo%22%3E%3Cuse%20xlink:href=%22/media/angle_down.svg%23angleDown%22%20href=%22/media/angle_down.svg%23angleDown%22%3E%3C/use%3E%3C/svg%3E%3Cdiv%20class=%22Submenu_submenuWrapper__F9bWI%20Menu_submenuWrapper__SQlb2%22%3E%3Csection%20class=%22Submenu_submenu__4X1GF%20Menu_submenu__VGcRf%20Submenu_isVisible__vc3Zx%22%3E%3Cul%20class=%22Submenu_submenu__mainlist__OEZcO%22%3E%3Cli%3E%3C/li%3E%3Cli%20class=%22Submenu_submenu__mainlist__item__7VGcv%22%3E%3Cul%20class=%22Submenu_submenu__sublist__NLlB7%22%3E%3Cli%3E%3Cdiv%20class=%22Submenu_submenu__sublist__item__z1vTi%22%3E%3Cdiv%20class=%22Submenu_imageWrapper__nMh6K%22%3E%3Cdiv%20class=%22Submenu_image__cH19Y%22%3E%3Cimg%20alt=%22submenu%20icon%22%20loading=%22lazy%22%20decoding=%22async%22%20data-nimg=%22fill%22%20style=%22position:absolute;height:100%25;width:100%25;left:0;top:0;right:0;bottom:0;color:transparent%22%20src=%22https://sapientpro.fra1.digitaloceanspaces.com/63ac20be9e26fbf5da726aa0f6441139.svg%22/%3E%3C/div%3E%3C/div%3E%3Cdiv%3E%3Ca%20class=%22Submenu_title__ceSEA%22%20href=%22/legacy-software-modernization-services%22%3ELegacy%20Software%20Modernization%3C/a%3E%3C/div%3E%3C/div%3E%3C/li%3E%3Cli%3E%3Cdiv%20class=%22Submenu_submenu__sublist__item__z1vTi%22%3E%3Cdiv%20class=%22Submenu_imageWrapper__nMh6K%22%3E%3Cdiv%20class=%22Submenu_image__cH19Y%22%3E%3Cimg%20alt=%22submenu%20icon%22%20loading=%22lazy%22%20decoding=%22async%22%20data-nimg=%22fill%22%20style=%22position:absolute;height:100%25;width:100%25;left:0;top:0;right:0;bottom:0;color:transparent%22%20src=%22https://sapientpro.fra1.digitaloceanspaces.com/cc6f2e1fe7df157b60eaa254cdac5721.svg%22/%3E%3C/div%3E%3C/div%3E%3Cdiv%3E%3Ca%20class=%22Submenu_title__ceSEA%22%20href=%22/web-development-services%22%3EWeb%203.0%20Development%3C/a%3E%3C/div%3E%3C/div%3E%3C/li%3E%3Cli%3E%3Cdiv%20class=%22Submenu_submenu__sublist__item__z1vTi%22%3E%3Cdiv%20class=%22Submenu_imageWrapper__nMh6K%22%3E%3Cdiv%20class=%22Submenu_image__cH19Y%22%3E%3Cimg%20alt=%22submenu%20icon%22%20loading=%22lazy%22%20decoding=%22async%22%20data-nimg=%22fill%22%20style=%22position:absolute;height:100%25;width:100%25;left:0;top:0;right:0;bottom:0;color:transparent%22%20src=%22https://sapientpro.fra1.digitaloceanspaces.com/c87d62e9b8a55c2708a4ba2ba1489935.svg%22/%3E%3C/div%3E%3C/div%3E%3Cdiv%3E%3Ca%20class=%22Submenu_title__ceSEA%22%20href=%22/custom-software-development%22%3ECustom%20Software%20Development%20%3C/a%3E%3C/div%3E%3C/div%3E%3C/li%3E%3Cli%3E%3Cdiv%20class=%22Submenu_submenu__sublist__item__z1vTi%22%3E%3Cdiv%20class=%22Submenu_imageWrapper__nMh6K%22%3E%3Cdiv%20class=%22Submenu_image__cH19Y%22%3E%3Cimg%20alt=%22submenu%20icon%22%20loading=%22lazy%22%20decoding=%22async%22%20data-nimg=%22fill%22%20style=%22position:absolute;height:100%25;width:100%25;left:0;top:0;right:0;bottom:0;color:transparent%22%20src=%22https://sapientpro.fra1.digitaloceanspaces.com/1fcf391753fad4c59a797d4cf4438530.svg%22/%3E%3C/div%3E%3C/div%3E%3Cdiv%3E%3Ca%20class=%22Submenu_title__ceSEA%22%20href=%22/business-digitalization-solutions%22%3EBusiness%20Digitalization%3C/a%3E%3C/div%3E%3C/div%3E%3C/li%3E%3Cli%3E%3Cdiv%20class=%22Submenu_submenu__sublist__item__z1vTi%22%3E%3Cdiv%20class=%22Submenu_imageWrapper__nMh6K%22%3E%3Cdiv%20class=%22Submenu_image__cH19Y%22%3E%3Cimg%20alt=%22submenu%20icon%22%20loading=%22lazy%22%20decoding=%22async%22%20data-nimg=%22fill%22%20style=%22position:absolute;height:100%25;width:100%25;left:0;top:0;right:0;bottom:0;color:transparent%22%20src=%22https://sapientpro.fra1.digitaloceanspaces.com/ed786473dd7f304528d1226e9e98dbea.svg%22/%3E%3C/div%3E%3C/div%3E%3Cdiv%3E%3Ca%20class=%22Submenu_title__ceSEA%22%20href=%22/big-data-and-scraping-services%22%3EBigData%20and%20Scraping%3C/a%3E%3C/div%3E%3C/div%3E%3C/li%3E%3C/ul%3E%3C/li%3E%3Cli%20class=%22Submenu_submenu__mainlist__item__7VGcv%22%3E%3Cul%20class=%22Submenu_submenu__sublist__NLlB7%22%3E%3Cli%3E%3Cdiv%20class=%22Submenu_submenu__sublist__item__z1vTi%22%3E%3Cdiv%20class=%22Submenu_imageWrapper__nMh6K%22%3E%3Cdiv%20class=%22Submenu_image__cH19Y%22%3E%3Cimg%20alt=%22submenu%20icon%22%20loading=%22lazy%22%20decoding=%22async%22%20data-nimg=%22fill%22%20style=%22position:absolute;height:100%25;width:100%25;left:0;top:0;right:0;bottom:0;color:transparent%22%20src=%22https://sapientpro.fra1.digitaloceanspaces.com/da7c2ffd03d6bfe325b052a6cea90ba1.svg%22/%3E%3C/div%3E%3C/div%3E%3Cdiv%3E%3Ca%20class=%22Submenu_title__ceSEA%22%20href=%22/software-development-for-startups%22%3EStartups%20Launching%3C/a%3E%3C/div%3E%3C/div%3E%3C/li%3E%3Cli%3E%3Cdiv%20class=%22Submenu_submenu__sublist__item__z1vTi%22%3E%3Cdiv%20class=%22Submenu_imageWrapper__nMh6K%22%3E%3Cdiv%20class=%22Submenu_image__cH19Y%22%3E%3Cimg%20alt=%22submenu%20icon%22%20loading=%22lazy%22%20decoding=%22async%22%20data-nimg=%22fill%22%20style=%22position:absolute;height:100%25;width:100%25;left:0;top:0;right:0;bottom:0;color:transparent%22%20src=%22https://sapientpro.fra1.digitaloceanspaces.com/Services_Icon_2_1_6d37e4e23b.svg%22/%3E%3C/div%3E%3C/div%3E%3Cdiv%3E%3Ca%20class=%22Submenu_title__ceSEA%22%20href=%22/ui-ux-design-services%22%3EUI/UX%20Design%20Services%3C/a%3E%3C/div%3E%3C/div%3E%3C/li%3E%3Cli%3E%3Cdiv%20class=%22Submenu_submenu__sublist__item__z1vTi%22%3E%3Cdiv%20class=%22Submenu_imageWrapper__nMh6K%22%3E%3Cdiv%20class=%22Submenu_image__cH19Y%22%3E%3Cimg%20alt=%22submenu%20icon%22%20loading=%22lazy%22%20decoding=%22async%22%20data-nimg=%22fill%22%20style=%22position:absolute;height:100%25;width:100%25;left:0;top:0;right:0;bottom:0;color:transparent%22%20src=%22https://sapientpro.fra1.digitaloceanspaces.com/6c5df13ffb3ac21667c42ed4eb141be6.svg%22/%3E%3C/div%3E%3C/div%3E%3Cdiv%3E%3Ca%20class=%22Submenu_title__ceSEA%22%20href=%22/saas-development%22%3ESaaS%20Development%20%3C/a%3E%3C/div%3E%3C/div%3E%3C/li%3E%3Cli%3E%3Cdiv%20class=%22Submenu_submenu__sublist__item__z1vTi%22%3E%3Cdiv%20class=%22Submenu_imageWrapper__nMh6K%22%3E%3Cdiv%20class=%22Submenu_image__cH19Y%22%3E%3Cimg%20alt=%22submenu%20icon%22%20loading=%22lazy%22%20decoding=%22async%22%20data-nimg=%22fill%22%20style=%22position:absolute;height:100%25;width:100%25;left:0;top:0;right:0;bottom:0;color:transparent%22%20src=%22https://sapientpro.fra1.digitaloceanspaces.com/3e3d0656915b4d8d5479f5b21774cc14.svg%22/%3E%3C/div%3E%3C/div%3E%3Cdiv%3E%3Ca%20class=%22Submenu_title__ceSEA%22%20href=%22/ecommerce-development-services%22%3EE-commerce%20Development%3C/a%3E%3C/div%3E%3C/div%3E%3C/li%3E%3Cli%3E%3Cdiv%20class=%22Submenu_submenu__sublist__item__z1vTi%22%3E%3Cdiv%20class=%22Submenu_imageWrapper__nMh6K%22%3E%3Cdiv%20class=%22Submenu_image__cH19Y%22%3E%3Cimg%20alt=%22submenu%20icon%22%20loading=%22lazy%22%20decoding=%22async%22%20data-nimg=%22fill%22%20style=%22position:absolute;height:100%25;width:100%25;left:0;top:0;right:0;bottom:0;color:transparent%22%20src=%22https://sapientpro.fra1.digitaloceanspaces.com/71af5d77fc049335a840785c4df5b87b.svg%22/%3E%3C/div%3E%3C/div%3E%3Cdiv%3E%3Ca%20class=%22Submenu_title__ceSEA%22%20href=%22/ai-development-services%22%3EAI-driven%20Solutions%3C/a%3E%3C/div%3E%3C/div%3E%3C/li%3E%3C/ul%3E%3C/li%3E%3C/ul%3E%3C/section%3E%3C/div%3E%3C/button%3E%3C/li%3E%3Cli%20id=%22headedNavItem-10%22%20class=%22Menu_menu__item__Ze9KX%22%3E%3Ca%20class=%22Menu_menuItem__lORev%22%20href=%22/cases%22%3ECases%3C/a%3E%3C/li%3E%3Cli%20id=%22headedNavItem-15%22%20class=%22Menu_menu__item__Ze9KX%22%3E%3Ca%20class=%22Menu_menuItem__lORev%22%20href=%22/company%22%3ECompany%3C/a%3E%3C/li%3E%3Cli%20id=%22headedNavItem-1%22%20class=%22Menu_menu__item__Ze9KX%22%3E%3Ca%20class=%22Menu_menuItem__lORev%22%20href=%22/blog%22%3EBlog%3C/a%3E%3C/li%3E%3Cli%20id=%22headedNavItem-11%22%20class=%22Menu_menu__item__Ze9KX%22%3E%3Ca%20class=%22Menu_menuItem__lORev%22%20href=%22/contacts%22%3EContacts%3C/a%3E%3C/li%3E%3Cli%20id=%22headedNavItem-6%22%20class=%22Menu_menu__item__Ze9KX%22%3E%3Cbutton%20type=%22button%22%20class=%22Menu_menuItem__lORev%20Menu_linkless__XjyKx%20Menu_dropdownButton__AheqL%22%3ECareer%3Csvg%20class=%22Menu_dropdownIcon__A4roo%22%3E%3Cuse%20xlink:href=%22/media/angle_down.svg%23angleDown%22%20href=%22/media/angle_down.svg%23angleDown%22%3E%3C/use%3E%3C/svg%3E%3Cdiv%20class=%22DropdownMenu_dropdown__GymYD%20Menu_dropdown__GwiQD%22%3E%3Ca%20class=%22DropdownMenu_link__pgZ4G%22%20href=%22/career/vacancies%22%3E%3Cdiv%20class=%22DropdownMenu_link__icon__3DwsB%22%3E%3Cimg%20alt=%22Vacancies%22%20loading=%22lazy%22%20decoding=%22async%22%20data-nimg=%22fill%22%20style=%22position:absolute;height:100%25;width:100%25;left:0;top:0;right:0;bottom:0;color:transparent%22%20src=%22https://sapientpro.fra1.digitaloceanspaces.com/cbe572143c839c95f74007a19671ca97.svg%22/%3E%3C/div%3EVacancies%3C/a%3E%3Ca%20class=%22DropdownMenu_link__pgZ4G%22%20href=%22/career/education%22%3E%3Cdiv%20class=%22DropdownMenu_link__icon__3DwsB%22%3E%3Cimg%20alt=%22Education%22%20loading=%22lazy%22%20decoding=%22async%22%20data-nimg=%22fill%22%20style=%22position:absolute;height:100%25;width:100%25;left:0;top:0;right:0;bottom:0;color:transparent%22%20src=%22https://sapientpro.fra1.digitaloceanspaces.com/dc1c85ce7203d624f1d0a60608b306f1.svg%22/%3E%3C/div%3EEducation%3C/a%3E%3C/div%3E%3C/button%3E%3C/li%3E%3C/ul%3E%3C/nav%3E%3Cbutton%20type=%22button%22%20aria-label=%22search%22%20class=%22Header_searchButton__tLL_S%22%20name=%22Search%22%3E%3Csvg%3E%3Cuse%20xlink:href=%22/media/search.svg%23searchSVG%22%20href=%22/media/search.svg%23searchSVG%22%3E%3C/use%3E%3C/svg%3E%3C/button%3E%3Cbutton%20type=%22button%22%20class=%22ThemeToggle_toggle__KXKLn%22%3E%3Cdiv%20class=%22ThemeToggle_circle__gfBDv%22%3E%3Cimg%20alt=%22particles%22%20loading=%22lazy%22%20width=%2216%22%20height=%2216%22%20decoding=%22async%22%20data-nimg=%221%22%20class=%22ThemeToggle_particles__uQsJU%22%20style=%22color:transparent%22%20srcSet=%22/_next/image?url=%252Fmedia%252FthemeToggle%252FthemeParticles-dark.webp&amp;w=16&amp;q=75%201x,%20/_next/image?url=%252Fmedia%252FthemeToggle%252FthemeParticles-dark.webp&amp;w=32&amp;q=75%202x%22%20src=%22/_next/image?url=%252Fmedia%252FthemeToggle%252FthemeParticles-dark.webp&amp;w=32&amp;q=75%22/%3E%3Cimg%20alt=%22shadow%22%20loading=%22lazy%22%20width=%2216%22%20height=%2216%22%20decoding=%22async%22%20data-nimg=%221%22%20class=%22ThemeToggle_particles__shadow__Ap5A2%22%20style=%22color:transparent%22%20src=%22/media/themeToggle/themeShadow-dark.svg%22/%3E%3C/div%3E%3C/button%3E%3C/div%3E%3Cbutton%20aria-label=%22Toggle%20menu%22%20type=%22button%22%20class=%22Header_menuButton__0azx_%22%3E%3Cdiv%20class=%22Header_menuButton__line__x3Q44%22%3E%3C/div%3E%3Cdiv%20class=%22Header_menuButton__line__x3Q44%22%3E%3C/div%3E%3C/button%3E%3C/header%3E%3Cmain%20class=%22Article_article__Njabh%22%3E%3Csection%20class=%22Article_hero__X7BaQ%22%3E%3Cdiv%20class=%22container%22%3E%3Cdiv%20class=%22ArticleBreadcrumbs_breadcrumbs__1jiWc%22%3E%3Ca%20class=%22ArticleBreadcrumbs_breadcrumb__hwLTB%22%20href=%22/blog%22%3EBlog%3C/a%3E%3Csvg%20class=%22ArticleBreadcrumbs_arrowIcon__Y2Cea%22%3E%3Cuse%20href=%22/media/angle_down.svg%23angleDown%22%20xlink:href=%22/media/angle_down.svg%23angleDown%22%3E%3C/use%3E%3C/svg%3E%3Ca%20class=%22ArticleBreadcrumbs_breadcrumb__hwLTB%22%20href=%22/blog/category/reviews%22%3ETechs%E2%80%99%20reviews%3C/a%3E%3Csvg%20class=%22ArticleBreadcrumbs_arrowIcon__Y2Cea%22%3E%3Cuse%20href=%22/media/angle_down.svg%23angleDown%22%20xlink:href=%22/media/angle_down.svg%23angleDown%22%3E%3C/use%3E%3C/svg%3E%3Ca%20class=%22ArticleBreadcrumbs_breadcrumb__hwLTB%20ArticleBreadcrumbs_active__YMqNN%22%20href=%22/blog/named-entity-recognition-implementation-tips%22%3ENamed%20Entity%20Recognition:%20Mechanism,%20Methods,%20Use%20Cases,%20and%20Implementation%20Tips%3C/a%3E%3Csvg%20class=%22ArticleBreadcrumbs_arrowIcon__Y2Cea%22%3E%3Cuse%20href=%22/media/angle_down.svg%23angleDown%22%20xlink:href=%22/media/angle_down.svg%23angleDown%22%3E%3C/use%3E%3C/svg%3E%3C/div%3E%3Cdiv%20class=%22Article_titleBlock__kvIpz%22%3E%3Ch1%20class=%22Article_title__VtXM_%22%3E%3Ca%20type=%22button%22%20class=%22Button_button__nbDXA%20Article_titleButton__6F_vg%20Button_outlined__mOu3b%20Button_withIcon__JksZi%20Button_withIcon_left__zz_uA%22%20href=%22/blog%22%3EAll%3Cdiv%20class=%22Button_icon__BGcBT%22%20style=%22width:24px;height:24px%22%3E%3Csvg%3E%3Cuse%20xlink:href=%22/media/arrow-left-bold.svg%23arrowLeft%22%20href=%22/media/arrow-left-bold.svg%23arrowLeft%22%3E%3C/use%3E%3C/svg%3E%3C/div%3E%3C/a%3E%20%3Cspan%3ENamed%20Entity%20Recognition:%20Mechanism,%20Methods,%20Use%20Cases,%20and%20Implementation%20Tips%3C/span%3E%3C/h1%3E%3C/div%3E%3Cdiv%20class=%22Article_articleDetails__Tjv1Q%22%3E%3Cp%20class=%22Article_articleInfo__N5Aar%22%3E%3Cspan%20class=%22Article_articleInfo__updated__3Jpb8%22%3EUpdated:%3C/span%3E%3Cspan%20class=%22Article_articleInfo__date__ul54n%22%3EApril%2028,%202025%3C/span%3E%3Cspan%3E15%20min%20read%3C/span%3E%3C/p%3E%3Cdiv%20class=%22Article_authorBlock__ipWmC%22%3E%3Cdiv%20class=%22AuthorCard_author__6xxtE%22%3E%3Ca%20class=%22AuthorCard_author__avatar__nH9od%22%20style=%22width:48px;height:48px%22%20href=%22/blog/author/Max%22%3E%3Cimg%20alt=%22Max%20Tatarchenko%22%20loading=%22lazy%22%20decoding=%22async%22%20data-nimg=%22fill%22%20style=%22position:absolute;height:100%25;width:100%25;left:0;top:0;right:0;bottom:0;color:transparent;background-size:cover;background-position:50%25%2050%25;background-repeat:no-repeat;background-image:url(&quot;data:image/svg+xml;charset=utf-8,%253Csvg%20xmlns=&%23x27;http://www.w3.org/2000/svg&%23x27;%20%253E%253Cfilter%20id=&%23x27;b&%23x27;%20color-interpolation-filters=&%23x27;sRGB&%23x27;%253E%253CfeGaussianBlur%20stdDeviation=&%23x27;20&%23x27;/%253E%253CfeColorMatrix%20values=&%23x27;1%200%200%200%200%200%201%200%200%200%200%200%201%200%200%200%200%200%20100%20-1&%23x27;%20result=&%23x27;s&%23x27;/%253E%253CfeFlood%20x=&%23x27;0&%23x27;%20y=&%23x27;0&%23x27;%20width=&%23x27;100%2525&%23x27;%20height=&%23x27;100%2525&%23x27;/%253E%253CfeComposite%20operator=&%23x27;out&%23x27;%20in=&%23x27;s&%23x27;/%253E%253CfeComposite%20in2=&%23x27;SourceGraphic&%23x27;/%253E%253CfeGaussianBlur%20stdDeviation=&%23x27;20&%23x27;/%253E%253C/filter%253E%253Cimage%20width=&%23x27;100%2525&%23x27;%20height=&%23x27;100%2525&%23x27;%20x=&%23x27;0&%23x27;%20y=&%23x27;0&%23x27;%20preserveAspectRatio=&%23x27;none&%23x27;%20style=&%23x27;filter:%20url(%2523b);&%23x27;%20href=&%23x27;data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEASABIAAD/2wBDAAUDBAQEAwUEBAQFBQUGBwwIBwcHBw8LCwkMEQ8SEhEPERETFhwXExQaFRERGCEYGh0dHx8fExciJCIeJBweHx7/2wBDAQUFBQcGBw4ICA4eFBEUHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh7/wAARCAAKAAoDAREAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAABgQH/8QAIBAAAgIBAwUAAAAAAAAAAAAAAQIDEQASEyEEFEFhof/EABYBAQEBAAAAAAAAAAAAAAAAAAIBA//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oADAMBAAIRAxEAPwDXJJITFvqSgdLbULqvPzLUg5LKjSue2ha2JsR8HFUVxs2vp11GtscXmZDk7MJ5ACQAxoX7xC//2Q==&%23x27;/%253E%253C/svg%253E&quot;)%22%20sizes=%22100vw%22%20srcSet=%22/_next/image?url=https%253A%252F%252Fsapientpro.fra1.digitaloceanspaces.com%252Fimage_29_1fa9833b8d.webp&amp;w=640&amp;q=75%20640w,%20/_next/image?url=https%253A%252F%252Fsapientpro.fra1.digitaloceanspaces.com%252Fimage_29_1fa9833b8d.webp&amp;w=750&amp;q=75%20750w,%20/_next/image?url=https%253A%252F%252Fsapientpro.fra1.digitaloceanspaces.com%252Fimage_29_1fa9833b8d.webp&amp;w=828&amp;q=75%20828w,%20/_next/image?url=https%253A%252F%252Fsapientpro.fra1.digitaloceanspaces.com%252Fimage_29_1fa9833b8d.webp&amp;w=1080&amp;q=75%201080w,%20/_next/image?url=https%253A%252F%252Fsapientpro.fra1.digitaloceanspaces.com%252Fimage_29_1fa9833b8d.webp&amp;w=1200&amp;q=75%201200w,%20/_next/image?url=https%253A%252F%252Fsapientpro.fra1.digitaloceanspaces.com%252Fimage_29_1fa9833b8d.webp&amp;w=1920&amp;q=75%201920w,%20/_next/image?url=https%253A%252F%252Fsapientpro.fra1.digitaloceanspaces.com%252Fimage_29_1fa9833b8d.webp&amp;w=2048&amp;q=75%202048w,%20/_next/image?url=https%253A%252F%252Fsapientpro.fra1.digitaloceanspaces.com%252Fimage_29_1fa9833b8d.webp&amp;w=3840&amp;q=75%203840w%22%20src=%22/_next/image?url=https%253A%252F%252Fsapientpro.fra1.digitaloceanspaces.com%252Fimage_29_1fa9833b8d.webp&amp;w=3840&amp;q=75%22/%3E%3C/a%3E%3Cdiv%20class=%22AuthorCard_author__content__p18vL%22%3E%3Ca%20class=%22AuthorCard_author__name__6f1Iq%22%20href=%22/blog/author/Max%22%3EMax%20Tatarchenko%3C/a%3E%3Cp%20class=%22AuthorCard_author__info__Sb3ke%22%3ECTO%3C/p%3E%3C/div%3E%3C/div%3E%3C/div%3E%3C/div%3E%3Cdiv%20class=%22Article_firstEllipse__Z1OxB%22%3E%3C/div%3E%3Cdiv%20class=%22Article_secondEllipse__0bCgJ%22%3E%3C/div%3E%3C/div%3E%3C/section%3E%3Cdiv%20class=%22container%22%3E%3Csection%20class=%22Article_main__v_hZi%22%3E%3Caside%20class=%22Article_aside__1zKJ2%22%3E%3Cdiv%20class=%22Article_asideSticky__SjNnf%22%3E%3Cnav%20class=%22Article_articleMenuWrapper__72zxu%22%3E%3Cdiv%20class=%22Article_articleMenu__03hi8%22%3E%3Cbutton%20type=%22button%22%20class=%22Article_articleAnchor__1HoGo%22%3E%3Cspan%20class=%22Article_sectionNumber__PX9Wo%22%3E1%3C/span%3E%3Cp%3EIntro%3C/p%3E%3C/button%3E%3Cbutton%20type=%22button%22%20class=%22Article_articleAnchor__1HoGo%22%3E%3Cspan%20class=%22Article_sectionNumber__PX9Wo%22%3E2%3C/span%3E%3Cp%3EWhat%20Is%20Named%20Entity%20Recognition?%3C/p%3E%3C/button%3E%3Cbutton%20type=%22button%22%20class=%22Article_articleAnchor__1HoGo%22%3E%3Cspan%20class=%22Article_sectionNumber__PX9Wo%22%3E3%3C/span%3E%3Cp%3ENER%20Benefits%20&amp;%20Challenges?%3C/p%3E%3C/button%3E%3Cbutton%20type=%22button%22%20class=%22Article_articleAnchor__1HoGo%22%3E%3Cspan%20class=%22Article_sectionNumber__PX9Wo%22%3E4%3C/span%3E%3Cp%3EHow%20Named-entity%20Recognition%20Works?%3C/p%3E%3C/button%3E%3Cbutton%20type=%22button%22%20class=%22Article_articleAnchor__1HoGo%22%3E%3Cspan%20class=%22Article_sectionNumber__PX9Wo%22%3E5%3C/span%3E%3Cp%3ENamed%20Entity%20Recognition%20Techniques%3C/p%3E%3C/button%3E%3Cbutton%20type=%22button%22%20class=%22Article_articleAnchor__1HoGo%22%3E%3Cspan%20class=%22Article_sectionNumber__PX9Wo%22%3E6%3C/span%3E%3Cp%3ENER%20Methodologies%3C/p%3E%3C/button%3E%3Cbutton%20type=%22button%22%20class=%22Article_articleAnchor__1HoGo%22%3E%3Cspan%20class=%22Article_sectionNumber__PX9Wo%22%3E7%3C/span%3E%3Cp%3EUse%20Cases%20for%20Named%20Entity%20Recognition%3C/p%3E%3C/button%3E%3Cbutton%20type=%22button%22%20class=%22Article_articleAnchor__1HoGo%22%3E%3Cspan%20class=%22Article_sectionNumber__PX9Wo%22%3E8%3C/span%3E%3Cp%3ENER%20Examples%3C/p%3E%3C/button%3E%3Cbutton%20type=%22button%22%20class=%22Article_articleAnchor__1HoGo%22%3E%3Cspan%20class=%22Article_sectionNumber__PX9Wo%22%3E9%3C/span%3E%3Cp%3EHow%20to%20Implement%20Named%20Entity%20Recognition%20%3C/p%3E%3C/button%3E%3Cbutton%20type=%22button%22%20class=%22Article_articleAnchor__1HoGo%22%3E%3Cspan%20class=%22Article_sectionNumber__PX9Wo%22%3E10%3C/span%3E%3Cp%3ERecent%20Trends%20in%20Named%20Entity%20Recognition%20(NER)%20and%20Its%20Future%3C/p%3E%3C/button%3E%3Cbutton%20type=%22button%22%20class=%22Article_articleAnchor__1HoGo%22%3E%3Cspan%20class=%22Article_sectionNumber__PX9Wo%22%3E11%3C/span%3E%3Cp%3ESummary%3C/p%3E%3C/button%3E%3C/div%3E%3C/nav%3E%3Cdiv%20class=%22Article_socialBar__JZfBi%22%3E%3Cp%20class=%22Article_socialBar__title__ohqqE%22%3EShare%20this%20article%3C/p%3E%3Cdiv%20class=%22Article_socialBar__content__BL8wn%22%3E%3Ca%20href=%22https://twitter.com/intent/tweet?url=https://sapient.pro/blog/named-entity-recognition-implementation-tips&amp;mini=true&amp;text=Named%20Entity%20Recognition:%20Mechanism,%20Methods,%20Use%20Cases,%20and%20Implementation%20Tips%22%20class=%22Article_social__tk25G%22%20target=%22_blank%22%20aria-label=%22Twitter%22%20rel=%22noreferrer%22%3E%3Csvg%3E%3Cuse%20xlink:href=%22/media/socials/twitter.svg%23twitterSVG%22%20href=%22/media/socials/twitter.svg%23twitterSVG%22%3E%3C/use%3E%3C/svg%3E%3C/a%3E%3Ca%20href=%22https://www.linkedin.com/shareArticle?url=https://sapient.pro/blog/named-entity-recognition-implementation-tips&amp;mini=true%22%20class=%22Article_social__tk25G%22%20target=%22_blank%22%20aria-label=%22LinkedIn%22%20rel=%22noreferrer%22%3E%3Csvg%3E%3Cuse%20xlink:href=%22/media/socials/linkedin.svg%23linkedinSVG%22%20href=%22/media/socials/linkedin.svg%23linkedinSVG%22%3E%3C/use%3E%3C/svg%3E%3C/a%3E%3Ca%20href=%22https://telegram.me/share/https://sapient.pro?url=https://sapient.pro/blog/named-entity-recognition-implementation-tips&amp;text=Named%20Entity%20Recognition:%20Mechanism,%20Methods,%20Use%20Cases,%20and%20Implementation%20Tips%22%20class=%22Article_social__tk25G%22%20target=%22_blank%22%20aria-label=%22Telegram%22%20rel=%22noreferrer%22%3E%3Csvg%3E%3Cuse%20xlink:href=%22/media/socials/telegram.svg%23telegramSVG%22%20href=%22/media/socials/telegram.svg%23telegramSVG%22%3E%3C/use%3E%3C/svg%3E%3C/a%3E%3Ca%20href=%22https://www.facebook.com/sharer/sharer.php?u=https://sapient.pro/blog/named-entity-recognition-implementation-tips&amp;quote=Named%20Entity%20Recognition:%20Mechanism,%20Methods,%20Use%20Cases,%20and%20Implementation%20Tips%22%20class=%22Article_social__tk25G%22%20target=%22_blank%22%20aria-label=%22Facebook%22%20rel=%22noreferrer%22%3E%3Csvg%3E%3Cuse%20xlink:href=%22/media/socials/facebook.svg%23facebookSVG%22%20href=%22/media/socials/facebook.svg%23facebookSVG%22%3E%3C/use%3E%3C/svg%3E%3C/a%3E%3C/div%3E%3C/div%3E%3C/div%3E%3C/aside%3E%3Cdiv%20class=%22Article_mainContent__eMCzN%22%3E%3Cdiv%20class=%22Article_articleContent__yMQdW%22%3E%3Cdiv%20class=%22Article_contentStyles__FOoh1%20Article_contentStyles__withoutPaddingTopForFirstH2__LejJ1%22%3E%3Cp%3EBusinesses%20are%20all%20about%20automation%20now,%20using%20chatbots%20and%20voice%20assistants%20to%20do%20tasks%20that%20previously%20required%20people.%20Machine%20learning%20and%20natural%20language%20processing%20(NLP)%20have%20become%20essential.%20For%20example,%C2%A0%3Ca%20href=%22https://technologymagazine.com/top10/top-10-companies-advancing-natural-language-processing%22%20target=%22_blank%22%20rel=%22noopener%20noreferrer%22%3EGoogle%20Cloud&%23x27;s%20NLP%20platform%3C/a%3E%20uses%20Google%20machine%20learning%20to%20help%20users%20understand%20and%20gain%20insights%20from%20unstructured%20texts.%C2%A0%3C/p%3E%3Cp%3EAccording%20to%20a%3Ca%20href=%22https://www.marketsandmarkets.com/Market-Reports/natural-language-processing-nlp-825.html%22%20target=%22_blank%22%20rel=%22noopener%20noreferrer%22%3E%C2%A0MarketsandMarkets%3C/a%3E%C2%A0report,%20the%20NLP%20market%20is%20expected%20to%20reach%20$68.1%20billion%20by%202028,%20with%C2%A0Named%20Entity%20Recognition%20(NER)%20being%20a%20key%20driver%20of%20this%20growth.%20Since%20about%3Ca%20href=%22https://mitsloan.mit.edu/ideas-made-to-matter/tapping-power-unstructured-data%22%20target=%22_blank%22%20rel=%22noopener%20noreferrer%22%3E%C2%A080%E2%80%9390%25%3C/a%3E%C2%A0of%20all%20data%20is%20unorganized,%20tools%20like%20NER%20are%20necessary%20for%20finding%20meaningful%20information.%3C/p%3E%3C/div%3E%3Cdiv%20class=%22Article_contentStyles__FOoh1%22%20data-id=%221798%22%3E%3Ch2%3EIntro%3C/h2%3E%3Cdiv%20class=%22%22%3E%3Cp%3ENER%20is%20popular%20because%20it%20can%20automatically%20find%20and%20categorize%20key%20information%20from%20large%20pieces%20of%20text.%20This%20allows%20organizations%20to%20easily%20extract%20needed%20data%20from%20customer%20interactions,%20financial%20reports,%20legal%20contracts,%20social%20media,%20etc.%3C/p%3E%3Cp%3EThis%20guide%20provides%20all%20the%20information%20about%20Named%20Entity%20Recognition.%20You'll%20learn%20how%20NER%20works,%20what&nbsp;named%20entity%20recognition%20custom%20entities%20are,%20discover%20its%20use%20cases,%20and%20learn&nbsp;how%20to%20build%20named%20entity%20recognition%20model.%3C/p%3E%3C/div%3E%3C/div%3E%3Cdiv%20class=%22Article_contentStyles__FOoh1%22%20data-id=%221799%22%3E%3Ch2%3EWhat%20Is%20Named%20Entity%20Recognition?%3C/h2%3E%3Cdiv%20class=%22%22%3E%3Cp%3ENamed%20entity%20recognition%20means&nbsp;a%20technique%20in%20natural%20language%20processing%20used%20to%20recognize%20specific%20types%20of%20entities%20in%20a%20text,%20like%20names,%20places,%20dates,%20and%20organizations.&nbsp;Named%20entity%20recognition%20history%20began%20in%201996.%20NER%20mostly%20used%20rule-based%20methods%20and%20ontologies%20at%20that%20time.%20By%202007,%20NER%20models%20started%20to%20adopt%20machine%20learning%20to%20engineer%20features.&nbsp;%3C/p%3E%3Cp%3E&nbsp;%3C/p%3E%3Cp%3EImplementation%20of%20deep%20learning%20has%20greatly%20improved%20NER.%20Deep%20learning&nbsp;models%20for%20named%20entity%20recognition&nbsp;are%20more%20flexible%20and%20can%20manage%20different%20domains%20and%20new%20data%20by%20using%20characters,%20sub-words,%20and%20word%20embeddings.%3C/p%3E%3Cp%3E&nbsp;%3C/p%3E%3Cp%3EMachines%20can%20process%20large%20amounts%20of%20text%20and%20extract%20key%20information%20in%20organized&nbsp;named%20entity%20recognition%20categories.%20By%20identifying%20specific%20entities%20within%20the%20text,%20NER%20changes%20how%20we%20manage%20and%20use%20written%20information.%3C/p%3E%3C/div%3E%3Cfigure%20class=%22Article_imageBlock__JlKMT%22%3E%3Cdiv%20class=%22Article_image__QmZ2p%22%3E%3Cimg%20alt=%22NER%20on%20New%20York%20Times%20Dataset%22%20loading=%22lazy%22%20width=%221296%22%20height=%221394%22%20decoding=%22async%22%20data-nimg=%221%22%20style=%22color:transparent;background-size:cover;background-position:50%25%2050%25;background-repeat:no-repeat;background-image:url(&quot;data:image/svg+xml;charset=utf-8,%253Csvg%20xmlns=&%23x27;http://www.w3.org/2000/svg&%23x27;%20viewBox=&%23x27;0%200%201296%201394&%23x27;%253E%253Cfilter%20id=&%23x27;b&%23x27;%20color-interpolation-filters=&%23x27;sRGB&%23x27;%253E%253CfeGaussianBlur%20stdDeviation=&%23x27;20&%23x27;/%253E%253CfeColorMatrix%20values=&%23x27;1%200%200%200%200%200%201%200%200%200%200%200%201%200%200%200%200%200%20100%20-1&%23x27;%20result=&%23x27;s&%23x27;/%253E%253CfeFlood%20x=&%23x27;0&%23x27;%20y=&%23x27;0&%23x27;%20width=&%23x27;100%2525&%23x27;%20height=&%23x27;100%2525&%23x27;/%253E%253CfeComposite%20operator=&%23x27;out&%23x27;%20in=&%23x27;s&%23x27;/%253E%253CfeComposite%20in2=&%23x27;SourceGraphic&%23x27;/%253E%253CfeGaussianBlur%20stdDeviation=&%23x27;20&%23x27;/%253E%253C/filter%253E%253Cimage%20width=&%23x27;100%2525&%23x27;%20height=&%23x27;100%2525&%23x27;%20x=&%23x27;0&%23x27;%20y=&%23x27;0&%23x27;%20preserveAspectRatio=&%23x27;none&%23x27;%20style=&%23x27;filter:%20url(%2523b);&%23x27;%20href=&%23x27;data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEASABIAAD/2wBDAAUDBAQEAwUEBAQFBQUGBwwIBwcHBw8LCwkMEQ8SEhEPERETFhwXExQaFRERGCEYGh0dHx8fExciJCIeJBweHx7/2wBDAQUFBQcGBw4ICA4eFBEUHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh7/wAARCAAKAAoDAREAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAABgQH/8QAIBAAAgIBAwUAAAAAAAAAAAAAAQIDEQASEyEEFEFhof/EABYBAQEBAAAAAAAAAAAAAAAAAAIBA//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oADAMBAAIRAxEAPwDXJJITFvqSgdLbULqvPzLUg5LKjSue2ha2JsR8HFUVxs2vp11GtscXmZDk7MJ5ACQAxoX7xC//2Q==&%23x27;/%253E%253C/svg%253E&quot;)%22%20srcSet=%22/_next/image?url=https%253A%252F%252Fsapientpro.fra1.digitaloceanspaces.com%252FDark_1_727de2f7a4.webp&amp;w=1920&amp;q=75%201x,%20/_next/image?url=https%253A%252F%252Fsapientpro.fra1.digitaloceanspaces.com%252FDark_1_727de2f7a4.webp&amp;w=3840&amp;q=75%202x%22%20src=%22/_next/image?url=https%253A%252F%252Fsapientpro.fra1.digitaloceanspaces.com%252FDark_1_727de2f7a4.webp&amp;w=3840&amp;q=75%22/%3E%3C/div%3E%3Cfigcaption%3ENER%20on%20New%20York%20Times%20Dataset%3C/figcaption%3E%3C/figure%3E%3C/div%3E%3Cdiv%20class=%22Article_contentStyles__FOoh1%22%20data-id=%221800%22%3E%3Ch2%3ENER%20Benefits%20&amp;%20Challenges?%3C/h2%3E%3Cdiv%20class=%22%22%3E%3Cp%3ENamed%20entity%20recognition%20has%20several%20great%20benefits,%20but%20also%20some%20limitations.%20We%E2%80%99ll%20explain%20both%20to%20you.%3C/p%3E%3Ch3%3EAdvantages%20of%20Using%20NER%3C/h3%3E%3Cp%3EThe%20main%20advantage%20of%20NER%20is%20that%20it%20helps%20us%20find%20important%20details%20in%20large%20amounts%20of%20textual%20data,%20like%20articles,%20social%20media%20posts,%20websites,%20and%20research%20papers.%20Let%E2%80%99s%20check%20out%20some%20more%20benefits%20of%20NER:%3C/p%3E%3Cul%3E%3Cli%3E%3Cstrong%3EEnhanced%20user%20experience%3C/strong%3E:%20NER%20improves%20customer%20experience%20by%20providing%20better%20search%20results%20and%20personalized%20recommendations.%3C/li%3E%3Cli%3E%3Cstrong%3ESimple%20analysis%20of%20data%20and%20trends%3C/strong%3E:%20NER%20makes%20it%20easier%20to%20analyze%20data%20to%20identify%20tendencies.&nbsp;&nbsp;%3C/li%3E%3Cli%3E%3Cstrong%3EAutomated%20workflows%3C/strong%3E:&nbsp;NER%20automates%20processes,%20which%20helps%20save%20our%20time%20and%20resources.%3C/li%3E%3C/ul%3E%3Ch3%3EAny%20Limitations%20of%20NER?%3C/h3%3E%3Cp%3ENow%20let's%20look%20at%20some&nbsp;named%20entity%20recognition%20challenges:%3C/p%3E%3Cul%3E%3Cli%3E%3Cstrong%3EContext%20misunderstanding%3C/strong%3E:&nbsp;algorithms%20often%20struggle%20to%20understand%20context%20because%20words%20get%20meaning%20from%20the%20surrounding%20text.%20For%20example,%20the%20word%20%22Bat%22%20can%20mean%20a%20flying%20animal%20or%20a%20baseball%20tool%20(depending%20on%20the%20context).%3C/li%3E%3Cli%3E%3Cstrong%3ELanguage%20variation%3C/strong%3E:&nbsp;human%20language%20includes%20slang,%20dialects,%20and%20regional%20differences,%20which%20can%20make%20it%20harder%20to%20understand%20words%20that%20are%20common%20in%20one%20place%20but%20not%20in%20another.%3C/li%3E%3Cli%3E%3Cstrong%3EData%20sparsity%3C/strong%3E:%20machine%20learning%20models%20need%20a%20lot%20of%20labeled%20data%20to%20identify%20entities.%20This%20can%20be%20difficult%20to%20find,%20especially%20for%20rare%20languages%20or%20specialized%20areas.%3C/li%3E%3C/ul%3E%3C/div%3E%3C/div%3E%3Cdiv%20class=%22Article_contentStyles__FOoh1%22%20data-id=%221801%22%3E%3Ch2%3EHow%20Named-entity%20Recognition%20Works?%3C/h2%3E%3Cdiv%20class=%22%22%3E%3Cp%3ENamed&nbsp;Entity%20Recognition&nbsp;%3Ca%20href=%22https://sapient.pro/natural-language-processing-services%22%20target=%22_blank%22%20rel=%22noopener%20noreferrer%22%3ENLP&nbsp;%3C/a%3Euses%20unique%20algorithms%20with%20grammar%20rules%20and%20statistical%20models%20to%20find%20and%20tag%20names%20in%20text.%20It%20identifies%20categories%20like%20people,%20locations,%20dates,%20percentages,&nbsp;%20organizations,%20and%20currency%20amounts.%20These%20categories%20often%20use%20abbreviations,%20such%20as%20LOC%20for%20location,%20PER%20for%20person,%20and%20ORG%20for%20organization.%3C/p%3E%3Cp%3EOnce%20the&nbsp;named%20entity%20recognition%20best%20model&nbsp;can%20work%20with%20labeled%20text%20data,%20it%20automatically%20analyzes%20new%20text,%20identifies%20named%20entities,%20and%20sorts%20them%20into%20categories.&nbsp;%3C/p%3E%3Cp%3EAfter%20identifying%20the%20information,%20a%20tool%20collects%20details%20about%20these%20entities%20and%20creates%20a%20machine-readable%20document.%20Other%20tools%20can%20then%20use%20this%20document%20to%20extract%20additional%20information.%3C/p%3E%3C/div%3E%3Cfigure%20class=%22Article_imageBlock__JlKMT%22%3E%3Cdiv%20class=%22Article_image__QmZ2p%22%3E%3Cimg%20alt=%22article%20image%22%20loading=%22lazy%22%20width=%221296%22%20height=%221216%22%20decoding=%22async%22%20data-nimg=%221%22%20style=%22color:transparent;background-size:cover;background-position:50%25%2050%25;background-repeat:no-repeat;background-image:url(&quot;data:image/svg+xml;charset=utf-8,%253Csvg%20xmlns=&%23x27;http://www.w3.org/2000/svg&%23x27;%20viewBox=&%23x27;0%200%201296%201216&%23x27;%253E%253Cfilter%20id=&%23x27;b&%23x27;%20color-interpolation-filters=&%23x27;sRGB&%23x27;%253E%253CfeGaussianBlur%20stdDeviation=&%23x27;20&%23x27;/%253E%253CfeColorMatrix%20values=&%23x27;1%200%200%200%200%200%201%200%200%200%200%200%201%200%200%200%200%200%20100%20-1&%23x27;%20result=&%23x27;s&%23x27;/%253E%253CfeFlood%20x=&%23x27;0&%23x27;%20y=&%23x27;0&%23x27;%20width=&%23x27;100%2525&%23x27;%20height=&%23x27;100%2525&%23x27;/%253E%253CfeComposite%20operator=&%23x27;out&%23x27;%20in=&%23x27;s&%23x27;/%253E%253CfeComposite%20in2=&%23x27;SourceGraphic&%23x27;/%253E%253CfeGaussianBlur%20stdDeviation=&%23x27;20&%23x27;/%253E%253C/filter%253E%253Cimage%20width=&%23x27;100%2525&%23x27;%20height=&%23x27;100%2525&%23x27;%20x=&%23x27;0&%23x27;%20y=&%23x27;0&%23x27;%20preserveAspectRatio=&%23x27;none&%23x27;%20style=&%23x27;filter:%20url(%2523b);&%23x27;%20href=&%23x27;data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEASABIAAD/2wBDAAUDBAQEAwUEBAQFBQUGBwwIBwcHBw8LCwkMEQ8SEhEPERETFhwXExQaFRERGCEYGh0dHx8fExciJCIeJBweHx7/2wBDAQUFBQcGBw4ICA4eFBEUHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh7/wAARCAAKAAoDAREAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAABgQH/8QAIBAAAgIBAwUAAAAAAAAAAAAAAQIDEQASEyEEFEFhof/EABYBAQEBAAAAAAAAAAAAAAAAAAIBA//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oADAMBAAIRAxEAPwDXJJITFvqSgdLbULqvPzLUg5LKjSue2ha2JsR8HFUVxs2vp11GtscXmZDk7MJ5ACQAxoX7xC//2Q==&%23x27;/%253E%253C/svg%253E&quot;)%22%20srcSet=%22/_next/image?url=https%253A%252F%252Fsapientpro.fra1.digitaloceanspaces.com%252FDark_2_ba6b1ca0e0.webp&amp;w=1920&amp;q=75%201x,%20/_next/image?url=https%253A%252F%252Fsapientpro.fra1.digitaloceanspaces.com%252FDark_2_ba6b1ca0e0.webp&amp;w=3840&amp;q=75%202x%22%20src=%22/_next/image?url=https%253A%252F%252Fsapientpro.fra1.digitaloceanspaces.com%252FDark_2_ba6b1ca0e0.webp&amp;w=3840&amp;q=75%22/%3E%3C/div%3E%3C/figure%3E%3C/div%3E%3Cdiv%20class=%22Article_contentStyles__FOoh1%22%20data-id=%221802%22%3E%3Ch2%3ENamed%20Entity%20Recognition%20Techniques%3C/h2%3E%3Cdiv%20class=%22%22%3E%3Cp%3ETo%20develop%20the%20best%20model%20for%20named%20entity%20recognition,%20the%20text%20must%20go%20through%20various%20steps%20like%20tokenization%20and%20tagging.%20In%20tagging,%20each%20word%20in%20a%20sentence%20is%20labeled%20with%20tags%20like%20%E2%80%9CPerson%E2%80%9D%20or%20%E2%80%9CLocation%E2%80%9D.&nbsp;%20We%E2%80%99ll%20explain%20what%20techniques%20NER%20uses:&nbsp;%3C/p%3E%3Ch3%3EIO%20Tagging%3C/h3%3E%3Cp%3EIn%20this%20simple%20tagging%20method,%20each%20word%20in%20a%20sentence%20is%20tagged%20as%20%E2%80%9Cinside%E2%80%9D%20(I)%20if%20it's%20part%20of%20an%20entity%20or%20%E2%80%9Coutside%E2%80%9D%20(O)%20if%20it's%20not.%3C/p%3E%3Cp%3EIn%20the%20sentence%20%E2%80%9CSara%20is%20going%20to%20London,%E2%80%9D%20the%20words%20%E2%80%9CSara%E2%80%9D%20and%20%E2%80%9CLondon%E2%80%9D%20are%20tagged%20as%20entities%20(I%20tag),%20while%20the%20words%20%22is,%22%20%22going,%22%20and%20%22to%22%20are%20not%20entities%20(O%20tag).%3C/p%3E%3Cp%3EThis%20method%20has%20limitations,%20especially%20with%20tagging%20consecutive%20entities%20of%20the%20same%20type.%3C/p%3E%3Ch3%3EBIO%20/%20IOB%20Tagging%3C/h3%3E%3Cp%3EIOB%20is%20a%20widely%20used%20tagging%20method.%20This%20system%20labels%20each%20word%20to%20show%20if%20it%20is%20at%20the%20beginning%20(B)%20of%20a%20named%20entity,%20inside%20(I)%20of%20a%20named%20entity,%20or%20outside%20(O)%20of%20any%20named%20entity.%3C/p%3E%3Cp%3EIn%20the%20sentence%20%E2%80%9CSara%20is%20going%20to%20London,%E2%80%9D%20%E2%80%9CSara%E2%80%9D%20is%20marked%20as%20%E2%80%9CB-PER%E2%80%9D%20to%20show%20it's%20the%20start%20of%20a%20person's%20name,%20while%20%E2%80%9CLondon%E2%80%9D%20is%20tagged%20as%20%E2%80%9CI-LOC%E2%80%9D%20because%20it's%20a%20place.%3C/p%3E%3Ch3%3EIOE%20Tagging%3C/h3%3E%3Cp%3EThis%20approach%20is%20similar%20to%20IOB,%20but%20it%20uses%20an&nbsp;E%20tag&nbsp;to%20mark%20the%20end%20of%20an%20entity%20instead%20of%20the%20beginning.%3C/p%3E%3Ch3%3EBILOU%20Tagging%3C/h3%3E%3Cp%3EBILOU%20is%20a%20more%20detailed%20version%20of%20the%20BIO%20labeling%20system%20that%20detects%20entities.%20It%20includes%20two%20extra%20labels,%20Last%20(L)%20and%20Unit%20(U),%20to%20improve&nbsp;ner%20metrics%20accuracy,%20especially%20with%20longer%20entities.%3C/p%3E%3Cp%3EIn%20a%20sentence%20like%20%E2%80%9CSteve%20Jobs%20was%20born%20in%20San%20Francisco,%E2%80%9D%20BILOU%20tagging%20would%20be:%20Steve%20%E2%80%94&nbsp;&nbsp;B-PER%20(beginning%20of%20a%20Person%20entity),%20Jobs%20%E2%80%94&nbsp;&nbsp;L-PER%20(last%20token%20of%20a%20Person%20entity),%20was%20%E2%80%94&nbsp;&nbsp;O%20(outside%20any%20named%20entity),%20born%20%E2%80%94&nbsp;&nbsp;O,%20in%20%E2%80%94&nbsp;&nbsp;O,%20San%20Francisco%20%E2%80%94&nbsp;&nbsp;U-LOC%20(Location).%3C/p%3E%3Ch3%3EConditional%20Random%20Fields%20(CRFs)%3C/h3%3E%3Cp%3ECRFs%20are%20statistical%20tools%20that%20help%20make%20structured%20predictions.%20They%20consider%20the%20context%20and%20relationships%20between%20nearby%20tokens.%20CRFs%20are%20quite%20practical%20for%20custom%20named%20entity%20recognition,%20which%20involve%20labeling%20sequences.%3C/p%3E%3Cp%3EIn%20the%20sentence%20%E2%80%9CSamsung%20announced%20the%20new%20Galaxy%20Buds%20in%20California,%E2%80%9D%20Samsung%20is%20marked%20as%20an%20organization%20(B-ORG),%20Galaxy%20Buds%20as%20a%20product%20(B-PROD),%20and%20California%20as%20a%20location%20(B-LOC).%20CRFs%20use%20the%20context%20and%20relationships%20between%20words%20to%20identify%20these%20distinctions.%3C/p%3E%3C/div%3E%3C/div%3E%3Cdiv%20class=%22Article_contentStyles__FOoh1%22%20data-id=%221803%22%3E%3Ch2%3ENER%20Methodologies%3C/h2%3E%3Cdiv%20class=%22%22%3E%3Cp%3ENamed%20entity%20recognition%20data%20augmentation%20uses%20different%20methodologies%20to%20help%20identify%20and%20classify%20names%20and%20other%20specific%20entities%20in%20large%20texts.%20Let's%20see%20what%20they%20are.%3C/p%3E%3Ch3%3ENamed%20Entity%20Recognition%20Methods%20Based%20on%20Rules%3C/h3%3E%3Cp%3ERule-based%20methods%20often%20use%20linguistic%20patterns,%20expressions,%20or%20dictionaries.%20They%20are%20effective%20in%20tasks%20like%20extracting%20standard%20medical%20terms%20from%20clinical%20notes.%20Yet,%20rule-based%20techniques%20can't%20handle%20a%20large&nbsp;named%20entity%20recognition%20dataset%20because%20they%20follow%20fixed%20rules.%3C/p%3E%3Ch3%3EStatistical%20Methods%3C/h3%3E%3Cp%3EStatistical%20methods,%20like&nbsp;%20Conditional%20Random%20Fields%20(CRF)%20and%20Hidden%20Markov%20Models%20(HMM),%20use%20probabilities%20learned%20from%20training%20data%20to%20indicate%20named%20entities.%20These%20methods%20work%20well%20with%20lots%20of%20labeled%20data%20because%20they%20can%20adapt%20to%20different%20types%20of%20text.&nbsp;%3C/p%3E%3Ch3%3EMachine%20Learning%20Methods&nbsp;%3C/h3%3E%3Cp%3E%3Ca%20href=%22https://sapient.pro/blog/best-programming-languages-for-machine-learning%22%3EMachine%20learning%20techniques&nbsp;%3C/a%3Euse%20algorithms%20like%20support%20vector%20machines%20and%20decision%20trees%20to%20learn%20from%20labeled%20data%20and%20predict%20specific%20named%20entities.%20These%20techniques%20help%20run%20large%20datasets%20and%20complex%20patterns.&nbsp;%3C/p%3E%3Ch3%3EDeep%20Learning%20Methods%3C/h3%3E%3Cp%3EDeep%20learning%20methods%20are%20the%20latest%20development%20that%20uses%20neural%20networks.%20Techniques%20like%20Recurrent%20Neural%20Networks%20(RNNs)%20and%20transformers%20are%20popular%20because%20they%20can%20handle%20long-term%20text%20patterns.%20These%20methods%20work%20great%20for%20big%20tasks%20with%20lots%20of%20training%20data,%20but%20they%20require%20a%20lot%20of%20computing%20power.%3C/p%3E%3Ch3%3EHybrid%20Methodologies%3C/h3%3E%3Cp%3ENo%20single%20method%20works%20for%20every%20situation%20in%20NER.%20So,%20this%20led%20to%20the%20development%20of%20hybrid%20methods.%20They%20use%20a%20mix%20of%20rules,%20stats,%20and%20machine%20learning%20to%20get%20the%20best%20of%20each.%20For%20example,%20rule-based%20methods%20can%20work%20with%20specific%20entities%20in%20a%20particular%20field,%20while%20machine%20learning%20or%20deep%20learning%20is%20better%20for%20identifying%20more%20general%20entities.%3C/p%3E%3C/div%3E%3C/div%3E%3Cdiv%20class=%22Article_contentStyles__FOoh1%22%20data-id=%221804%22%3E%3Ch2%3EUse%20Cases%20for%20Named%20Entity%20Recognition%3C/h2%3E%3Cdiv%20class=%22%22%3E%3Cp%3ENER%20has%20changed%20how%20different%20businesses%20and%20industries%20operate%20by%20efficiently%20processing%20large%20datasets.%20Here%20are%20some%20key&nbsp;named%20entity%20recognition%20use%20cases.%3C/p%3E%3Ch3%3ENews%20Search%3C/h3%3E%3Cp%3ENews%20companies%20create%20online%20content%20daily.%20NER%20helps%20automatically%20identify%20the%20who,%20what,%20when,%20where,%20and%20why%20in%20news%20and%20other%20articles.%20It%20highlights%20key%20details%20and%20helps%20understand%20the%20context%20better.&nbsp;%3C/p%3E%3Cp%3EIf%20you're%20searching%20for%20information%20about%20a%20celebrity%20or%20a%20particular%20event,%20NER%20can%20categorize%20articles%20based%20on%20the%20entities%20they%20mention.%20For%20example,%20if%20you%20want%20to%20find%20news%20about%20Mark%20Zuckerberg,%20an%20NER-powered%20platform%20can%20suggest%20articles%20that%20mention%20%E2%80%9CMark%20Zuckerberg%E2%80%9D%20or%20%E2%80%9CFacebook,%E2%80%9D%20even%20if%20these%20terms%20aren't%20in%20the%20headlines.%3C/p%3E%3Ch3%3EChatbots%3C/h3%3E%3Cp%3EChatbots%20use%20NER%20to%20understand%20user%20questions.%20By%20identifying%20key%20information,%20like%20names%20or%20places,%20they%20can%20accurately%20respond.%20For%20example,%20if%20a%20person%20asks%20a%20chatbot%20to%20find%20a%20fast%20casual%20restaurant%20in%20the%20City%20Hall%20Park,%20NER%20helps%20the%20chatbot%20identify%20entities%20such%20as%20the%20type%20of%20food%20(fast%20casual),%20the%20type%20of%20place%20(restaurants),%20and%20the%20location%20(City%20Hall%20Park).%3C/p%3E%3Ch3%3EScientific%20research%3C/h3%3E%3Cp%3EAn%20online%20journal%20or%20publication%20platform%20hosts%20millions%20of%20research%20papers%20and%20academic%20articles.%20With%20possibly%20hundreds%20of%20papers%20on%20the%20same%20topic,%20organizing%20this%20information%20can%20be%20quite%20challenging.%20For%20example,%20with%20about%20100,000%20publications%20on%20Machine%20Learning,%20tagging%20them%20by%20key%20topics%20makes%20it%20easy%20to%20find%20articles%20on%20how%20two-layer%20neural%20networks%20learn.%3C/p%3E%3Ch3%3ELegal%20documentation%3C/h3%3E%3Cp%3ELegal%20documents,%20especially%20contracts,%20provide%20important%20information%20about%20the%20parties%20and%20specifics%20like%20duration%20and%20scope.%20Tracking%20these%20details%20is%20a%20must%20to%20manage%20contracts%20and%20avoid%20accidental%20renewals.%20NER%20automatically%20finds%20key%20details%20like%20names%20and%20dates%20in%20long%20documents.%3C/p%3E%3Ch3%3EPharmaceuticals%20and%20healthcare%3C/h3%3E%3Cp%3EThe%20healthcare%20system%20has%20about%3Ca%20href=%22https://pmc.ncbi.nlm.nih.gov/articles/PMC6372467/%23:~:text=The%2520big%2520problem%2520of%2520healthcare,image%252C%2520signal%252C%2520etc.)%22%20target=%22_blank%22%20rel=%22noopener%20noreferrer%22%3E%2080%25%20of%20unstructured%20medical%20data.&nbsp;%3C/a%3ENER%20helps%20identify%20and%20organize%20medical%20information%20like%20treatments,%20drugs,%20diseases,%20tests,%20and%20medication%20names%20in%20different%20documents.%20For%20example,%20tagging%20promotional%20materials%20makes%20it%20easier%20for%20medical%20representatives%20to%20find%20and%20share%20the%20most%20relevant%20information%20with%20healthcare%20professionals.%3C/p%3E%3Ch3%3ECybersecurity%3C/h3%3E%3Cp%3ENER%20helps%20companies%20detect%20potential%20threats%20in%20network%20logs%20and%20other%20security%20data.%20The%20tool%20detects%20suspicious%20URLs,%20IP%20addresses,%20filenames,%20and%20usernames.%20This%20makes%20the%20network%20more%20secure%20and%20helps%20with%20safety%20investigations.%3C/p%3E%3Ch3%3EFinance%3C/h3%3E%3Cp%3EIn%20finance,%20NER%20helps%20identify%20trends%20and%20improve%20risk%20assessments.%20It%20not%20only%20manages%20financial%20data%20like%20loans%20and%20earnings%20reports,%20but%20also%20analyzes%20company%20mentions%20on%20social%20media.%20This%20also%20helps%20to%20track%20events%20that%20might%20affect%20stock%20prices.%3C/p%3E%3Ch3%3ESocial%20Media%3C/h3%3E%3Cp%3EBusinesses%20use%20NER%20in%20social%20media%20analysis%20because%20it%20helps%20them%20find%20mentions%20of%20their%20brands,%20products,%20or%20competitors%20in%20conversations.%20This%20information%20helps%20improve%20brand%20reputation%20and%20create%20more%20targeted%20marketing%20strategies.%3C/p%3E%3C/div%3E%3Cfigure%20class=%22Article_imageBlock__JlKMT%22%3E%3Cdiv%20class=%22Article_image__QmZ2p%22%3E%3Cimg%20alt=%22article%20image%22%20loading=%22lazy%22%20width=%221296%22%20height=%221386%22%20decoding=%22async%22%20data-nimg=%221%22%20style=%22color:transparent;background-size:cover;background-position:50%25%2050%25;background-repeat:no-repeat;background-image:url(&quot;data:image/svg+xml;charset=utf-8,%253Csvg%20xmlns=&%23x27;http://www.w3.org/2000/svg&%23x27;%20viewBox=&%23x27;0%200%201296%201386&%23x27;%253E%253Cfilter%20id=&%23x27;b&%23x27;%20color-interpolation-filters=&%23x27;sRGB&%23x27;%253E%253CfeGaussianBlur%20stdDeviation=&%23x27;20&%23x27;/%253E%253CfeColorMatrix%20values=&%23x27;1%200%200%200%200%200%201%200%200%200%200%200%201%200%200%200%200%200%20100%20-1&%23x27;%20result=&%23x27;s&%23x27;/%253E%253CfeFlood%20x=&%23x27;0&%23x27;%20y=&%23x27;0&%23x27;%20width=&%23x27;100%2525&%23x27;%20height=&%23x27;100%2525&%23x27;/%253E%253CfeComposite%20operator=&%23x27;out&%23x27;%20in=&%23x27;s&%23x27;/%253E%253CfeComposite%20in2=&%23x27;SourceGraphic&%23x27;/%253E%253CfeGaussianBlur%20stdDeviation=&%23x27;20&%23x27;/%253E%253C/filter%253E%253Cimage%20width=&%23x27;100%2525&%23x27;%20height=&%23x27;100%2525&%23x27;%20x=&%23x27;0&%23x27;%20y=&%23x27;0&%23x27;%20preserveAspectRatio=&%23x27;none&%23x27;%20style=&%23x27;filter:%20url(%2523b);&%23x27;%20href=&%23x27;data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEASABIAAD/2wBDAAUDBAQEAwUEBAQFBQUGBwwIBwcHBw8LCwkMEQ8SEhEPERETFhwXExQaFRERGCEYGh0dHx8fExciJCIeJBweHx7/2wBDAQUFBQcGBw4ICA4eFBEUHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh7/wAARCAAKAAoDAREAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAABgQH/8QAIBAAAgIBAwUAAAAAAAAAAAAAAQIDEQASEyEEFEFhof/EABYBAQEBAAAAAAAAAAAAAAAAAAIBA//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oADAMBAAIRAxEAPwDXJJITFvqSgdLbULqvPzLUg5LKjSue2ha2JsR8HFUVxs2vp11GtscXmZDk7MJ5ACQAxoX7xC//2Q==&%23x27;/%253E%253C/svg%253E&quot;)%22%20srcSet=%22/_next/image?url=https%253A%252F%252Fsapientpro.fra1.digitaloceanspaces.com%252FDark_3_bef01613af.webp&amp;w=1920&amp;q=75%201x,%20/_next/image?url=https%253A%252F%252Fsapientpro.fra1.digitaloceanspaces.com%252FDark_3_bef01613af.webp&amp;w=3840&amp;q=75%202x%22%20src=%22/_next/image?url=https%253A%252F%252Fsapientpro.fra1.digitaloceanspaces.com%252FDark_3_bef01613af.webp&amp;w=3840&amp;q=75%22/%3E%3C/div%3E%3C/figure%3E%3C/div%3E%3Cdiv%20class=%22Article_contentStyles__FOoh1%22%20data-id=%221805%22%3E%3Ch2%3ENER%20Examples%3C/h2%3E%3Cdiv%20class=%22%22%3E%3Cp%3ENamed%20Entity%20Recognition%20lets%20systems%20understand%20the%20context%20of%20words.%20For%20example,%20it%20allows%20a%20search%20engine%20to%20know%20if%20%E2%80%9CApple%E2%80%9D%20means%20the%20company%20or%20the%20fruit,%20depending%20on%20the%20sentence.%3C/p%3E%3Cp%3E%3Ca%20href=%22https://sapient.pro/ai-development-services%22%20target=%22_blank%22%20rel=%22noopener%20noreferrer%22%3EAI-driven%20solutions&nbsp;%3C/a%3Elike%20chatbots%20and%20virtual%20assistants%20also%20use%20NER%20to%20specify%20key%20entities%20in%20user%20questions,%20like%20names,%20places,%20or%20dates.%20So%20they%20can%20give%20more%20precise%20answers.%3C/p%3E%3Cp%3ETo%20understand%20how%20NER%20works,%20let's%20look%20at%20an%20example%20where%20it%20identifies%20entities%20like%20people,%20organizations,%20locations,%20and%20dates%20in%20a%20text.%20Consider%20this%20passage:%3C/p%3E%3Cp%3E%3Cstrong%3EMartin%20Eberhard%20and%20Marc%20Tarpenning&nbsp;%3C/strong%3E%3Ca%20href=%22https://www.forbes.com/sites/qai/2022/09/29/tesla-a-history-of-innovation-and-headaches/%22%20target=%22_blank%22%20rel=%22noopener%20noreferrer%22%3E%3Cstrong%3Efounded%20Tesla%20Motors%3C/strong%3E%3C/a%3E%3Cstrong%3E%20in%20July%202003,%20in%20San%20Carlos,%20California,%20U.S.%3C/strong%3E%3C/p%3E%3Cp%3EWith%20NER,%20we%20would%20identify%20these%20words:%3C/p%3E%3Cul%3E%3Cli%3E%3Cstrong%3EPerson%3C/strong%3E:%20Martin%20Eberhard,%20Marc%20Tarpenning;%3C/li%3E%3Cli%3E%3Cstrong%3EOrganization%3C/strong%3E:&nbsp;Tesla%20Motors;%3C/li%3E%3Cli%3E%3Cstrong%3ELocation%3C/strong%3E:%20San%20Carlos,%20California;%3C/li%3E%3Cli%3E%3Cstrong%3EDate%3C/strong%3E:%20July%201,%202003.%3C/li%3E%3C/ul%3E%3Cp%3ENER%20identifies%20the%20specific%20entities%20that%20interest%20you.%20You%20define%20these%20named%20entity%20recognition%20types&nbsp;and%20then%20find%20the%20matching%20words%20in%20the%20text%20for%20each%20category.%3C/p%3E%3C/div%3E%3Cfigure%20class=%22Article_imageBlock__JlKMT%22%3E%3Cdiv%20class=%22Article_image__QmZ2p%22%3E%3Cimg%20alt=%22article%20image%22%20loading=%22lazy%22%20width=%221296%22%20height=%22360%22%20decoding=%22async%22%20data-nimg=%221%22%20style=%22color:transparent;background-size:cover;background-position:50%25%2050%25;background-repeat:no-repeat;background-image:url(&quot;data:image/svg+xml;charset=utf-8,%253Csvg%20xmlns=&%23x27;http://www.w3.org/2000/svg&%23x27;%20viewBox=&%23x27;0%200%201296%20360&%23x27;%253E%253Cfilter%20id=&%23x27;b&%23x27;%20color-interpolation-filters=&%23x27;sRGB&%23x27;%253E%253CfeGaussianBlur%20stdDeviation=&%23x27;20&%23x27;/%253E%253CfeColorMatrix%20values=&%23x27;1%200%200%200%200%200%201%200%200%200%200%200%201%200%200%200%200%200%20100%20-1&%23x27;%20result=&%23x27;s&%23x27;/%253E%253CfeFlood%20x=&%23x27;0&%23x27;%20y=&%23x27;0&%23x27;%20width=&%23x27;100%2525&%23x27;%20height=&%23x27;100%2525&%23x27;/%253E%253CfeComposite%20operator=&%23x27;out&%23x27;%20in=&%23x27;s&%23x27;/%253E%253CfeComposite%20in2=&%23x27;SourceGraphic&%23x27;/%253E%253CfeGaussianBlur%20stdDeviation=&%23x27;20&%23x27;/%253E%253C/filter%253E%253Cimage%20width=&%23x27;100%2525&%23x27;%20height=&%23x27;100%2525&%23x27;%20x=&%23x27;0&%23x27;%20y=&%23x27;0&%23x27;%20preserveAspectRatio=&%23x27;none&%23x27;%20style=&%23x27;filter:%20url(%2523b);&%23x27;%20href=&%23x27;data:image/jpeg;base64,/9j/4AAQSkZJRgABAQEASABIAAD/2wBDAAUDBAQEAwUEBAQFBQUGBwwIBwcHBw8LCwkMEQ8SEhEPERETFhwXExQaFRERGCEYGh0dHx8fExciJCIeJBweHx7/2wBDAQUFBQcGBw4ICA4eFBEUHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh4eHh7/wAARCAAKAAoDAREAAhEBAxEB/8QAFgABAQEAAAAAAAAAAAAAAAAABgQH/8QAIBAAAgIBAwUAAAAAAAAAAAAAAQIDEQASEyEEFEFhof/EABYBAQEBAAAAAAAAAAAAAAAAAAIBA//EABURAQEAAAAAAAAAAAAAAAAAAAAR/9oADAMBAAIRAxEAPwDXJJITFvqSgdLbULqvPzLUg5LKjSue2ha2JsR8HFUVxs2vp11GtscXmZDk7MJ5ACQAxoX7xC//2Q==&%23x27;/%253E%253C/svg%253E&quot;)%22%20srcSet=%22/_next/image?url=https%253A%252F%252Fsapientpro.fra1.digitaloceanspaces.com%252FDark_4_6aa3963993.webp&amp;w=1920&amp;q=75%201x,%20/_next/image?url=https%253A%252F%252Fsapientpro.fra1.digitaloceanspaces.com%252FDark_4_6aa3963993.webp&amp;w=3840&amp;q=75%202x%22%20src=%22/_next/image?url=https%253A%252F%252Fsapientpro.fra1.digitaloceanspaces.com%252FDark_4_6aa3963993.webp&amp;w=3840&amp;q=75%22/%3E%3C/div%3E%3C/figure%3E%3C/div%3E%3Cdiv%20class=%22Article_contentStyles__FOoh1%22%20data-id=%221806%22%3E%3Ch2%3EHow%20to%20Implement%20Named%20Entity%20Recognition%20%3C/h2%3E%3Cdiv%20class=%22%22%3E%3Cp%3EImplementing%20NER%20involves%208%20key%20steps.%20Let's%20go%20through%20them%20so%20you%20can%20better%20understand%20how%20the%20process%20works.%3C/p%3E%3Ch3%3EStep%20%231:%20Setting%20Goals%3C/h3%3E%3Cp%3EDecide%20which%20entities%20to%20recognize,%20like%20people%20and%20places,%20and%20how%20you'll%20use%20NER,%20such%20as%20for%20extracting%20information.%3C/p%3E%3Ch3%3EStep%20%232:%20Data%20preparation%3C/h3%3E%3Cp%3EStart%20by%20collecting%20the%20data%20with%20the%20entities%20you%20need.%20Use%20tools%20like%20SpaCy%20Prodigy%20or%20datasets%20like%20CoNLL-03%20to%20tag%20them.%20Next,%20clean%20and%20preprocess%20the%20data%20to%20fix%20any%20issues%20with%20punctuation%20or%20special%20characters.%3C/p%3E%3Ch3%3EStep%20%233:%20Deciding%20on%20Approach%3C/h3%3E%3Cp%3EChoose%20from%20different%20methods%20like:%3C/p%3E%3Cul%3E%3Cli%3ERule-based%20approaches%20that%20use%20set%20rules%20for%20certain%20tasks;%3C/li%3E%3Cli%3EMachine%20Learning%20techniques,%20such%20as%20Conditional%20Random%20Fields%20(CRFs);%3C/li%3E%3Cli%3EDeep%20learning%20tools.%3C/li%3E%3C/ul%3E%3Ch3%3EStep%20%234:%20Building%20the%20Model%3C/h3%3E%3Cp%3EPick%20a%20library%20like%20SpaCy%20or%20Transformers.%20You%20can%20train%20a%20model%20from%20the%20beginning%20or%20adjust%20an%20existing%20one%20for%20your%20special%20needs.%3C/p%3E%3Ch3%3EStep%20%235:%20Model%20Assessment%3C/h3%3E%3Cp%3EMeasure%20how%20well%20your%20model%20performs%20using%20metrics%20like%20precision,%20recall,%20and%20F1%20score.%20Also,%20test%20it%20on%20various%20datasets%20to%20ensure%20it%20works%20properly%20with%20new%20data.%3C/p%3E%3Ch3%3EStep%20%236:%20Deployment%20and%20Integration%3C/h3%3E%3Cp%3EIntegrate%20the%20NER%20model%20into%20your%20application%20and%20make%20sure%20it%20works%20with%20other%20tools%20and%20processes.%3C/p%3E%3Ch3%3EStep%20%237:%20Maintenance%3C/h3%3E%3Cp%3ERegularly%20check%20the%20model%20performance%20in%20real-world%20situations%20and%20update%20it%20as%20needed.%3C/p%3E%3Ch3%3EStep%20%238:%20Solving%20Challenges%3C/h3%3E%3Cp%3EIn%20this%20last%20phase,%20manage%20any%20uncertainties%20and%20differences%20in%20identifying%20entities.%20You%20can%20adjust%20the%20model%20to%20fit%20the%20language%20and%20requirements%20of%20your%20field.%3C/p%3E%3Cp%3E&nbsp;%3C/p%3E%3Cp%3EUsing%20an&nbsp;%3Ca%20href=%22https://www.ibm.com/topics/api%22%20target=%22_blank%22%20rel=%22noopener%20noreferrer%22%3EAPI&nbsp;%3C/a%3Ecan%20make%20it%20much%20easier%20to%20set%20up&nbsp;named%20entity%20recognition%20software.%20These%20APIs%20are%20available%20online%20or%20as%20local%20tools%20that%20offer%20NER%20features.%20For%20example,&nbsp;Stanford%20Named%20Entity%20Recognizer%20is%20a%20popular%20Java%20tool%20used%20for%20extracting%20entities.%20It%20uses%20Conditional%20Random%20Fields%20(CRF)%20and%20comes%20with%20a%20pre-trained&nbsp;named%20entity%20recognition%20model&nbsp;to%20identify%20entities.%3C/p%3E%3Cp%3E&nbsp;%3C/p%3E%3Cp%3EIf%20you%E2%80%99re%20interested%20in&nbsp;how%20to%20do%20named%20entity%20recognition%20in%20Python,%20the&nbsp;Natural%20Language%20Toolkit%20(NLTK)%20is%20a%20helpful%20open-source%20tool%20for%20processing%20human%20language%20data.%20It's%20easy%20to%20use%20and%20works%20with%20over%20100%20pre-trained&nbsp;large%20language%20models%20for%20named%20entity%20recognition.%20NLTK%20offers%20tools%20for%20tasks%20like%20named%20entity%20recognition%20classification,%20stemming,%20tokenization,%20parsing,%20tagging,%20and%20understanding%20meaning.%20It%20includes%20a%20named%20entity%20recognizer%20(%60ne_chunk%60)%20and%20can%20be%20used%20with%20the%20Stanford%20NER%20in%20Python.%3C/p%3E%3C/div%3E%3C/div%3E%3Cdiv%20class=%22Article_contentStyles__FOoh1%22%20data-id=%221807%22%3E%3Ch2%3ERecent%20Trends%20in%20Named%20Entity%20Recognition%20(NER)%20and%20Its%20Future%3C/h2%3E%3Cdiv%20class=%22%22%3E%3Cp%3ELet's%20check%20out%20some%20predictions%20for%20the%20future%20of%20Named%20Entity%20Recognition%20(NER).%3C/p%3E%3Cp%3E&nbsp;%3C/p%3E%3Cp%3EFirst,%20experts%20believe%20pairing%20named%20entity%20recognition%20with%20knowledge%20graphs,%20large%20databases%20that%20show%20how%20different%20entities%20are%20connected,%20will%20improve%20its%20performance.%20This%20could%20make%20NER%20more%20precise%20and%20help%20discover%20new%20entities%20more%20easily.%3C/p%3E%3Cp%3E&nbsp;%3C/p%3E%3Cp%3ENext,%20named%20entity%20recognition%20could%20play%20a%20more%20significant%20role%20in%20voice%20assistants%20and%20chatbots,%20like%20ChatGPT.%20Recent%20stats%20show%20that&nbsp;%3Ca%20href=%22https://cases.media/en/article/the-chatbot-market-in-2024-forecasts-and-latest-statistics%22%20target=%22_blank%22%20rel=%22noopener%20noreferrer%22%3E67%25%20of%20clients%20use%20chatbots%3C/a%3E%20for%20customer%20support,%20while%20chatbots%20manage%2064%25%20of%20routine%20requests.&nbsp;%3C/p%3E%3Cp%3E&nbsp;%3C/p%3E%3Cp%3EAs%20these%20technologies%20become%20more%20popular,%20it's%20important%20to%20identify%20specific%20parts%20of%20speech%20or%20text%20to%20understand%20what%20users%20want%20and%20give%20the%20right%20response.%20If%20a%20customer%20asks%20the%20chatbot,%20%22I%20lost%20my%20phone%20in%20London%20yesterday.%20Can%20you%20help%20me%20block%20my%20number?%22%20a%20NER%20system%20will%20identify%20a%20phone%20as%20a%20PRODUCT,%20London%20as%20a%20LOCATION,%20and%20yesterday%20as%20a%20DATE.&nbsp;%3C/p%3E%3Cp%3E&nbsp;%3C/p%3E%3Cp%3EA%20chatbot%20will%20be%20able%20to%20quickly%20share%20location%20services%20and%20temporarily%20block%20a%20customer's%20number.%20This%20will%20make%20support%20service%20faster%20and%20more%20efficient.%3C/p%3E%3Cp%3E&nbsp;%3C/p%3E%3Cp%3EFinally,%20as%20big%20data,&nbsp;%3Ca%20href=%22https://sapient.pro/blog/how-to-build-ai-software%22%20target=%22_blank%22%20rel=%22noopener%20noreferrer%22%3Eartificial%20intelligence%3C/a%3E,%20and%20the%20Internet%20of%20Things%20expand,%20companies%20will%20use%20named%20entity%20recognition%20for%20cybersecurity%20and%20fraud%20detection.%20NER%20can%20interpret%20large%20amounts%20of%20data%20to%20find%20potential%20threats,%20which%20helps%20protect%20people%20and%20companies%20from%20cyberattacks.&nbsp;%3C/p%3E%3Cp%3E&nbsp;%3C/p%3E%3Cp%3E%3Ca%20href=%22https://www.scitepress.org/Papers/2019/73142/73142.pdf\"}, \"bdf0635f\": {\"success\": true, \"paper_id\": \"bdf0635f\", \"url\": \"https://arxiv.org/pdf/2206.07318v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_bdf0635f.pdf\", \"extracted_info\": {\"title\": \"Named Entity Recognition on Code-Mixed Dataset using Multilingual BERT\", \"authors\": [\"Suman Dowlagar\", \"Radhika Mamidi\"], \"abstract\": \"Identifying named entities is a practical and challenging task in the field of Natural Language Processing (NLP). This paper addresses the shared task of named entity recognition (NER) for a code-mixed dataset, focusing on multilingual and social media text.\", \"methodology\": \"The proposed approach uses a pre-trained multilingual BERT (mBERT) model fine-tuned on a code-mixed training dataset. The method aims to learn language-agnostic features by combining multilingual and code-mixed data. Baselines include Conditional Random Fields (CRF) and the MultiCoNER baseline for comparison.\", \"results\": \"On the Dravidian code-mixed dataset, the models achieved the following F1-scores: CRF - 0.565, mBERT - 0.627, MultiCoNER baseline - 0.651. mBERT outperformed CRF but was slightly below the MultiCoNER baseline in overall performance.\", \"conclusion\": \"The paper contributes a fine-tuned multilingual BERT approach for code-mixed NER, demonstrating improved performance over traditional CRF models. It highlights the effectiveness of leveraging multilingual pre-trained models for handling code-mixed social media text and suggests potential for further improvement in downstream tasks.\", \"figures\": null, \"tables\": null}, \"citations\": [\"Gustavo Aguilar, Fahad AlGhamdi, Victor Soto, Mona\", \"Diab, Julia Hirschberg, and Thamar Solorio. 2019.\", \"Kalika Bali, Jatin Sharma, Monojit Choudhury, and Yo-\", \"tional Approaches to Code Switching , pages 116–\", \"126.\", \"Partha Sarathy Banerjee, Baisakhi Chakraborty,\", \"Deepak Tripathi, Hardik Gupta, and Sourabh S\", \"Communications , 108(3):1909–1931.\", \"Jacob Devlin, Ming-Wei Chang, Kenton Lee, and\", \"guage Technologies for Dravidian Languages , pages\", \"154–159.\", \"Besnik Fetahu, Anjie Fang, Oleg Rokhlenko, and\", \"ment in Information Retrieval , pages 1677–1681.\", \"Simran Khanuja, Sandipan Dandapat, Sunayana\", \"Sitaram, and Monojit Choudhury. 2020. A\", \"arXiv:2004.05051 .Canasai Kruengkrai, Thien Hai Nguyen, Sharifah Ma-\", \"hani Aljunied, and Lidong Bing. 2020. Improving\", \"58th Annual Meeting of the Association for Compu-\", \"tational Linguistics , pages 5898–5905.\", \"John Lafferty, Andrew McCallum, and Fernando CN\", \"Jing Li, Aixin Sun, Jianglei Han, and Chenliang Li.\", \"2020. A survey on deep learning for named entity\", \"Data Engineering , 34(1):50–70.\", \"Linlin Liu, Bosheng Ding, Lidong Bing, Shaﬁq Joty,\", \"Luo Si, and Chunyan Miao. 2021. Mulda: A\", \"59th Annual Meeting of the Association for Compu-\", \"ume 1: Long Papers) , pages 5834–5846.\", \"Shervin Malmasi, Anjie Fang, Besnik Fetahu, Sudipta\", \"Kar, and Oleg Rokhlenko. 2022a. MultiCoNER:\", \"Shervin Malmasi, Anjie Fang, Besnik Fetahu, Sudipta\", \"Kar, and Oleg Rokhlenko. 2022b. SemEval-2022\", \"Tao Meng, Anjie Fang, Oleg Rokhlenko, and Shervin\", \"2021 Conference of the North American Chapter of\", \"man Language Technologies , pages 1499–1512.\", \"Nita Patil, Ajay S Patil, and BV Pawar. 2016. Survey\", \"of Computer Applications , 134(16).\", \"Ruba Priyadharshini, Bharathi Raja Chakravarthi,\", \"Mani Vegupatti, and John P McCrae. 2020. Named\", \"systems (ICACCS) , pages 68–72. IEEE.\", \"pora, pages 157–176. Springer.\", \"Vinay Singh, Deepanshu Vijay, Syed Sarfaraz Akhtar,\", \"workshop , pages 27–35.\", \"Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob\", \"Uszkoreit, Llion Jones, Aidan N Gomez, Łukasz\", \"Kaiser, and Illia Polosukhin. 2017. Attention is all\", \"Genta Indra Winata, Zhaojiang Lin, and Pascale Fung.\", \"2019. Learning multilingual meta-embeddings for\", \"Learning for NLP (RepL4NLP-2019) , pages 181–\", \"186.\"], \"error\": null}, \"33791e1c\": {\"success\": false, \"paper_id\": \"33791e1c\", \"url\": \"https://cta-eu1.hubspot.com/web-interactives/public/v1/track/redirect?encryptedPayload=AVxigLJqORkF%2BRvYYGuy6h9%2B8IxF3iPZDTaB95Qpgek5gvm7%2BLKlI9zadL5tiM%2FLwx3xblSlmcZG9XfKBEpqXpXUlTHhfP0HQI86PTKOOdj5YUjrbdbWs2AWGZderzN0M3Anr4VCOjqXV35KFFPTC%2FeJ%2Bq90xulOrb0muRVrpfZebcH3WmK6VbBiwageJmtLQErKsdu3duvUIvsDToWzbA%3D%3D&amp;webInteractiveContentId=182768045260&amp;portalId=143515705\\\" target=\\\"_blank\\\" class=\\\"button b-xl b-black-filled f13 mt-30\\\"> LEARN MORE </a></div><h2 class=\\\"h2\\\" id=\\\"what-is-ner\\\">What is NER?</h2><p class=\\\"f16 mt-20 mb0\\\">Named Entity Recognition (NER) is a <a href=\\\"https://labelyourdata.com/articles/natural-language-processing/techniques\\\">Natural Language Processing technique</a> that picks out important information from text and puts it into categories like people, places, organizations, dates, and more.</p><p class=\\\"f16 mt-20 mb0\\\">It turns messy text into organized data that&rsquo;s easy to understand and use.</p><p class=\\\"f16 mt-20 mb0\\\">NER helps answer questions like <i>who</i>, <i>where</i>, and <i>when</i> by finding key parts of text. For example, it can highlight names, dates, and places in a <a target=\\\"_blank\\\" rel=\\\"nofollow\\\" href=\\\"https://github.com/RiadBensalem/Real-Time-News-Article-Analysis-with-NER\\\">news article</a>. This process is also called entity extraction or entity chunking and is used in search engines, chatbots, and text summaries.</p><div class=\\\"mt-40\\\"><figure><div class=\\\"flex flex-stretch gallery-tile\\\"><div class=\\\"flex-1 img-tile\\\"><img src=\\\"/img/article-illustrations/named-entity-recognition_1.jpg\\\" class=\\\"dblock\\\" alt=\\\"Example of NER\\\"></div></div><figcaption class=\\\"mt-10 f12 cgrey\\\">Example of NER</figcaption></figure></div><p class=\\\"f16 mt-20 mb0\\\"><strong>Here&rsquo;s how it works:</strong></p><ol class=\\\"mt-10\\\"><li><p class=\\\"f16\\\">First, NER finds possible important words (like names or dates).</p></li><li><p class=\\\"f16\\\">Next, it sorts those words into categories.</p></li></ol><p class=\\\"f16 mt-20 mb0\\\">For example, in the sentence: <i>&ldquo;Tesla unveiled its latest model in California on January 1, 2025,&rdquo;</i></p><ul class=\\\"mt-10\\\"><li><p class=\\\"f16\\\"><strong>Tesla &rarr; </strong>Organization</p></li><li><p class=\\\"f16\\\"><strong>California &rarr; </strong>Location</p></li><li><p class=\\\"f16\\\"><strong>January 1, 2025 &rarr; </strong>Date</p></li></ul><p class=\\\"f16 mt-20 mb0\\\">Modern named entity recognition models uses a <a href=\\\"https://labelyourdata.com/articles/how-to-choose-a-machine-learning-algorithm\\\">machine learning algorithm</a> and deep learning to improve over time. These models learn from data and get better at recognizing entities.</p><p class=\\\"f16 mt-20 mb0\\\">NER is useful because it saves time, improves search accuracy, and helps organize large amounts of text. Businesses use it to process reports, answer customer questions faster, and make better decisions with data.</p><h2 class=\\\"h2\\\" id=\\\"common-applications-of-named-entity-recognition\\\">Common Applications of Named Entity Recognition</h2><div class=\\\"mt-40\\\"><figure><div class=\\\"flex flex-stretch gallery-tile\\\"><div class=\\\"flex-1 img-tile\\\"><img src=\\\"/img/article-illustrations/named-entity-recognition_2.jpg\\\" class=\\\"dblock\\\" alt=\\\"Named entity recognition workflow\\\"></div></div><figcaption class=\\\"mt-10 f12 cgrey\\\">Named entity recognition workflow</figcaption></figure></div><p class=\\\"f16 mt-20 mb0\\\">Named Entity Recognition (NER) is used in many industries to make sense of large amounts of text. It helps businesses, researchers, and organizations organize and analyze text faster.</p><p class=\\\"f16 mt-20 mb0\\\">Now that you know what is named entity recognition, here are some of its most common applications:</p><h3 class=\\\"h3 mt-40 mb0\\\" id=\\\"search-engines\\\">Search Engines</h3><p class=\\\"f16 mt-20 mb0\\\">NER improves search accuracy by identifying names, places, and dates in search queries. This makes it easier for users to find the right information.</p><h3 class=\\\"h3 mt-40 mb0\\\" id=\\\"customer-support\\\">Customer Support</h3><p class=\\\"f16 mt-20 mb0\\\">Companies use NER to sort customer questions and complaints. This helps support teams respond faster by sending requests to the right department.</p><h3 class=\\\"h3 mt-40 mb0\\\" id=\\\"healthcare\\\">Healthcare</h3><p class=\\\"f16 mt-20 mb0\\\">NER extracts key details from patient records, such as symptoms, treatments, and dates. This reduces manual work for doctors and helps them make quicker decisions.</p><h3 class=\\\"h3 mt-40 mb0\\\" id=\\\"finance\\\">Finance</h3><p class=\\\"f16 mt-20 mb0\\\">Financial companies use NER to process <a href=\\\"https://labelyourdata.com/articles/financial-datasets-for-machine-learning\\\">financial datasets</a>, extract company names, transaction details, and identify trends. It speeds up tasks like credit analysis and fraud detection.</p><h3 class=\\\"h3 mt-40 mb0\\\" id=\\\"news-and-media\\\">News and Media</h3><p class=\\\"f16 mt-20 mb0\\\">NER helps categorize news articles by identifying people, events, and locations mentioned in stories. This makes it easier to find related news.</p><h3 class=\\\"h3 mt-40 mb0\\\" id=\\\"human-resources\\\">Human Resources</h3><p class=\\\"f16 mt-20 mb0\\\">NER can analyze job applications by picking out key details like skills, experience, and education, helping recruiters find the right candidates faster.</p><p class=\\\"f16 mt-20 mb0\\\">NER&rsquo;s ability to quickly turn raw text into organized data makes it essential for improving search accuracy, automating data entry, and gaining valuable insights from <a href=\\\"https://labelyourdata.com/articles/unlabeled-data-in-machine-learning\\\">unlabeled data</a>.</p><h2 class=\\\"h2\\\" id=\\\"types-of-entities-recognized-in-ner\\\">Types of Entities Recognized in NER</h2><p class=\\\"f16 mt-20 mb0\\\">Named entity recognition in NLP can identify a wide range of entities in text. These entities fall into standard categories and specialized ones, depending on the task.</p><h3 class=\\\"h3 mt-40 mb0\\\" id=\\\"standard-entities\\\">Standard Entities</h3><p class=\\\"f16 mt-20 mb0\\\">These are common types used in NER:</p><ul class=\\\"mt-10\\\"><li><p class=\\\"f16\\\"><strong>Person: </strong>Names of individuals (e.g., Elon Musk)</p></li><li><p class=\\\"f16\\\"><strong>Location: </strong>Cities, countries, and geographic regions (e.g., Paris, France)</p></li><li><p class=\\\"f16\\\"><strong>Organization: </strong>Companies, institutions, and groups (e.g., Tesla, United Nations)</p></li><li><p class=\\\"f16\\\"><strong>Date/Time: </strong>Specific dates or times (e.g., January 1, 2025, 2 PM)</p></li><li><p class=\\\"f16\\\"><strong>Monetary Values: </strong>Amounts of money (e.g., $1,000,000)</p></li><li><p class=\\\"f16\\\"><strong>Percentages: </strong>Percent-based information (e.g., 85%)</p></li></ul><h3 class=\\\"h3 mt-40 mb0\\\" id=\\\"domain-specific-entities\\\">Domain-Specific Entities</h3><p class=\\\"f16 mt-20 mb0\\\">Some industries need custom entity categories that go beyond the standard ones:</p><ul class=\\\"mt-10\\\"><li><p class=\\\"f16\\\"><strong>Healthcare: </strong>Disease names, drug names, medical codes (e.g., diabetes, Ibuprofen)</p></li><li><p class=\\\"f16\\\"><strong>Finance: </strong>Stock symbols, financial instruments (e.g., AAPL, Bitcoin)</p></li><li><p class=\\\"f16\\\"><strong>E-commerce: </strong>Product names, SKUs, brands (e.g., iPhone 15 Pro)</p></li></ul><p class=\\\"f16 mt-20 mb0\\\">Customizing NER to recognize these specialized entities is essential for tasks like medical research, financial analysis, or product management. Modern named entity recognition models allow this level of customization by training on domain-specific datasets.</p><h2 class=\\\"h2\\\" id=\\\"techniques-for-building-a-ner-model\\\">Techniques for Building a NER Model</h2><div class=\\\"mt-40\\\"><figure><div class=\\\"flex flex-stretch gallery-tile\\\"><div class=\\\"flex-1 img-tile\\\"><img src=\\\"/img/article-illustrations/named-entity-recognition_3.jpg\\\" class=\\\"dblock\\\" alt=\\\"Key steps in Named Entity Recognition (NER)\\\"></div></div><figcaption class=\\\"mt-10 f12 cgrey\\\">Key steps in Named Entity Recognition (NER)</figcaption></figure></div><p class=\\\"f16 mt-20 mb0\\\">There are several techniques for building a NER model, ranging from simple rule-based approaches to advanced deep learning models. The right technique depends on your data and the complexity of the task.</p><h3 class=\\\"h3 mt-40 mb0\\\" id=\\\"rule-based-systems\\\">Rule-Based Systems</h3><p class=\\\"f16 mt-20 mb0\\\">These systems use predefined rules like word patterns, capitalization, and context to identify entities.</p><ul class=\\\"mt-10\\\"><li><p class=\\\"f16\\\"><strong>Example: </strong>Capitalized words after titles like &ldquo;Mr.&rdquo; or &ldquo;Dr.&rdquo; may be identified as names.</p></li><li><p class=\\\"f16\\\"><strong>Limitations: </strong>Hard to scale and struggles with variations in text.</p></li></ul><h3 class=\\\"h3 mt-40 mb0\\\" id=\\\"dictionary-based-systems\\\">Dictionary-Based Systems</h3><p class=\\\"f16 mt-20 mb0\\\">This method checks words against a dictionary of known entities. It works well for simple tasks but needs constant updating.</p><ul class=\\\"mt-10\\\"><li><p class=\\\"f16\\\"><strong>Example: </strong>A list of company names to identify business-related entities.</p></li><li><p class=\\\"f16\\\"><strong>Limitations: </strong>Misses new or uncommon terms not in the dictionary.</p></li></ul><h3 class=\\\"h3 mt-40 mb0\\\" id=\\\"machine-learning-based-ner\\\">Machine Learning-Based NER</h3><p class=\\\"f16 mt-20 mb0\\\">Machine learning models are trained on labeled datasets to identify and classify entities. These models require feature engineering and can generalize well to unseen data. Common algorithms include <a target=\\\"_blank\\\" rel=\\\"nofollow\\\" href=\\\"https://medium.com/data-science-in-your-pocket/named-entity-recognition-ner-using-conditional-random-fields-in-nlp-3660df22e95c\\\">Conditional Random Fields (CRF)</a> and <a target=\\\"_blank\\\" rel=\\\"nofollow\\\" href=\\\"https://www.ibm.com/think/topics/support-vector-machine\\\">Support Vector Machines (SVM)</a>.</p><ul class=\\\"mt-10\\\"><li><p class=\\\"f16\\\"><strong>Advantages: </strong>More adaptable than rule-based methods.</p></li><li><p class=\\\"f16\\\"><strong>Example: </strong>Training a model to recognize names and dates in news articles.</p></li></ul><h3 class=\\\"h3 mt-40 mb0\\\" id=\\\"deep-learning-based-ner\\\">Deep Learning-Based NER</h3><p class=\\\"f16 mt-20 mb0\\\">Deep learning models, like <a target=\\\"_blank\\\" rel=\\\"nofollow\\\" href=\\\"https://arxiv.org/pdf/2409.10521\\\">LSTM</a> and <a target=\\\"_blank\\\" rel=\\\"nofollow\\\" href=\\\"https://peerj.com/articles/cs-1731.pdf\", \"pdf_path\": null, \"extracted_info\": null, \"error\": \"download failed: request failed: 400 Client Error: Bad Request for url: https://cta-eu1.hubspot.com/web-interactives/public/v1/track/redirect?encryptedPayload=AVxigLJqORkF%252BRvYYGuy6h9%252B8IxF3iPZDTaB95Qpgek5gvm7%252BLKlI9zadL5tiM%252FLwx3xblSlmcZG9XfKBEpqXpXUlTHhfP0HQI86PTKOOdj5YUjrbdbWs2AWGZderzN0M3Anr4VCOjqXV35KFFPTC%252FeJ%252Bq90xulOrb0muRVrpfZebcH3WmK6VbBiwageJmtLQErKsdu3duvUIvsDToWzbA%253D%253D&amp;webInteractiveContentId=182768045260&amp;portalId=143515705%22%20target=%22_blank%22%20class=%22button%20b-xl%20b-black-filled%20f13%20mt-30%22%3E%20LEARN%20MORE%20%3C/a%3E%3C/div%3E%3Ch2%20class=%22h2%22%20id=%22what-is-ner%22%3EWhat%20is%20NER?%3C/h2%3E%3Cp%20class=%22f16%20mt-20%20mb0%22%3ENamed%20Entity%20Recognition%20(NER)%20is%20a%20%3Ca%20href=%22https://labelyourdata.com/articles/natural-language-processing/techniques%22%3ENatural%20Language%20Processing%20technique%3C/a%3E%20that%20picks%20out%20important%20information%20from%20text%20and%20puts%20it%20into%20categories%20like%20people,%20places,%20organizations,%20dates,%20and%20more.%3C/p%3E%3Cp%20class=%22f16%20mt-20%20mb0%22%3EIt%20turns%20messy%20text%20into%20organized%20data%20that&rsquo;s%20easy%20to%20understand%20and%20use.%3C/p%3E%3Cp%20class=%22f16%20mt-20%20mb0%22%3ENER%20helps%20answer%20questions%20like%20%3Ci%3Ewho%3C/i%3E,%20%3Ci%3Ewhere%3C/i%3E,%20and%20%3Ci%3Ewhen%3C/i%3E%20by%20finding%20key%20parts%20of%20text.%20For%20example,%20it%20can%20highlight%20names,%20dates,%20and%20places%20in%20a%20%3Ca%20target=%22_blank%22%20rel=%22nofollow%22%20href=%22https://github.com/RiadBensalem/Real-Time-News-Article-Analysis-with-NER%22%3Enews%20article%3C/a%3E.%20This%20process%20is%20also%20called%20entity%20extraction%20or%20entity%20chunking%20and%20is%20used%20in%20search%20engines,%20chatbots,%20and%20text%20summaries.%3C/p%3E%3Cdiv%20class=%22mt-40%22%3E%3Cfigure%3E%3Cdiv%20class=%22flex%20flex-stretch%20gallery-tile%22%3E%3Cdiv%20class=%22flex-1%20img-tile%22%3E%3Cimg%20src=%22/img/article-illustrations/named-entity-recognition_1.jpg%22%20class=%22dblock%22%20alt=%22Example%20of%20NER%22%3E%3C/div%3E%3C/div%3E%3Cfigcaption%20class=%22mt-10%20f12%20cgrey%22%3EExample%20of%20NER%3C/figcaption%3E%3C/figure%3E%3C/div%3E%3Cp%20class=%22f16%20mt-20%20mb0%22%3E%3Cstrong%3EHere&rsquo;s%20how%20it%20works:%3C/strong%3E%3C/p%3E%3Col%20class=%22mt-10%22%3E%3Cli%3E%3Cp%20class=%22f16%22%3EFirst,%20NER%20finds%20possible%20important%20words%20(like%20names%20or%20dates).%3C/p%3E%3C/li%3E%3Cli%3E%3Cp%20class=%22f16%22%3ENext,%20it%20sorts%20those%20words%20into%20categories.%3C/p%3E%3C/li%3E%3C/ol%3E%3Cp%20class=%22f16%20mt-20%20mb0%22%3EFor%20example,%20in%20the%20sentence:%20%3Ci%3E&ldquo;Tesla%20unveiled%20its%20latest%20model%20in%20California%20on%20January%201,%202025,&rdquo;%3C/i%3E%3C/p%3E%3Cul%20class=%22mt-10%22%3E%3Cli%3E%3Cp%20class=%22f16%22%3E%3Cstrong%3ETesla%20&rarr;%20%3C/strong%3EOrganization%3C/p%3E%3C/li%3E%3Cli%3E%3Cp%20class=%22f16%22%3E%3Cstrong%3ECalifornia%20&rarr;%20%3C/strong%3ELocation%3C/p%3E%3C/li%3E%3Cli%3E%3Cp%20class=%22f16%22%3E%3Cstrong%3EJanuary%201,%202025%20&rarr;%20%3C/strong%3EDate%3C/p%3E%3C/li%3E%3C/ul%3E%3Cp%20class=%22f16%20mt-20%20mb0%22%3EModern%20named%20entity%20recognition%20models%20uses%20a%20%3Ca%20href=%22https://labelyourdata.com/articles/how-to-choose-a-machine-learning-algorithm%22%3Emachine%20learning%20algorithm%3C/a%3E%20and%20deep%20learning%20to%20improve%20over%20time.%20These%20models%20learn%20from%20data%20and%20get%20better%20at%20recognizing%20entities.%3C/p%3E%3Cp%20class=%22f16%20mt-20%20mb0%22%3ENER%20is%20useful%20because%20it%20saves%20time,%20improves%20search%20accuracy,%20and%20helps%20organize%20large%20amounts%20of%20text.%20Businesses%20use%20it%20to%20process%20reports,%20answer%20customer%20questions%20faster,%20and%20make%20better%20decisions%20with%20data.%3C/p%3E%3Ch2%20class=%22h2%22%20id=%22common-applications-of-named-entity-recognition%22%3ECommon%20Applications%20of%20Named%20Entity%20Recognition%3C/h2%3E%3Cdiv%20class=%22mt-40%22%3E%3Cfigure%3E%3Cdiv%20class=%22flex%20flex-stretch%20gallery-tile%22%3E%3Cdiv%20class=%22flex-1%20img-tile%22%3E%3Cimg%20src=%22/img/article-illustrations/named-entity-recognition_2.jpg%22%20class=%22dblock%22%20alt=%22Named%20entity%20recognition%20workflow%22%3E%3C/div%3E%3C/div%3E%3Cfigcaption%20class=%22mt-10%20f12%20cgrey%22%3ENamed%20entity%20recognition%20workflow%3C/figcaption%3E%3C/figure%3E%3C/div%3E%3Cp%20class=%22f16%20mt-20%20mb0%22%3ENamed%20Entity%20Recognition%20(NER)%20is%20used%20in%20many%20industries%20to%20make%20sense%20of%20large%20amounts%20of%20text.%20It%20helps%20businesses,%20researchers,%20and%20organizations%20organize%20and%20analyze%20text%20faster.%3C/p%3E%3Cp%20class=%22f16%20mt-20%20mb0%22%3ENow%20that%20you%20know%20what%20is%20named%20entity%20recognition,%20here%20are%20some%20of%20its%20most%20common%20applications:%3C/p%3E%3Ch3%20class=%22h3%20mt-40%20mb0%22%20id=%22search-engines%22%3ESearch%20Engines%3C/h3%3E%3Cp%20class=%22f16%20mt-20%20mb0%22%3ENER%20improves%20search%20accuracy%20by%20identifying%20names,%20places,%20and%20dates%20in%20search%20queries.%20This%20makes%20it%20easier%20for%20users%20to%20find%20the%20right%20information.%3C/p%3E%3Ch3%20class=%22h3%20mt-40%20mb0%22%20id=%22customer-support%22%3ECustomer%20Support%3C/h3%3E%3Cp%20class=%22f16%20mt-20%20mb0%22%3ECompanies%20use%20NER%20to%20sort%20customer%20questions%20and%20complaints.%20This%20helps%20support%20teams%20respond%20faster%20by%20sending%20requests%20to%20the%20right%20department.%3C/p%3E%3Ch3%20class=%22h3%20mt-40%20mb0%22%20id=%22healthcare%22%3EHealthcare%3C/h3%3E%3Cp%20class=%22f16%20mt-20%20mb0%22%3ENER%20extracts%20key%20details%20from%20patient%20records,%20such%20as%20symptoms,%20treatments,%20and%20dates.%20This%20reduces%20manual%20work%20for%20doctors%20and%20helps%20them%20make%20quicker%20decisions.%3C/p%3E%3Ch3%20class=%22h3%20mt-40%20mb0%22%20id=%22finance%22%3EFinance%3C/h3%3E%3Cp%20class=%22f16%20mt-20%20mb0%22%3EFinancial%20companies%20use%20NER%20to%20process%20%3Ca%20href=%22https://labelyourdata.com/articles/financial-datasets-for-machine-learning%22%3Efinancial%20datasets%3C/a%3E,%20extract%20company%20names,%20transaction%20details,%20and%20identify%20trends.%20It%20speeds%20up%20tasks%20like%20credit%20analysis%20and%20fraud%20detection.%3C/p%3E%3Ch3%20class=%22h3%20mt-40%20mb0%22%20id=%22news-and-media%22%3ENews%20and%20Media%3C/h3%3E%3Cp%20class=%22f16%20mt-20%20mb0%22%3ENER%20helps%20categorize%20news%20articles%20by%20identifying%20people,%20events,%20and%20locations%20mentioned%20in%20stories.%20This%20makes%20it%20easier%20to%20find%20related%20news.%3C/p%3E%3Ch3%20class=%22h3%20mt-40%20mb0%22%20id=%22human-resources%22%3EHuman%20Resources%3C/h3%3E%3Cp%20class=%22f16%20mt-20%20mb0%22%3ENER%20can%20analyze%20job%20applications%20by%20picking%20out%20key%20details%20like%20skills,%20experience,%20and%20education,%20helping%20recruiters%20find%20the%20right%20candidates%20faster.%3C/p%3E%3Cp%20class=%22f16%20mt-20%20mb0%22%3ENER&rsquo;s%20ability%20to%20quickly%20turn%20raw%20text%20into%20organized%20data%20makes%20it%20essential%20for%20improving%20search%20accuracy,%20automating%20data%20entry,%20and%20gaining%20valuable%20insights%20from%20%3Ca%20href=%22https://labelyourdata.com/articles/unlabeled-data-in-machine-learning%22%3Eunlabeled%20data%3C/a%3E.%3C/p%3E%3Ch2%20class=%22h2%22%20id=%22types-of-entities-recognized-in-ner%22%3ETypes%20of%20Entities%20Recognized%20in%20NER%3C/h2%3E%3Cp%20class=%22f16%20mt-20%20mb0%22%3ENamed%20entity%20recognition%20in%20NLP%20can%20identify%20a%20wide%20range%20of%20entities%20in%20text.%20These%20entities%20fall%20into%20standard%20categories%20and%20specialized%20ones,%20depending%20on%20the%20task.%3C/p%3E%3Ch3%20class=%22h3%20mt-40%20mb0%22%20id=%22standard-entities%22%3EStandard%20Entities%3C/h3%3E%3Cp%20class=%22f16%20mt-20%20mb0%22%3EThese%20are%20common%20types%20used%20in%20NER:%3C/p%3E%3Cul%20class=%22mt-10%22%3E%3Cli%3E%3Cp%20class=%22f16%22%3E%3Cstrong%3EPerson:%20%3C/strong%3ENames%20of%20individuals%20(e.g.,%20Elon%20Musk)%3C/p%3E%3C/li%3E%3Cli%3E%3Cp%20class=%22f16%22%3E%3Cstrong%3ELocation:%20%3C/strong%3ECities,%20countries,%20and%20geographic%20regions%20(e.g.,%20Paris,%20France)%3C/p%3E%3C/li%3E%3Cli%3E%3Cp%20class=%22f16%22%3E%3Cstrong%3EOrganization:%20%3C/strong%3ECompanies,%20institutions,%20and%20groups%20(e.g.,%20Tesla,%20United%20Nations)%3C/p%3E%3C/li%3E%3Cli%3E%3Cp%20class=%22f16%22%3E%3Cstrong%3EDate/Time:%20%3C/strong%3ESpecific%20dates%20or%20times%20(e.g.,%20January%201,%202025,%202%20PM)%3C/p%3E%3C/li%3E%3Cli%3E%3Cp%20class=%22f16%22%3E%3Cstrong%3EMonetary%20Values:%20%3C/strong%3EAmounts%20of%20money%20(e.g.,%20$1,000,000)%3C/p%3E%3C/li%3E%3Cli%3E%3Cp%20class=%22f16%22%3E%3Cstrong%3EPercentages:%20%3C/strong%3EPercent-based%20information%20(e.g.,%2085%25)%3C/p%3E%3C/li%3E%3C/ul%3E%3Ch3%20class=%22h3%20mt-40%20mb0%22%20id=%22domain-specific-entities%22%3EDomain-Specific%20Entities%3C/h3%3E%3Cp%20class=%22f16%20mt-20%20mb0%22%3ESome%20industries%20need%20custom%20entity%20categories%20that%20go%20beyond%20the%20standard%20ones:%3C/p%3E%3Cul%20class=%22mt-10%22%3E%3Cli%3E%3Cp%20class=%22f16%22%3E%3Cstrong%3EHealthcare:%20%3C/strong%3EDisease%20names,%20drug%20names,%20medical%20codes%20(e.g.,%20diabetes,%20Ibuprofen)%3C/p%3E%3C/li%3E%3Cli%3E%3Cp%20class=%22f16%22%3E%3Cstrong%3EFinance:%20%3C/strong%3EStock%20symbols,%20financial%20instruments%20(e.g.,%20AAPL,%20Bitcoin)%3C/p%3E%3C/li%3E%3Cli%3E%3Cp%20class=%22f16%22%3E%3Cstrong%3EE-commerce:%20%3C/strong%3EProduct%20names,%20SKUs,%20brands%20(e.g.,%20iPhone%2015%20Pro)%3C/p%3E%3C/li%3E%3C/ul%3E%3Cp%20class=%22f16%20mt-20%20mb0%22%3ECustomizing%20NER%20to%20recognize%20these%20specialized%20entities%20is%20essential%20for%20tasks%20like%20medical%20research,%20financial%20analysis,%20or%20product%20management.%20Modern%20named%20entity%20recognition%20models%20allow%20this%20level%20of%20customization%20by%20training%20on%20domain-specific%20datasets.%3C/p%3E%3Ch2%20class=%22h2%22%20id=%22techniques-for-building-a-ner-model%22%3ETechniques%20for%20Building%20a%20NER%20Model%3C/h2%3E%3Cdiv%20class=%22mt-40%22%3E%3Cfigure%3E%3Cdiv%20class=%22flex%20flex-stretch%20gallery-tile%22%3E%3Cdiv%20class=%22flex-1%20img-tile%22%3E%3Cimg%20src=%22/img/article-illustrations/named-entity-recognition_3.jpg%22%20class=%22dblock%22%20alt=%22Key%20steps%20in%20Named%20Entity%20Recognition%20(NER)%22%3E%3C/div%3E%3C/div%3E%3Cfigcaption%20class=%22mt-10%20f12%20cgrey%22%3EKey%20steps%20in%20Named%20Entity%20Recognition%20(NER)%3C/figcaption%3E%3C/figure%3E%3C/div%3E%3Cp%20class=%22f16%20mt-20%20mb0%22%3EThere%20are%20several%20techniques%20for%20building%20a%20NER%20model,%20ranging%20from%20simple%20rule-based%20approaches%20to%20advanced%20deep%20learning%20models.%20The%20right%20technique%20depends%20on%20your%20data%20and%20the%20complexity%20of%20the%20task.%3C/p%3E%3Ch3%20class=%22h3%20mt-40%20mb0%22%20id=%22rule-based-systems%22%3ERule-Based%20Systems%3C/h3%3E%3Cp%20class=%22f16%20mt-20%20mb0%22%3EThese%20systems%20use%20predefined%20rules%20like%20word%20patterns,%20capitalization,%20and%20context%20to%20identify%20entities.%3C/p%3E%3Cul%20class=%22mt-10%22%3E%3Cli%3E%3Cp%20class=%22f16%22%3E%3Cstrong%3EExample:%20%3C/strong%3ECapitalized%20words%20after%20titles%20like%20&ldquo;Mr.&rdquo;%20or%20&ldquo;Dr.&rdquo;%20may%20be%20identified%20as%20names.%3C/p%3E%3C/li%3E%3Cli%3E%3Cp%20class=%22f16%22%3E%3Cstrong%3ELimitations:%20%3C/strong%3EHard%20to%20scale%20and%20struggles%20with%20variations%20in%20text.%3C/p%3E%3C/li%3E%3C/ul%3E%3Ch3%20class=%22h3%20mt-40%20mb0%22%20id=%22dictionary-based-systems%22%3EDictionary-Based%20Systems%3C/h3%3E%3Cp%20class=%22f16%20mt-20%20mb0%22%3EThis%20method%20checks%20words%20against%20a%20dictionary%20of%20known%20entities.%20It%20works%20well%20for%20simple%20tasks%20but%20needs%20constant%20updating.%3C/p%3E%3Cul%20class=%22mt-10%22%3E%3Cli%3E%3Cp%20class=%22f16%22%3E%3Cstrong%3EExample:%20%3C/strong%3EA%20list%20of%20company%20names%20to%20identify%20business-related%20entities.%3C/p%3E%3C/li%3E%3Cli%3E%3Cp%20class=%22f16%22%3E%3Cstrong%3ELimitations:%20%3C/strong%3EMisses%20new%20or%20uncommon%20terms%20not%20in%20the%20dictionary.%3C/p%3E%3C/li%3E%3C/ul%3E%3Ch3%20class=%22h3%20mt-40%20mb0%22%20id=%22machine-learning-based-ner%22%3EMachine%20Learning-Based%20NER%3C/h3%3E%3Cp%20class=%22f16%20mt-20%20mb0%22%3EMachine%20learning%20models%20are%20trained%20on%20labeled%20datasets%20to%20identify%20and%20classify%20entities.%20These%20models%20require%20feature%20engineering%20and%20can%20generalize%20well%20to%20unseen%20data.%20Common%20algorithms%20include%20%3Ca%20target=%22_blank%22%20rel=%22nofollow%22%20href=%22https://medium.com/data-science-in-your-pocket/named-entity-recognition-ner-using-conditional-random-fields-in-nlp-3660df22e95c%22%3EConditional%20Random%20Fields%20(CRF)%3C/a%3E%20and%20%3Ca%20target=%22_blank%22%20rel=%22nofollow%22%20href=%22https://www.ibm.com/think/topics/support-vector-machine%22%3ESupport%20Vector%20Machines%20(SVM)%3C/a%3E.%3C/p%3E%3Cul%20class=%22mt-10%22%3E%3Cli%3E%3Cp%20class=%22f16%22%3E%3Cstrong%3EAdvantages:%20%3C/strong%3EMore%20adaptable%20than%20rule-based%20methods.%3C/p%3E%3C/li%3E%3Cli%3E%3Cp%20class=%22f16%22%3E%3Cstrong%3EExample:%20%3C/strong%3ETraining%20a%20model%20to%20recognize%20names%20and%20dates%20in%20news%20articles.%3C/p%3E%3C/li%3E%3C/ul%3E%3Ch3%20class=%22h3%20mt-40%20mb0%22%20id=%22deep-learning-based-ner%22%3EDeep%20Learning-Based%20NER%3C/h3%3E%3Cp%20class=%22f16%20mt-20%20mb0%22%3EDeep%20learning%20models,%20like%20%3Ca%20target=%22_blank%22%20rel=%22nofollow%22%20href=%22https://arxiv.org/pdf/2409.10521%22%3ELSTM%3C/a%3E%20and%20%3Ca%20target=%22_blank%22%20rel=%22nofollow%22%20href=%22https://peerj.com/articles/cs-1731.pdf\"}, \"520a5c82\": {\"success\": true, \"paper_id\": \"520a5c82\", \"url\": \"https://arxiv.org/pdf/1805.03784v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_520a5c82.pdf\", \"extracted_info\": {\"title\": \"SlugNERDS: A Named Entity Recognition and Linking Tool for Open Domain Dialogue Systems\", \"authors\": [\"Ram, A.\", \"Prasad, R.\", \"Khatri, C.\", \"Venkatesh, A.\", \"Gabriel, R.\", \"Liu, Q.\", \"Nunn, J.\", \"Hedayatnia, B.\", \"Chen, M.\", \"Walker, M.A.\"], \"abstract\": \"In dialogue systems, the tasks of named entity recognition (NER) and named entity linking (NEL) are critical for understanding user input and providing relevant responses. This paper presents SlugNERDS, a tool optimized for open-domain conversations, integrating NER and NEL to improve entity detection and linking accuracy.\", \"methodology\": \"The SlugNERDS tool primarily utilizes the Google Knowledge Graph for entity linking. The methodology includes text segmentation, ranking entities using SlugNERDS, incorporating verbs and nouns from the SchemaActuators corpus, and applying an ensemble method that merges multiple resources. Experiments were conducted with different threshold settings to evaluate performance against the Stanford NER baseline.\", \"results\": \"Results show that Stanford NER performs poorly in open-domain discourse with low macro-F1 (0.079) and accuracy (0.029). SlugNERDS, with iterative improvements and ensemble methods, detects more correct entities but also experiences over-classification. Threshold tuning impacts performance, with higher thresholds generally improving precision.\", \"conclusion\": \"The paper contributes an open-domain optimized NER/NEL pipeline, demonstrates integration with Google Knowledge Graph, and provides detailed error analysis highlighting contextual and linguistic challenges. It offers insights into improving dialogue systems through better entity detection, linking, and preprocessing techniques such as automatic capitalization and punctuation restoration.\", \"figures\": null, \"tables\": null}, \"citations\": [], \"error\": null}, \"f303cd5b\": {\"success\": true, \"paper_id\": \"f303cd5b\", \"url\": \"https://arxiv.org/pdf/2303.09306v2\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_f303cd5b.pdf\", \"extracted_info\": {\"title\": \"Complex Named Entity Recognition in Bangla using Feature-Based and Deep Learning Approaches\", \"authors\": [\"Asif Ekbal\", \"Rejwanul Haque\", \"Sivaji Bandyopadhyay\"], \"abstract\": \"Named Entity Recognition (NER) is a fundamental task in natural language processing that involves identifying and classifying named entities in text. This paper focuses on Complex Named Entity Recognition (CNER) in Bangla, exploring both feature-based machine learning and deep learning approaches.\", \"methodology\": \"The study used a labeled Bangla dataset in CoNLL format containing multiple entity categories (LOC, GRP, PROD, CW, CORP, PER, and O). Two main approaches were applied: (1) Feature-Based Learning using hand-crafted features such as cluster information from embeddings and digit-based features, with CRF as the classifier; (2) Deep Learning using BanglaBERT (large), a BERT/ELECTRA-based model leveraging masked language modeling and alternative token replacement strategies for pretraining. Iterative feature addition and hyperparameter tuning were performed to optimize performance.\", \"results\": \"BanglaBERT (large) outperformed the CRF-based feature model significantly, achieving an overall F1 score of 0.7898. Per-category F1 scores included: GRP 0.7692, CORP 0.7936, CW 0.7531, PROD 0.6941, LOC 0.8246, PER 0.9324. Precision and recall for the final model were 0.7859 and 0.7937 respectively.\", \"conclusion\": \"The paper demonstrates that deep learning models, specifically BanglaBERT, achieve superior performance over traditional feature-based approaches for Bangla CNER. The work contributes by providing a comparative analysis of CRF and transformer-based models for Bangla NER, presenting a high-quality labeled dataset, and achieving state-of-the-art results that can inspire further research in low-resource language NLP.\", \"figures\": null, \"tables\": null}, \"citations\": [], \"error\": null}, \"1dc5f02b\": {\"success\": true, \"paper_id\": \"1dc5f02b\", \"url\": \"https://arxiv.org/pdf/1912.10016v2\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_1dc5f02b.pdf\", \"extracted_info\": {\"title\": \"Unified End-to-End Model for Information Extraction from Document Images\", \"authors\": [\"J. Ignacio Toledo\", \"Manuel Carbonell\", \"Alicia Fornés\", \"Josep Lladós\"], \"abstract\": \"In recent years, deep neural network architectures have consolidated for information extraction, which is traditionally performed with separate methods for each task. This work proposes an end-to-end model that combines a one-stage object detection network with branches for recognition, enabling simultaneous resolution of interdependent tasks by leveraging shared features. Experimental results demonstrate that the model benefits from shared representations compared to sequential approaches.\", \"methodology\": \"The proposed methodology integrates information extraction tasks into a unified neural model. Convolutional features are extracted using ResNet18 combined with a Feature Pyramid Network (FPN). The architecture includes classification and regression branches for object detection, and a recognition branch for transcribing the content of detected boxes. The model is trained end-to-end to perform localization, transcription, and named entity recognition simultaneously. Multiple variations of the model are tested, including a triple-task unified approach, sequential triple-task, and detection plus classification setups. Evaluation metrics include Average Precision (AP) for text localization, accuracy for named entity recognition, and transcription performance across datasets such as IEHHR, WR, and sGMB.\", \"results\": \"The model achieves high localization performance across datasets (AP up to 0.994). Text recognition performance is similar across methods, with the triple-task unified approach (Setup A) slightly outperforming others in the WR dataset. The results indicate that the unified model benefits from contextual information, especially in challenging datasets with out-of-vocabulary words. Named entity recognition also shows improved performance when tasks are jointly trained, highlighting the advantages of shared feature learning.\", \"conclusion\": \"The key contributions of this work are: (1) Introduction of the first end-to-end method for information extraction from full handwritten pages; (2) A unified deep learning architecture that simultaneously performs text localization, transcription, and named entity recognition; (3) Demonstration of the benefits of shared features across tasks, leading to improved performance over sequential approaches; (4) Provision of a versatile baseline applicable to a wide range of information extraction scenarios; (5) Empirical validation on multiple datasets showing competitive or superior results in localization, recognition, and entity extraction.\", \"figures\": null, \"tables\": null}, \"citations\": [\"[1] J. Ignacio Toledo, Manuel Carbonell, Alicia Forn ´es, and Josep Llad ´os.\", \"a context-aware neural model. Pattern Recognition , 86:27–36, 2019.\", \"[2] Rasmus Berg Palm, Florian Laws, and Ole Winther. Attend, copy, parse\", \"ference on Document Analysis and Recognition (ICDAR) , 2019.\", \"[3] Manuel Carbonell, Mauricio Villegas, Alicia Forns, and Josep Llads.\", \"tems, pages 399–404, 04 2018.\", \"[4] Manuel Carbonell, Joan Mas, Mauricio Villegas, Alicia Forn ´es, and Josep\", \"[5] J. A. S ´anchez, V . Romero, A. H. Toselli, and E. Vidal. Icfhr2014 competi-\", \"2014 14th International Conference on Frontiers in Handwriting Recog-\", \"nition , pages 785–790, Sept 2014.\", \"[6] J.R.R. Uijlings, K.E.A. van de Sande, T. Gevers, and A.W.M. Smeulders.\", \"puter Vision , 2013.[7] Ross B. Girshick. Fast R-CNN. CoRR , abs/1504.08083, 2015.\", \"[8] Wei Liu, Dragomir Anguelov, Dumitru Erhan, Christian Szegedy, Scott E.\", \"Reed, Cheng-Yang Fu, and Alexander C. Berg. SSD: single shot multibox\", \"detector. CoRR , abs/1512.02325, 2015.\", \"[9] Joseph Redmon, Santosh Kumar Divvala, Ross B. Girshick, and Ali\", \"Farhadi. You only look once: Uniﬁed, real-time object detection. CoRR ,\", \"abs/1506.02640, 2015.\", \"[10] Tsung-Yi Lin, Priya Goyal, Ross B. Girshick, Kaiming He, and Piotr\", \"Doll´ar. Focal loss for dense object detection. CoRR , abs/1708.02002,\", \"2017.\", \"[11] Th ´eodore Bluche, J ´erˆome Louradour, and Ronaldo O. Messina. Scan, at-\", \"Analysis and Recognition (ICDAR) , 01:1050–1055, 2017.\", \"[12] Joan Puigcerver. Are multidimensional recurrent layers really neces-\", \"Conference on Document Analysis and Recognition (ICDAR) , volume 1,\", \"pages 67–72. IEEE, 2017.\", \"[13] Curtis Wigington, Chris Tensmeyer, Brian Davis, William Barrett, Brian\", \"Price, and Scott Cohen. Start, follow, read: End-to-end full-page hand-\", \"(ECCV) , September 2018.\", \"[14] Guillaume Lample, Miguel Ballesteros, Sandeep Subramanian, Kazuya\", \"Kawakami, and Chris Dyer. Neural architectures for named entity recog-\", \"nition. In HLT-NAACL , 2016.\", \"[15] Xuezhe Ma and Eduard Hovy. End-to-end sequence labeling via bi-\", \"Papers) , pages 1064–1074, Berlin, Germany, August 2016. Association\", \"[16] Alan Akbik, Duncan Blythe, and Roland V ollgraf. Contextual string em-\", \"Conference on Computational Linguistics , pages 1638–1649, Santa Fe,\", \"New Mexico, USA, August 2018. Association for Computational Lin-\", \"[17] J. Ignacio Toledo, Sebastian Sudholt, Alicia Forn ´es, Jordi Cucurull, Ger-\", \"not A. Fink, and Josep Llad ´os. Handwritten word image categorization\", \"tonio Robles-Kelly, Marco Loog, Battista Biggio, Francisco Escolano,\", \"and Richard Wilson, editors, Structural, Syntactic, and Statistical Pattern\", \"Recognition , pages 543–552, Cham, 2016. Springer International Pub-\", \"[18] Vijay Rowtula, Praveen Krishnan, and C.V . Jawahar. Pos tagging and\", \"Conference on NaturalLanguage Processing , 2018.\", \"[19] Curtis Wigington, Brian Price, and Scott Cohen. Multi-label connection-\", \"on Document Analysis and Recognition (ICDAR) . IEEE, 2019.\", \"[20] Alex Graves, Santiago Fern ´andez, Faustino Gomez, and J ¨urgen Schmid-\", \"International Conference on Machine Learning , ICML ’06, pages 369–\", \"376, New York, NY , USA, 2006. ACM.\", \"[21] He Ping Guo, Xiameng Qin, Jiaming Liu, Junyu Han, Jingtuo Liu, and\", \"traction. ArXiv , abs/1909.09380, 2019.\", \"[22] Tsung-Yi Lin, Piotr Doll ´ar, Ross B. Girshick, Kaiming He, Bharath Hari-\", \"haran, and Serge J. Belongie. Feature pyramid networks for object detec-\", \"tion. CoRR , abs/1612.03144, 2016.\", \"[23] Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual\", \"learning for image recognition. CoRR , abs/1512.03385, 2015.\", \"[24] Urs-Viktor Marti and Horst Bunke. The iam-database: an english sen-\", \"on Document Analysis and Recognition , 5:39–46, 2002.\", \"[25] Vincent Dumoulin and Francesco Visin. A guide to convolution arith-\", \"metic for deep learning. ArXiv , abs/1603.07285, 2016.\", \"[26] Johan Bos, Valerio Basile, Kilian Evang, Noortje Venhuizen, and Jo-\", \"Pustejovsky, editors, Handbook of Linguistic Annotation , volume 2, pages\", \"463–496. Springer, 2017.\", \"[27] Sebastian Ruder. An overview of multi-task learning in deep neural net-\", \"works. CoRR , abs/1706.05098, 2017.\"], \"error\": null}, \"82162cfa\": {\"success\": true, \"paper_id\": \"82162cfa\", \"url\": \"https://arxiv.org/pdf/1908.10261v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_82162cfa.pdf\", \"extracted_info\": {\"title\": \"Morphologically Informed Bi-LSTM-CRF Model for Named Entity Recognition\", \"authors\": [\"Preslav Nakov\", \"fkivs\", \"petyag\"], \"abstract\": \"We propose a morphologically informed model for named entity recognition, which is based on LSTM-CRF.\", \"methodology\": \"The proposed approach uses a Bi-directional Long Short-Term Memory (Bi-LSTM) network combined with a Conditional Random Field (CRF) layer. The model integrates both automatically learned features (word embeddings and character embeddings) and hand-crafted morphological features such as POS tags of varying granularity. Experiments were conducted primarily on Bulgarian, with comparisons to other Slavic languages, and optimization was performed using the Adam optimizer.\", \"results\": \"Baseline LSTM-CRF (words only) achieved an F1 score of 82.03. Adding forward LSTM character embeddings improved F1 to 85.15, and further enhancements with backward LSTM characters and POS tags increased performance. The best model (POS3 + Morphological features) achieved an F1 score of 92.20. The confusion matrix showed strong performance across entity types, with minimal misclassifications.\", \"conclusion\": \"The study demonstrates that incorporating morphological information significantly boosts NER performance in morphologically rich languages like Bulgarian. The integration of grammatical features into Bi-LSTM-CRF models leads to state-of-the-art results, showing the approach's adaptability to other Slavic languages and potential applicability to broader multilingual NER tasks.\", \"figures\": null, \"tables\": null}, \"citations\": [\"Alan Akbik, Tanja Bergmann, and Roland V ollgraf.\", \"2019. Pooled contextualized embeddings for named\", \"Language Technologies . Minneapolis, MN, USA,\", \"NAACL-HLT ’19, pages 724–728.\", \"Douglas E. Appelt, Jerry R. Hobbs, John Bear, David\", \"Israel, Megumi Kameyama, David Martin, Karen\", \"Myers, and Mabry Tyson. 1995. SRI international\", \"Understanding . Columbia, MD, USA, MUC6 ’95,\", \"Piotr Bojanowski, Edouard Grave, Armand Joulin, and\", \"Jacob Devlin, Ming-Wei Chang, Kenton Lee, and\", \"Computational Linguistics . Minneapolis, MN, USA,\", \"NAACL-HLT ’2019, pages 4171–4186.\", \"George Doddington, Alexis Mitchell, Mark Przybocki,\", \"Lance Ramshaw, Stephanie Strassel, and Ralph\", \"tion (ACE) program – tasks, data, and evaluation.\", \"bon, Portugal, LREC ’04.\", \"Georgi Georgiev, Preslav Nakov, Kuzman Ganchev,\", \"Petya Osenova, and Kiril Simov. 2009. Feature-\", \"Natural Language Processing . Borovets, Bulgaria,\", \"RANLP ’09, pages 113–117.\", \"Dan Gillick, Cliff Brunk, Oriol Vinyals, and Amarnag\", \"guage Technologies . San Diego, CA, USA, NAACL-\", \"HLT ’16, pages 1296–1306.\", \"Linguistics . Copenhagen, Denmark, COLING ’96,\", \"pages 466–471.Geoffrey E. Hinton, Nitish Srivastava, Alex\", \"Krizhevsky, Ilya Sutskever, and Ruslan Salakhut-\", \"Kaufmann, ICML ’01, pages 282–289.\", \"Guillaume Lample, Miguel Ballesteros, Sandeep Sub-\", \"ramanian, Kazuya Kawakami, and Chris Dyer. 2016.\", \"gies. San Diego, CA, USA, NAACL-HLT ’16, pages\", \"260–270.\", \"The Anh Le, Mikhail Y . Arkhipov, and Mikhail S. Burt-\", \"tion. In Andrey Filchenkov, Lidia Pivovarova, and\", \"JanˇZiˇzka, editors, Artiﬁcial Intelligence and Nat-\", \"ural Language . Springer International Publishing,\", \"Wang Ling, Chris Dyer, Alan W Black, Isabel Tran-\", \"coso, Ram ´on Fermandez, Silvio Amir, Lu ´ıs Marujo,\", \"guage Processing . Lisbon, Portugal, EMNLP ’15,\", \"Xiaodong Liu, Pengcheng He, Weizhu Chen, and Jian-\", \"Xiaodong Liu, Pengcheng He, Weizhu Chen, and Jian-\", \"Yinhan Liu, Myle Ott, Naman Goyal, Jingfei Du, Man-\", \"dar Joshi, Danqi Chen, Omer Levy, Mike Lewis,\", \"Luke Zettlemoyer, and Veselin Stoyanov. 2019c.\", \"Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey\", \"Alexandre Passos, Vineet Kumar, and Andrew McCal-\", \"guage Learning . Ann Arbor, MI, USA, CoNLL ’14,\", \"Jeffrey Pennington, Richard Socher, and Christopher\", \"ing. Doha, Qatar, EMNLP ’14, pages 1532–1543.\", \"Matthew Peters, Mark Neumann, Mohit Iyyer, Matt\", \"Gardner, Christopher Clark, Kenton Lee, and Luke\", \"Technologies . New Orleans, LA, USA, NAACL-\", \"HLT ’18, pages 2227–2237.\", \"Jakub Piskorski, Peter Homola, Małgorzata Marciniak,\", \"Agnieszka Mykowiecka, Adam Przepi ´orkowski,\", \"Mieczysław A. Kłopotek, Sławomir T. Wierzcho ´n,\", \"and Krzysztof Trojanowski, editors, Intelligent In-\", \"Berlin Heidelberg, pages 227–236.\", \"Jakub Piskorski, Laska Laskova, Michał Marci ´nczuk,\", \"Lidia Pivovarova, Pavel P ˇrib´aˇn, Josef Steinberger,\", \"lingual challenge on recognition, normalization,\", \"classiﬁcation, and linking of named entities across\", \"Florence, Italy, BSNLP ’19, pages 63–74.\", \"Jakub Piskorski, Lidia Pivovarova, Jan ˇSnajder, Josef\", \"Steinberger, and Roman Yangarber. 2017. The ﬁrst\", \"cross-lingual challenge on recognition, normaliza-\", \"tion, and matching of named entities in Slavic lan-\", \"cia, Spain, BSNLP ’17, pages 76–85.\", \"guage Processing . Vancouver, Canada, EMNLP ’05,\", \"Hasim Sak, Andrew W. Senior, and Franc ¸oise Beau-\", \"Iman Saleh, Scott Cyphers, Jim Glass, Shaﬁq Joty,\", \"Llu´ıs M `arquez, Alessandro Moschitti, and Preslav\", \"beling. In Proceedings of the 25th InternationalConference on Computational Linguistics . Dublin,\", \"Ireland, COLING ’14, pages 193–202.\", \"Kiril Simov, Petya Osenova, Alexander Simov, and\", \"Journal of Research on Language and Computation,\", \"Special Issue . Kluwer Academic Publishers, pages\", \"495–522.\", \"Kiril Simov, Petya Osenova, and Milena Slavcheva.\", \"2004b. BTB-TR03: BulTreeBank Morphosyntactic\", \"Tagset. BulTreeBank Project, IICT-BAS.\", \"Jana Strakov ´a, Milan Straka, and Jan Haji ˇc. 2013. A\", \"In Ivan Habernal and V ´aclav Matou ˇsek, editors,\", \"Text, Speech, and Dialogue . Springer Berlin Heidel-\", \"Emma Strubell, Patrick Verga, David Belanger, and\", \"ods in Natural Language Processing . Copenhagen,\", \"Denmark, EMNLP ’17, pages 2670–2680.\", \"Yu Sun, Shuohuan Wang, Yukun Li, Shikun Feng, Hao\", \"Tian, Hua Wu, and Haifeng Wang. 2019. ERNIE\", \"2.0: A continual pre-training framework for lan-\", \"Conference on Natural Language Learning . Taipei,\", \"Taiwan, COLING ’02, pages 1–4.\", \"2003. Introduction to the CoNLL-2003 shared\", \"on Natural Language Learning . Edmonton, Canada,\", \"CoNLL ’03, pages 142–147.\", \"Ashia C. Wilson, Rebecca Roelofs, Mitchell Stern,\", \"Nati Srebro, and Benjamin Recht. 2017. The\", \"Beach, CA, USA, NIPS ’17, pages 4151–4161.\", \"Zhilin Yang, Zihang Dai, Yiming Yang, Jaime G.\", \"Carbonell, Ruslan Salakhutdinov, and Quoc V .\", \"ciation for Computational Linguistics . Philadelphia,\", \"PA, USA, ACL ’02, pages 473–480.\"], \"error\": null}, \"304795a3\": {\"success\": true, \"paper_id\": \"304795a3\", \"url\": \"https://arxiv.org/pdf/2112.04189v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_304795a3.pdf\", \"extracted_info\": {\"title\": \"End-to-End Paragraph-Level Handwriting and Named Entity Recognition\", \"authors\": [\"M. A. Souibgui\", \"A. Fornès\", \"Y. Kessentini\", \"C. Tudor\"], \"abstract\": \"The paper proposes an end-to-end neural network architecture that jointly performs handwriting recognition (HTR) and named entity recognition (NER) at the paragraph level. This approach aims to overcome limitations of traditional line-level methods, such as irreversible segmentation errors, by leveraging larger contextual information for improved semantic tag extraction in handwritten documents.\", \"methodology\": \"The proposed method integrates HTR and NER into a single-stage, end-to-end transformer-based architecture. ResNet-50 is used as the backbone feature extractor. Positional encoding is applied in both 2D and 1D forms to capture spatial and sequential features. The system is trained and evaluated using different strategies (one-stage, two-stage, mixed-level) and tag representations (joint vs. separate). Experiments are conducted on datasets from the IEHHR competition and the FHMR dataset to assess performance under varying complexities and languages.\", \"results\": \"Joint tag representation achieved higher accuracy (Basic: 95.74%, Complete: 95.127%) compared to separate tags (Basic: 93.2%, Complete: 91.5%). Two-stage mixed-level learning yielded the best performance (Basic: 96.25%, Complete: 95.+). Compared to the best IEHHR competition method, the proposed approach showed gains of +2.09% (Basic) and +3.57% (Complete). On the FHMR dataset, the proposed transformer joint model achieved 86.11% (Basic) and 77.26% (Complete), outperforming Transformer+CamemBERT and CRNN-based methods.\", \"conclusion\": \"The key contributions include: (1) introducing a paragraph-level joint HTR and NER approach to avoid early segmentation errors; (2) designing an end-to-end transformer-based architecture with ResNet-50 backbone and dual positional encoding; (3) demonstrating that joint tag representation improves accuracy over separate tagging; (4) achieving state-of-the-art results on IEHHR and FHMR datasets without using dictionaries, language models, or post-processing; (5) validating the method’s robustness across different languages and complex document layouts.\", \"figures\": null, \"tables\": null}, \"citations\": [\"[1] M. A. Souibgui, A. Forn´ es, Y. Kessentini, C. Tudor, A few-shot learn-\", \"ing approach for historical ciphered manuscript recognition, in: 2020 25th\", \"International Conference on Pattern Recognition (ICPR), 2021, pp. 5413–\", \"5420. doi:10.1109/ICPR48806.2021.9413255 .\", \"[2] A. Hamdi, A. Jean-Caurant, N. Sidere, M. Coustaty, A. Doucet, An anal-\", \"ysis of the performance of named entity recognition over ocred documents,\", \"in: 2019 ACM/IEEE Joint Conference on Digital Libraries (JCDL), 2019,\", \"[3] T. Ruokolainen, K. Kettunen, Name the name - named entity recognition in\", \"[4] M. Dinarelli, S. Rosset, Tree-structured named entity recognition on OCR\", \"data: Analysis, processing and results, in: Proceedings of the Eighth Inter-\", \"national Conference on Language Resources and Evaluation (LREC’12),\", \"European Language Resources Association (ELRA), Istanbul, Turkey,\", \"2012, pp. 1266–1272.\", \"[5] V. Romero, A. Forn´ es, E. Granell, E. Vidal, J. A. S´ anchez, Information\", \"extraction in handwritten marriage licenses books, in: Proceedings of the\", \"5th International Workshop on Historical Document Imaging and Process-\", \"ing, HIP ’19, Association for Computing Machinery, New York, NY, USA,\", \"2019, p. 66–71.\", \"[6] M. Carbonell, M. Villegas, A. Forn´ es, J. Llad´ os, Joint recognition of hand-\", \"written text and named entities with a neural end-to-end model, in: 2018\", \"18\", \"13th IAPR International Workshop on Document Analysis Systems (DAS),\", \"2018, pp. 399–404.\", \"[7] M. Carbonell, A. Forn´ es, M. Villegas, J. Llad´ os, A neural model for text lo-\", \"calization, transcription and named entity recognition in full pages, Pattern\", \"[8] J. I. Toledo, S. Sudholt, A. Forn´ es, J. Cucurull-Juan, G. A. Fink, J. Llad´ os,\", \"and spatial pyramid pooling, in: S+SSPR, 2016.\", \"[9] J. I. Toledo, M. Carbonell, A. Forn´ es, J. Llad´ os, Information extraction\", \"model, Pattern Recognition 86 (2019) 27 – 36.\", \"[10] Y. Deng, A. Kanervisto, J. Ling, A. M. Rush, Image-to-markup generation\", \"with coarse-to-ﬁne attention, in: Proceedings of the 34th International Con-\", \"ference on Machine Learning - Volume 70, ICML’17, JMLR.org, 2017, p.\", \"980–989.\", \"[11] J. Michael, R. Labahn, T. Gr¨ uning, J. Z¨ ollner, Evaluating sequence-to-\", \"sequence models for handwritten text recognition, in: 2019 International\", \"Conference on Document Analysis and Recognition (ICDAR), 2019, pp.\", \"1286–1293.\", \"[12] L. Kang, P. Riba, M. Rusi˜ nol, A. Forn´ es, M. Villegas, Pay attention to\", \"what you read: Non-recurrent handwritten text-line recognition, CoRR\", \"[13] M. A. Souibgui, Y. Kessentini, De-gan: A conditional generative adver-\", \"sarial network for document enhancement, IEEE Transactions on Pattern\", \"3022406 .\", \"[14] O. Mechi, M. Mehri, R. Ingold, N. Essoukri Ben Amara, Text line segmen-\", \"tation in historical document images using an adaptive u-net architecture,\", \"19\", \"(ICDAR), 2019, pp. 369–374.\", \"[15] T. Monnier, M. Aubry, docextractor: An oﬀ-the-shelf historical document\", \"element extraction, in: 2020 17th International Conference on Frontiers in\", \"Handwriting Recognition (ICFHR), 2020, pp. 91–96.\", \"[16] Z. Xie, Y. Huang, L. Jin, Y. Liu, Y. Zhu, L. Gao, X. Zhang, Weakly su-\", \"pervised precise segmentation for historical document images, Neurocom-\", \"[17] T. Bluche, J. Louradour, R. Messina, Scan, attend and read: End-to-end\", \"handwritten paragraph recognition with mdlstm attention, in: 2017 14th\", \"(ICDAR), Vol. 01, 2017, pp. 1050–1055.\", \"[18] D. Coquenet, C. Chatelain, T. Paquet, End-to-end handwritten paragraph\", \"03868 .\", \"[19] M. Yousef, T. E. Bishop, Origaminet: Weakly-supervised, segmentation-\", \"free, one-step, full page text recognition by learning to unfold, CoRR\", \"[20] M. Schall, M. Schambach, M. O. Franz, Multi-dimensional connectionist\", \"classiﬁcation: Reading text in one step, in: 2018 13th IAPR International\", \"Workshop on Document Analysis Systems (DAS), 2018, pp. 405–410.\", \"[21] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez,\", \"u. Kaiser, I. Polosukhin, Attention is all you need, in: Proceedings of the\", \"31st International Conference on Neural Information Processing Systems,\", \"NIPS’17, Curran Associates Inc., Red Hook, NY, USA, 2017, p. 6000–6010.\", \"[22] A. Forn´ es, V. Romero, A. Bar´ o, J. I. Toledo, J. A. S´ anchez, E. Vidal,\", \"J. Llad´ os, Icdar2017 competition on information extraction in historical\", \"20\", \"handwritten records, in: 2017 14th IAPR International Conference on Doc-\", \"ument Analysis and Recognition (ICDAR), Vol. 01, 2017, pp. 1389–1394.\", \"[23] K. He, X. Zhang, S. Ren, J. Sun, Deep residual learning for image recogni-\", \"tion, in: 2016 IEEE Conference on Computer Vision and Pattern Recogni-\", \"tion (CVPR), 2016, pp. 770–778.\", \"[24] J. Lee, S. Park, J. Baek, S. Oh, S. Kim, H. Lee, On recognizing texts\", \"of arbitrary shapes with 2d self-attention, in: 2020 IEEE/CVF Conference\", \"on Computer Vision and Pattern Recognition Workshops (CVPRW), IEEE\", \"Computer Society, Los Alamitos, CA, USA, 2020, pp. 2326–2335.\", \"[25] V. Romero, A. Forn´ es, N. Serrano, J. A. S´ anchez, A. H. Toselli, V. Frinken,\", \"E. Vidal, J. Llad´ os, The esposalles database: An ancient marriage license\", \"corpus for oﬀ-line handwriting recognition, Pattern Recognition 46 (6)\", \"(2013) 1658 – 1669.\", \"[26] M. Dhiaf, S. Khamekhem, Y. Kessentini, Docner: A deep learning system\", \"for named entity recognition in handwritten document images, in: 28th\", \"International Conference on Neural Information Processing, 2021.\", \"[27] L. Martin, B. M¨ uller, P. J. O. Su´ arez, Y. Dupont, L. Romary, ´E. V. de la\", \"Clergerie, D. Seddah, B. Sagot, Camembert: a tasty french language model,\", \"21\", \"1\", \"Ahmed Cheikh Rouhoua,∗∗, Marwa Dhiafa,b,c, Yousri Kessentinib,c, Sinda Ben Salema\", \"cSM@RTS : Laboratory of Signals, systeMs, aRtiﬁcial Intelligence and neTworkS\", \"Named-Entity-Recognition, Text\", \"Block Recognition, Transformer,\", \"tion as separate subsequent tasks, we propose in this paper an end-to-end trans-\", \"operates at the paragraph level, which brings two main beneﬁts. First, it allows\", \"the model to avoid unrecoverable early errors due to line segmentation. Second,\", \"tify the semantic categories, reaching a higher ﬁnal prediction accuracy. We also\", \"higher ﬁnal prediction accuracy. As far as we know, this work presents the ﬁrst\", \"ICDAR 2017 Information Extraction competition using the Esposalles database,\", \"for the complete task, even though the proposed technique does not use any dic-\", \"tionaries, language modeling, or post-processing.\", \"1. Introduction\", \"In the last decades, researchers have been exploring\", \"tual information from images. Lately, optical character\", \"covering texts from modern documents. However, they\", \"information [ ?], there is an increasing interest within the\", \"In this context, Named Entity Recognition (NER) from\", \"tical problems, which consists of transcribing textual con-\", \"tents and classifying them into semantic categories (names,\", \"organizations, locations, etc). 20\", \"In the literature, traditional NER methods on docu-\", \"cess, and then Natural Language Processing (NLP) tech-\", \"of deep learning-based NLP systems, the performance of\", \"2\", \"the HTR processing step. Generally, errors of the HTR\", \"stage due to the low-quality scans, for example, aﬀect the 30\", \"step. However, this approach does not use the context sur- 40\", \"rounding the word to be classiﬁed, which might be critical\", \"work to integrate a larger context, achieving better results\", \"compared to [ ?]. Still, in this work, the context is lim- 45\", \"ited to the line level, which aﬀects the extraction of se-\", \"context, authors in [ ?] propose an end-to-end model that\", \"jointly performs handwritten text detection, transcription,\", \"and named entity recognition at the page level, capable 50\", \"approach presents two main drawbacks. First, it requires\", \"word bounding box annotation, which is a huge cost saving\", \"in the real application. Second, the proposed multi-task\", \"Recently, inspired by their success in many NLP appli-\", \"cations, Sequence-to-Sequence (Seq2Seq) approaches using\", \"cently, authors in [ ?] propose an architecture inspired 65\", \"by transformers, which dispenses any recurrent network\", \"For handwritten historical document recognition, the\", \"written texts (inconsistent spaces between lines, charac-\", \"ters of successive lines can be overlaid, etc.), text images 75\", \"[?] or to improve the segmentation quality in historical\", \"documents [ ? ? ? ]. However, in most cases, the segmen- 80\", \"Lately, researchers have been examining the recognition of\", \"step [ ? ?], following two categories of approaches. In the\", \"ﬁrst category, the text-block images are transformed into 85lines representation using convolution layers [ ?] or at-\", \"tention mechanism [ ?], in order to perform Connectionist\", \"approach, feature extraction conserves the 2D represen-\", \"tation of the text block, then, the decoding is performed 90\", \"ture [ ?]. As far as we know, there have been no works\", \"Motivated by the above observations, we propose in 95\", \"our knowledge, this is the ﬁrst study that involves the\", \"is to surpass the line segmentation problems, as well as\", \"end, our ﬁrst contribution consists in adapting the trans-\", \"the input text block. For this aim, the 2D features maps\", \"1D sequential features using ﬂattening operation. In order\", \"to add positional information, we have tested two posi-\", \"ing, mixed-data learning, and curriculum learning to show 115\", \"and named entity recognition at the paragraph level,\", \"stage learning, mixed-data learning, and curriculum\", \"not use any dictionaries, language modeling, or post-\", \"processing, we achieve new state-of-the-art perfor-\", \"3\", \"2. Proposed Approach 145\", \"end neural network architecture, shown in ﬁgure 1, that\", \"ple 2D convolutional layer. After, the 2D positions encod- 155\", \"mation to each feature vector. Next, the 2D features map\", \"function. At this level, this sequence matches the require-\", \"mechanism on the visual-features-sequence. Finally, the\", \"1D positional encoding technique then to the transformer\", \"decoder, where visual encoded features are matched with 165\", \"2.1. Multi-line feature extraction\", \"To perform HTR and named entity recognition, text 170\", \"representation. In this approach, we deal with paragraph-\", \"level images, where the number of lines per paragraph is\", \"tual entities in images. Moreover, we duplicate the image\", \"chitecture. Next, the image is resized to match the pro-\", \"operation is not mandatory, but experiments have proved\", \"ward, we have chosen to use ResNet-50 [ ?] as our feature\", \"extractor, also called backbone architecture. The ResNet\", \"32185\", \"32) with a contextualized view of the full\", \"hidden-size (hidden) hyper-parameter of the transformer,\", \"we added a 2D-convolutional layer ( Conv 2D), preserving\", \"the same height/width dimensions of the input, that trans-\", \"architecture, and Adaptive 2D Position Encoding (A2DPE)\", \"[?] is applied, to add 2D positional information to the fea-\", \"two-dimensional inputs, which ﬁts best with our proposed\", \"A2DPE (E) ={Eh,w+POS h,w}\", \"whereEh,wrepresents a feature vector at position ( h,w)\", \"obtained from Conv 2DandPOS h,ware the positional en- 205\", \"1,Wh\", \"2,Ww\", \"1,Ww\", \"2):\", \"α(E) =sigmoid (max(0,g(E)Wh\", \"1)Wh\", \"2),\", \"β(E) =sigmoid (max(0,g(E)Ww\", \"1)Ww\", \"2)(2)\", \"POS h,w=α(E)/tildewidePh+β(E)/tildewidePw (3)\", \"/tildewidePp,2i=sin(p/100002i/D),\", \"/tildewidePp,2i+1=cos(p/100002i/D)(4)\", \"mensions, respectively.\", \"age, we obtain a features sequence of the whole image in- 220\", \"2.2. Transformer-based sequence labeling\", \"In our approach, we utilize the transformer architec-\", \"2.2.1. Feature sequence encoding\", \"4\", \"tity, in the input sequence. The self-attention mechanism\", \"FEncoder ={v0,v1,..vSeqLen−1}\", \"whereSeqlen=h/prime×w/prime,Krepresents the key, Vrepre-\", \"sents the value, qi∈Qandi={0,..,Seq len−1}represents\", \"2.2.2. Text and named entity decoder\", \"sop > ), the end of line ( < eol > ), the end of paragraph 250\", \"<eop> , and named entities tags ([ tag]). All these labels\", \"The input of the decoder, as shown in ﬁgure 2, is the\", \"< eop > tags, and contains the possible tags (placed be-\", \"fore their relative word). After preparing the input text,\", \"mension. Then, the ﬁnal input of the transformer decoder\", \"(Flabels ) is prepared by applying 1D Positional encoding 260\", \"(1DPE) [ ?] to the embedded labels. The transformer\", \"formation, due to the self-attention mechanism involved,\", \"coded features. In the recurrent networks, the decoding 265\", \"learns the relation between diﬀerent characters and tags, 270\", \"nally, a linear layer transforms the output of the decoder\", \"into classes ( NBclass), followed by Softmax andArg−\", \"2.3. Named entities encoding\", \"In the previous section, we have shown that labels of\", \"them. Given a paragraph composed of Nwords,Mtags,\", \"andLlines, the encoding is presented as shown in ﬁgure\", \"2.\", \"In this study, two types of named entities are avail-\", \"(name, occupation, location, etc). The person tags ( Ptags)\", \"provide the person associated to each category (husband,\", \"wife, wife’s father, etc). The full list of tags is described\", \"1. Single Separate tagging: the category and person\", \"[husband]. As a result, each named entity should\", \"2. Joint tagging: a single tag is assigned to each named\", \"entity, where the tag contains the category and the\", \"5\", \"Following this encoding, the model learns to predict NE\", \"2.4. Two-stage learning 295\", \"In this work, we propose to train the architecture using\", \"training the model for HTR only, i.e. named entity tags\", \"pre-training, where the model learns how to recognize the 300\", \"In the second stage, the model is ﬁnetuned using the\", \"applying this stage, the model can perform the recognition\", \"2.5. Mixed-level learning vs Curriculum learning\", \"the paragraph level. Nevertheless, we believe that train-\", \"ing it on diﬀerent levels of input (1-line bloc, 2-lines, ...,\", \"aim, we propose two diﬀerent scenarios named mixed-level\", \"ing scenario, the model is learned in one stage on a collec-\", \"curriculum learning scenario, our model starts with learn- 320\", \"creases the number of lines in the bloc (2-lines, 3-lines, etc)\", \"work. The ﬁrst one, denoted curriculum sequential learn-\", \"ing, consists of training the model progressively on text\", \"put (1-line bloc, 2-lines, ..., paragraph). When the training\", \"reaches the paragraph-level images, a ﬁnal ﬁne-tuning is 330\", \"learning, where the model alternates the training on text\", \"3. Experiments 335\", \"3.1. Datasets\", \"(IEHHR) competition [ ?]. This dataset is a subset of 340\", \"ten pages, containing 1221 marriage records (paragraphs).\", \"mation of the husband, wife, and their parent’s names, 345\", \"occupations, locations, and civil states. We have used\", \"872 records for training, 96 records for validation, and 253records for evaluation.\", \"[?]. FHMR is a private dataset that provides a collec-\", \"contains several text lines giving information of the wife,\", \"husband, and their parent’s names, occupations, locations, 355\", \"shown in Figure 3. We have used 997, 103, 132 records for\", \"the training, the validation, and the evaluation, respec-\", \"3.2. Metrics\", \"In this study, we utilize the same metrics used in the\", \"egory tags, at a ﬁrst level, the person tags, at a second\", \"level, then text recognition accuracy at a ﬁnal level. We\", \"recognition accuracy, and the complete score considers all 370\", \"3.3. Ablation study\", \"model, we have performed an ablation study online and 375\", \"put image size, positional encoding algorithm, hidden size,\", \"heads, and layers of the transformer. For the positional en-\", \"coding operation, we have tested also the 1DPE algorithm 380\", \"ter the multi-line ﬂattening operation, where features are\", \"made with image size greater than 384 ×1024, heads >1,\", \"6\", \"levels. Concerning the hyper-parameters, the best perfor-\", \"and self-attention sizes, 1 attention-head, and 2 layers. We\", \"age input is a paragraph for both tasks (basic, complete) 400\", \"tic NE while considering only a single line image, due to\", \"For the next experiments, we keep the best hyper-\", \"3.4. Results of diﬀerent NE encoding 410\", \"As explained in section 2, our study is conducted us-\", \"As presented in table 2, the joint tagging gave better 415\", \"of tags. As an explanation, it is simpler for the decoder to\", \"choose a combined tag instead of two separated tags. Also,\", \"using a single tag approach, the system wrongly detects\", \"3.5. Results of the diﬀerent learning strategies\", \"ing one-stage learning, two-stage learning, mixed-level learn-\", \"ing, curriculum sequential learning and curriculum dual\", \"As shown in Table 3, the two-stage learning (learn-\", \"(learning directly on text transcription and NE tags). AnTable 3. Results of the diﬀerent learning strategies.\", \"images in the training. As shown in table 3, the best per-\", \"3.6. Comparaison with IEHHR Competition\", \"in table 4, our model presents the best performance with\", \"complete scores, compared to the best method perform-\", \"1. This result conﬁrms the suitability of the proposed ap-\", \"proach even though it does not use any dictionaries, lan-\", \"guage modeling, or post-processing. 455\", \"3.7. FHMR Results\", \"1https://rrc.cvc.uab.es/?ch=10&com=evaluation&task=1\", \"7\", \"[?] 90.58 89.39 Line\", \"second approach relies on two stages, the ﬁrst stage em-\", \"text, while the second seeks to locate semantic entities\", \"Compared to the ”CRNN joint” model, ”Transformer\", \"the basic task, which is the simplest one. This can be ex-\", \"compared to CRNN. On the contrary, for the complete 475\", \"task, which is more complex as the semantic category of\", \"NE need to be identiﬁed, ”CRNN joint” model achieves a\", \"the named entities. As shown in table 5, the best perfor- 480\", \"4. Conclusion 485\", \"In this paper, we have proposed an end-to-end architec-\", \"as we know, it is the ﬁrst approach that adopts the trans-\", \"subsequent tasks (HTR and NLP), the proposed methodjointly learns these two tasks on only one stage. De-\", \"ule, conﬁrming the suitability of the proposed method by 495\", \"capturing more contextual information. Indeed, the pre-\", \"naries, language modeling, or post-processing. In our fu-\", \"ture work, we can scale the proposed approach to work on 500\", \"page-level images, where recent alternatives of the trans-\", \"former have been proposed (TransformerXL, Performer,\", \"etc). Also, we can investigate the impact of using the\"], \"error\": null}, \"1f21ae51\": {\"success\": true, \"paper_id\": \"1f21ae51\", \"url\": \"https://arxiv.org/pdf/1908.09138v2\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_1f21ae51.pdf\", \"extracted_info\": {\"title\": \"Reformulating Named Entity Recognition as Machine Reading Comprehension\", \"authors\": [\"Not specified in provided content\"], \"abstract\": \"In this paper, we propose a new strategy for the task of named entity recognition (NER) by reformulating it as a machine reading comprehension (MRC) question answering task. This approach achieves new state-of-the-art (SOTA) results on multiple NER datasets.\", \"methodology\": \"The authors reformalize NER as an MRC task, where natural language queries are constructed to represent entity types, and the model predicts entity spans in the text by answering these queries. The approach leverages pre-trained language models such as BERT for encoding both the query and passage, and applies a scalable transition-based method to handle nested entity structures.\", \"results\": \"The proposed method achieves SOTA results on five NER datasets in English and Chinese: MSRA, RESUME, Chinese OntoNotes, ACE04, and ACE05. Performance surpasses previous best models in precision, recall, and F1 scores across all datasets.\", \"conclusion\": \"The key contributions include: (1) Reformulating NER as an MRC task, enabling the use of powerful QA models for entity recognition; (2) Achieving SOTA results on multiple benchmark datasets in both English and Chinese; (3) Demonstrating scalability and effectiveness for handling nested entity structures; (4) Providing empirical evidence through ablation studies that query-based formulation improves NER performance.\", \"figures\": null, \"tables\": null}, \"citations\": [\"Danqi Chen, Adam Fisch, Jason Weston, and An-\", \"Ronan Collobert, Jason Weston, L ´eon Bottou, Michael\", \"Karlen, Koray Kavukcuoglu, and Pavel Kuksa.\", \"2011. Natural language processing (almost) from\", \"scratch. Journal of Machine Learning Research ,\", \"12(Aug):2493–2537.\", \"Jacob Devlin, Ming-Wei Chang, Kenton Lee, and\", \"George R Doddington, Alexis Mitchell, Mark A Przy-\", \"bocki, Lance A Ramshaw, Stephanie M Strassel, and\", \"extraction (ace) program-tasks, data, and evaluation.\", \"InLrec, volume 2, page 1.\", \"Natural Language Processing: Volume 1-Volume 1 ,\", \"HLT-NAACL 2003-Volume 4 , pages 172–175. Asso-\", \"2018 Conference of the North American Chapter of\", \"man Language Technologies, Volume 1 (Long Pa-\", \"pers) , pages 861–871.J-D Kim, Tomoko Ohta, Yuka Tateisi, and Jun’ichi\", \"tated corpus for bio-textmining. Bioinformatics ,\", \"19(suppl 1):i180–i182.\", \"John Lafferty, Andrew McCallum, and Fernando CN\", \"Guillaume Lample, Miguel Ballesteros, Sandeep Sub-\", \"ramanian, Kazuya Kawakami, and Chris Dyer. 2016.\", \"Processing, SIGHAN@COLING/ACL 2006, Sydney,\", \"Australia, July 22-23, 2006 , pages 108–117.\", \"Omer Levy, Minjoon Seo, Eunsol Choi, and Luke\", \"ods in Natural Language Processing , pages 857–\", \"867.\", \"Bryan McCann, Nitish Shirish Keskar, Caiming Xiong,\", \"Nassir Navab Milletari, Fausto and Seyeds-Ahmad Ah-\", \"2016 Fourth International Conference on 3D Vision\", \"(3DV) .\", \"Matthew E Peters, Mark Neumann, Mohit Iyyer, Matt\", \"Gardner, Christopher Clark, Kenton Lee, and Luke\", \"Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and\", \"Percy Liang. 2016. Squad: 100,000+ questions\", \"2015. Boosting named entity recognition with\", \"Minjoon Seo, Aniruddha Kembhavi, Ali Farhadi, and\", \"Yelong Shen, Po-Sen Huang, Jianfeng Gao, and\", \"on Knowledge Discovery and Data Mining , pages\", \"1047–1055. ACM.\", \"Charles Sutton, Andrew McCallum, and Khashayar Ro-\", \"Learning Research , 8(Mar):693–723.\", \"Bailin Wang, Wei Lu, Yu Wang, and Hongxia Jin. 2018.\", \"Zhiguo Wang, Haitao Mi, Wael Hamza, and Radu\", \"Ralph Weischedel, Sameer Pradhan, Lance Ramshaw,\", \"Martha Palmer, Nianwen Xue, Mitchell Marcus,\", \"Ann Taylor, Craig Greenberg, Eduard Hovy, Robert\", \"Belvin, et al. 2011. Ontonotes release 4.0.\", \"LDC2011T03, Philadelphia, Penn.: Linguistic Data\", \"Wei Wu, Yuxian Meng, Qinghong Han, Muyu Li, Xi-\", \"aoya Li, Jie Mei, Ping Nie, Xiaofei Sun, and Jiwei Li.\", \"2019. Glyce: Glyph-vectors for chinese character\", \"Caiming Xiong, Victor Zhong, and Richard Socher.\", \"2016. Dynamic coattention networks for question\", \"Caiming Xiong, Victor Zhong, and Richard Socher.\", \"2017. Dcn+: Mixed objective and deep residual\", \"Mingbin Xu, Hui Jiang, and Sedtawut Watcharawit-\", \"Papers) , volume 1, pages 1237–1247.\"], \"error\": null}, \"5399a5a9\": {\"success\": true, \"paper_id\": \"5399a5a9\", \"url\": \"https://arxiv.org/pdf/2412.16976v3\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_5399a5a9.pdf\", \"extracted_info\": {\"title\": \"Enhancing Discontinuous Named Entity Recognition with ChatGPT-Coordinated Ensemble Learning\", \"authors\": [\"Y. Wang\", \"L. Wang\", \"M. Rastegar-Mojarad\", \"S. Moon\", \"F. Shen\", \"N. Afzal\", \"et al.\"], \"abstract\": \"Named Entity Recognition (NER) has traditionally been a key task in natural language processing (NLP), aiming to identify and extract important terms from unstructured text data. However, methods to address Discontinuous Named Entity Recognition (DNER) have not been explored using ensemble learning to the best of our knowledge. With the rise of large language models (LLMs) such as ChatGPT, this study investigates integrating ChatGPT as an arbitrator within an ensemble method to enhance DNER performance. The proposed method combines five state-of-the-art (SOTA) NER models with ChatGPT using custom prompt engineering to assess robustness and generalization. Experiments on three benchmark medical datasets (CADEC, ShARe13, ShARe14) show that the fusion of ChatGPT with ensemble learning outperforms SOTA results, achieving F1-score improvements of approximately 1.13%, 0.54%, and 0.67%, respectively, and demonstrating potential for healthcare NLP applications.\", \"methodology\": \"The study integrates ChatGPT as an arbitrator within an ensemble learning framework for DNER tasks. Five deep learning-based SOTA NER models are combined, with outputs standardized into a uniform format containing original sentences and predicted entities. Custom prompt engineering is applied to mitigate issues such as synonym replacement and input order sensitivity. Two ensemble approaches are compared: majority voting and the proposed ChatGPT-coordinated method. Experiments are conducted on three benchmark biomedical datasets (CADEC, ShARe13, ShARe14), with performance evaluated against baseline models, GPT-3.5, GPT-4, and majority voting ensembles.\", \"results\": \"The ChatGPT-coordinated ensemble algorithm outperforms five baseline models, GPT-3.5, GPT-4, and majority voting ensembles in terms of F1-score. Compared to the best baseline (TOE), improvements are 1.13% (CADEC), 0.54% (ShARe13), and 0.67% (ShARe14). Compared to majority voting, improvements are 0.63%, 0.32%, and 0.09%, respectively. Compared to GPT-3.5 and GPT-4, average F1-score gains are approximately 7.42%, 0.89%, and 0.54% higher. The method consistently achieves higher precision and F1-scores across datasets.\", \"conclusion\": \"1. Proposed a novel ensemble learning method using ChatGPT as an arbitrator for DNER tasks.  \\n2. Demonstrated that integrating ChatGPT with multiple deep learning models improves robustness and generalization.  \\n3. Achieved superior performance over SOTA models, majority voting ensembles, and individual LLMs on three benchmark medical datasets.  \\n4. Identified and addressed challenges in prompt engineering, such as synonym replacement and input order sensitivity.  \\n5. Showcased the potential of ChatGPT-coordinated ensemble learning for enhancing NLP applications in the healthcare domain.\", \"figures\": null, \"tables\": null}, \"citations\": [\"1. Y. Wang, L. Wang, M. Rastegar -Mojarad, S. Moon, F. Shen, N. Afzal, et al, \\\"Clinical information extraction applications:\", \"a literature review,\\\" Journal of Biomedical Informatics , vol. 77, pp. 34-49,2018.\", \"2. L. Jing, S. Aixin, H. Jianglei, and L. Chenliang, \\\"A Survey on Deep Learning for Named Entity Recognition,\\\" IEEE\", \"Transactions on Knowledge and Data Engineering , vol. 34, pp. 50 -70, 2020.\", \"3. Z. Huang, W. Xu, and K. Yu, \\\"Bidirectional LSTM -CRF model s for sequence tagging,\\\" arXiv preprint arXiv:1508.01991,\", \"2015.\", \"4. M. Gridach, \\\"Character -level neural network for biomedical named entity recognition,\\\"  Journal of Biomedical Informatics ,\", \"vol. 70, pp. 85 –91, 2017.\", \"5. T. Gui, R. Ma, Q. Zhang, L. Zhao, Y. -G. Jiang , and X. Huang, \\\"CNN based chinese NER with lexicon rethinking,\\\" in\", \"Proceedings of the International Joint Conference on Artificial Intelligence , pp. 4982 – 4988, 2019.\", \"6. X. Mengge, B. Yu, Z. Zhang, T. Liu, Y. Zhang, and B. Wang, \\\"Coarseto -fine pre -training f or named entity recognition,\\\"\", \"in Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing , pp. 6345 –6354, 2020.\", \"7. L. Liu, J. Shang, X. Ren, F. Xu, H. Gui, J. Peng, and J. Han, \\\"Empower sequence labeling with task -aware neural la n-\", \"guage model,\\\" in  Proceedings of the AAAI Conference on Artificial Intelligence , pp. 5253 –5260, 2018.\", \"8. Y. Cao, Z. Hu, T. -S. Chua, Z. Liu, and H. Ji, \\\"Low -resource name tagging learned with weakly labeled data,\\\" in  Pro-\", \"ence on Natural Language Processing , pp. 261–270, 2019.\", \"9. S. Pradhan, N. Elhadad, B. R. South, D. Martinez, L. Christensen, A. Vogel, H. Suominen, W. W. Chapman, and G.\", \"Savova,  \\\"Evaluating the state of the art in disorder recognition and normalization of the clinical narrative,\\\" Journal of\", \"the American Medical Informatics Association , vol. 22, no. 1, pp. 143 –154, 2015.\", \"10. B. Jensen, J. Jensen, and S. Brunak, \\\"Mining electronic heal th records: towards better research applications and clinical\", \"care,\\\" Nature Reviews Genetics , vol. 13, no. 6, pp. 395 -405, 2012.\", \"11. M. A. Khalid, V. Jijkoun, and M. d. Rijke, \\\"The impact of named entity normalization on information retrieval for\", \"question answ ering,\\\"  in Proceedings of the European Conference on Information Retrieval , pp. 705–710, 2008.\", \"12. N. Zara, J. S.Wyed, and M. M. Kamran, \\\"Named entity recognition and relation extraction: State -of-the-art,\\\" ACM\", \"Computing Surveys , vol. 54, no.20, pp. 1 -39, 2021 .\", \"13. B. Tang, J. Hu, X. Wang, and Q. Chen, \\\"Recognizing continuous and discontinuous adverse drug reaction mentions\", \"from social media using LSTM -CRF,\\\" in Proceedings of the Wireless Communications and Mobile Computing , vol. 2018,\", \"2018. [Online]. Available: https://doi.org/10.1155/2018/2379208\", \"14. H. Yan, T. Gui, J. Dai, Q. Guo, Z. Zhang, and X. Qiu, \\\"A unified generative framework for various ner subtasks,\\\" in\", \"ference on Natural Language Processing , pp. 5808 –5822, 2021.\", \"15. H. Fei, D. Ji, B. Li, Y. Liu, Y. Ren, and F. Li, \\\"Rethinking boundaries: End -to-end recognition of discontinuous mentions\", \"with pointer networks,\\\" in Proceedings of the AAAI Conference on Artificial Intelligence , vol. 35, no. 14, pp. 12785 –12793,\", \"2021.\", \"16. Z. Yan, L. Yuexian, Z. Puning, Y. Zhigang, and Z. Rongjian, \\\"Frequent words and syntactic context integrated bio-\", \"medical discontinuous named entity recognition method,\\\" Journal of Supercomputing , vol. 79, pp. 13670 -13695, 2023.\", \"17. R. Speck and A. -C. N. Ngomo, \\\"Ensemble learning for named entity recognition,\\\" International Symposium on Wearable\", \"Computers 2014 , pp. 519–534, 2014.\", \"18. OpenAI. Introducing ChatGpt. Available from: https://openai.com/blog/chatgpt\", \"19. Y. Bang, S.Cahyawijaya, N. Lee, W. Dai, D. Su, B. Wilie, et al., \\\"A multitask, multilingual, multimodal evaluation of\", \"ChatGPT on reasoning, hallucination, and interactivity,\\\" arXiv preprint , arXiv:230204023, 2023.\", \"20. T. Brown, B. Mann, N. Ryder, M. Subbiah, D. Kaplan, P. Dhariwal, et al.,\\\" Language models are few -shot learners,\\\"\", \"Advances in Neural Information Processing Systems , vol. 33, pp. 1877 -901, 2020.\", \"21. J. Achiam, S. Adler, S. Agarwal, L. Ahmad, I. Akkaya, L. Alema n, et al., \\\"Gpt -4 technical report,\\\" arXiv preprint ,\", \"arXiv:230308774, 2023.\", \"22. A. Gilson, W. Safranek, T. Huang, V. Socrates, L. Chi, A. Taylor, et al., \\\"How does CHATGPT perform on the United\", \"knowledge assessment,\\\" JMIR Medical Education , vol. 9, no. 1, e45312, 2023.\", \"23. S. Karimi, A. M. Jimenez, M. Kemp, and C. Wang, \\\"Cadec: A corpus of adverse drug event annotations,\\\" Journal of\", \"Biomedical Informatics , vol.  55, pp. 73 -81, 2015.\", \"24. S. Pradhan, N. Elhadad, B. R. South, D. Martinez, L. M.Christense, A. Vogel, H. Suominen, W. W. Chapman, and G.\", \"K. Savova, \\\"Task 1: ShARe/clef ehealth evaluation lab 2013a,\\\" in  Proceedings of the Conference and Labs of the Evaluation\", \"Forum , pp. 212–31, 2013.\", \"25. D. L. Mowery, S. Velupillai, B. R. South, L. Christensen, D. Martinez, L. Kelly, L. Goeuriot, N. Elhadad, S. Pradhan, G.\", \"Savova, et al., \\\"Task 2: Share/clef ehealth evaluation lab 2014,\\\" in  Proceedings of the Conference and Labs of  the Evaluation\", \"Forum , pp. 31–42, 2014.\", \"13\", \"26. J. Wang, E. Shi, S. Yu, Z. Wu, C. Ma, H. Dai, et al., \\\"Prompt engineering for healthcare: Methodologies and applica-\", \"tions,\\\" arXiv preprint , arXiv:230414670, 2023.\", \"27. F. Yu, L. Quartey, and F. Schilder, \\\"Exploring the eff ectiveness of prompt engineering for legal reasoning tasks,\\\" in\", \"Findings of the Association for Computational Linguistics: ACL 2023 , pp. 13582 –13596, 2023.\", \"28. C. Ma. \\\"Prompt engineering and calibration for zero -shot commonsense reasoning,\\\" arXiv preprint , arXiv:230406962,\", \"2023.\", \"29. C. Hsueh, Y. Zhang, Y. Lu, J Han, and W. Meesawad, \\\"NCU -IISR: Prompt engineering on GPT -4 to stove biological\", \"problems in BioASQ 11b phase B,\\\" 11th BioASQ Workshop at the 14th Conference and Labs of the Evaluation Forum , 2023.\", \"30. S. Chen, Y. Li, S. Lu, H. Van, J. Aerts, K. Savova, et al, \\\"Evaluation of ChatGPT family of models for biomedical rea-\", \"soning and classification,\\\" arXiv preprint , arXiv:230402496, 2023.\", \"31. K X. Dai, S. Karimi, B. Hachey, and C. Paris, \\\"An effective transition -based mode l for discontinuous NER,\\\" in  Proceed-\", \"ings of the 58th Annual Meeting of the Association for Computational Linguistics , pp. 5860 –5870, 2020.\", \"32. F. Li, Z. Lin, M. Zhang, and D. Ji, \\\"A span -based model for joint overlapped and discontinuous named entity recog-\", \"nition,\\\" in  Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International\", \"Joint Conference on Natural Language Processing , pp. 4814 –4828, 2021.\", \"33. Y. Wang, B. Yu, H. Zhu, T. Liu, N. Yu, and L. Sun, \\\"Discontinuo us named entity recognition as maximal clique dis-\", \"covery,\\\" in  Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International\", \"Joint Conference on Natural Language Processing , pp. 764–774, 2021.\", \"34. J. Li, H. Fe i, J. Liu, S. Wu, M. Zhang, C. Teng, D. Ji, and F. Li, \\\"Unified named entity recognition as word -word relation\", \"classification,\\\"  in Proceedings of the 11th AAAI Conference on Artificial Intelligence , pp. 10 965 –10 973, 2022.\", \"35. J. Liu, D.Ji, J. Li, D. Xie, C. Teng, L. Zhao, and F. Li. \\\"TOE: A grid -tagging discontinuous NER model enhanced by\", \"embedding tag/word relations and more fine -grained tags,\\\" IEEE/ACM Transactions on Audio, Speech, and Language\", \"Processing , vol. 31, pp. 177 -187, 2023.\", \"36. F. Huang, G. Xie, and R. Xiao, \\\"Research on ensemble learning,\\\" in Proceedings of International Conference on Artificial\", \"Intelligence and Computational Intelligence , pp. 249–252, 2009.\", \"37. T. Dietterich, et al.,\\\" Ensemble learning,\\\" The Handbook of B rain Theory and Neural Networks , vol. 2, p. 110 –25, 2002.\"], \"error\": null}, \"54e85f2d\": {\"success\": false, \"paper_id\": \"54e85f2d\", \"url\": \"#conclusion\\\" aria-hidden=\\\"true\\\" tabindex=\\\"-1\\\"><span class=\\\"icon icon-link\\\"></span></a>Conclusion</h1><p>NER extracts structured entities from unstructured text. Key takeaways:</p><p><strong>Understanding NER:</strong></p><ul><li>BIO tagging handles multi-token entities</li><li>Entity types depend on your use case</li><li>Evaluation must be entity-level, not token-level</li></ul><p><strong>Choosing an approach:</strong></p><ul><li>Rule-based for known patterns</li><li>spaCy statistical for general production use</li><li>Transformers for maximum accuracy</li><li>Combine approaches for best results</li></ul><p><strong>Custom training:</strong></p><ul><li>Needed for domain-specific entities</li><li>Quality of labels matters more than quantity</li><li>200-500 diverse examples is a good starting point</li></ul><p><strong>Production tips:</strong></p><ul><li>Use batch processing (<code>nlp.pipe</code>)</li><li>Start simple, add complexity as needed</li><li>Monitor and iterate on real data</li></ul><h1 id=\\\"references\\\"><a href=\\\"#references\\\" aria-hidden=\\\"true\\\" tabindex=\\\"-1\\\"><span class=\\\"icon icon-link\\\"></span></a>References</h1><ul><li><a target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\" href=\\\"https://spacy.io/usage/linguistic-features#named-entities\\\">spaCy NER Documentation</a> - Production NLP library.</li><li><a target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\" href=\\\"https://huggingface.co/docs/transformers/tasks/token_classification\\\">Hugging Face Token Classification</a> - Transformer-based NER.</li><li><a target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\" href=\\\"https://github.com/chakki-works/seqeval\\\">seqeval</a> - Sequence labeling evaluation.</li><li>Devlin, J., et al. (2019). <a target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\" href=\\\"https://arxiv.org/abs/1810.04805\\\">&quot;BERT: Pre-training of Deep Bidirectional Transformers&quot;</a>. NAACL 2019.</li><li><a target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\" href=\\\"https://catalog.ldc.upenn.edu/docs/LDC2013T19/OntoNotes-Release-5.0.pdf\", \"pdf_path\": null, \"extracted_info\": null, \"error\": \"download failed: request failed: No connection adapters were found for '#conclusion\\\" aria-hidden=\\\"true\\\" tabindex=\\\"-1\\\"><span class=\\\"icon icon-link\\\"></span></a>Conclusion</h1><p>NER extracts structured entities from unstructured text. Key takeaways:</p><p><strong>Understanding NER:</strong></p><ul><li>BIO tagging handles multi-token entities</li><li>Entity types depend on your use case</li><li>Evaluation must be entity-level, not token-level</li></ul><p><strong>Choosing an approach:</strong></p><ul><li>Rule-based for known patterns</li><li>spaCy statistical for general production use</li><li>Transformers for maximum accuracy</li><li>Combine approaches for best results</li></ul><p><strong>Custom training:</strong></p><ul><li>Needed for domain-specific entities</li><li>Quality of labels matters more than quantity</li><li>200-500 diverse examples is a good starting point</li></ul><p><strong>Production tips:</strong></p><ul><li>Use batch processing (<code>nlp.pipe</code>)</li><li>Start simple, add complexity as needed</li><li>Monitor and iterate on real data</li></ul><h1 id=\\\"references\\\"><a href=\\\"#references\\\" aria-hidden=\\\"true\\\" tabindex=\\\"-1\\\"><span class=\\\"icon icon-link\\\"></span></a>References</h1><ul><li><a target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\" href=\\\"https://spacy.io/usage/linguistic-features#named-entities\\\">spaCy NER Documentation</a> - Production NLP library.</li><li><a target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\" href=\\\"https://huggingface.co/docs/transformers/tasks/token_classification\\\">Hugging Face Token Classification</a> - Transformer-based NER.</li><li><a target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\" href=\\\"https://github.com/chakki-works/seqeval\\\">seqeval</a> - Sequence labeling evaluation.</li><li>Devlin, J., et al. (2019). <a target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\" href=\\\"https://arxiv.org/abs/1810.04805\\\">&quot;BERT: Pre-training of Deep Bidirectional Transformers&quot;</a>. NAACL 2019.</li><li><a target=\\\"_blank\\\" rel=\\\"noopener noreferrer\\\" href=\\\"https://catalog.ldc.upenn.edu/docs/LDC2013T19/OntoNotes-Release-5.0.pdf'\"}, \"770dd303\": {\"success\": true, \"paper_id\": \"770dd303\", \"url\": \"https://arxiv.org/pdf/2109.15121v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_770dd303.pdf\", \"extracted_info\": {\"title\": \"Feature-rich Named Entity Recognition for Bulgarian using Conditional Random Fields\", \"authors\": [\"D. E. Appelt\", \"J. R. Hobbs\", \"J. Bear\", \"D. Israel\", \"M. Kameyama\", \"A. Kehler\", \"D. Martin\", \"K. Myers\", \"Y. Benajiba\", \"M. Diab\", \"P. Rosso\", \"A. McCallum\", \"W. Li\", \"E. F. Tjong Kim Sang\", \"J. Z\"], \"abstract\": \"The paper presents a feature-rich approach to the automatic recognition and categorization of named entities in Bulgarian, achieving results comparable to state-of-the-art systems for English. The approach leverages conditional random fields and a variety of linguistic and domain-specific features to improve performance.\", \"methodology\": \"The study employs a statistical sequence tagging model based on conditional random fields (CRFs) for named entity recognition. A rich set of features is used, including orthographic, gazetteer-based, local and nonlocal morphological, feature induction, and mutual information features. Experiments are conducted incrementally by adding different feature sets to observe their impact on precision, recall, and F1-score. The BIO tagging scheme is applied for entity classification into categories such as person, organization, location, and miscellaneous.\", \"results\": \"Baseline orthographic features achieved an F1-score of 82.14%. Adding domain-specific features improved performance to 84.57%, gazetteers to 84.27%, local morphology to 87.80%, nonlocal morphology to 87.86%, feature induction to 88.97%, and mutual information to 89.73%. The best overall performance reached 90.38% precision, 88.44% recall, and 89.40% F1-score, outperforming reported results for other Slavic languages and approaching state-of-the-art English NER results.\", \"conclusion\": \"The paper demonstrates that CRF models with carefully engineered, language-specific and general-purpose features can achieve high accuracy in Bulgarian named entity recognition. It is the first statistical approach for Bulgarian NER, surpassing results for other Slavic languages and showing that feature-rich modeling is crucial for high performance. The work provides a foundation for further improvements using unlabeled data and more advanced feature engineering.\", \"figures\": null, \"tables\": null}, \"citations\": [], \"error\": null}, \"fe5d69b4\": {\"success\": true, \"paper_id\": \"fe5d69b4\", \"url\": \"https://arxiv.org/pdf/1405.7397v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_fe5d69b4.pdf\", \"extracted_info\": {\"title\": \"Named Entity Recognition System for ICON 2013 NLP Tools Contest\", \"authors\": [\"Not specified\"], \"abstract\": \"This paper reports our work in the ICON 2013 NLP Tools Contest on Named Entity Recognition.\", \"methodology\": \"The system is based on a Hidden Markov Model (HMM) for named entity tagging. Training data provided by the contest organizers was used without modification to NE annotations. The HMM bigram tagger estimates the most probable tag sequence for the given observations, producing NE-tagged output in IOB format.\", \"results\": \"The HMM-based NER system produced NE-tagged output in IOB format for Indian languages such as Bengali and English. Results were obtained using the provided corpora, and performance was discussed in relation to the quality of the training data.\", \"conclusion\": \"The paper presents a HMM-based named entity recognition system for Indian languages, demonstrates its application in the ICON 2013 NLP Tools Contest, and discusses the impact of training data quality on system performance.\", \"figures\": null, \"tables\": null}, \"citations\": [\"proach to Named Entity Recognition . Ph.D. thesis,\", \"Computer Science Department, New York Universi-\", \"Asif Ekbal, Rejwanul Haque, Amitava Das, Venkates-\", \"Language Technology, 2(1).\", \"Language Processing, Computational Linguistics\", \"and Speech Recognition” , Preason Education Series.\", \"Daniel M. Bikel, Scott Miller, Richard Schwartz and\", \"Pustejovsky, editors, Corpus Processing for Lexical\", \"(EAIT), Kolkata. pp. 36-40.\", \"Karthik Gali, Harshit Surana, Ashwini Vaidya, Praneeth\", \"nical Report, IIT Bombay, India.\", \"Rohini Srihari, Cheng Niu and Wei Li. 2000. A Hybrid\", \"Takahiro Wakao, Robert Gaizauskas and Yorick Wilks.\", \"1996. Evaluationof an algorithm for the recognition\", \"Conference, pp. 224-231.\"], \"error\": null}, \"66589949\": {\"success\": false, \"paper_id\": \"66589949\", \"url\": \"https://www.researchgate.net/publication/288266760_An_Efficient_Passage_Ranking_Technique_For_a_QA_System/fulltext/57aa188608ae0932c96e6154/An-Efficient-Passage-Ranking-Technique-For-a-QA-System.pdf\", \"pdf_path\": null, \"extracted_info\": null, \"error\": \"download failed: request failed: 403 Client Error: Forbidden for url: https://www.researchgate.net/publication/288266760_An_Efficient_Passage_Ranking_Technique_For_a_QA_System/fulltext/57aa188608ae0932c96e6154/An-Efficient-Passage-Ranking-Technique-For-a-QA-System.pdf\"}, \"2c070bd3\": {\"success\": true, \"paper_id\": \"2c070bd3\", \"url\": \"https://arxiv.org/pdf/1511.05806v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_2c070bd3.pdf\", \"extracted_info\": {\"title\": \"Ranking library materials\", \"authors\": [\"Dirk Lewandowski\"], \"abstract\": \"This paper discusses ranking factors suitable for library materials and shows that ranking in general is a complex process requiring a variety of techniques. It reviews relevant literature to provide a systematic overview of suitable ranking factors, based on an analysis of ranking factors used in Web search engines. Findings indicate that while many ranking factors are applicable to library materials, current library systems use only a subset. The paper argues that an individual weighting of applicable factors is necessary for effective ranking in library catalogues. Although no specific ranking formula is provided, the discussion emphasizes that such formulas must be tailored to specific use cases.\", \"methodology\": \"The study is based on a literature review of relevant works on ranking factors, both in the context of Web search engines and library catalogues. It systematically analyzes the applicability of Web search engine ranking factors to library materials and discusses their potential integration into library search systems.\", \"results\": \"The paper finds that current library catalogues are incomplete, often missing journal articles and other resources, and rely heavily on freshness as the sole ranking criterion. It identifies four main groups of ranking factors from Web search engines—text matching, popularity, freshness, and locality—and discusses their adaptation for library materials. Additional factors such as item size, document type, and user group preferences are also proposed. The study emphasizes the need for combining multiple ranking factors and ensuring a good mix of results to improve search relevance in library catalogues.\", \"conclusion\": \"The paper’s key contributions include: (1) providing the first systematic discussion of ranking library materials based on factors used in Web search engines; (2) identifying limitations of current OPAC ranking methods; (3) proposing a comprehensive set of applicable ranking factors, including text matching, popularity, freshness, locality, and other contextual factors; (4) stressing the importance of combining multiple factors for effective ranking; and (5) advocating for results lists that offer a diverse mix of relevant materials rather than homogeneous sets. The work positions ranking as a core component for the future success of library catalogues.\", \"figures\": null, \"tables\": null}, \"citations\": [], \"error\": null}, \"7fc54d0d\": {\"success\": true, \"paper_id\": \"7fc54d0d\", \"url\": \"https://arxiv.org/pdf/2103.16669v3\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_7fc54d0d.pdf\", \"extracted_info\": {\"title\": \"Qa-DocRank: Passage-Level Transfer Learning for Document Ranking using BERT-based Models\", \"authors\": [\"Koustav Rudra\", \"others not specified in provided text\"], \"abstract\": \"Pre-trained contextual language models such as BERT, GPT, and XLNet work effectively for document retrieval tasks. These models are fine-tuned based on query-document pairs to improve retrieval performance. The paper investigates limitations of existing BERT-based ranking approaches and proposes Qa-DocRank, a passage-level transfer learning method that aggregates passage representations to predict document relevance, aiming to balance performance and inference cost.\", \"methodology\": \"The study focuses on the second-stage ranking problem in information retrieval using contextual ranking models based on BERT. It compares Doc-Labelled and BERT-3S methods with the proposed Qa-DocRank approach. Qa-DocRank selectively transfers labels from documents to relevant passages, reducing training size and inference cost. Four aggregation strategies are tested for combining passage-level scores into document-level relevance predictions. Experiments are conducted on multiple datasets (TREC-DL, Robust04, Core17, ClueWeb09) using PyTorch 1.7.1 and Transformers 4.10.2, with statistical significance measured via paired t-tests.\", \"results\": \"Qa-DocRank consistently achieves competitive or superior MAP, nDCG@20, and P@20 scores compared to baselines across datasets. For example, on TREC-DL, Qa-DocRank achieves MAP 0.269 and nDCG@20 0.603, outperforming BERT-3S (MAP 0.267, nDCG@20 0.595). Performance improves with larger training sizes, and the method shows robustness to passage length variation. Cross-domain experiments demonstrate that Qa-DocRank maintains strong performance without dataset-specific tuning.\", \"conclusion\": \"The paper’s key contributions include: (1) identifying limitations of existing BERT-based document ranking methods; (2) proposing Qa-DocRank, a passage-level transfer learning approach that reduces label noise and inference cost; (3) demonstrating improved retrieval performance across multiple datasets; (4) analyzing the impact of training size, passage granularity, and cross-domain transfer on performance; and (5) providing insights into efficient inference strategies for contextual ranking models.\", \"figures\": null, \"tables\": null}, \"citations\": [\"Amin Ahmad, Noah Constant, Yinfei Yang, and Daniel Cer. Reqa: An evaluation for end-to-end\", \"answer retrieval models. arXiv preprint arXiv:1907.04780 , 2019.\", \"Zeynep Akkalyoncu Yilmaz, Wei Yang, Haotian Zhang, and Jimmy Lin. Cross-domain modeling\", \"ference on Natural Language Processing (EMNLP-IJCNLP) , pages 3481–3487, November\", \"2019.\", \"Abhijit Anand, Jurek Leonhardt, Jaspreet Singh, Koustav Rudra, and Avishek Anand. Data\", \"Wei-Cheng Chang, Felix X Yu, Yin-Wen Chang, Yiming Yang, and Sanjiv Kumar. Pre-training\", \"tasks for embedding-based large-scale retrieval. arXiv preprint arXiv:2002.03932 , 2020.\", \"Eunseong Choi, Sunkyung Lee, Minjin Choi, Hyeseon Ko, Young-In Song, and Jongwuk Lee.\", \"Knowledge Management , CIKM ’22, page 272–282, 2022.\", \"Nachshon Cohen, Amit Portnoy, Besnik Fetahu, and Amir Ingber. SDR: Efficient neural\", \"Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pages\", \"6624–6637, Dublin, Ireland, May 2022. Association for Computational Linguistics. doi:\", \"10.18653/v1/2022.acl-long.457. URL https://aclanthology.org/2022.acl-long.457.\", \"Nick Craswell, Onno Zoeter, Michael Taylor, and Bill Ramsey. An experimental comparison\", \"search and data mining , pages 87–94, 2008.\", \"Nick Craswell, Bhaskar Mitra, Emine Yilmaz, and Daniel Campos. TREC-2019-Deep-Learning.\", \"https://microsoft.github.io/TREC-2019-Deep-Learning/, 2019.\", \"modeling. In ACM SIGIR’19 , pages 985–988, 2019.\", \"Zhuyun Dai, Chenyan Xiong, Jamie Callan, and Zhiyuan Liu. Convolutional neural networks\", \"Conference on Web Search and Data Mining , WSDM ’18, pages 126–134. ACM, 2018.\", \"3159652.3159659.\", \"Mostafa Dehghani, Hamed Zamani, Aliaksei Severyn, Jaap Kamps, and W. Bruce Croft. Neural\", \"ranking models with weak supervision. In SIGIR ’17 , pages 65–74. ACM, 2017. ISBN 978-\", \"1-4503-5022-8. doi: 10.1145/3077136.3080832. URL http://doi.acm.org/10.1145/3077136.\", \"3080832.\", \"Mostafa Dehghani, Arash Mehrjou, Stephan Gouws, Jaap Kamps, and Bernhard Sch¨ olkopf.\", \"Fidelity-weighted learning. In ICLR ’18 , 2018. URL https://openreview.net/forum?id=\", \"Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: pre-training of\", \"deep bidirectional transformers for language understanding. CoRR , abs/1810.04805, 2018.\", \"Yixing Fan, Jiafeng Guo, Yanyan Lan, Jun Xu, Chengxiang Zhai, and Xueqi Cheng. Modeling\", \"Conference on Research & Development in Information Retrieval , SIGIR ’18, pages 375–\", \"384. ACM, 2018a. ISBN 978-1-4503-5657-2. doi: 10.1145/3209978.3209980. URL http:\", \"Yixing Fan, Jiafeng Guo, Yanyan Lan, Jun Xu, Chengxiang Zhai, and Xueqi Cheng. Modeling\", \"diverse relevance patterns in ad-hoc retrieval. In ACM SIGIR’18 , pages 375–384, 2018b.\", \"Zhen Fan, Luyu Gao, Rohan Jha, and Jamie Callan. Coilcr: Efficient semantic matching in\", \"contextualized exact match retrieval. In Jaap Kamps, Lorraine Goeuriot, Fabio Crestani,\", \"Maria Maistro, Hideo Joho, Brian Davis, Cathal Gurrin, Udo Kruschwitz, and Annalina\", \"22 Koustav Rudra et al.\", \"Caputo, editors, Advances in Information Retrieval , pages 298–312, Cham, 2023. Springer\", \"Luke Gallagher. Pairwise t-test on TREC Run Files. https://github.com/lgrz/pairwise-ttest/,\", \"2019.\", \"Luyu Gao, Zhuyun Dai, and Jamie Callan. COIL: Revisit exact lexical match in information\", \"guage Technologies , pages 3030–3042, Online, June 2021a. Association for Computational\", \"Luyu Gao, Zhuyun Dai, Tongfei Chen, Zhen Fan, Benjamin Van Durme, and Jamie Callan.\", \"Complement lexical retrieval model with semantic residual embeddings. In Djoerd Hiemstra,\", \"Marie-Francine Moens, Josiane Mothe, Raffaele Perego, Martin Potthast, and Fabrizio\", \"Sebastiani, editors, Advances in Information Retrieval , pages 146–160, Cham, 2021b.\", \"Jiafeng Guo, Yixing Fan, Qingyao Ai, and W. Bruce Croft. A deep relevance matching model\", \"for ad-hoc retrieval. In CIKM’16 , pages 55–64. ACM, 2016. ISBN 978-1-4503-4073-1. doi:\", \"10.1145/2983323.2983769. URL http://doi.acm.org/10.1145/2983323.2983769.\", \"Geoffrey Hinton, Oriol Vinyals, and Jeff Dean. Distilling the knowledge in a neural network.\", \"arXiv preprint arXiv:1503.02531 , 2015.\", \"Sepp Hochreiter and J¨ urgen Schmidhuber. Long short-term memory. Neural computation , 9\", \"(8):1735–1780, 1997.\", \"infrastructure to include performance aspects. arXiv preprint arXiv:1907.04614 , 2019.\", \"Sebastian Hofst¨ atter, Hamed Zamani, Bhaskar Mitra, Nick Craswell, and Allan Hanbury.\", \"arXiv:2005.04908 , 2020a.\", \"Sebastian Hofst¨ atter, Markus Zlabinger, and Allan Hanbury. Interpretable & time-budget-\", \"constrained contextualization for re-ranking. arXiv preprint arXiv:2002.01854 , 2020b.\", \"Sebastian Hofst¨ atter, Omar Khattab, Sophia Althammer, Mete Sertkan, and Allan Hanbury.\", \"Information & Knowledge Management , CIKM ’22, page 737–747, 2022.\", \"Baotian Hu, Zhengdong Lu, Hang Li, and Qingcai Chen. Convolutional neural network\", \"tional Conference on Neural Information Processing Systems - Volume 2 , NIPS’14, page\", \"2042–2050, 2014.\", \"Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Acero, and Larry Heck. Learning\", \"deep structured semantic models for web search using clickthrough data. In CIKM ’13 ,\", \"pages 2333–2338. ACM, 2013. ISBN 978-1-4503-2263-8. doi: 10.1145/2505515.2505665.\", \"Kai Hui, Andrew Yates, Klaus Berberich, and Gerard de Melo. PACRR: A position-aware\", \"neural ir model for relevance matching. In EMNLP ’17 , pages 1049–1058, Copenhagen,\", \"Denmark, September 2017. URL https://www.aclweb.org/anthology/D17-1110.\", \"Kai Hui, Andrew Yates, Klaus Berberich, and Gerard de Melo. Co-PACRR: A context-aware\", \"neural ir model for ad-hoc retrieval. In WSDM ’18 , pages 279–287. ACM, 2018. ISBN 978-\", \"1-4503-5581-0. doi: 10.1145/3159652.3159689. URL http://doi.acm.org/10.1145/3159652.\", \"3159689.\", \"ACM Trans. Inf. Syst. , 20(4):422–446, 2002.\", \"Vladimir Karpukhin, Barlas O˘ guz, Sewon Min, Ledell Wu, Sergey Edunov, Danqi Chen, and\", \"arXiv:2004.04906 , 2020.\", \"InAcm Sigir Forum , volume 37, pages 18–28. ACM New York, NY, USA, 2003.\", \"Information Retrieval , SIGIR ’01, pages 120–127, New York, NY, USA, 2001. ACM. ISBN 1-\", \"58113-331-6. doi: 10.1145/383952.383972. URL http://doi.acm.org/10.1145/383952.383972.\", \"Victor Lavrenko and W Bruce Croft. Relevance-based language models. In ACM SIGIR Forum ,\", \"volume 51, pages 260–267. ACM, 2017.\", \"Kenton Lee, Ming-Wei Chang, and Kristina Toutanova. Latent retrieval for weakly supervised\", \"open domain question answering. arXiv preprint arXiv:1906.00300 , 2019.\", \"Jurek Leonhardt, Koustav Rudra, Megha Khosla, Abhijit Anand, and Avishek Anand. Efficient\", \"neural ranking using forward indexes. In Proceedings of the ACM Web Conference 2022 ,\", \"WWW ’22, page 266–276, 2022.\", \"Jurek Leonhardt, Henrik M¨ uller, Koustav Rudra, Megha Khosla, Abhijit Anand, and Avishek\", \"Trans. Inf. Syst. , nov 2023a. ISSN 1046-8188. URL https://doi.org/10.1145/3631939. Just\", \"Jurek Leonhardt, Koustav Rudra, and Avishek Anand. Extractive explanations for interpretable\", \"text ranking. ACM Trans. Inf. Syst. , 41(4), mar 2023b. doi: 10.1145/3576924.\", \"Canjia Li, Andrew Yates, Sean MacAvaney, Ben He, and Yingfei Sun. Parade: Passage\", \"representation aggregation for document reranking. arXiv preprint arXiv:2008.09093 , 2020.\", \"Yi Luan, Jacob Eisenstein, Kristina Toutanova, and Michael Collins. Sparse, dense, and\", \"attentional representations for text retrieval. arXiv preprint arXiv:2005.00181 , 2020.\", \"Sean MacAvaney, Andrew Yates, Arman Cohan, and Nazli Goharian. Contextualized word\", \"representations for document re-ranking. arXiv preprint arXiv:1904.07094 , 2019.\", \"Irina Matveeva, Chris Burges, Timo Burkard, Andy Laucius, and Leon Wong. High accuracy\", \"retrieval with multiple nested ranker. In SIGIR ’06 , pages 437–444. ACM, 2006. ISBN\", \"1-59593-369-7. doi: 10.1145/1148170.1148246. URL http://doi.acm.org/10.1145/1148170.\", \"1148246.\", \"Ryan McDonald, George Brokos, and Ion Androutsopoulos. Deep relevance ranking using\", \"enhanced document-query interactions. In EMNLP ’18 , pages 1849–1860. ACL, 2018. URL\", \"Bhaskar Mitra, Eric T. Nalisnick, Nick Craswell, and Rich Caruana. A dual embedding\", \"space model for document ranking. arXiv preprint , arXiv:1602.01137, 2016. URL http:\", \"Bhaskar Mitra, Fernando Diaz, and Nick Craswell. Learning to match using local and distributed\", \"representations of text for web search. In WWW’17 , pages 1291–1299, 2017. ISBN 978-1-\", \"4503-4913-0. doi: 10.1145/3038912.3052579. URL https://doi.org/10.1145/3038912.3052579.\", \"similarity. In Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence ,\", \"AAAI’16, page 2786–2792, 2016.\", \"Eric Nalisnick, Bhaskar Mitra, Nick Craswell, and Rich Caruana. Improving document ranking\", \"with dual word embeddings. In WWW ’16 Companion , pages 83–84, 2016. ISBN 978-1-4503-\", \"4144-8. doi: 10.1145/2872518.2889361. URL https://doi.org/10.1145/2872518.2889361.\", \"Yifan Nie, Yanling Li, and Jian-Yun Nie. Empirical study of multi-level convolution models\", \"for ir based on representations and interactions. In ICTIR ’18 , pages 59–66. ACM, 2018a.\", \"3234944.3234954.\", \"Yifan Nie, Alessandro Sordoni, and Jian-Yun Nie. Multi-level abstraction convolutional model\", \"with weak supervision for information retrieval. In SIGIR ’18 , pages 985–988. ACM, 2018b.\", \"3209978.3210123.\", \"Rodrigo Nogueira and Kyunghyun Cho. Passage re-ranking with BERT. CoRR , abs/1901.04085,\", \"2019. URL http://arxiv.org/abs/1901.04085.\", \"Rodrigo Nogueira, Wei Yang, Kyunghyun Cho, and Jimmy Lin. Multi-stage document ranking\", \"Hamid Palangi, Li Deng, Yelong Shen, Jianfeng Gao, Xiaodong He, Jianshu Chen, Xinying\", \"Song, and Rabab Ward. Deep sentence embedding using long short-term memory networks:\", \"Analysis and application to information retrieval. IEEE/ACM Trans. Audio, Speech and\", \"Lang. Proc. , 24(4):694–707, April 2016.\", \"Liang Pang, Yanyan Lan, Jiafeng Guo, Jun Xu, and Xueqi Cheng. A study of MatchPyramid\", \"models on ad-hoc retrieval. arXiv:1606.04648, 2016. URL http://arxiv.org/abs/1606.04648.\", \"Liang Pang, Yanyan Lan, Jiafeng Guo, Jun Xu, Jingfang Xu, and Xueqi Cheng. DeepRank:\", \"the 2017 ACM on Conference on Information and Knowledge Management , CIKM ’17,\", \"pages 257–266. ACM, 2017. ISBN 978-1-4503-4918-5. doi: 10.1145/3132847.3132914. URL\", \"24 Koustav Rudra et al.\", \"Matthew Peters, Mark Neumann, Mohit Iyyer, Matt Gardner, Christopher Clark, Kenton Lee,\", \"2018 Conference of the North American Chapter of the Association for Computational\", \"Linguistics: Human Language Technologies, Volume 1 (Long Papers) , pages 2227–2237,\", \"2018.\", \"on Artificial Intelligence , IJCAI’15, page 1305–1311, 2015.\", \"Alec Radford, Jeffrey Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever.\", \"Language models are unsupervised multitask learners. OpenAI blog , 1(8):9, 2019.\", \"networks. In EMNLP/IJCNLP (1) , pages 3980–3990. Association for Computational\", \"beyond. Found. Trends Inf. Retr. , 3(4):333–389, April 2009.\", \"Management , CIKM ’20, page 2197–2200, 2020.\", \"Yelong Shen, Xiaodong He, Jianfeng Gao, Li Deng, and Gr´ egoire Mesnil. A latent semantic\", \"model with convolutional-pooling structure for information retrieval. In CIKM ’14 , pages\", \"101–110. ACM, 2014a. ISBN 978-1-4503-2598-1. doi: 10.1145/2661829.2661935. URL\", \"Yelong Shen, Xiaodong He, Jianfeng Gao, Li Deng, and Gr´ egoire Mesnil. Learning semantic\", \"ion, pages 373–374. ACM, 2014b. ISBN 978-1-4503-2745-9. doi: 10.1145/2567948.2577348.\", \"Trevor Strohman, Donald Metzler, Howard Turtle, and W Bruce Croft. Indri: A language model-\", \"on Intelligent Analysis , volume 2, pages 2–6, 2005.\", \"Sainbayar Sukhbaatar, Joan Bruna, Manohar Paluri, Lubomir Bourdev, and Rob Fergus.\", \"Training convolutional networks with noisy labels. arXiv preprint arXiv:1406.2080 , 2014.\", \"information retrieval. Proceedings of the AAAI Conference on Artificial Intelligence , 33\", \"(01):289–296, 2019.\", \"Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\", \"Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. In Advances in Neural\", \"Information Processing Systems , volume 30, 2017.\", \"Andreas Veit, Neil Alldrin, Gal Chechik, Ivan Krasin, Abhinav Gupta, and Serge Belongie.\", \"Learning from noisy large-scale datasets with minimal supervision. In IEEE CVPR’17 ,\", \"Shengxian Wan, Yanyan Lan, Jiafeng Guo, Jun Xu, Liang Pang, and Xueqi Cheng. A deep\", \"Proceedings of the Thirtieth AAAI Conference on Artificial Intelligence , AAAI’16, page\", \"2835–2841, 2016.\", \"Ryen W White, Joemon M Jose, and Ian Ruthven. Comparing explicit and implicit feedback\", \"Text Retrieval Conference (TREC-10) , pages 534–538, 2002.\", \"Zhijing Wu, Jiaxin Mao, Yiqun Liu, Min Zhang, and Shaoping Ma. Investigating passage-level\", \"relevance and its role in document-level relevance judgment. SIGIR’19, page 605–614, 2019.\", \"Zhijing Wu, Jiaxin Mao, Yiqun Liu, Jingtao Zhan, Yukun Zheng, Min Zhang, and Shaoping\", \"The Web Conference 2020 , page 2421–2431, 2020.\", \"Tong Xiao, Tian Xia, Yi Yang, Chang Huang, and Xiaogang Wang. Learning from massive\", \"noisy labeled data for image classification. In IEEE CVPR’15 , pages 2691–2699, 2015.\", \"Chenyan Xiong, Zhuyun Dai, Jamie Callan, Zhiyuan Liu, and Russell Power. End-to-end neural\", \"ad-hoc ranking with kernel pooling. In SIGIR ’17 , pages 55–64. ACM, 2017. ISBN 978-\", \"1-4503-5022-8. doi: 10.1145/3077136.3080809. URL http://doi.acm.org/10.1145/3077136.\", \"3080809.\", \"Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul Bennett, Junaid Ahmed,\", \"dense text retrieval. arXiv preprint arXiv:2007.00808 , 2020.\", \"Liu Yang, Qingyao Ai, Jiafeng Guo, and W. Bruce Croft. Anmm: Ranking short answer texts\", \"on Conference on Information and Knowledge Management , CIKM ’16, page 287–296,\", \"2016.\", \"Wei Yang, Haotian Zhang, and Jimmy Lin. Simple applications of bert for ad hoc document\", \"retrieval. arXiv preprint arXiv:1903.10972 , 2019.\", \"Kaitao Zhang, Chenyan Xiong, Zhenghao Liu, and Zhiyuan Liu. Selective weak supervision for\", \"neural information retrieval. In Proceedings of The Web Conference 2020 , page 474–485,\", \"2020.\", \"matching and efficient passage expansion. arXiv preprint arXiv:2108.08513 , 2021a.\", \"and Development in Information Retrieval , SIGIR ’21, page 1483–1492, 2021b.\"], \"error\": null}, \"1637f9b5\": {\"success\": true, \"paper_id\": \"1637f9b5\", \"url\": \"https://people.csail.mit.edu/weifang/files/resume.pdf\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_1637f9b5.pdf\", \"extracted_info\": {\"title\": \"Beyond Single-Shot: Multi-step Tool Retrieval via Query Planning\", \"authors\": [\"Wei Fang\", \"James Glass\"], \"abstract\": \"This work explores methods to enhance large language model (LLM) agents’ tool-using capabilities through post-training and inference-time techniques. The focus is on improving multi-step tool retrieval by incorporating query planning strategies, enabling agents to perform complex tasks more effectively.\", \"methodology\": \"The research employs supervised fine-tuning (SFT), reinforcement learning (RL), retrieval-augmented generation (RAG), agentic approaches, and data generation techniques. It also integrates information retrieval methods such as joint re-ranking with cross-encoders and generative models, as well as query expansion ranking to improve open-domain question answering.\", \"results\": \"The proposed multi-step tool retrieval method demonstrates improved performance in zero-shot passage re-ranking and open-domain QA tasks, showing that query planning can significantly enhance LLM agents’ ability to select and use tools effectively.\", \"conclusion\": \"This work contributes a novel approach for multi-step tool retrieval via query planning, advances in zero-shot passage re-ranking, and query expansion ranking for open-domain QA, along with practical integration of multiple ML methodologies to boost agentic AI capabilities.\", \"figures\": null, \"tables\": null}, \"citations\": [], \"error\": null}, \"48e9f139\": {\"success\": true, \"paper_id\": \"48e9f139\", \"url\": \"https://aclanthology.org/2024.findings-eacl.151.pdf\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_48e9f139.pdf\", \"extracted_info\": {\"title\": \"Joint Passage Re-ranking: Combining Discriminative and Generative Models via Mutual Information Optimization\", \"authors\": [\"Not specified in provided content\"], \"abstract\": \"Passage retrieval is a crucial component of modern open-domain question answering (QA) systems. This paper proposes a novel method, Joint Passage Re-ranking (JPR), that optimizes the mutual information between query and passage distributions by integrating both cross-encoder and generative model scores in the re-ranking process. Experimental results demonstrate that JPR outperforms conventional re-rankers and language model scorers in both open-domain QA and zero-shot retrieval settings.\", \"methodology\": \"The proposed JPR method combines a discriminative cross-encoder model and a generative model for passage re-ranking. It optimizes the pointwise mutual information (PMI) between queries and passages. The approach re-ranks the top-100 passages initially retrieved by BM25. Multiple model pairings are tested, including BERT, T5, UPR, and large language models (LLMs) like LLaMA-33B. Evaluation is conducted on open-domain QA datasets (Natural Questions, TriviaQA) and BEIR benchmark datasets in both fine-tuned and zero-shot settings.\", \"results\": \"On Natural Questions and TriviaQA, JPR achieves top-1 accuracy of 51.0% and 68.3% respectively, outperforming BM25, BERT-FT, T5-FT, and UPR. With LLaMA-33B, JPR reaches 48.2% (NQ) and 70.1% (TriviaQA) top-1 accuracy. In zero-shot BEIR evaluation, JPR attains ~2% absolute gain on average over baselines, achieving best overall nDCG@10 scores across multiple datasets. The method consistently outperforms both discriminative-only and generative-only re-rankers.\", \"conclusion\": \"The key contributions of this work are: (1) Introduction of Joint Passage Re-ranking (JPR), a simple yet effective method combining discriminative and generative re-rankers via mutual information maximization; (2) Demonstration of superior performance over conventional re-rankers and LLM-based scorers in open-domain QA and zero-shot retrieval; (3) Empirical validation across diverse datasets showing robustness and generalizability; (4) Exploration of different cross-encoder and generative model pairings to optimize retrieval performance.\", \"figures\": null, \"tables\": null}, \"citations\": [\"L. Bahl, P. Brown, P. de Souza, and R. Mercer. 1986.\", \"Acoustics, Speech, and Signal Processing , volume 11,\", \"Alexander Bondarenko, Maik Fröbe, Meriem Be-\", \"loucif, Lukas Gienapp, Yamen Ajjour, Alexander\", \"Panchenko, Chris Biemann, Benno Stein, Henning\", \"Wachsmuth, Martin Potthast, and Matthias Hagen.\", \"2020. Overview of touché 2020: Argument retrieval.\", \"InExperimental IR Meets Multilinguality, Multi-\", \"modality, and Interaction , pages 384–395, Cham.\", \"Vera Boteva, Demian Gholipour, Artem Sokolov, and\", \"vances in Information Retrieval , pages 716–722,\", \"Linguistics: Tutorial Abstracts , pages 34–37, Online.\", \"Arman Cohan, Sergey Feldman, Iz Beltagy, Doug\", \"Downey, and Daniel Weld. 2020. SPECTER:\", \"for Computational Linguistics , pages 2270–2282,\", \"Jacob Devlin, Ming-Wei Chang, Kenton Lee, and\", \"nologies, Volume 1 (Long and Short Papers) , pages\", \"4171–4186, Minneapolis, Minnesota. Association for\", \"Thomas Diggelmann, Jordan Boyd-Graber, Jannis Bu-\", \"lian, Massimiliano Ciaramita, and Markus Leip-\", \"Fernando Ferraretto, Thiago Laitz, Roberto Lotufo, and\", \"Research and Development in Information Retrieval ,\", \"SIGIR ’23, page 2409–2414, New York, NY , USA.\", \"Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasu-\", \"pat, and Ming-Wei Chang. 2020. Realm: Retrieval-\", \"Learning , ICML’20. JMLR.org.\", \"Faegheh Hasibi, Fedor Nikolaev, Chenyan Xiong, Krisz-\", \"tian Balog, Svein Erik Bratsberg, Alexander Kotov,\", \"40th International ACM SIGIR Conference on Re-\", \"search and Development in Information Retrieval ,\", \"SIGIR ’17, page 1265–1268, New York, NY , USA.\", \"Doris Hoogeveen, Karin M. Verspoor, and Timothy\", \"puting Symposium (ADCS) , ADCS ’15, pages 3:1–\", \"3:8, New York, NY , USA. ACM.Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke\", \"ume 1: Long Papers) , pages 1601–1611, Vancouver,\", \"Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick\", \"Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and\", \"2020 Conference on Empirical Methods in Natural\", \"Language Processing (EMNLP) , pages 6769–6781,\", \"Tom Kwiatkowski, Jennimaria Palomaki, Olivia Red-\", \"field, Michael Collins, Ankur Parikh, Chris Alberti,\", \"Danielle Epstein, Illia Polosukhin, Jacob Devlin, Ken-\", \"ton Lee, Kristina Toutanova, Llion Jones, Matthew\", \"Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob\", \"Uszkoreit, Quoc Le, and Slav Petrov. 2019. Natu-\", \"tational Linguistics , 7:452–466.\", \"Kenton Lee, Ming-Wei Chang, and Kristina Toutanova.\", \"2019. Latent retrieval for weakly supervised open\", \"57th Annual Meeting of the Association for Computa-\", \"tional Linguistics , pages 6086–6096, Florence, Italy.\", \"Jiwei Li, Michel Galley, Chris Brockett, Jianfeng Gao,\", \"tional Linguistics: Human Language Technologies ,\", \"pages 110–119, San Diego, California. Association\", \"Jimmy Lin, Xueguang Ma, Sheng-Chieh Lin, Jheng-\", \"Hong Yang, Ronak Pradeep, and Rodrigo Nogueira.\", \"2021. Pyserini: A Python toolkit for reproducible\", \"2021) , pages 2356–2362.\", \"Jing Lu, Gustavo Hernandez Abrego, Ji Ma, Jianmo Ni,\", \"cal Methods in Natural Language Processing , pages\", \"6091–6103, Online and Punta Cana, Dominican Re-\", \"Yi Luan, Jacob Eisenstein, Kristina Toutanova, and\", \"Michael Collins. 2021. Sparse, dense, and attentional\", \"Association for Computational Linguistics , 9:329–\", \"345.\", \"Hongyin Luo, Shang-Wen Li, Mingye Gao, Seunghak\", \"Yu, and James Glass. 2022. Cooperative self-training\", \"tics: Human Language Technologies , pages 244–257,\", \"Seattle, United States. Association for Computational\", \"cal Methods in Natural Language Processing , pages\", \"3698–3707, Brussels, Belgium. Association for Com-\", \"Macedo Maia, Siegfried Handschuh, André Freitas,\", \"Brian Davis, Ross McDermott, Manel Zarrouk, and\", \"2018 , WWW ’18, page 1941–1942, Republic and\", \"Canton of Geneva, CHE. International World Wide\", \"Yuning Mao, Pengcheng He, Xiaodong Liu, Yelong\", \"Shen, Jianfeng Gao, Jiawei Han, and Weizhu Chen.\", \"2021. Reader-guided passage reranking for open-\", \"2021 , pages 344–350, Online. Association for Com-\", \"Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-\", \"rado, and Jeff Dean. 2013. Distributed representa-\", \"tems, volume 26. Curran Associates, Inc.\", \"Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao,\", \"Saurabh Tiwary, Rangan Majumder, and Li Deng.\", \"2017. MS MARCO: A human-generated MAchine\", \"Rodrigo Nogueira, Zhiying Jiang, Ronak Pradeep, and\", \"EMNLP 2020 , pages 708–718, Online. Association\", \"Colin Raffel, Noam Shazeer, Adam Roberts, Katherine\", \"Lee, Sharan Narang, Michael Matena, Yanqi Zhou,\", \"Wei Li, Peter J Liu, et al. 2020. Exploring the limits\", \"former. J. Mach. Learn. Res. , 21(140):1–67.Revanth Gangi Reddy, Vikas Yadav, Md Arafat Sul-\", \"tan, Martin Franz, Vittorio Castelli, Heng Ji, and\", \"ral Language Processing (EMNLP-IJCNLP) , pages\", \"3982–3992, Hong Kong, China. Association for Com-\", \"Stephen Robertson, Hugo Zaragoza, et al. 2009. The\", \"trieval , 3(4):333–389.\", \"Devendra Sachan, Mike Lewis, Mandar Joshi, Armen\", \"Aghajanyan, Wen-tau Yih, Joelle Pineau, and Luke\", \"ural Language Processing , pages 3781–3797, Abu\", \"Dhabi, United Arab Emirates. Association for Com-\", \"G. Salton, A. Wong, and C. S. Yang. 1975. A vector\", \"space model for automatic indexing. Commun. ACM ,\", \"18(11):613–620.\", \"Victor Sanh, Albert Webson, Colin Raffel, Stephen\", \"Bach, Lintang Sutawika, Zaid Alyafeai, Antoine\", \"Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey,\", \"M Saiful Bari, Canwen Xu, Urmish Thakker,\", \"Shanya Sharma Sharma, Eliza Szczechla, Taewoon\", \"Kim, Gunjan Chhablani, Nihal Nayak, Debajyoti\", \"Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han\", \"Wang, Matteo Manica, Sheng Shen, Zheng Xin Yong,\", \"Harshit Pandey, Rachel Bawden, Thomas Wang, Tr-\", \"ishala Neeraj, Jos Rozen, Abheesht Sharma, An-\", \"drea Santilli, Thibault Fevry, Jason Alan Fries, Ryan\", \"Teehan, Teven Le Scao, Stella Biderman, Leo Gao,\", \"Thomas Wolf, and Alexander M Rush. 2022. Multi-\", \"Christopher Sciavolino, Zexuan Zhong, Jinhyuk Lee,\", \"ral Language Processing , pages 6138–6148, Online\", \"and Punta Cana, Dominican Republic. Association\", \"Shang-Yu Su, Yung-Sung Chuang, and Yun-Nung Chen.\", \"2020. Dual inference for improving language under-\", \"ation for Computational Linguistics: EMNLP 2020 ,\", \"pages 4930–4936, Online. Association for Computa-\", \"Weiwei Sun, Lingyong Yan, Xinyu Ma, Shuaiqiang\", \"Wang, Pengjie Ren, Zhumin Chen, Dawei Yin, and\", \"ing, pages 14918–14937, Singapore. Association for\", \"Duyu Tang, Nan Duan, Tao Qin, Zhao Yan, and Ming\", \"Nandan Thakur, Nils Reimers, Andreas Rücklé, Ab-\", \"hishek Srivastava, and Iryna Gurevych. 2021. BEIR:\", \"James Thorne, Andreas Vlachos, Christos\", \"Christodoulopoulos, and Arpit Mittal. 2018.\", \"Human Language Technologies, Volume 1 (Long\", \"Papers) , pages 809–819, New Orleans, Louisiana.\", \"Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier\", \"Martinet, Marie-Anne Lachaux, Timothée Lacroix,\", \"Baptiste Rozière, Naman Goyal, Eric Hambro,\", \"Faisal Azhar, et al. 2023. Llama: Open and effi-\", \"Retrieval , SIGIR ’18, page 873–876, New York, NY ,\", \"Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob\", \"Uszkoreit, Llion Jones, Aidan N Gomez, Ł ukasz\", \"Kaiser, and Illia Polosukhin. 2017. Attention is all\", \"cessing Systems , volume 30. Curran Associates, Inc.\", \"Ellen V oorhees, Tasmeer Alam, Steven Bedrick, Dina\", \"Demner-Fushman, William R. Hersh, Kyle Lo, Kirk\", \"Roberts, Ian Soboroff, and Lucy Lu Wang. 2021.\", \"retrieval test collection. SIGIR Forum , 54(1).\", \"answering track report. In Trec, volume 99, pages\", \"77–82. Citeseer.\", \"Henning Wachsmuth, Shahbaz Syed, and Benno Stein.\", \"2018. Retrieval of the best counterargument without\", \"Linguistics (Volume 1: Long Papers) , pages 241–251,\", \"Melbourne, Australia. Association for Computational\", \"Linguistics.David Wadden, Shanchuan Lin, Kyle Lo, Lucy Lu\", \"Wang, Madeleine van Zuylen, Arman Cohan, and\", \"Processing (EMNLP) , pages 7534–7550, Online. As-\", \"Yining Wang, Liwei Wang, Yuanzhi Li, Di He, and Tie-\", \"ranking measures. In Conference on learning theory ,\", \"Thomas Wolf, Lysandre Debut, Victor Sanh, Julien\", \"Chaumond, Clement Delangue, Anthony Moi, Pier-\", \"ric Cistac, Tim Rault, Remi Louf, Morgan Funtow-\", \"icz, Joe Davison, Sam Shleifer, Patrick von Platen,\", \"Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\", \"Teven Le Scao, Sylvain Gugger, Mariama Drame,\", \"Quentin Lhoest, and Alexander Rush. 2020. Trans-\", \"Demonstrations , pages 38–45, Online. Association\", \"speech recognition. Computer Speech & Language ,\", \"16(1):25–47.\", \"Yingce Xia, Tao Qin, Wei Chen, Jiang Bian, Nenghai\", \"Yu, and Tie-Yan Liu. 2017. Dual supervised learning.\", \"on Machine Learning-Volume 70 , pages 3789–3798.\", \"Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio,\", \"William Cohen, Ruslan Salakhutdinov, and Christo-\", \"diverse, explainable multi-hop question answering.\", \"cal Methods in Natural Language Processing , pages\", \"2369–2380, Brussels, Belgium. Association for Com-\", \"Apache License 2.0, which we follow, and Trivi-\", \"Natural Questions 58,880 8,757 3,610\", \"TriviaQA 60,413 8,837 11,313\", \"Generally, conventional cross-encoders are trained\", \"−Ex,z∼p(x,z)[logpϕ(z|x)], where pϕ(z|x)is usu-\", \"passage pairs, with the partition function approxi-\", \"and Collins, 2018). We choose to fine-tune our\", \"cross-encoder, BERT- FT, using a 6-layer trans-\", \"former model (Vaswani et al., 2017), which takes\", \"the concatenated input of a query and a passage,\", \"contrastive learning (Mikolov et al., 2013). The\", \"6-layer SBERT model MiniLM-L-6-v2 we use was\", \"previously pre-trained on MS MARCO, which we\", \"train with a batch size of 128, learning rate of 5e-5,\", \"For training of T5- FT, we fine-tune with\", \"Lgeneration (θ)using the t5-base-lm-adapt model,\", \"220M parameters initialized from T5-base v1.1 and\", \"We use a batch size of 64, learning rate of 5e-5,\", \"JPRuses BERT- FTand T5- FT, described ear-\", \"lier, directly during inference (see Sec. B.2 below).\", \"JPR-FTrequires further fine-tuning, which we train\", \"searched with the dev set, with one run for each hy-\", \"perparameter setting, shown in Table 4. We report\", \"Transformers library (Wolf et al., 2020), using the\", \"AdamW optimizer (Loshchilov and Hutter, 2018)\", \"and 512, respectively, for generative models. ForHyper-\", \"the cross-encoding BERT- FT, we set the maximum\", \"with four Nvidia A6000 GPUs, with around 2.5\", \"GPU hours per epoch, equating to around 250 GPU-\", \"(BERT- FT), we re-rank with Eq. 1 by directly rank-\", \"JPR, we approximate logpϕ(z|x)by taking Soft-\", \"For generative re-rankers T5- FTandUPR, we fol-\", \"over the passages. For JPR, the preceding two terms\", \"models of different sizes for the cross-encoders,\", \"els were previously pre-trained on MS MARCO,\", \"which we fine-tune on NQ, and the T5 models were\", \"fine-tuned on NQ, all following training procedures\", \"reported in Sec. B. For inference, we use λ= 0.5\", \"From the results, notice that when T5-small is\", \"paired with MiniLM-L-6 for JPR, it aligns with the\", \"T5-small) with the standalone BERT-base, which\", \"is in the same parameter ballpark, and the larger\", \"BERT-large, it’s evident that the gains from JPR2297\", \"a variety of text retrieval tasks and domains,\", \"14 of which are publicly available. In this\", \"COVID (V oorhees et al., 2021), NFCorpus (Boteva\", \"et al., 2016), NQ (Kwiatkowski et al., 2019), Hot-\", \"potQA (Yang et al., 2018), FiQA-2018 (Maia\", \"et al., 2018), ArguAna (Wachsmuth et al., 2018),\", \"Touché-2020 (Bondarenko et al., 2020), CQADup-\", \"Stack (Hoogeveen et al., 2015), Quora6, DB-\", \"Pedia (Hasibi et al., 2017), SCIDOCS (Cohan\", \"et al., 2020), FEVER (Thorne et al., 2018),\", \"Climate-FEVER (Diggelmann et al., 2020), and\", \"SciFact (Wadden et al., 2020). For details on\", \"dataset statistics, links, and licenses please refer\", \"to BEIR (Thakur et al., 2021). Note that datasets\", \"this study, and 4 out of the 14 publicly available\", \"For BEIR, since the SBERT model was already\", \"pre-trained on MS MARCO, we directly use it for\", \"BERT- FT. On the other hand, T5- FTstills requires\", \"fine-tuning, which we train for 3 epochs on query-\", \"passage pairs in the training set, with batch size\", \"QA retrieval, described earlier in Sec. B.2, except\", \"6https://quoradata.quora.com/First-Quora-Dataset-Release-Question-\"], \"error\": null}, \"312d82ca\": {\"success\": true, \"paper_id\": \"312d82ca\", \"url\": \"https://arxiv.org/pdf/2101.00294v1.pdf\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_312d82ca.pdf\", \"extracted_info\": {\"title\": \"Reader-guided Passage Reranking for Open-domain Question Answering (RIDER)\", \"authors\": [\"Akari Asai\", \"Kazuma Hashimoto\", \"Hannaneh Hajishirzi\", \"Richard Socher\", \"Caiming Xiong\"], \"abstract\": \"Current open-domain question answering (QA) systems often follow a Retriever-Reader (R2) architecture. This paper proposes a simple and effective passage reranking method, Reader-guided Reranker (RIDER), which does not involve any training and reranks retrieved passages solely based on reader predictions, improving QA performance with limited reader input.\", \"methodology\": \"The study assumes an open-domain QA system with an R2 architecture. RIDER reranks initially retrieved passages using the top-N predicted answers from a generative reader, without additional training. The method is evaluated on two benchmark datasets (Natural Questions and TriviaQA) by comparing retrieval accuracy and end-to-end QA performance before and after reranking. Experiments analyze the quality of reranking signals and measure improvements in exact match (EM) scores and retrieval accuracy.\", \"results\": \"RIDER significantly improves retrieval accuracy and end-to-end QA performance over baseline retrievers (GAR, GAR+DPR) on both datasets. For example, on Natural Questions, EM improved from 43.8 to 48.3, and on TriviaQA, RIDER achieved 66.4 EM. RIDER provides higher-quality input for the reader, achieving comparable or better performance than state-of-the-art methods with fewer input tokens, except for FID-large which uses substantially more passages.\", \"conclusion\": \"RIDER is a training-free, computationally efficient passage reranking method for open-domain QA. It improves QA results significantly on benchmark datasets, achieves competitive performance with less reader input, and can be easily integrated into existing R2 architectures, enabling more efficient and effective QA systems.\", \"figures\": null, \"tables\": null}, \"citations\": [\"Akari Asai, Kazuma Hashimoto, Hannaneh Hajishirzi,\", \"Richard Socher, and Caiming Xiong. 2019. Learn-\", \"Tom B Brown, Benjamin Mann, Nick Ryder, Melanie\", \"Subbiah, Jared Kaplan, Prafulla Dhariwal, Arvind\", \"Neelakantan, Pranav Shyam, Girish Sastry, Amanda\", \"Askell, et al. 2020. Language models are few-shot\", \"Rajarshi Das, Shehzaad Dhuliawala, Manzil Zaheer,\", \"Jacob Devlin, Ming-Wei Chang, Kenton Lee, and\", \"Technologies, Volume 1 (Long and Short Papers) ,\", \"pages 4171–4186, Minneapolis, Minnesota. Associ-\", \"Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasu-\", \"pat, and Ming-Wei Chang. 2020. Realm: Retrieval-\", \"Srinivasan Iyer, Sewon Min, Yashar Mehdad, and Wen-\", \"Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke\", \"(Volume 1: Long Papers) , pages 1601–1611, Van-\", \"couver, Canada. Association for Computational Lin-\", \"guistics.Vladimir Karpukhin, Barlas O ˘guz, Sewon Min, Ledell\", \"Wu, Sergey Edunov, Danqi Chen, and Wen-\", \"Tom Kwiatkowski, Jennimaria Palomaki, Olivia Red-\", \"ﬁeld, Michael Collins, Ankur Parikh, Chris Al-\", \"berti, Danielle Epstein, Illia Polosukhin, Jacob De-\", \"vlin, Kenton Lee, Kristina Toutanova, Llion Jones,\", \"Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai,\", \"Jakob Uszkoreit, Quoc Le, and Slav Petrov. 2019.\", \"for Computational Linguistics , 7:452–466.\", \"Jinhyuk Lee, Seongjun Yun, Hyunjae Kim, Miyoung\", \"Ko, and Jaewoo Kang. 2018. Ranking paragraphs\", \"Processing , pages 565–569, Brussels, Belgium. As-\", \"Kenton Lee, Ming-Wei Chang, and Kristina Toutanova.\", \"2019. Latent retrieval for weakly supervised open\", \"57th Annual Meeting of the Association for Com-\", \"putational Linguistics , pages 6086–6096, Florence,\", \"Mike Lewis, Yinhan Liu, Naman Goyal, Mar-\", \"jan Ghazvininejad, Abdelrahman Mohamed, Omer\", \"Levy, Ves Stoyanov, and Luke Zettlemoyer. 2019.\", \"for natural language generation, translation, and\", \"Patrick Lewis, Ethan Perez, Aleksandara Piktus, Fabio\", \"Petroni, Vladimir Karpukhin, Naman Goyal, Hein-\", \"rich K ¨uttler, Mike Lewis, Wen-tau Yih, Tim\", \"Rockt ¨aschel, et al. 2020. Retrieval-augmented gen-\", \"Yuning Mao, Pengcheng He, Xiaodong Liu, Ye-\", \"long Shen, Jianfeng Gao, Jiawei Han, and Weizhu\", \"Sewon Min, Danqi Chen, Hannaneh Hajishirzi, and\", \"9th International Joint Conference on Natural Lan-\", \"guage Processing (EMNLP-IJCNLP) , pages 2851–\", \"2864, Hong Kong, China. Association for Computa-\", \"Sewon Min, Danqi Chen, Luke Zettlemoyer, and Han-\", \"Sewon Min, Julian Michael, Hannaneh Hajishirzi, and\", \"Peng Qi, Haejun Lee, Oghenetegiri Sido, Christo-\", \"pher D Manning, et al. 2020. Retrieve, rerank, read,\", \"Yifan Qiao, Chenyan Xiong, Zhenghao Liu, and\", \"Adam Roberts, Colin Raffel, and Noam Shazeer. 2020.\", \"Shuohang Wang, Mo Yu, Xiaoxiao Guo, Zhiguo Wang,\", \"Tim Klinger, Wei Zhang, Shiyu Chang, Gerald\", \"Tesauro, Bowen Zhou, and Jing Jiang. 2018a. R3:\", \"Shuohang Wang, Mo Yu, Jing Jiang, Wei Zhang, Xiaox-\", \"iao Guo, Shiyu Chang, Zhiguo Wang, Tim Klinger,\", \"Gerald Tesauro, and Murray Campbell. 2018b. Ev-\"], \"error\": null}, \"8d5ab4a4\": {\"success\": true, \"paper_id\": \"8d5ab4a4\", \"url\": \"https://arxiv.org/pdf/2207.13332v2\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_8d5ab4a4.pdf\", \"extracted_info\": {\"title\": \"REALTIMEQA: A Dynamic Benchmark for Real-Time Open-Domain Question Answering\", \"authors\": [\"Not specified in provided content\"], \"abstract\": \"We introduce REALTIMEQA, a dynamic question answering (QA) platform that announces questions and evaluates models in real time. Our experiments over the past year show that GPT-3 can often properly update its generation results based on newly retrieved documents, highlighting the importance of up-to-date information retrieval. We hope that REALTIMEQA will spur progress in instantaneous applications of question answering and beyond.\", \"methodology\": \"The study presents a dynamic QA benchmark where questions are posted weekly, and participants submit answers in real time. The methodology includes open-book and closed-book QA models, with open-book models using document retrieval (Google Custom Search or Dense Passage Retrieval) followed by answer generation using GPT-3 or Retrieval-Augmented Generation (RAG). Closed-book baselines include GPT-3 and finetuned T5 models. Temporal context is incorporated by prepending top-5 retrieved articles to the question. Evaluation spans from June 17, 2022, to June 2, 2023, with a total of 1,470 QA pairs collected in real time and an additional 2,886 QA pairs collected similarly for finetuning and analysis.\", \"results\": \"Across multiple-choice and generation settings, GPT-3 with Google Custom Search retrieval achieved the best performance, outperforming closed-book baselines and open-book models with other retrieval methods. For example, GCS GPT-3 attained scores of 66.5 (Orig.), 58.4 (NOTA), 34.6 (EM), and 45.3 (F1), compared to lower scores for DPR GPT-3 and closed-book models. Ablation studies showed that inserting temporal information improved accuracy. Error analysis categorized mistakes into three types, with temporal specificity improving results consistently over time.\", \"conclusion\": \"Key contributions include: (1) Introduction of REALTIMEQA, a dynamic, time-sensitive QA benchmark for real-world evaluation; (2) Demonstration that up-to-date document retrieval significantly improves open-domain QA performance; (3) Development of a prompting method for GPT-3 incorporating temporal context; (4) Comprehensive evaluation over a year showing superiority of GCS-based retrieval with GPT-3; (5) Provision of datasets, baselines, and infrastructure to facilitate future research in real-time QA.\", \"figures\": null, \"tables\": null}, \"citations\": [\"James Allan, Rahul Gupta, and Vikas Khandelwal. 2001. Temporal summaries of new topics. In\", \"James Allan, Ron Papka, and Victor Lavrenko. 1998. On-line new event detection and tracking. In\", \"9\", \"Jafar Ahmad Abed Alzubi, Rachna Jain, Anubhav Singh, Pritee Parwekar, and Meenu Gupta. 2021.\", \"Akari Asai, Jungo Kasai, Jonathan H Clark, Kenton Lee, Eunsol Choi, and Hannaneh Hajishirzi.\", \"2021. XOR QA: Cross-lingual open-retrieval question answering. In Proc. of NAACL .\", \"Akari Asai, Shayne Longpre, Jungo Kasai, Chia-Hsuan Lee, Rui Zhang, Junjie Hu, Ikuya Yamada,\", \"Jonathan H. Clark, and Eunsol Choi. 2022. MIA 2022 shared task: Evaluating cross-lingual\", \"Javed A. Aslam, Fernando Diaz, Matthew Ekstrand-Abueg, Richard McCreadie, Virgil Pavlu, and\", \"Javed A. Aslam, Matthew Ekstrand-Abueg, Virgil Pavlu, Fernando Diaz, Richard McCreadie, and\", \"Javed A. Aslam, Matthew Ekstrand-Abueg, Virgil Pavlu, Fernando Diaz, and Tetsuya Sakai. 2013.\", \"Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. 2013. Semantic parsing on Freebase\", \"Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\", \"Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel\", \"Herbert-V oss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler,\", \"Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott Gray,\", \"Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya Sutskever,\", \"Cody Buntain, Richard McCreadie, and Ian Soboroff. 2020. Incident streams 2020: TRECIS in the\", \"Roberta Catizone, Angelo Dalli, and Yorick Wilks. 2006. Evaluating automatically generated\", \"Danqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. 2017. Reading Wikipedia to answer\", \"Wenhu Chen, Xinyi Wang, and William Yang Wang. 2021. A dataset for answering time-sensitive\", \"Xiuying Chen, Zhangming Chan, Shen Gao, Meng-Hsuan Yu, Dongyan Zhao, and Rui Yan. 2019.\", \"Jonathan H. Clark, Eunsol Choi, Michael Collins, Dan Garrette, Tom Kwiatkowski, Vitaly Nikolaev,\", \"Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of\", \"Bhuwan Dhingra, Jeremy R. Cole, Julian Martin Eisenschlos, Daniel Gillick, Jacob Eisenstein, and\", \"David Kirk Evans, Judith L. Klavans, and Kathleen R. McKeown. 2004. Columbia Newsblaster:\", \"10\", \"Katja Filippova, Mihai Surdeanu, Massimiliano Ciaramita, and Hugo Zaragoza. 2009. Company-\", \"Sebastian Gehrmann, Tosin P. Adewumi, Karmanya Aggarwal, Pawan Sasanka Ammanamanchi,\", \"Aremu Anuoluwapo, Antoine Bosselut, Khyathi Raghavi Chandu, Miruna-Adriana Clinciu, Di-\", \"panjan Das, Kaustubh D. Dhole, Wanyu Du, Esin Durmus, Ondrej Dusek, Chris Emezue, Varun\", \"Gangal, Cristina Garbacea, Tatsunori Hashimoto, Yufang Hou, Yacine Jernite, Harsh Jhamtani,\", \"Yangfeng Ji, Shailza Jolly, Dhruv Kumar, Faisal Ladhak, Aman Madaan, Mounica Maddela, Khyati\", \"Mahajan, Saad Mahamood, Bodhisattwa Prasad Majumder, Pedro Henrique Martins, Angelina\", \"McMillan-Major, Simon Mille, Emiel van Miltenburg, Moin Nadeem, Shashi Narayan, Vitaly\", \"Nikolaev, Rubungo Andre Niyongabo, Salomey Osei, Ankur P. Parikh, Laura Perez-Beltrachini,\", \"Niranjan Ramesh Rao, Vikas Raunak, Juan Diego Rodriguez, Sashank Santhanam, João Sedoc,\", \"Thibault Sellam, Samira Shaikh, Anastasia Shimorina, Marco Antonio Sobrevilla Cabezudo, Hen-\", \"drik Strobelt, Nishant Subramani, Wei Xu, Diyi Yang, Akhila Yerukola, and Jiawei Zhou. 2021.\", \"The GEM benchmark: Natural language generation, its evaluation and metrics. In Proc. of GEM .\", \"Sebastian Gehrmann, Abhik Bhattacharjee, Abinaya Mahendiran, Alex Wang, Alexandros Papangelis,\", \"Aman Madaan, Angelina McMillan-Major, Anna Shvets, Ashish Upadhyay, Bingsheng Yao, Bryan\", \"Wilie, Chandra Bhagavatula, Chaobin You, Craig Thomson, Cristina Garbacea, Dakuo Wang,\", \"Daniel Deutsch, Deyi Xiong, Di Jin, Dimitra Gkatzia, Dragomir Radev, Elizabeth Clark, Esin\", \"Durmus, Faisal Ladhak, Filip Ginter, Genta Indra Winata, Hendrik Strobelt, Hiroaki Hayashi,\", \"Jekaterina Novikova, Jenna Kanerva, Jenny Chim, Jiawei Zhou, Jordan Clive, Joshua Maynez,\", \"João Sedoc, Juraj Juraska, Kaustubh D. Dhole, Khyathi Raghavi Chandu, Laura Perez-Beltrachini,\", \"Leonardo F. R. Ribeiro, Lewis Tunstall, Li Zhang, Mahima Pushkarna, Mathias Creutz, Michael\", \"White, Mihir Sanjay Kale, Moussa Kamal Eddine, Nico Daheim, Nishant Subramani, Ondrej\", \"Dusek, Paul Pu Liang, Pawan Sasanka Ammanamanchi, Qi Zhu, Ratish Puduppully, Reno Kriz,\", \"Rifat Shahriyar, Ronald Cardenas, Saad Mahamood, Salomey Osei, Samuel Cahyawijaya, Sanja\", \"Stajner, Sébastien Montella, Shailza Jolly, Simon Mille, Tahmid Hasan, Tianhao Shen, Tosin P.\", \"AMahidewumi, Vikas Raunak, Vipul Raheja, Vitaly Nikolaev, Vivian Tsai, Yacine Jernite, Ying\", \"Xu, Yisi Sang, Yixin Liu, and Yufang Hou. 2022. GEMv2: Multilingual NLG benchmarking in a\", \"Saptarshi Ghosh, Kripabandhu Ghosh, Debasis Ganguly, Tanmoy Chakraborty, Gareth J.F. Jones, and\", \"Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. 2020. REALM:\", \"Karl Moritz Hermann, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa\", \"Suleyman, and Phil Blunsom. 2015. Teaching machines to read and comprehend. In Proc. of\", \"Muhammad Imran, Carlos Castillo, Fernando Diaz, and Sarah Vieweg. 2015. Processing social media\", \"Muhammad Imran, Shady Elbassuoni, Carlos Castillo, Fernando Diaz, and Patrick Meier. 2013.\", \"Muhammad Imran, Prasenjit Mitra, and Carlos Castillo. 2016. Twitter as a lifeline: Human-annotated\", \"11\", \"Joel Jang, Seonghyeon Ye, Changho Lee, Sohee Yang, Joongbo Shin, Janghoon Han, Gyeonghun\", \"Kim, and Minjoon Seo. 2022a. TemporalWiki: A lifelong benchmark for training and evaluating\", \"Joel Jang, Seonghyeon Ye, Sohee Yang, Joongbo Shin, Janghoon Han, Gyeonghun Kim, Stan-\", \"ley Jungkyu Choi, and Minjoon Seo. 2022b. Towards continual knowledge learning of language\", \"Zhen Jia, Abdalghani Abujabal, Rishiraj Saha Roy, Jannik Strötgen, and Gerhard Weikum. 2018.\", \"Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke Zettlemoyer. 2017. TriviaQA: A large scale\", \"Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi\", \"Chen, and Wen-tau Yih. 2020. Dense passage retrieval for open-domain question answering. In\", \"Jungo Kasai, Keisuke Sakaguchi, Ronan Le Bras, Lavinia Dunagan, Jacob Morrison, Alexander R.\", \"Fabbri, Yejin Choi, and Noah A. Smith. 2022. Bidimensional leaderboards: Generate and evaluate\", \"Douwe Kiela, Max Bartolo, Yixin Nie, Divyansh Kaushik, Atticus Geiger, Zhengxuan Wu, Bertie\", \"Vidgen, Grusha Prasad, Amanpreet Singh, Pratik Ringshia, Zhiyi Ma, Tristan Thrush, Sebastian\", \"Riedel, Zeerak Waseem, Pontus Stenetorp, Robin Jia, Mohit Bansal, Christopher Potts, and Adina\", \"Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris\", \"Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, et al. 2019. Natural questions:\", \"Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang, and Eduard Hovy. 2017. RACE: Large-scale\", \"Angeliki Lazaridou, Elena Gribovskaya, Wojciech Stokowiec, and Nikolai Grigorev. 2022. Internet-\", \"Angeliki Lazaridou, Adhiguna Kuncoro, Elena Gribovskaya, Devang Agrawal, Adam Liska, Tayfun\", \"Terzi, Mai Gimenez, Cyprien de Masson d’Autume, Tomás Kociský, Sebastian Ruder, Dani\", \"Yogatama, Kris Cao, Susannah Young, and Phil Blunsom. 2021. Mind the gap: Assessing temporal\", \"Jinhyuk Lee, Sean S. Yi, Minbyul Jeong, Mujeen Sung, WonJin Yoon, Yonghwa Choi, Miyoung\", \"Ko, and Jaewoo Kang. 2020. Answering questions on COVID-19 in real-time. In Proc. of the 1st\", \"Kyungjae Lee, Wookje Han, Seung-won Hwang, Hwaran Lee, Joonsuk Park, and Sang-Woo Lee.\", \"2022. Plug-and-play adaptation for continuously-updated QA. In Findings of the ACL: ACL 2022 .\", \"Mike Lewis, Yinhan Liu, Naman Goyal, Marjan Ghazvininejad, Abdelrahman Mohamed, Omer\", \"Levy, Veselin Stoyanov, and Luke Zettlemoyer. 2020a. BART: Denoising sequence-to-sequence\", \"pre-training for natural language generation, translation, and comprehension. In Proc. of ACL .\", \"Patrick S. H. Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman\", \"Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, and Douwe\", \"Zhiwei Li, Bin Wang, Mingjing Li, and Wei-Ying Ma. 2005. A probabilistic model for retrospective\", \"Jimmy Lin, Salman Mohammed, Royal Sequiera, Luchen Tan, Nimesh Ghelani, Mustafa Abualsaud,\", \"Richard McCreadie, Dmitrijs Milajevs, and Ellen M. V oorhees. 2017. Overview of the TREC 2017\", \"12\", \"Jimmy Lin, Adam Roegiest, Luchen Tan, Richard McCreadie, Ellen M. V oorhees, and Fernando\", \"Adam Liška, Tomáš Ko ˇciský, Elena Gribovskaya, Tayfun Terzi, Eren Sezener, Devang Agrawal,\", \"Cyprien de Masson d’Autume, Tim Scholtes, Manzil Zaheer, Susannah Young, Ellen Gilsenan-\", \"McMahon Sophia Austin, Phil Blunsom, and Angeliki Lazaridou. 2022. StreamingQA: A bench-\", \"Shayne Longpre, Yi Lu, and Joachim Daiber. 2021a. MKQA: A linguistically diverse benchmark for\", \"Shayne Longpre, Kartik Perisetla, Anthony Chen, Nikhil Ramesh, Chris DuBois, and Sameer Singh.\", \"2021b. Entity-based knowledge conflicts in question answering. In Proc. of EMNLP .\", \"Kelvin Luu, Daniel Khashabi, Suchin Gururangan, Karishma Mandyam, and Noah A. Smith. 2022.\", \"Zhiyi Ma, Kawin Ethayarajh, Tristan Thrush, Somya Jain, Ledell Wu, Robin Jia, Christopher Potts,\", \"Adina Williams, and Douwe Kiela. 2021. Dynaboard: An evaluation-as-a-service platform for\", \"Richard McCreadie, Cody Buntain, and Ian Soboroff. 2019. TREC incident streams: Finding\", \"Kathleen McKeown, Regina Barzilay, John Chen, David Elson, David Evans, Judith Klavans, Ani\", \"Nenkova, Barry Schiffman, and Sergey Sigelman. 2003. Columbia’s newsblaster: New features\", \"Kathleen R. McKeown, Regina Barzilay, David Evans, Vasileios Hatzivassiloglou, Judith L. Klavans,\", \"Ani Nenkova, Carl Sable, Barry Schiffman, and Sergey Sigelman. 2002. Tracking and summarizing\", \"Sewon Min, Danqi Chen, Luke Zettlemoyer, and Hannaneh Hajishirzi. 2019. Knowledge guided text\", \"Timo Möller, Anthony Reina, Raghavan Jayakumar, and Malte Pietsch. 2020. COVID-QA: A\", \"Dat Tien Nguyen, Kamla Al-Mannai, Shafiq R. Joty, Hassan Sajjad, Muhammad Imran, and Prasenjit\", \"Yasumasa Onoe, Michael J. Q. Zhang, Eunsol Choi, and Greg Durrett. 2022. Entity cloze by date:\", \"Arian Pasquali, Ricardo Campos, Alexandre Ribeiro, Brenda Santana, Alípio Jorge, and Adam\", \"Tatiana Passali, Alexios Gidiotis, Efstathios Chatzikyriakidis, and Grigorios Tsoumakas. 2021.\", \"Christopher Potts, Zhengxuan Wu, Atticus Geiger, and Douwe Kiela. 2021. DynaSent: A dynamic\", \"13\", \"Dragomir R. Radev, Sasha Blair-Goldensohn, Zhu Zhang, and Revathi Sundara Raghavan. 2001.\", \"NewsInEssence: A system for domain-independent, real-time news clustering and multi-document\", \"Colin Raffel, Noam Shazeer, Adam Roberts, Katherine Lee, Sharan Narang, Michael Matena, Yanqi\", \"Zhou, Wei Li, and Peter J. Liu. 2020. Exploring the limits of transfer learning with a unified\", \"Pranav Rajpurkar, Robin Jia, and Percy Liang. 2018. Know what you don’t know: Unanswerable\", \"Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. SQuAD: 100,000+\", \"Matthew Richardson, Christopher J.C. Burges, and Erin Renshaw. 2013. MCTest: A challenge\", \"Adam Roberts, Colin Raffel, and Noam Shazeer. 2020. How much knowledge can you pack into the\", \"2021 .\", \"Keisuke Sakaguchi, Ronan Le Bras, Chandra Bhagavatula, and Yejin Choi. 2020. WinoGrande: An\", \"Minjoon Seo, Jinhyuk Lee, Tom Kwiatkowski, Ankur Parikh, Ali Farhadi, and Hannaneh Hajishirzi.\", \"2019. Real-time open-domain question answering with dense-sparse phrase index. In Proc. of\", \"Royal Sequiera, Luchen Tan, and Jimmy Lin. 2018. Overview of the TREC 2018 real-time summa-\", \"Lidan Shou, Zhenhua Wang, Ke Chen, and Gang Chen. 2013. Sumblr: Continuous summarization of\", \"Alon Talmor, Jonathan Herzig, Nicholas Lourie, and Jonathan Berant. 2019. CommonsenseQA: A\", \"Irina Temnikova, Andrea Varga, and Dogan Biyikli. 2014. Building a crisis management term\", \"Tristan Thrush, Kushal Tirumala, Anmol Gupta, Max Bartolo, Pedro Rodriguez, Tariq Kane, William\", \"Gaviria Rojas, Peter Mattson, Adina Williams, and Douwe Kiela. 2022. Dynatask: A framework\", \"Giang Tran, Mohammad Alrifai, and Eelco Herder. 2015. Timeline summarization from relevant\", \"Giang Binh Tran, Mohammad Alrifai, and Dat Quoc Nguyen. 2013. Predicting relevant news events\", \"Lu Wang, Claire Cardie, and Galen Marchetti. 2015. Socially-informed timeline generation for\", \"Lucy Lu Wang, Kyle Lo, Yoganand Chandrasekhar, Russell Reas, Jiangjiang Yang, Doug Burdick,\", \"Darrin Eide, Kathryn Funk, Yannis Katsis, Rodney Michael Kinney, Yunyao Li, Ziyang Liu,\", \"William Merrill, Paul Mooney, Dewey A. Murdick, Devvret Rishi, Jerry Sheehan, Zhihong Shen,\", \"Brandon Stilson, Alex D. Wade, Kuansan Wang, Nancy Xin Ru Wang, Christopher Wilhelm,\", \"Boya Xie, Douglas M. Raymond, Daniel S. Weld, Oren Etzioni, and Sebastian Kohlmeier. 2020.\", \"14\", \"Zhiguo Wang, Patrick Ng, Xiaofei Ma, Ramesh Nallapati, and Bing Xiang. 2019. Multi-passage\", \"René Witte, Ralf Krestel, and Sabine Bergler. 2007. Generating update summaries for DUC 2007. In\", \"Thomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi,\", \"Pierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick\", \"von Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gugger,\", \"Mariama Drame, Quentin Lhoest, and Alexander Rush. 2020. Transformers: State-of-the-art\", \"Rui Yan, Liang Kong, Congrui Huang, Xiaojun Wan, Xiaoming Li, and Yan Zhang. 2011a. Timeline\", \"Rui Yan, Xiaojun Wan, Mirella Lapata, Wayne Xin Zhao, Pu-Jen Cheng, and Xiaoming Li. 2012.\", \"Rui Yan, Xiaojun Wan, Jahna Otterbacher, Liang Kong, Xiaoming Li, and Yan Zhang. 2011b.\", \"Rowan Zellers, Yonatan Bisk, Roy Schwartz, and Yejin Choi. 2018. SWAG: A large-scale adversarial\", \"Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali Farhadi, and Yejin Choi. 2019. HellaSwag: Can a\", \"Xinyu Zhang, Xueguang Ma, Peng Shi, and Jimmy Lin. 2021. Mr. TyDi: A multi-lingual benchmark\", \"1. For all authors...\", \"(a)Do the main claims made in the abstract and introduction accurately reflect the paper’s\", \"(b) Did you describe the limitations of your work? [Yes]\", \"(c) Did you discuss any potential negative societal impacts of your work? [Yes]\", \"(d)Have you read the ethics review guidelines and ensured that your paper conforms to\", \"2. If you are including theoretical results...\", \"(a) Did you state the full set of assumptions of all theoretical results? [N/A]\", \"(b) Did you include complete proofs of all theoretical results? [N/A]\", \"3. If you ran experiments (e.g. for benchmarks)...\", \"(a)Did you include the code, data, and instructions needed to reproduce the main experi-\", \"(b)Did you specify all the training details (e.g., data splits, hyperparameters, how they\", \"(c)Did you report error bars (e.g., with respect to the random seed after running experi-\", \"(d)Did you include the total amount of compute and the type of resources used (e.g., type\", \"of GPUs, internal cluster, or cloud provider)? [Yes]\", \"4. If you are using existing assets (e.g., code, data, models) or curating/releasing new assets...\", \"15\", \"(a) If your work uses existing assets, did you cite the creators? [Yes]\", \"(b) Did you mention the license of the assets? [Yes]\", \"(c)Did you include any new assets either in the supplemental material or as a URL? [Yes]\", \"(d)Did you discuss whether and how consent was obtained from people whose data you’re\", \"(e)Did you discuss whether the data you are using/curating contains personally identifiable\", \"5. If you used crowdsourcing or conducted research with human subjects...\", \"(a)Did you include the full text of instructions given to participants and screenshots, if\", \"(b)Did you describe any potential participant risks, with links to Institutional Review\", \"Board (IRB) approvals, if applicable? [N/A]\", \"(c)Did you include the estimated hourly wage paid to participants and the total amount\", \"16\", \"We provide the configurations for our real-time baselines (§2.4). We use the open-source, Transform-\", \"retrieval (Karpukhin et al., 2020) and retrieval-augmented generation (Lewis et al., 2020b). We gener-\", \"Table 4: Configurations for dense passage retrieval (Karpukhin et al., 2020) and retrieval-augmented\", \"generation (Lewis et al., 2020b) from the Transformers library (Wolf et al., 2020).\", \"Fig. 7 shows our REALTIME QAinterface. It gets updated every week, and all six baselines are\", \"evaluated as soon as the questions are available. Submissions will be shown on the same page,\", \"questions were not strictly time-sensitive. These questions include, for example, “Temperatures in\", \"Britain are set to soar this weekend, but what is the hottest UK temperature on record?” from June 17,\", \"2022. We do not filter out these cases to simulate information-seeking, naturally-occurring scenarios.\", \"17\", \"Table 5: Configuration for the closed-book T5 baseline (Raffel et al., 2020) from the Transformer\", \"Figure 7: REALTIMEQAinterface. It is updated every week, and all six baselines are evaluated as\", \"soon as the questions are available. Submissions will be shown on the same page, together with their\", \"18\", \"time-sensitive. These questions include, for example, “Temperatures in Britain are set to soar this\", \"weekend, but what is the hottest UK temperature on record?” from June 17, 2022. We do not filter\", \"out these cases to simulate information-seeking, naturally-occurring scenarios.\", \"36.9% 17.5% 17.5% 7.0% 7.0% 8.8% 5.2%\", \"12.3% 19.2% 5.3% 22.8% 3.5% 8.8% 28.1%\", \"19\"], \"error\": null}, \"1f60c61f\": {\"success\": true, \"paper_id\": \"1f60c61f\", \"url\": \"https://arxiv.org/pdf/2504.11972v2\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_1f60c61f.pdf\", \"extracted_info\": {\"title\": \"LLM-as-a-Judge: Reassessing the Performance of LLMs in Extractive QA\", \"authors\": [\"Not specified in provided content\"], \"abstract\": \"Extractive reading comprehension question answering (QA) datasets are typically evaluated using exact match (EM) and F1 metrics. This paper investigates replacing these metrics with LLM-as-a-judge, showing that it is highly correlated with human judgments and can serve as a more reliable evaluation method.\", \"methodology\": \"The study uses a few-shot prompting approach with large language models (LLMs) to evaluate predicted answers in extractive QA tasks. Multiple datasets, including DROP, HotpotQA, and 2Wiki, are used for experiments. LLM-as-a-judge scores are compared against traditional EM and F1 scores, and correlations with human judgments are computed. Analyses are conducted across different answer types (name, number, place, string).\", \"results\": \"LLM-as-a-judge achieved a correlation of 0.85 with human judgments, significantly higher than EM (0.22) and F1 (0.40). Correlation by answer type: name (0.862), number (0.899), place (0.771), string (value not fully provided). Results are consistent across multiple LLMs (Mistral 7B v0.3, Llama 3.3 70B, Qwen 2.5 72B) and datasets.\", \"conclusion\": \"LLM-as-a-judge offers a more accurate and human-aligned evaluation for extractive QA tasks compared to traditional EM/F1 metrics. It can better capture the true capabilities of QA models, reduce underestimation, and potentially replace existing evaluation methods in future research.\", \"figures\": null, \"tables\": null}, \"citations\": [\"Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla\", \"Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini\", \"Agarwal, Ariel Herbert-Voss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya\", \"Ramesh, Daniel Ziegler, Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric\", \"Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam\", \"McCandlish, Alec Radford, Ilya Sutskever, and Dario Amodei. Language models are\", \"few-shot learners. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin\", \"(eds.), Advances in Neural Information Processing Systems , volume 33, pp. 1877–1901. Curran\", \"Associates, Inc., 2020. URL https://proceedings.neurips.cc/paper files/paper/2020/\", \"Danqi Chen. Neural Reading Comprehension and Beyond . PhD thesis, Stanford University,\", \"2018.\", \"Lei Chen, Bobo Li, Li Zheng, Haining Wang, Zixiang Meng, Runfeng Shi, Hao Fei, Jun Zhou,\", \"Fei Li, Chong Teng, and Donghong Ji. What factors influence LLMs’ judgments? a case\", \"study on question answering. In Nicoletta Calzolari, Min-Yen Kan, Veronique Hoste,\", \"Alessandro Lenci, Sakriani Sakti, and Nianwen Xue (eds.), Proceedings of the 2024 Joint\", \"International Conference on Computational Linguistics, Language Resources and Evaluation\", \"(LREC-COLING 2024) , pp. 17473–17485, Torino, Italia, May 2024. ELRA and ICCL. URL\", \"tational Linguistics (Volume 1: Long Papers) , pp. 15607–15631, Toronto, Canada, July 2023.\", \"Eunsol Choi, He He, Mohit Iyyer, Mark Yatskar, Wen-tau Yih, Yejin Choi, Percy Liang,\", \"Conference on Empirical Methods in Natural Language Processing , pp. 2174–2184, Brussels,\", \"Belgium, October-November 2018. Association for Computational Linguistics. doi: 10.\", \"18653/v1/D18-1241. URL https://aclanthology.org/D18-1241 .\", \"Christopher Clark, Kenton Lee, Ming-Wei Chang, Tom Kwiatkowski, Michael Collins, and\", \"for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Pa-\", \"pers) , pp. 2924–2936, Minneapolis, Minnesota, June 2019. Association for Computational\", \"Pradeep Dasigi, Nelson F. Liu, Ana Marasovi ´c, Noah A. Smith, and Matt Gardner. Quoref:\", \"9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP) , pp. 5925–\", \"5932, Hong Kong, China, November 2019. Association for Computational Linguistics.\", \"10\", \"Dheeru Dua, Yizhong Wang, Pradeep Dasigi, Gabriel Stanovsky, Sameer Singh, and Matt\", \"the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long\", \"and Short Papers) , pp. 2368–2378, Minneapolis, Minnesota, June 2019. Association for\", \"Mor Geva, Daniel Khashabi, Elad Segal, Tushar Khot, Dan Roth, and Jonathan Berant.\", \"strategies. Transactions of the Association for Computational Linguistics , 9:346–361, 2021. doi:\", \"10.1162/tacl a00370. URL https://aclanthology.org/2021.tacl-1.21 .\", \"Aaron Grattafiori, Abhimanyu Dubey, Abhinav Jauhri, Abhinav Pandey, Abhishek Kadian,\", \"Ahmad Al-Dahle, Aiesha Letman, Akhil Mathur, Alan Schelten, Alex Vaughan, and et al.\", \"The llama 3 herd of models. arXiv:2407.21783 , 2024. URL https://arxiv.org/abs/2407.\", \"21783 .\", \"Jiawei Gu, Xuhui Jiang, Zhichao Shi, Hexiang Tan, Xuehao Zhai, Chengjin Xu, Wei Li,\", \"Yinghan Shen, Shengjie Ma, Honghao Liu, Saizhuo Wang, Kun Zhang, Yuanzhuo Wang,\", \"Wen Gao, Lionel Ni, and Jian Guo. A survey on llm-as-a-judge. arXiv:2411.15594 , 2025.\", \"Karl Moritz Hermann, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will\", \"Kay, Mustafa Suleyman, and Phil Blunsom. Teaching machines to read and com-\", \"prehend. In C. Cortes, N. Lawrence, D. Lee, M. Sugiyama, and R. Garnett\", \"(eds.), Advances in Neural Information Processing Systems , volume 28. Curran Asso-\", \"ciates, Inc., 2015. URL https://proceedings.neurips.cc/paper files/paper/2015/\", \"Lynette Hirschman, Marc Light, Eric Breck, and John D. Burger. Deep read: A read-\", \"ation for Computational Linguistics , pp. 325–332, College Park, Maryland, USA, June\", \"1999. Association for Computational Linguistics. doi: 10.3115/1034678.1034731. URL\", \"Xanh Ho, Anh-Khoa Duong Nguyen, Saku Sugawara, and Akiko Aizawa. Constructing a\", \"of the 28th International Conference on Computational Linguistics , pp. 6609–6625, Barcelona,\", \"Spain (Online), December 2020. International Committee on Computational Linguis-\", \"Naoya Inoue, Pontus Stenetorp, and Kentaro Inui. R4C: A benchmark for evaluating RC\", \"Meeting of the Association for Computational Linguistics , pp. 6740–6750, Online, July 2020.\", \"Albert Q. Jiang, Alexandre Sablayrolles, Arthur Mensch, Chris Bamford, Devendra Singh\", \"Chaplot, Diego de las Casas, Florian Bressand, Gianna Lengyel, Guillaume Lample,\", \"Lucile Saulnier, L ´elio Renard Lavaud, Marie-Anne Lachaux, Pierre Stock, Teven Le Scao,\", \"Thibaut Lavril, Thomas Wang, Timoth ´ee Lacroix, and William El Sayed. Mistral 7b.\", \"arXiv:2310.06825 , 2023. URL https://arxiv.org/abs/2310.06825 .\", \"Albert Q. Jiang, Alexandre Sablayrolles, Antoine Roux, Arthur Mensch, Blanche Savary,\", \"Chris Bamford, Devendra Singh Chaplot, Diego de las Casas, Emma Bou Hanna, Florian\", \"Bressand, Gianna Lengyel, Guillaume Bour, Guillaume Lample, L ´elio Renard Lavaud,\", \"Lucile Saulnier, Marie-Anne Lachaux, Pierre Stock, Sandeep Subramanian, Sophia Yang,\", \"Szymon Antoniak, Teven Le Scao, Th ´eophile Gervet, Thibaut Lavril, Thomas Wang,\", \"Timoth ´ee Lacroix, and William El Sayed. Mixtral of experts. arXiv:2401.04088 , 2024. URL\", \"11\", \"for Machine Translation , pp. 193–203, Tampere, Finland, June 2023. European Association\", \"Takeshi Kojima, Shixiang (Shane) Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwa-\", \"sawa. Large language models are zero-shot reasoners. In S. Koyejo, S. Mo-\", \"hamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh (eds.), Advances in Neu-\", \"ral Information Processing Systems , volume 35, pp. 22199–22213. Curran Associates,\", \"Inc., 2022. URL https://proceedings.neurips.cc/paper files/paper/2022/file/\", \"8bb0d291acd4acf06ef112099c16f326-Paper-Conference.pdf .\", \"Ryan Koo, Minhwa Lee, Vipul Raheja, Jong Inn Park, Zae Myung Kim, and Dongyeop\", \"Wei Ku, Andre Martins, and Vivek Srikumar (eds.), Findings of the Association for Com-\", \"putational Linguistics: ACL 2024 , pp. 517–545, Bangkok, Thailand, August 2024. Asso-\", \"Zhen Li, Xiaohan Xu, Tao Shen, Can Xu, Jia-Chen Gu, Yuxuan Lai, Chongyang Tao, and\", \"lenges. In Yaser Al-Onaizan, Mohit Bansal, and Yun-Nung Chen (eds.), Proceedings of\", \"the 2024 Conference on Empirical Methods in Natural Language Processing , pp. 16028–16045,\", \"Miami, Florida, USA, November 2024. Association for Computational Linguistics. doi:\", \"10.18653/v1/2024.emnlp-main.896. URL https://aclanthology.org/2024.emnlp-main.\", \"896/ .\", \"Yiqi Liu, Nafise Moosavi, and Chenghua Lin. LLMs as narcissistic evaluators: When\", \"ego inflates evaluation scores. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar\", \"(eds.), Findings of the Association for Computational Linguistics: ACL 2024 , pp. 12688–12701,\", \"Bangkok, Thailand, August 2024. Association for Computational Linguistics. doi: 10.\", \"18653/v1/2024.findings-acl.753. URL https://aclanthology.org/2024.findings-acl.\", \"753/ .\", \"Yixin Liu, Alex Fabbri, Pengfei Liu, Yilun Zhao, Linyong Nan, Ruilin Han, Simeng Han,\", \"Shafiq Joty, Chien-Sheng Wu, Caiming Xiong, and Dragomir Radev. Revisiting the\", \"1: Long Papers) , pp. 4140–4170, Toronto, Canada, July 2023. Association for Computational\", \"Arjun Panickssery, Samuel R. Bowman, and Shi Feng. LLM evaluators recognize and\", \"Processing Systems , 2024. URL https://openreview.net/forum?id=4NJBV6Wp0h .\", \"of the Royal Society of London , 58(347-352):240–242, 1895.\", \"Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah Smith, and Mike Lewis.\", \"Bouamor, Juan Pino, and Kalika Bali (eds.), Findings of the Association for Computational\", \"Linguistics: EMNLP 2023 , pp. 5687–5711, Singapore, December 2023. Association for\", \"Vyas Raina, Adian Liusie, and Mark Gales. Is LLM-as-a-judge robust? investigating\", \"universal adversarial attacks on zero-shot LLM assessment. In Yaser Al-Onaizan, Mohit\", \"Bansal, and Yun-Nung Chen (eds.), Proceedings of the 2024 Conference on Empirical Methods\", \"in Natural Language Processing , pp. 7499–7517, Miami, Florida, USA, November 2024.\", \"12\", \"Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. SQuAD: 100,000+\", \"Empirical Methods in Natural Language Processing , pp. 2383–2392, Austin, Texas, November\", \"2016. Association for Computational Linguistics. doi: 10.18653/v1/D16-1264. URL\", \"Pranav Rajpurkar, Robin Jia, and Percy Liang. Know what you don’t know: Unanswerable\", \"Computational Linguistics (Volume 2: Short Papers) , pp. 784–789, Melbourne, Australia,\", \"Siva Reddy, Danqi Chen, and Christopher D. Manning. CoQA: A conversational question\", \"answering challenge. Transactions of the Association for Computational Linguistics , 7:249–266,\", \"2019. doi: 10.1162/tacl a00266. URL https://aclanthology.org/Q19-1016 .\", \"Jiawen Shi, Zenghui Yuan, Yinuo Liu, Yue Huang, Pan Zhou, Lichao Sun, and Neil Zhen-\", \"curity , CCS ’24, pp. 660–674, New York, NY, USA, 2024. Association for Comput-\", \"Ondrej Skopek, Rahul Aralikatte, Sian Gooding, and Victor Carbune. Towards better\", \"evaluation of instruction-following: A case-study in summarization. In Jing Jiang,\", \"David Reitter, and Shumin Deng (eds.), Proceedings of the 27th Conference on Compu-\", \"tational Natural Language Learning (CoNLL) , pp. 221–237, Singapore, December 2023.\", \"Yuqing Tang, Chau Tran, Xian Li, Peng-Jen Chen, Naman Goyal, Vishrav Chaudhary,\", \"Jiatao Gu, and Angela Fan. Multilingual translation from denoising pre-training. In\", \"Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021 , pp. 3450–3466,\", \"Online, August 2021. Association for Computational Linguistics. doi: 10.18653/v1/2021.\", \"arXiv:2408.00118 , 2024.\", \"Aman Singh Thakur, Kartik Choudhary, Venkat Srinik Ramayapally, Sankaran\", \"Vaidyanathan, and Dieuwke Hupkes. Judging the judges: Evaluating alignment and\", \"vulnerabilities in llms-as-judges. arXiv:2406.12624 , 2025. URL https://arxiv.org/abs/\", \"2406.12624 .\", \"Adam Trischler, Tong Wang, Xingdi Yuan, Justin Harris, Alessandro Sordoni, Philip Bach-\", \"man, and Kaheer Suleman. NewsQA: A machine comprehension dataset. In Proceedings\", \"of the 2nd Workshop on Representation Learning for NLP , pp. 191–200, Vancouver, Canada,\", \"Harsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. MuSiQue:\", \"for Computational Linguistics , 10:539–554, 2022. doi: 10.1162/tacl a00475. URL https:\", \"Pat Verga, Sebastian Hofstatter, Sophia Althammer, Yixuan Su, Aleksandra Piktus, Arkady\", \"Arkhangorodsky, Minjie Xu, Naomi White, and Patrick Lewis. Replacing judges with\", \"juries: Evaluating llm generations with a panel of diverse models. arXiv:2404.18796 , 2024.\", \"Peiyi Wang, Lei Li, Liang Chen, Zefan Cai, Dawei Zhu, Binghuai Lin, Yunbo Cao, Lingpeng\", \"Kong, Qi Liu, Tianyu Liu, and Zhifang Sui. Large language models are not fair evaluators.\", \"13\", \"In Lun-Wei Ku, Andre Martins, and Vivek Srikumar (eds.), Proceedings of the 62nd Annual\", \"Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pp. 9440–\", \"9450, Bangkok, Thailand, August 2024. Association for Computational Linguistics. doi:\", \"10.18653/v1/2024.acl-long.511. URL https://aclanthology.org/2024.acl-long.511/ .\", \"Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, brian ichter, Fei Xia, Ed Chi,\", \"Quoc V Le, and Denny Zhou. Chain-of-thought prompting elicits reasoning in large\", \"language models. In S. Koyejo, S. Mohamed, A. Agarwal, D. Belgrave, K. Cho, and A. Oh\", \"(eds.), Advances in Neural Information Processing Systems , volume 35, pp. 24824–24837. Cur-\", \"ran Associates, Inc., 2022. URL https://proceedings.neurips.cc/paper files/paper/\", \"2022/file/9d5609613524ecf4f15af0f7b31abca4-Paper-Conference.pdf .\", \"Johannes Welbl, Pontus Stenetorp, and Sebastian Riedel. Constructing datasets for multi-hop\", \"Linguistics , 6:287–302, 2018. doi: 10.1162/tacl a00021. URL https://aclanthology.org/\", \"Jian Wu, Linyi Yang, Dongyuan Li, Yuliang Ji, Manabu Okumura, and Yue Zhang. MMQA:\", \"tional Conference on Learning Representations , 2025. URL https://openreview.net/forum?\", \"Ning Wu, Ming Gong, Linjun Shou, Shining Liang, and Daxin Jiang. Large language\", \"Processing and Chinese Computing: 12th National CCF Conference, NLPCC 2023, Foshan,\", \"China, October 12–15, 2023, Proceedings, Part I , pp. 695–707, Berlin, Heidelberg, 2023.\", \"An Yang, Baosong Yang, and et al. Qwen2 technical report. arXiv:2407.10671 , 2024.\", \"An Yang, Baosong Yang, and et al. Qwen2.5 technical report. arXiv:2412.15115 , 2025.\", \"Zhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William Cohen, Ruslan Salakhut-\", \"dinov, and Christopher D. Manning. HotpotQA: A dataset for diverse, explainable\", \"in Natural Language Processing , pp. 2369–2380, Brussels, Belgium, October-November\", \"2018. Association for Computational Linguistics. doi: 10.18653/v1/D18-1259. URL\", \"Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao\", \"Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, Hao Zhang, Joseph E Gonza-\", \"lez, and Ion Stoica. Judging LLM-as-a-judge with MT-bench and chatbot arena. In\", \"A. Oh, T. Naumann, A. Globerson, K. Saenko, M. Hardt, and S. Levine (eds.), Ad-\", \"vances in Neural Information Processing Systems , volume 36, pp. 46595–46623. Curran\", \"Associates, Inc., 2023. URL https://proceedings.neurips.cc/paper files/paper/2023/\", \"Andrew Zhu, Alyssa Hwang, Liam Dugan, and Chris Callison-Burch. FanOutQA: A multi-\", \"hop, multi-document question answering benchmark for large language models. In\", \"Lun-Wei Ku, Andre Martins, and Vivek Srikumar (eds.), Proceedings of the 62nd Annual\", \"Meeting of the Association for Computational Linguistics (Volume 2: Short Papers) , pp. 18–\", \"37, Bangkok, Thailand, August 2024. Association for Computational Linguistics. doi:\", \"10.18653/v1/2024.acl-short.2. URL https://aclanthology.org/2024.acl-short.2/ .\", \"14\", \"- Break down the problem into smaller parts, if necessary.\", \"Table 10 presents LLM-as-a-judge scores for Mistral 7B v0.3, Llama 3.3 70B, and Qwen 2.5\", \"72B across four datasets. Columns labeled Mistral, Llama, or Qwen show scores for false\", \"EM samples only, while Mistral-A, Llama-A, or Qwen-A show scores for all samples.\", \"15\", \"*CORRECT : The predicted answer matches the gold answer or is a valid alternative (e.g.,\", \"*In some ambiguous cases, where it is unclear whether the predicted answer is correct\", \"or not, please refer to the provided context and use it as the final source for making your\", \"*Question: What nationality is the performer of song Daddy, Come Home?\", \"Wigmore, who was born in 1909.\", \"*Predicted Answer: Diana Quick, who played the Duchess in ’The Revengers Tragedy’,\", \"16\", \"Table 10: LLM-as-a-judge scores for Mistral 7B v0.3, Llama 3.3 70B, and Qwen 2.5 72B\", \"across four datasets. Columns labeled Mistral, Llama, or Qwen indicate scores on false EM\", \"samples only, while Mistral-A, Llama-A, or Qwen-A indicate scores on all samples.\", \"17\"], \"error\": null}, \"f5ab0431\": {\"success\": true, \"paper_id\": \"f5ab0431\", \"url\": \"https://arxiv.org/pdf/2204.07496v4\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_f5ab0431.pdf\", \"extracted_info\": {\"title\": \"Unsupervised Passage Re-Ranking for Open-Domain Question Answering\", \"authors\": [\"Not specified in provided content\"], \"abstract\": \"We propose a simple and effective re-ranking method for improving passage retrieval in open question answering. The re-ranker re-scores retrieved passages with a zero-shot question generation approach on top of any retrieval method (e.g., neural or keyword-based), without requiring any domain- or task-specific training. This enables achieving new state-of-the-art results on full open-domain question answering by simply adding the new re-ranker to existing models with no further changes.\", \"methodology\": \"The proposed method, called Unsupervised Passage Re-Ranking (UPR), uses pre-trained language models (PLMs) to perform zero-shot question generation conditioned on the query and passage. The generated question likelihood is used to re-score passages retrieved by any retriever (BM25, dense retrievers, hybrid methods). UPR applies task-independent cross-attention between query and passage, and works without supervised fine-tuning. Experiments are conducted on multiple datasets (SQuAD-Open, Entity Questions, BEIR benchmark) and with various retrievers. Ablation studies evaluate the effect of instructions, PLM size, and retrieval pool size.\", \"results\": \"UPR consistently improves retrieval accuracy across datasets and retrievers. On SQuAD-Open, BM25+UPR outperforms BM25 by 14% in top-20 accuracy. On Entity Questions, BM25+UPR achieves 79.3% top-20 accuracy vs. 71.2% for BM25. On BEIR benchmark, NDCG@10 improves by 3–8% and Recall@100 by 5–6%. UPR narrows the gap between sparse and dense retrievers and achieves results close to supervised models like monoT5 without requiring labeled data. In open-domain QA with FiD readers, UPR improves EM scores by 1–3 points over baselines.\", \"conclusion\": \"UPR is a simple, effective, and domain-agnostic re-ranking method that leverages zero-shot question generation with PLMs to improve passage retrieval. It achieves state-of-the-art results without supervised training, works with any retriever, and provides consistent gains across datasets and metrics. Key contributions include: (1) introducing an unsupervised, task-independent re-ranking approach; (2) demonstrating substantial improvements over both sparse and dense retrievers; (3) showing competitive performance with supervised models; (4) validating effectiveness across diverse benchmarks and in full QA pipelines; and (5) highlighting scalability and applicability to various retrieval settings.\", \"figures\": null, \"tables\": null}, \"citations\": [\"Payal Bajaj, Daniel Campos, Nick Craswell, Li Deng,\", \"Jianfeng Gao, Xiaodong Liu, Rangan Majumder,\", \"Andrew McNamara, Bhaskar Mitra, Tri Nguyen,\", \"Jonathan Berant, Andrew Chou, Roy Frostig, and Percy\", \"Sid Black, Gao Leo, Phil Wang, Connor Leahy, and\", \"Tom Brown, Benjamin Mann, Nick Ryder, Melanie\", \"Subbiah, Jared D Kaplan, Prafulla Dhariwal,\", \"Arvind Neelakantan, Pranav Shyam, Girish Sastry,Amanda Askell, Sandhini Agarwal, Ariel Herbert-\", \"V oss, Gretchen Krueger, Tom Henighan, Rewon\", \"Child, Aditya Ramesh, Daniel Ziegler, Jeffrey Wu,\", \"Clemens Winter, Chris Hesse, Mark Chen, Eric\", \"Sigler, Mateusz Litwin, Scott Gray, Benjamin Chess,\", \"Jack Clark, Christopher Berner, Sam McCandlish,\", \"Alec Radford, Ilya Sutskever, and Dario Amodei.\", \"2020. Language models are few-shot learners. In\", \"Advances in Neural Information Processing Systems ,\", \"Danqi Chen, Adam Fisch, Jason Weston, and Antoine\", \"Xilun Chen, Kushal Lakhotia, Barlas O ˘guz, Anchit\", \"Gupta, Patrick Lewis, Stan Peshterliev, Yashar\", \"Mehdad, Sonal Gupta, and Wen-tau Yih. 2021.\", \"Aakanksha Chowdhery, Sharan Narang, Jacob Devlin,\", \"Maarten Bosma, Gaurav Mishra, Adam Roberts,\", \"Paul Barham, Hyung Won Chung, Charles Sutton,\", \"Sebastian Gehrmann, Parker Schuh, Kensen Shi,\", \"Sasha Tsvyashchenko, Joshua Maynez, Abhishek\", \"Rao, Parker Barnes, Yi Tay, Noam M. Shazeer, Vin-\", \"odkumar Prabhakaran, Emily Reif, Nan Du, Ben-\", \"ton C. Hutchinson, Reiner Pope, James Bradbury, Ja-\", \"cob Austin, Michael Isard, Guy Gur-Ari, Pengcheng\", \"Yin, Toju Duke, Anselm Levskaya, Sanjay Ghe-\", \"mawat, Sunipa Dev, Henryk Michalewski, Xavier\", \"García, Vedant Misra, Kevin Robinson, Liam Fe-\", \"dus, Denny Zhou, Daphne Ippolito, David Luan,\", \"Hyeontaek Lim, Barret Zoph, Alexander Spiridonov,\", \"Ryan Sepassi, David Dohan, Shivani Agrawal, Mark\", \"Omernick, Andrew M. Dai, Thanumalayan Sankara-\", \"narayana Pillai, Marie Pellat, Aitor Lewkowycz, Er-\", \"ica Oliveira Moreira, Rewon Child, Oleksandr Polo-\", \"zov, Katherine Lee, Zongwei Zhou, Xuezhi Wang,\", \"Brennan Saeta, Mark Diaz, Orhan Firat, Michele\", \"Catasta, Jason Wei, Kathleen S. Meier-Hellstern,\", \"Douglas Eck, Jeff Dean, Slav Petrov, and Noah\", \"with pathways. ArXiv , abs/2204.02311.\", \"Michiel de Jong, Yury Zemlyanskiy, Nicholas FitzGer-\", \"ald, Fei Sha, and William W. Cohen. 2022. Mention\", \"Jacob Devlin, Ming-Wei Chang, Kenton Lee, and\", \"nologies, Volume 1 (Long and Short Papers) .\", \"Tianyu Gao, Xingcheng Yao, and Danqi Chen. 2021.\", \"Suchin Gururangan, Ana Marasovi ´c, Swabha\", \"Swayamdipta, Kyle Lo, Iz Beltagy, Doug Downey,\", \"Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pa-\", \"supat, and Mingwei Chang. 2020. Retrieval aug-\", \"Gautier Izacard, Mathilde Caron, Lucas Hosseini, Se-\", \"bastian Riedel, Piotr Bojanowski, Armand Joulin,\", \"Mandar Joshi, Eunsol Choi, Daniel Weld, and Luke\", \"(Volume 1: Long Papers) .\", \"Jia-Huei Ju, Jheng-Hong Yang, and Chuan-Ju Wang.\", \"2021. Text-to-text multi-view learning for passage\", \"Vladimir Karpukhin, Barlas O ˘guz, Sewon Min, Ledell\", \"Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih.\", \"2020. Dense passage retrieval for open-domain\", \"Tom Kwiatkowski, Jennimaria Palomaki, Olivia Red-\", \"ﬁeld, Michael Collins, Ankur Parikh, Chris Alberti,\", \"Danielle Epstein, Illia Polosukhin, Matthew Kelcey,\", \"Jacob Devlin, Kenton Lee, Kristina N. Toutanova,\", \"Llion Jones, Ming-Wei Chang, Andrew Dai, JakobUszkoreit, Quoc Le, and Slav Petrov. 2019. Natu-\", \"Kenton Lee, Ming-Wei Chang, and Kristina Toutanova.\", \"2019. Latent retrieval for weakly supervised open\", \"57th Annual Meeting of the Association for Compu-\", \"Brian Lester, Rami Al-Rfou, and Noah Constant. 2021.\", \"Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio\", \"Petroni, Vladimir Karpukhin, Naman Goyal, Hein-\", \"rich Küttler, Mike Lewis, Wen-tau Yih, Tim Rock-\", \"täschel, Sebastian Riedel, and Douwe Kiela. 2020.\", \"Jimmy Lin, Xueguang Ma, Sheng-Chieh Lin, Jheng-\", \"Hong Yang, Ronak Pradeep, and Rodrigo Nogueira.\", \"2021. Pyserini: A Python toolkit for reproducible\", \"2021) .\", \"Xueguang Ma, Kai Sun, Ronak Pradeep, and Jimmy\", \"Sewon Min, Mike Lewis, Luke Zettlemoyer, and Han-\", \"Rodrigo Nogueira, Zhiying Jiang, Ronak Pradeep, and\", \"Cicero Nogueira dos Santos, Xiaofei Ma, Ramesh Nal-\", \"lapati, Zhiheng Huang, and Bing Xiang. 2020. Be-\", \"Adam Paszke, Sam Gross, Francisco Massa, Adam\", \"Lerer, James Bradbury, Gregory Chanan, Trevor\", \"Killeen, Zeming Lin, Natalia Gimelshein, Luca\", \"Antiga, Alban Desmaison, Andreas Kopf, Edward\", \"Yang, Zachary DeVito, Martin Raison, Alykhan Te-\", \"jani, Sasank Chilamkurthy, Benoit Steiner, Lu Fang,\", \"Junjie Bai, and Soumith Chintala. 2019. Pytorch:\", \"An imperative style, high-performance deep learn-\", \"Alec Radford, Jeff Wu, Rewon Child, David Luan,\", \"Dario Amodei, and Ilya Sutskever. 2019. Language\", \"Jack W. Rae, Sebastian Borgeaud, Trevor Cai, Katie\", \"Millican, Jordan Hoffmann, Francis Song, John\", \"Aslanides, Sarah Henderson, Roman Ring, Susan-\", \"nah Young, Eliza Rutherford, Tom Hennigan, Ja-\", \"cob Menick, Albin Cassirer, Richard Powell, George\", \"van den Driessche, Lisa Anne Hendricks, Mari-\", \"beth Rauh, Po-Sen Huang, Amelia Glaese, Johannes\", \"Welbl, Sumanth Dathathri, Saffron Huang, Jonathan\", \"Uesato, John F. J. Mellor, Irina Higgins, Anto-\", \"nia Creswell, Nathan McAleese, Amy Wu, Erich\", \"Elsen, Siddhant M. Jayakumar, Elena Buchatskaya,\", \"David Budden, Esme Sutherland, Karen Simonyan,\", \"Michela Paganini, L. Sifre, Lena Martens, Xi-\", \"ang Lorraine Li, Adhiguna Kuncoro, Aida Ne-\", \"matzadeh, Elena Gribovskaya, Domenic Donato,\", \"Angeliki Lazaridou, Arthur Mensch, Jean-Baptiste\", \"Lespiau, Maria Tsimpoukelli, N. K. Grigorev, Doug\", \"Fritz, Thibault Sottiaux, Mantas Pajarskas, To-\", \"bias Pohlen, Zhitao Gong, Daniel Toyama, Cy-\", \"prien de Masson d’Autume, Yujia Li, Tayfun\", \"Terzi, Vladimir Mikulik, Igor Babuschkin, Aidan\", \"Clark, Diego de Las Casas, Aurelia Guy, Chris\", \"Jones, James Bradbury, Matthew G. Johnson,\", \"Blake A. Hechtman, Laura Weidinger, Iason Gabriel,\", \"William S. Isaac, Edward Lockhart, Simon Osin-\", \"dero, Laura Rimell, Chris Dyer, Oriol Vinyals, Ka-\", \"reem W. Ayoub, Jeff Stanway, L. L. Bennett, Demis\", \"Hassabis, Koray Kavukcuoglu, and Geoffrey Irv-\", \"ing. 2021. Scaling language models: Methods,\", \"analysis & insights from training gopher. ArXiv ,\", \"Colin Raffel, Noam Shazeer, Adam Roberts, Kather-\", \"ine Lee, Sharan Narang, Michael Matena, Yanqi\", \"Zhou, Wei Li, and Peter J. Liu. 2020. Exploring\", \"search , 21(140):1–67.\", \"Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and\", \"Percy Liang. 2016. SQuAD: 100,000+ questions for\", \"trieval .Devendra Singh Sachan, Mostofa Patwary, Mohammad\", \"Shoeybi, Neel Kant, Wei Ping, William L Hamilton,\", \"Devendra Singh Sachan, Siva Reddy, William L.\", \"Hamilton, Chris Dyer, and Dani Yogatama. 2021b.\", \"Victor Sanh, Albert Webson, Colin Raffel, Stephen\", \"Bach, Lintang Sutawika, Zaid Alyafeai, Antoine\", \"Chafﬁn, Arnaud Stiegler, Arun Raja, Manan Dey,\", \"M Saiful Bari, Canwen Xu, Urmish Thakker,\", \"Shanya Sharma Sharma, Eliza Szczechla, Tae-\", \"woon Kim, Gunjan Chhablani, Nihal Nayak, De-\", \"bajyoti Datta, Jonathan Chang, Mike Tian-Jian\", \"Jiang, Han Wang, Matteo Manica, Sheng Shen,\", \"Zheng Xin Yong, Harshit Pandey, Rachel Bawden,\", \"Thomas Wang, Trishala Neeraj, Jos Rozen, Ab-\", \"heesht Sharma, Andrea Santilli, Thibault Fevry, Ja-\", \"son Alan Fries, Ryan Teehan, Teven Le Scao, Stella\", \"Biderman, Leo Gao, Thomas Wolf, and Alexan-\", \"Christopher Sciavolino, Zexuan Zhong, Jinhyuk Lee,\", \"Shaden Smith, Mostofa Patwary, Brandon Norick,\", \"Patrick LeGresley, Samyam Rajbhandari, Jared\", \"Casper, Zhun Liu, Shrimai Prabhumoye, George\", \"Zerveas, Vijay Korthikanti, et al. 2022. Using\", \"nlg 530b, a large-scale generative language model.\", \"Nandan Thakur, Nils Reimers, Andreas Rücklé, Ab-\", \"hishek Srivastava, and Iryna Gurevych. 2021. BEIR:\", \"Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu,\", \"Adams Wei Yu, Brian Lester, Nan Du, Andrew M.\", \"Dai, and Quoc V Le. 2022. Finetuned language\", \"Thomas Wolf, Lysandre Debut, Victor Sanh, Julien\", \"Chaumond, Clement Delangue, Anthony Moi, Pier-\", \"ric Cistac, Tim Rault, Remi Louf, Morgan Funtow-\", \"icz, Joe Davison, Sam Shleifer, Patrick von Platen,\", \"Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\", \"Teven Le Scao, Sylvain Gugger, Mariama Drame,\", \"Quentin Lhoest, and Alexander Rush. 2020. Trans-\", \"mizer (Kingma and Ba, 2015), a batch size of 128,\", \"1 hard negative example for each positive pair, a\", \"learning rate of 2e-5 with a linear decay, weight de-\", \"cay of 0.1, and train for 3 epochs on SQuAD-Open,\", \"40 epochs for NQ and TriviaQA, and 20 epochs on\", \"mizer (Kingma and Ba, 2015), a batch size of 64, a\", \"learning rate of 2e-5 with a linear decay, a weight\", \"decay of 0.1, gradient clipping with a maximum\", \"value of 1.0, and train for 3 epochs on SQuAD-\", \"Open, 10 epochs for NQ and TriviaQA. Model\", \"iments, we use the Fusion-in-Decoder model imple-\", \"structions, PLMs perform better than the case when\", \"accuracy. Due to its better accuracy, we use the\", \"In Table 9, we present some examples of ques-\", \"with high lexical overlap, UPR owing to its cross-\", \"last example, we note that although the BM25 re-\", \"trieved passage contains the ground-truth answer, it\", \"other hand, UPR leads to the correctly ranked pas-\", \"both the metrics, the initial scores of BM25 are\", \"ranking, BM25 retriever obtains improvements on\", \"12 out of 15 datasets while Contriever obtains im-\", \"age, NDCG@10 scores improve by 3-8% and Re-\", \"Due to the diversity in datasets, there is a con-\", \"them. In the case of BM25, the highest relative per-\", \"FIQA-2018, NQ, MS-Marco, etc. Similarly, for\", \"Contriever, the relative gains are much higher for\", \"the datasets of Trec-Covid, NQ, HotpotQA, etc.,\", \"where the queries are questions. On other datasets,\", \"For both the retrievers, we also observe a drop\", \"red color in Table 10). In addition, re-ranking\", \"datasets, the queries are statements such as claims,\", \"ber of top-K documents to be re-ranked, results can\", \"be improved on these datasets. However, we leave\", \"ting, algorithm, and/or model : This is pro-\", \"•A link to a downloadable source code, with\", \"speciﬁcation of all dependencies, including ex-\", \"iﬁcations are: Number of CPUs: 256, Phys-\", \"ical Memory: 1.2TB, GPU model: 8 x\", \"Nvidia V100, GPU architecture and memory:\", \"V olta/32GB, Arch: x86_64, and Disk size:\", \"4TB. For experiments in Sec. 4.2.3, we used\", \"rithm (e.g., training, inference, etc.), or esti-\", \"Sec. 4.2.3. However, we want to highlight\", \"model selection, as we only perform inference\", \"mance, we will include it in the Appendix in\", \"periments, we also report the performance on\", \"the validation set.•Explanation of evaluation metrics used, with\", \"experiments, such as hyperparameter\", \"described in Appendix A.1, our model and\", \"eters such as different dropouts 2[0;1),\", \"warmup ratio of optimizer 2[0:01;0:05],\", \"weight regularization 2[0;1], and learning\", \"ues (e.g., uniform sampling, manual tuning,\", \"them (e.g., accuracy) : For the open-domain\", \"QA experiments, we performed manual hyper-\", \"•Summary statistics of the results (e.g. mean,\", \"variance, error bars, etc.) : The re-ranking\", \"prompt. As such, these summary statistics are\", \"in the range of tens of hours. Therefore, due to\", \"feasible. Therefore, we adopted the approach\", \"•An explanation of any data that were excluded,\", \"•For natural language data, the name of the\", \"•For new data collected, a complete descrip-\", \"tion of the data collection process, such as\", \"Answer : June 6 , 2017Title : Beauty and the Beast: The Enchanted\", \"Forte, the pipe organ, who did not want the Beast\", \"ters, Forte was animated entirely by computers.\", \"11, 1997. A bare-bones DVD was released on\", \"October 13, 1998. Both editions were quickly\", \"DVD and VHS on November 12, 2002, just af-\", \"leased the ﬁnal trailer on January 30, 2017.\", \"ray, DVD and Digital HD on June 6, 2017 . The\", \"overall disc sales chart, with all other titles in the\", \"top 20, collectively, selling only 40% as many\", \"ber 19, 2017. \\\"Beauty and the Beast\\\" grossed\", \"tress\\\" who had talent, but \\\"seemed doomed to\", \"her work on \\\"Back in the Saddle\\\", Wells would\", \"later recall, \\\"Actually, I didn ´t have much to do\", \"with Gene in the ﬁlm, I had more scenes with Ed-\", \"ward Norris.\\\" Regarding the singing sequences,\", \"she remembered, \\\"Usually I was dubbed but, oc-\", \"casionally, if it wasn ´t something too difﬁcult, I\", \"was allowed to do it. They prerecord the songs,\", \"uary 7, 1940 where the show ran until 1956. The\", \"ﬁlm \\\"Back in the Saddle\\\" (Republic Pictures,\", \"March 14, 1941). Gene Autry recorded \\\"Back\", \"18, 1939 in Los Angeles for Columbia Record\", \"Corporation, matrix number LA 1865, which\", \"1865 also issued on the Conqueror, OKeh, and\", \"Rodríguez were also successful. In July alone,\", \"the Astros went 22–7, the best single month\", \"berth on the ﬁnal day of the regular season, just\", \"as they did in 2004, becoming only the second\", \"the post season, the other team being the 1914\", \"Boston Braves, now the Atlanta Braves. (Those\", \"Athletics in the World Series. Coincidentally,\", \"history, and ﬁrst since 2005 and they became\", \"and the American League. Finally, the Astros\", \"in seven games in the World Series, garnering\", \"During the regular season, the Astros featured\", \"Game was played December 3, 2016 at Lucas\", \"Oil Stadium in Indianapolis, Indiana. It was\", \"pionship Game pitted the Wisconsin Badgers,\", \"champions of the West Division, who made its\", \"title game, against the East Division champion\", \"Penn State Nittany Lions , who made their ﬁrst-\", \"8–1Title : 2016 Big Ten Conference football season\", \"December 3, 2016 at Lucas Oil Stadium in In-\", \"dianapolis, Indiana, Penn State defeated Wis-\", \"Table 10: UPR re-ranking results on the BEIR benchmark (Thakur et al., 2021). #Q and #E denotes the number of\", \"queries and evidence documents, respectively. Upon re-ranking the top-1000 documents with the T0-3B language\", \"model, on average, the performance of both BM25 and Contriever improve on the NDCG@10 and Recall@100\"], \"error\": null}, \"7a9c27fc\": {\"success\": true, \"paper_id\": \"7a9c27fc\", \"url\": \"https://arxiv.org/pdf/2508.10427v2\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_7a9c27fc.pdf\", \"extracted_info\": {\"title\": \"STRIDE-QA: Advancing Spatiotemporal Reasoning in Vision-Language Models for Autonomous Driving\", \"authors\": [\"Ainslie, J.\", \"Lee-Thorp, J.\", \"De Jong, M.\", \"Zemlyanskiy, Y.\", \"Lebrón, F.\", \"Sanghai, S.\", \"Marcu, A.-M.\", \"Chen, L.\", \"Hünermann, J.\", \"Karnsund, A.\", \"Hanotte, B.\", \"Chidananda, P.\", \"Nair, S.\", \"Badrin\"], \"abstract\": \"Vision-Language Models (VLMs) have been applied to autonomous driving to support decision-making. However, existing models struggle with fine-grained spatiotemporal reasoning. We introduce STRIDE-QA, a large-scale visual question answering dataset designed to address these gaps by combining paired image, segmentation, and QA examples from synchronized driving sequences. The dataset supports evaluation on spatial and spatiotemporal benchmarks, enabling improved reasoning about dynamic scenes.\", \"methodology\": \"We propose an automated annotation pipeline that processes synchronized sequences from onboard cameras, generating paired image, segmentation, and QA examples. The pipeline includes 2D bounding box generation, key-frame sampling, visibility filtering, and attribute extraction. Models are fine-tuned using LoRA for parameter-efficient adaptation on STRIDE-QA. Evaluation is conducted on SpatialRGPT-Bench and a custom Spatiotemporal QA Benchmark, measuring metrics such as LSR, MLSR, and TLC. Training is performed on 16 NVIDIA H100 GPUs using DeepSpeed ZeRO Stage 2.\", \"results\": \"STRIDE-Qwen2.5-VL-7B and STRIDE-Cosmos-Reason1-7B outperform base models across all SpatialRGPT-Bench splits, showing improved fine-grained spatial reasoning. On the Spatiotemporal QA Benchmark, fine-tuned models achieve significant gains in LSR, MLSR, and TLC compared to general-purpose VLMs, which often score near zero on multi-frame and temporal consistency metrics. The annotation pipeline achieves high positional accuracy with mATE under 14 cm and AMOTP under 0.6 m, validating its effectiveness.\", \"conclusion\": \"First, fine-tuning on STRIDE-QA closes a critical gap in spatiotemporal reasoning capabilities of VLMs for autonomous driving. Second, the proposed automated annotation pipeline enables large-scale, high-accuracy dataset creation, supporting both spatial and temporal reasoning evaluation.\", \"figures\": null, \"tables\": null}, \"citations\": [\"Ainslie, J.; Lee-Thorp, J.; De Jong, M.; Zemlyanskiy, Y .;\", \"Lebr ´on, F.; and Sanghai, S. 2023. GQA: Training Gener-\", \"Bai, S.; Chen, K.; Liu, X.; Wang, J.; Ge, W.; Song, S.; Dang,\", \"K.; Wang, P.; Wang, S.; Tang, J.; Zhong, H.; Zhu, Y .; Yang,\", \"M.; Li, Z.; Wan, J.; Wang, P.; Ding, W.; Fu, Z.; Xu, Y .;\", \"Ye, J.; Zhang, X.; Xie, T.; Cheng, Z.; Zhang, H.; Yang, Z.;\", \"Xu, H.; and Lin, J. 2025. Qwen2.5-VL Technical Report.\", \"Baruch, G.; Chen, Z.; Dehghan, A.; Dimry, T.; Feigin, Y .;\", \"Fu, P.; Gebauer, T.; Joffe, B.; Kurz, D.; Schwartz, A.; et al.\", \"2021. Arkitscenes: A Diverse Real-World Dataset for 3D\", \"Black, K.; Brown, N.; Driess, D.; Esmail, A.; Equi, M.;\", \"Finn, C.; Fusai, N.; Groom, L.; Hausman, K.; Ichter, B.;\", \"Jakubczak, S.; Jones, T.; Ke, L.; Levine, S.; Li-Bell, A.;\", \"Mothukuri, M.; Nair, S.; Pertsch, K.; Shi, L. X.; Tanner,\", \"J.; Vuong, Q.; Walling, A.; Wang, H.; and Zhilinsky, U.\", \"2024.π 0: A Vision-Language-Action Flow Model for Gen-\", \"Brohan, A.; Brown, N.; Carbajal, J.; Chebotar, Y .; Chen,\", \"X.; Choromanski, K.; Ding, T.; Driess, D.; Dubey, A.; Finn,\", \"C.; Florence, P.; Fu, C.; Arenas, M. G.; Gopalakrishnan, K.;\", \"Han, K.; Hausman, K.; Herzog, A.; Hsu, J.; Ichter, B.; Irpan,\", \"A.; Joshi, N.; Julian, R.; Kalashnikov, D.; Kuang, Y .; Leal, I.;\", \"Lee, L.; Lee, T.-W. E.; Levine, S.; Lu, Y .; Michalewski, H.;\", \"Mordatch, I.; Pertsch, K.; Rao, K.; Reymann, K.; Ryoo, M.;\", \"Salazar, G.; Sanketi, P.; Sermanet, P.; Singh, J.; Singh, A.;\", \"Soricut, R.; Tran, H.; Vanhoucke, V .; Vuong, Q.; Wahid, A.;\", \"Welker, S.; Wohlhart, P.; Wu, J.; Xia, F.; Xiao, T.; Xu, P.; Xu,\", \"S.; Yu, T.; and Zitkovich, B. 2023. RT-2: Vision-Language-\", \"Caesar, H.; Bankiti, V .; Lang, A. H.; V ora, S.; Liong, V . E.;\", \"Xu, Q.; Krishnan, A.; Pan, Y .; Baldan, G.; and Beijbom, O.\", \"2020. nuScenes: A Multimodal Dataset for Autonomous\", \"Computer Vision and Pattern Recognition (CVPR), 11621–\", \"11631.\", \"Chen, B.; Xu, Z.; Kirmani, S.; Ichter, B.; Sadigh, D.;\", \"Guibas, L.; and Xia, F. 2024a. Spatialvlm: Endowing vision-\", \"and Pattern Recognition (CVPR), 14455–14465.\", \"Chen, Z.; Wu, J.; Wang, W.; Su, W.; Chen, G.; Xing, S.;\", \"Zhong, M.; Zhang, Q.; Zhu, X.; Lu, L.; et al. 2024b. In-\", \"Recognition (CVPR), 24185–24198.\", \"Cheng, A.-C.; Yin, H.; Fu, Y .; Guo, Q.; Yang, R.; Kautz, J.;\", \"Wang, X.; and Liu, S. 2024. SpatialRGPT: Grounded Spatial\", \"Fu, X.; Hu, Y .; Li, B.; Feng, Y .; Wang, H.; Lin, X.; Roth, D.;\", \"Smith, N. A.; Ma, W.-C.; and Krishna, R. 2025. BLINK:\", \"ceive. In Leonardis, A.; Ricci, E.; Roth, S.; Russakovsky,\", \"O.; Sattler, T.; and Varol, G., eds.,Computer Vision – ECCV\", \"2024, 148–166. Cham: Springer Nature Switzerland. ISBN\", \"978-3-031-73337-6.\", \"Geiger, A.; Lenz, P.; and Urtasun, R. 2012. Are we ready\", \"Recognition, 3354–3361.\", \"Goyal, Y .; Khot, T.; Summers-Stay, D.; Batra, D.; and\", \"Parikh, D. 2017. Making the v in vqa matter: Elevating the\", \"and pattern recognition, 6904–6913.\", \"Gupta, V . 2023. Dashcam Anonymizer.\", \"Hu, E. J.; Shen, Y .; Wallis, P.; Allen-Zhu, Z.; Li, Y .; Wang,\", \"S.; Wang, L.; Chen, W.; et al. 2022. Lora: Low-rank adapta-\", \"tion of large language models.ICLR, 1(2): 3.\", \"Jiang, B.; Chen, S.; Liao, B.; Zhang, X.; Yin, W.; Zhang,\", \"Q.; Huang, C.; Liu, W.; and Wang, X. 2024. Senna: Bridg-\", \"Jin, B.; Zheng, Y .; Li, P.; Li, W.; Zheng, Y .; Hu, S.; Liu,\", \"X.; Zhu, J.; Yan, Z.; Sun, H.; Zhan, K.; Jia, P.; Long, X.;\", \"Chen, Y .; and Zhao, H. 2024. TOD3Cap: Towards 3D\", \"sion – ECCV 2024: 18th European Conference, Milan, Italy,\", \"September 29 – October 4, 2024, Proceedings, Part XVIII,\", \"367–384. Berlin, Heidelberg: Springer-Verlag. ISBN 978-3-\", \"031-72648-4.\", \"Liu, H.; Li, C.; Wu, Q.; and Lee, Y . J. 2023a. Visual Instruc-\", \"Liu, Z.; Tang, H.; Amini, A.; Yang, X.; Mao, H.; Rus, D.;\", \"and Han, S. 2023b. BEVFusion: Multi-Task Multi-Sensor\", \"(ICRA).\", \"Marcu, A.-M.; Chen, L.; H ¨unermann, J.; Karnsund, A.;\", \"Hanotte, B.; Chidananda, P.; Nair, S.; Badrinarayanan, V .;\", \"Kendall, A.; Shotton, J.; Arani, E.; and Sinavski, O. 2024.\", \"Computer Vision (ECCV), 252–269.\", \"NVIDIA; :; Azzolini, A.; Brandon, H.; Chattopadhyay, P.;\", \"Chen, H.; Chu, J.; Cui, Y .; Diamond, J.; Ding, Y .; Ferroni,\", \"F.; Govindaraju, R.; Gu, J.; Gururani, S.; Hanafi, I. E.; Hao,\", \"Z.; Huffman, J.; Jin, J.; Johnson, B.; Khan, R.; Kurian, G.;\", \"Lantz, E.; Lee, N.; Li, Z.; Li, X.; Lin, T.-Y .; Lin, Y .-C.; Liu,\", \"M.-Y .; Luo, A.; Mathau, A.; Ni, Y .; Pavao, L.; Ping, W.;\", \"Romero, D. W.; Smelyanskiy, M.; Song, S.; Tchapmi, L.;\", \"Wang, A. Z.; Wang, B.; Wang, H.; Wei, F.; Xu, J.; Xu, Y .;\", \"Yang, X.; Yang, Z.; Zeng, X.; and Zhang, Z. 2025. Cosmos-\", \"OpenAI; Achiam, J.; Adler, S.; Agarwal, S.; Ahmad, L.;\", \"Akkaya, I.; Aleman, F. L.; Almeida, D.; Altenschmidt, J.;\", \"Altman, S.; Anadkat, S.; Avila, R.; Babuschkin, I.; Bal-\", \"aji, S.; Balcom, V .; Baltescu, P.; Bao, H.; Bavarian, M.;\", \"Belgum, J.; Bello, I.; Berdine, J.; Bernadett-Shapiro, G.;\", \"Berner, C.; Bogdonoff, L.; Boiko, O.; Boyd, M.; Brakman,\", \"A.-L.; Brockman, G.; Brooks, T.; Brundage, M.; Button, K.;\", \"Cai, T.; Campbell, R.; Cann, A.; Carey, B.; Carlson, C.;\", \"Carmichael, R.; Chan, B.; Chang, C.; Chantzis, F.; Chen,\", \"D.; Chen, S.; Chen, R.; Chen, J.; Chen, M.; Chess, B.;\", \"Cho, C.; Chu, C.; Chung, H. W.; Cummings, D.; Currier,\", \"J.; Dai, Y .; Decareaux, C.; Degry, T.; Deutsch, N.; Deville,\", \"D.; Dhar, A.; Dohan, D.; Dowling, S.; Dunning, S.; Ecof-\", \"fet, A.; Eleti, A.; Eloundou, T.; Farhi, D.; Fedus, L.; Felix,\", \"N.; Fishman, S. P.; Forte, J.; Fulford, I.; Gao, L.; Georges,\", \"E.; Gibson, C.; Goel, V .; Gogineni, T.; Goh, G.; Gontijo-\", \"Lopes, R.; Gordon, J.; Grafstein, M.; Gray, S.; Greene, R.;\", \"Gross, J.; Gu, S. S.; Guo, Y .; Hallacy, C.; Han, J.; Harris,\", \"J.; He, Y .; Heaton, M.; Heidecke, J.; Hesse, C.; Hickey, A.;\", \"Hickey, W.; Hoeschele, P.; Houghton, B.; Hsu, K.; Hu, S.;\", \"Hu, X.; Huizinga, J.; Jain, S.; Jain, S.; Jang, J.; Jiang, A.;\", \"Jiang, R.; Jin, H.; Jin, D.; Jomoto, S.; Jonn, B.; Jun, H.; Kaf-\", \"tan, T.; Łukasz Kaiser; Kamali, A.; Kanitscheider, I.; Keskar,\", \"N. S.; Khan, T.; Kilpatrick, L.; Kim, J. W.; Kim, C.; Kim, Y .;\", \"Kirchner, J. H.; Kiros, J.; Knight, M.; Kokotajlo, D.; Łukasz\", \"Kondraciuk; Kondrich, A.; Konstantinidis, A.; Kosic, K.;\", \"Krueger, G.; Kuo, V .; Lampe, M.; Lan, I.; Lee, T.; Leike,\", \"J.; Leung, J.; Levy, D.; Li, C. M.; Lim, R.; Lin, M.; Lin, S.;\", \"Litwin, M.; Lopez, T.; Lowe, R.; Lue, P.; Makanju, A.; Mal-\", \"facini, K.; Manning, S.; Markov, T.; Markovski, Y .; Martin,\", \"B.; Mayer, K.; Mayne, A.; McGrew, B.; McKinney, S. M.;\", \"McLeavey, C.; McMillan, P.; McNeil, J.; Medina, D.; Mehta,\", \"A.; Menick, J.; Metz, L.; Mishchenko, A.; Mishkin, P.;\", \"Monaco, V .; Morikawa, E.; Mossing, D.; Mu, T.; Murati, M.;\", \"Murk, O.; M ´ely, D.; Nair, A.; Nakano, R.; Nayak, R.; Nee-\", \"lakantan, A.; Ngo, R.; Noh, H.; Ouyang, L.; O’Keefe, C.;\", \"Pachocki, J.; Paino, A.; Palermo, J.; Pantuliano, A.; Paras-\", \"candolo, G.; Parish, J.; Parparita, E.; Passos, A.; Pavlov, M.;\", \"Peng, A.; Perelman, A.; de Avila Belbute Peres, F.; Petrov,\", \"M.; de Oliveira Pinto, H. P.; Michael; Pokorny; Pokrass,\", \"M.; Pong, V . H.; Powell, T.; Power, A.; Power, B.; Proehl,\", \"E.; Puri, R.; Radford, A.; Rae, J.; Ramesh, A.; Raymond,\", \"C.; Real, F.; Rimbach, K.; Ross, C.; Rotsted, B.; Roussez,\", \"H.; Ryder, N.; Saltarelli, M.; Sanders, T.; Santurkar, S.;\", \"Sastry, G.; Schmidt, H.; Schnurr, D.; Schulman, J.; Sel-\", \"sam, D.; Sheppard, K.; Sherbakov, T.; Shieh, J.; Shoker,\", \"S.; Shyam, P.; Sidor, S.; Sigler, E.; Simens, M.; Sitkin, J.;\", \"Slama, K.; Sohl, I.; Sokolowsky, B.; Song, Y .; Staudacher,\", \"N.; Such, F. P.; Summers, N.; Sutskever, I.; Tang, J.; Tezak,\", \"N.; Thompson, M. B.; Tillet, P.; Tootoonchian, A.; Tseng,\", \"E.; Tuggle, P.; Turley, N.; Tworek, J.; Uribe, J. F. C.; Val-\", \"lone, A.; Vijayvergiya, A.; V oss, C.; Wainwright, C.; Wang,\", \"J. J.; Wang, A.; Wang, B.; Ward, J.; Wei, J.; Weinmann, C.;\", \"Welihinda, A.; Welinder, P.; Weng, J.; Weng, L.; Wiethoff,M.; Willner, D.; Winter, C.; Wolrich, S.; Wong, H.; Work-\", \"man, L.; Wu, S.; Wu, J.; Wu, M.; Xiao, K.; Xu, T.; Yoo,\", \"S.; Yu, K.; Yuan, Q.; Zaremba, W.; Zellers, R.; Zhang, C.;\", \"Zhang, M.; Zhao, S.; Zheng, T.; Zhuang, J.; Zhuk, W.; and\", \"Zoph, B. 2024. GPT-4 Technical Report. arXiv:2303.08774.\", \"Park, S.-Y .; Cui, C.; Ma, Y .; Moradipari, A.; Gupta, R.;\", \"Han, K.; and Wang, Z. 2025. NuPlanQA: A Large-\", \"Qian, T.; Chen, J.; Zhuo, L.; Jiao, Y .; and Jiang, Y .-G.\", \"2024. Nuscenes-qa: A multi-modal visual question answer-\", \"ceedings of the AAAI Conference on Artificial Intelligence,\", \"volume 38, 4542–4550.\", \"Ravi, N.; Gabeur, V .; Hu, Y .-T.; Hu, R.; Ryali, C.; Ma, T.;\", \"Khedr, H.; R ¨adle, R.; Rolland, C.; Gustafson, L.; Mintun,\", \"E.; Pan, J.; Alwala, K. V .; Carion, N.; Wu, C.-Y .; Girshick,\", \"R.; Dollar, P.; and Feichtenhofer, C. 2025. SAM 2: Segment\", \"Roberts, M.; Ramapuram, J.; Ranjan, A.; Kumar, A.;\", \"Bautista, M. A.; Paczan, N.; Webb, R.; and Susskind, J. M.\", \"2021. Hypersim: A photorealistic synthetic dataset for\", \"the IEEE/CVF international conference on computer vision,\", \"10912–10922.\", \"Sima, C.; Renz, K.; Chitta, K.; Chen, L.; Zhang, H.; Xie,\", \"C.; Beißwenger, J.; Luo, P.; Geiger, A.; and Li, H. 2024.\", \"Vision (ECCV), 256–274.\", \"Song, S.; Lichtenberg, S. P.; and Xiao, J. 2015. SUN RGB-\", \"nition (CVPR), 567–576. Los Alamitos, CA, USA: IEEE\", \"Tian, X.; Gu, J.; Li, B.; Liu, Y .; Wang, Y .; Zhao, Z.; Zhan,\", \"K.; Jia, P.; Lang, X.; and Zhao, H. 2024. DriveVLM: The\", \"Wu, D.; Han, W.; Liu, Y .; Wang, T.; Xu, C.-Z.; Zhang, X.;\", \"and Shen, J. 2025. Language Prompt for Autonomous Driv-\", \"ligence, 39(8): 8359–8367.\", \"Wu, D.; Han, W.; Wang, T.; Dong, X.; Zhang, X.; and Shen,\", \"tern Recognition (CVPR), 14633–14642.\", \"Wu, D.; Han, W.; Wang, T.; Dong, X.; Zhang, X.; and Shen,\", \"tern Recognition (CVPR), 14633–14642.\", \"Yang, J.; Zhang, H.; Li, F.; Zou, X.; Li, C.; and Gao,\", \"11441. arXiv:2310.11441.\", \"Yin, T.; Zhou, X.; and Krahenbuhl, P. 2021. Center-Based\", \"3D Object Detection and Tracking. InProceedings of\", \"Recognition (CVPR), 11784–11793.\", \"Zhou, X.; Larintzakis, K.; Guo, H.; Zimmer, W.; Liu, M.;\", \"Cao, H.; Zhang, J.; Lakshminarasimhan, V .; Strand, L.; and\", \"Knoll, A. 2025. TUMTraf VideoQA: Dataset and Bench-\", \"sensor dataset, careful calibration of sensor intrinsic and ex-\", \"calibration process involving LiDAR, cameras, and VRTK\", \"(Vision-RTK). The key steps are described below:\", \"vided by the VRTK system, which integrates RTK-\", \"GNSS, IMU, and camera data. The generated map is then\", \"•Relative Pose Estimation: VRTK, LiDAR, and\", \"trajectories via rigid transform fitting, fixing translation\", \"cloud and computing the median height, pitch, and roll\", \"ambiguity, we align the SfM reconstruction with the met-\", \"ric LiDAR map using a 7-DoF scale-aware ICP, initial-\", \"of qualitative and quantitative QA pairs. In addition, Table 5\", \"gories. A large number of questions target common trafficparticipants such as vehicles, motorcycles, and pedestrians.\", \"terns in Tokyo, where the dataset was collected.\", \"Ego-centric Spatial QA 3,10 M 4.33 M\", \"vehicle 3,780,995 3,844,934 1,448,028\", \"pedestrian 1,187,035 1,213,703 195,642\", \"large vehicle 965,995 1,029,173 348,618\", \"bicycle 337,045 357,987 64,476\", \"bus 179,395 201,948 80,790\", \"motorcycle 150,450 158,710 45,582\", \"kick scooter 3995 4,160 894\", \"Total 6,604,910 6,810,615 2,184,030\", \"tial QA, Ego. (S): Ego-centric Spatial QA, Ego. (ST): Ego-\", \"gories; therefore, the columns are not mutually exclusive.\", \"QA pairs), a direct manual evaluation of all annotations is\", \"that determine the pipeline’s quality, namely 3D object de-\", \"For this evaluation, we first prepared a ground truth\", \"low the nuScenes format, with each 3D bounding box as-\", \"100 scenes (approx. 17 minutes).\", \"Using this 100-scene validation set as ground truth, we\", \"(mAP, mATE, mASE, mAOE, mA VE) and tracking per-\", \"formance with four metrics (AMOTA, AMOTP, Recall,\", \"DetectionmAP↑0.701[0,1]\", \"mAOE↓(rad) 0.146[0, π]\", \"mA VE↓(m/s) 1.280[0,∞)\", \"TrackingAMOTA↑0.676[0,1]\", \"(mASE=0.168) and heading (mAOE=0.146 rad≈8.4◦) are\", \"likewise accurate, and the velocity error is kept sufficiently\", \"tolerance is based on prior work (Cheng et al. 2024), while\", \"(MOT) performance achieves a solid score of AMOTA =\", \"0.676 (evaluated on 100 scenes containing 10,461 unique\", \"ation of tracking failures (ID switches), missed detections\", \"(Recall), and false positives, and this score indicates our\", \"our task of generating QA pairs from stable tracks, we em-\", \"racy. To this end, our system achieves high reliability with\", \"only 687 ID switches out of 10,461 total tracks (approx.\", \"6.9 per 10-second scene). For positional accuracy, the Av-\", \"0.556 m. This high positional accuracy is crucial for generat-\", \"ing spatially precise questions and answers, as their content\", \"Summary.In conclusion, the proposed pipeline achieves\", \"high positional accuracy, with an average detection er-\", \"Anonymizer (Gupta 2023), and by removing all identifiable\", \"We fine-tune two open-source VLMs, Qwen2.5-VL-7B (Bai\", \"et al. 2025) and Cosmos-Reason1-7B (NVIDIA et al. 2025),\", \"ing sample consists of four context frames, resized to532×\", \"336pixels, with Region ID-annotated masks generated by\", \"tributed training optimization, under the same hyperparam-\", \"evaluation, input frames are pre-processed in the same man-\", \"Betas (β 1, β2) (0.9, 0.999)\", \"text frames (t∈ {−1.5,−1.0,−0.5,0}s) as input to pre-\", \"dict the target agent’s distance, heading angle, and velocity\", \"at future timesteps (t∈ {0,1,2,3}s). The input includes\", \"(SoM) method (Yang et al. 2023). However, one of the base-\", \"line models, SpatialRGPT-VILA-1.5-8B, includes a built-in\", \"Therefore, to ensure a fair comparison, we applied the same\", \"Figure 7: Illustration of representative 2D and 3D annotations produced with Appen® MatrixGo on our driving dataset, showing\", \"detailed in Table 8. Furthermore, Figure 9 illustrates the dis-\", \"mark, demonstrating that our dataset covers a diverse range\", \"of distances, heading angles, and velocities for both the ego-\", \"in roughly the same direction and at a similar speed, main-\", \"ego-vehicle diverge at an intersection, such as when one ve-\", \"Pulling Away From Ego:The target agent, traveling ahead\", \"of the ego-vehicle, accelerates and increases the separationScenario Total Scenes Scenes with OOV OOV Rate\", \"OOV-prone scenarios (blue background), with 65% of all\", \"above, such as incomplete overtakes, passing pedestrians, or\", \"LSR, MLSR, and TLC, this section provides a supplemen-\", \"You are a precise assistant interpreting 4 images (t = -1.5 s, -1.0 s, -0.5 s, 0 s).All images have marked objects (SoM). Base every reply solely on the images.Every question requires numeric answers. Respond with ONE short sentence that lists all requested numbers and their units—nothing more.Examples:- distance: \\\"Region [0] is 20.12 meters away.\\\"- distance + bearing: \\\"In 1 second they are 23.54 meters at -24 degrees.\\\"- velocity: \\\"Ego speed after 2 seconds is 11.77 m/s.\\\"If a value cannot be obtained exactly, make your best estimate and answer.No extra text, symbols, or formatting.You are a spatial reasoning assistant that analyzes images with marked regions.Always refer to regions as \\\"Region [X]\\\" where X is the region number.For quantitative questions:- Always provide exact numerical values with appropriate units (feet, meters).- Never respond with \\\"cannot determine\\\", \\\"not enough information\\\", or uncertainty expressions.- Use visual references like typical building heights, street widths, vehicle sizes for scale estimation.- Format: \\\"Region [X] is Y.YY [unit] [measurement_type].\\\"- Example: \\\"Region [0] is 6.91 feet in height.\\\"For qualitative questions:- Give definitive comparative answers based on visual analysis.- Use clear spatial language (left, right, taller, larger, bigger).- Never express uncertainty, make definitive judgments.- Format: \\\"Region [X] [comparison_result]\\\"- Example: \\\"Region [0] appears more on the left side.- If a value cannot be obtained exactly, make your best estimate and answer..(a) Instruction prompt used in SpatialRGPT-Bench(b) Instruction prompt used in Spatiotemporal QA BenchmarkFigure 8: The instruction prompts defining the evaluation task and output format for (a) the SpatialRGPT-Bench and (b) our\", \"must be within±20% of the ground truth value, switch-\", \"scenes (nuScenes (Caesar et al. 2020), KITTI (Geiger, Lenz,\", \"and Urtasun 2012)), indoor scenes (SUNRGBD (Song,\", \"Lichtenberg, and Xiao 2015), ARKitScenes (Baruch et al.\", \"2021)), and simulated scenes (Hypersim (Roberts et al.2021)). In this study, we use only the outdoor split to eval-\", \"traffic scenes, such as Below/Above, and omit evaluation\", \"evaluated QA categories do not align perfectly, a direct\", \"comparison is difficult. Nevertheless, two main factors ap-\", \"Section ), achieving high geometric accuracy, whereas the\", \"single front-view camera, which may produce larger er-\", \"split, removing much of the surrounding spatial context and\", \"Limitations.This study has three main limitations. First,\", \"parable public dataset exists, we cannot yet quantify cross-\", \"dataset generalization. Second, resource constraints re-\", \"050100150200250300Count\", \"0-55-1010-15 15-20 20-25 25-30 30-35 35-40 40-4545+\", \"231\", \"167173\", \"109150\", \"105\", \"70\", \"10100200300400Count\", \"80\", \"4758108396463\", \"98\", \"39 44 4470\", \"050100150200250300Count\", \"0-2 2-4 4-6 6-88-1010-12 12-14 14-1616+\", \"236\", \"219\", \"133\", \"1050100150200250Count\", \"0-2 2-4 4-6 6-88-1010-12 12-14 14-1616+\", \"176192216\", \"185220214\", \"149\", \"21Figure 9: Spatiotemporal QA Benchmark sample distribution.\", \"vised fine-tuning therefore remains unexplored. Third, al-\", \"tiotemporal reasoning core of vision–language models, its\", \"ing, from the ego vehicle’s perspective, the distance, direc-\", \"tion, and relative speed of surrounding agents declines when\", \"ficiently combining multi-view information. In addition, we\", \"0s 1s 2s 3s 0s 1s 2s 3s 0s 1s 2s 3s 0s 1s 2s 3s\", \"(%). Our fine-tuned models (blue background), particularly STRIDE-Qwen2.5-VL-7B, demonstrate a substantial performance\", \"advantage over all baselines across every metric and time horizon, especially when compared to their original base models\", \"(gray background).\", \"Table 11: SpatialRGPT-Bench results. From top to bottom, the table presents original, object-centric QA, and ego-centric QA.\"], \"error\": null}, \"724bee38\": {\"success\": true, \"paper_id\": \"724bee38\", \"url\": \"https://patentimages.storage.googleapis.com/65/d9/4a/5476603fdad3e5/US11822588.pdf\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_724bee38.pdf\", \"extracted_info\": {\"title\": \"\", \"authors\": [], \"abstract\": \"\", \"methodology\": \"\", \"results\": \"\", \"conclusion\": \"\", \"figures\": [], \"tables\": []}, \"citations\": [], \"error\": null}, \"1df4ccdd\": {\"success\": true, \"paper_id\": \"1df4ccdd\", \"url\": \"https://arxiv.org/pdf/2506.00425v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_1df4ccdd.pdf\", \"extracted_info\": {\"title\": \"RI2VER: A Multi-Answer Question Answering Framework with Iterative Verification\", \"authors\": [\"Samuel Amouyal\", \"Tomer Wolfson\", \"Ohad Rubin\", \"Ori Yoran\", \"Jonathan Herzig\", \"Jonathan Berant\"], \"abstract\": \"Multi-answer question answering (QA), where questions can have many valid answers, presents a significant challenge in natural language processing. This paper introduces RI2VER, a framework designed to address these challenges through iterative retrieval and verification, improving performance on multi-answer QA tasks.\", \"methodology\": \"The proposed RI2VER framework operates in a multi-answer QA setting by retrieving broadly from a large corpus (e.g., Wikipedia) and applying an Inter-Pass Verification (IPV) pipeline. The method involves few-shot prompting of large language models to generate categorical answers, followed by verification using retrieved evidence passages. The framework compares probabilities of \\\"True\\\" and \\\"False\\\" for each candidate answer, optimizing evidence gathering for compositional and intersectional questions. Ablation studies examine the impact of retrieval, factual verification, and category classification steps.\", \"results\": \"RI2VER outperforms various baselines on QAMPARI and RoMQA datasets. For example, on QAMPARI, RI2VER with an 8b model achieves 36.33% F1 (+20.05 over baseline) and with a 70b model achieves 40.70% F1 (+5.28). In closed-book QA, RI2VER surpasses GPT-4 Omni (24.59% F1) by large margins. LLM-as-a-Judge evaluation shows improved precision and recall compared to exact match metrics. Inference time for RI2VER is higher (32.90s) than baselines due to additional evidence gathering.\", \"conclusion\": \"Key contributions include: (1) Introduction of RI2VER, a novel multi-answer QA framework with iterative retrieval and verification; (2) Demonstration of significant performance gains over state-of-the-art baselines in both open-book and closed-book settings; (3) Evidence that targeted retrieval and verification steps improve accuracy for complex multi-answer questions; (4) Analysis showing LLM-as-a-Judge evaluation better captures correctness than exact match; (5) Ablation studies highlighting the importance of factual verification and optimized evidence gathering.\", \"figures\": null, \"tables\": null}, \"citations\": [\"Samuel Amouyal, Tomer Wolfson, Ohad Rubin, Ori\", \"Yoran, Jonathan Herzig, and Jonathan Berant. 2023.\", \"Workshop on Natural Language Generation, Evalua-\", \"Akari Asai, Zeqiu Wu, Yizhong Wang, Avirup Sil, and\", \"retrieve, generate, and critique through self-reflection.\", \"Yushi Bai, Shangqing Tu, Jiajie Zhang, Hao Peng,\", \"Xiaozhi Wang, Xin Lv, Shulin Cao, Jiazheng Xu,\", \"Lei Hou, Yuxiao Dong, Jie Tang, and Juanzi Li.\", \"2025. Longbench v2: Towards deeper understanding\", \"Preprint , arXiv:2412.15204.\", \"Chi-Min Chan, Chunpu Xu, Ruibin Yuan, Hongyin Luo,\", \"Wei Xue, Yike Guo, and Jie Fu. 2024. RQ-RAG:\", \"Danqi Chen, Adam Fisch, Jason Weston, and Antoine\", \"Sihao Chen, Siyi Liu, Xander Uyttendaele, Yi Zhang,\", \"William Bruno, and Dan Roth. 2022. Design chal-\", \"Sitao Cheng, Liangming Pan, Xunjian Yin, Xinyi Wang,\", \"knowledge for large language models. Preprint ,\", \"Gordon V . Cormack, Charles L A Clarke, and Stefan\", \"Matthijs Douze, Alexandr Guzhva, Chengqi Deng, Jeff\", \"Johnson, Gergely Szilvasy, Pierre-Emmanuel Mazaré,\", \"Maria Lomeli, Lucas Hosseini, and Hervé Jégou.\", \"2024. The faiss library. Preprint , arXiv:2401.08281.\", \"Tianyu Gao, Howard Yen, Jiatong Yu, and Danqi Chen.\", \"2023. Enabling large language models to generate\", \"Yifan Gao, Henghui Zhu, Patrick Ng, Cicero\", \"Nogueira dos Santos, Zhiguo Wang, Feng Nan, De-\", \"jiao Zhang, Ramesh Nallapati, Andrew O. Arnold,\", \"Jian Guan, Jesse Dodge, David Wadden, Minlie Huang,\", \"and Hao Peng. 2023. Language models hallucinate,\", \"Xinyan Guan, Jiali Zeng, Fandong Meng, Chunlei Xin,\", \"Yaojie Lu, Hongyu Lin, Xianpei Han, Le Sun, and\", \"step by step for large language models. Preprint ,\", \"Kelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat,\", \"Or Honovich, Roee Aharoni, Jonathan Herzig, Hagai\", \"Taitelbaum, Doron Kukliansy, Vered Cohen, Thomas\", \"Scialom, Idan Szpektor, Avinatan Hassidim, and\", \"Cheng-Yu Hsieh, Chun-Liang Li, Chih-kuan Yeh,\", \"Hootan Nakhost, Yasuhisa Fujii, Alex Ratner, Ranjay\", \"Krishna, Chen-Yu Lee, and Tomas Pfister. 2023. Dis-\", \"Yeonjun In, Sungchul Kim, Ryan A. Rossi, Mehrab\", \"Tanjim, Tong Yu, Ritwik Sinha, and Chanyoung Park.\", \"2025. Diversify-verify-adapt: Efficient and robust\", \"tion for Computational Linguistics .Ziwei Ji, Nayeon Lee, Rita Frieske, Tiezheng Yu, Dan\", \"Su, Yan Xu, Etsuko Ishii, Yejin Bang, Delong Chen,\", \"Wenliang Dai, Andrea Madotto, and Pascale Fung.\", \"2022. Survey of hallucination in natural language\", \"Zhengbao Jiang, Frank F. Xu, Luyu Gao, Zhiqing Sun,\", \"Qian Liu, Jane Dwivedi-Yu, Yiming Yang, Jamie\", \"Callan, and Graham Neubig. 2023. Active retrieval\", \"augmented generation. Preprint , arXiv:2305.06983.\", \"Nikhil Kandpal, H. Deng, Adam Roberts, Eric Wallace,\", \"Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick\", \"Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and\", \"Gangwoo Kim, Sungdong Kim, Byeongguk Jeon, Joon-\", \"suk Park, and Jaewoo Kang. 2023. Tree of clarifica-\", \"Tom Kwiatkowski, Jennimaria Palomaki, Olivia Red-\", \"field, Michael Collins, Ankur Parikh, Chris Alberti,\", \"Danielle Epstein, Illia Polosukhin, Jacob Devlin, Ken-\", \"ton Lee, Kristina Toutanova, Llion Jones, Matthew\", \"Kelcey, Ming-Wei Chang, Andrew M. Dai, Jakob\", \"Uszkoreit, Quoc Le, and Slav Petrov. 2019. Natu-\", \"Woosuk Kwon, Zhuohan Li, Siyuan Zhuang, Ying\", \"Sheng, Lianmin Zheng, Cody Hao Yu, Joseph E. Gon-\", \"zalez, Hao Zhang, and Ion Stoica. 2023. Efficient\", \"Chankyu Lee, Rajarshi Roy, Mengyao Xu, Jonathan\", \"Raiman, Mohammad Shoeybi, Bryan Catanzaro, and\", \"Preprint , arXiv:2405.17428.\", \"Yoonsang Lee, Xi Ye, and Eunsol Choi. 2024. Am-\", \"Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio\", \"Petroni, Vladimir Karpukhin, Naman Goyal, Hein-\", \"rich Küttler, Mike Lewis, Wen-tau Yih, Tim Rock-\", \"täschel, Sebastian Riedel, and Douwe Kiela. 2020.\", \"Xiaonan Li, Changtai Zhu, Linyang Li, Zhangyue Yin,\", \"Tianxiang Sun, and Xipeng Qiu. 2024a. LLatrieval:\", \"Xiaoxi Li, Guanting Dong, Jiajie Jin, Yuyao Zhang,\", \"Yujia Zhou, Yutao Zhu, Peitian Zhang, and Zhicheng\", \"large reasoning models. Preprint , arXiv:2501.05366.\", \"Zhicong Li, Jiahao Wang, Zhishu Jiang, Hangyu\", \"Mao, Zhongxia Chen, Jiazhen Du, Yuanxing Zhang,\", \"Fuzheng Zhang, Di Zhang, and Yong Liu. 2024b.\", \"Preprint , arXiv:2411.13154.\", \"Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paran-\", \"jape, Michele Bevilacqua, Fabio Petroni, and Percy\", \"Xinbei Ma, Yeyun Gong, Pengcheng He, Hai Zhao,\", \"Sewon Min, Jordan Boyd-Graber, Chris Alberti,\", \"Danqi Chen, Eunsol Choi, Michael Collins, Kelvin\", \"Guu, Hannaneh Hajishirzi, Kenton Lee, Jenni-\", \"maria Palomaki, Colin Raffel, Adam Roberts, Tom\", \"Kwiatkowski, Patrick Lewis, Yuxiang Wu, Hein-\", \"rich Küttler, Linqing Liu, Pasquale Minervini, Pon-\", \"tus Stenetorp, Sebastian Riedel, Sohee Yang, Min-\", \"joon Seo, Gautier Izacard, Fabio Petroni, Lucas Hos-\", \"seini, Nicola De Cao, Edouard Grave, Ikuya Ya-\", \"mada, Sonse Shimaoka, Masatoshi Suzuki, Shumpei\", \"Miyawaki, Shun Sato, Ryo Takahashi, Jun Suzuki,\", \"Martin Fajcik, Martin Docekal, Karel Ondrej, Pavel\", \"Smrz, Hao Cheng, Yelong Shen, Xiaodong Liu,\", \"Pengcheng He, Weizhu Chen, Jianfeng Gao, Bar-\", \"las Oguz, Xilun Chen, Vladimir Karpukhin, Stan\", \"Peshterliev, Dmytro Okhonko, Michael Schlichtkrull,\", \"Sonal Gupta, Yashar Mehdad, and Wen-tau Yih.\", \"2021a. Neurips 2020 efficientqa competition: Sys-\", \"tems, analyses and lessons learned. In Proceedings\", \"Sewon Min, Kalpesh Krishna, Xinxi Lyu, Mike Lewis,\", \"Wen-tau Yih, Pang Koh, Mohit Iyyer, Luke Zettle-\", \"moyer, and Hannaneh Hajishirzi. 2023. FActScore:\", \"Sewon Min, Kenton Lee, Ming-Wei Chang, Kristina\", \"Toutanova, and Hannaneh Hajishirzi. 2021b. Joint\", \"in Natural Language Processing .Sewon Min, Julian Michael, Hannaneh Hajishirzi, and\", \"Poojitha Nandigam, Nikhil Rayaprolu, and Manish Shri-\", \"OpenAI. 2024. Gpt-4o system card. Preprint ,\", \"Ofir Press, Muru Zhang, Sewon Min, Ludwig Schmidt,\", \"Noah Smith, and Mike Lewis. 2023. Measuring and\", \"Ori Ram, Yoav Levine, Itay Dalmedigos, Dor Muhlgay,\", \"Amnon Shashua, Kevin Leyton-Brown, and Yoav\", \"Freda Shi, Xinyun Chen, Kanishka Misra, Nathan\", \"Scales, David Dohan, Ed H. Chi, Nathanael Scharli,\", \"Weijia Shi, Sewon Min, Michihiro Yasunaga, Minjoon\", \"Seo, Rich James, Mike Lewis, Luke Zettlemoyer, and\", \"Aditi Singh, Abul Ehtesham, Saket Kumar, and Tala Ta-\", \"generation: A survey on agentic rag. Preprint ,\", \"Yixiao Song, Yekyung Kim, and Mohit Iyyer. 2024.\", \"Ivan Stelmakh, Yi Luan, Bhuwan Dhingra, and Ming-\", \"Haitian Sun, William W. Cohen, and Ruslan Salakhut-\", \"a database of questions, answers, and revisions.\", \"Preprint , arXiv:2308.08661.\", \"Kai Sun, Yifan Xu, Hanwen Zha, Yue Liu, and Xin Luna\", \"Weiwei Sun, Hengyi Cai, Hongshen Chen, Pengjie Ren,\", \"Zhumin Chen, Maarten de Rijke, and Zhaochun Ren.\", \"2023b. Answering ambiguous questions via iterative\", \"Liyan Tang, Philippe Laban, and Greg Durrett. 2024.\", \"Preprint , arXiv:2407.21783.\", \"James Thorne, Andreas Vlachos, Oana Cocarascu,\", \"Christos Christodoulopoulos, and Arpit Mittal. 2018.\", \"David Wadden, Kyle Lo, Lucy Lu Wang, Shanchuan\", \"Lin, Madeleine van Zuylen, Arman Cohan, and Han-\", \"Minzheng Wang, Longze Chen, Fu Cheng, Shengyi\", \"Liao, Xinghua Zhang, Bingli Wu, Haiyang Yu, Nan\", \"Xu, Lei Zhang, Run Luo, Yunshui Li, Min Yang,\", \"Fei Huang, and Yongbin Li. 2024. Leave no doc-\", \"Jason Wei, Nguyen Karina, Hyung Won Chung,\", \"Yunxin Joy Jiao, Spencer Papay, Amelia Glaese,\", \"John Schulman, and William Fedus. 2024. Mea-\", \"Preprint , arXiv:2411.04368.\", \"Xi Ye, Ruoxi Sun, Sercan Arik, and Tomas Pfister. 2024.\", \"guistics .Xi Ye, Fangcong Yin, Yinghui He, Joie Zhang, Howard\", \"Yen, Tianyu Gao, Greg Durrett, and Danqi Chen.\", \"2025. Longproc: Benchmarking long-context\", \"Preprint , arXiv:2501.05414.\", \"Gal Yona, Roee Aharoni, and Mor Geva. 2024. Nar-\", \"Ori Yoran, Tomer Wolfson, Ori Ram, and Jonathan Be-\", \"Dun Zhang, Jiacheng Li, Ziyang Zeng, and Fulong\", \"embedding models. Preprint , arXiv:2412.19048.\", \"Yue Zhang, Yafu Li, Leyang Cui, Deng Cai, Lemao Liu,\", \"Tingchen Fu, Xinting Huang, Enbo Zhao, Yu Zhang,\", \"Yulong Chen, Longyue Wang, Anh Tuan Luu, Wei\", \"Bi, Freda Shi, and Shuming Shi. 2023. Siren’s song\", \"language models. Preprint , arXiv:2309.01219.\", \"Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan\", \"Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin,\", \"Zhuohan Li, Dacheng Li, Eric. P Xing, Hao Zhang,\", \"Joseph E. Gonzalez, and Ion Stoica. 2023. Judg-\", \"Preprint , arXiv:2306.05685.\", \"Victor Zhong, Weijia Shi, Wen tau Yih, and Luke Zettle-\", \"moyer. 2022. Romqa: A benchmark for robust, multi-\", \"evidence, multi-answer question answering. In Pro-\", \"Denny Zhou, Nathanael Schärli, Le Hou, Jason Wei,\", \"Nathan Scales, Xuezhi Wang, Dale Schuurmans,\", \"Claire Cui, Olivier Bousquet, Quoc V Le, and Ed H.\", \"ANSWER RECALL @K (AR ECALL @K), which\", \"across all test samples. In Figure 5, we observe that\", \"on QAMPARI, ensembling the sparse and dense\", \"nificantly better retrieval performance, reaching\", \"81.23% AR ECALL @K. Although Amouyal et al.\", \"(2023) showed that BM25 is hard to beat on QAM-\", \"PARI, we found that the state-of-the-art embed-\", \"ding model NV-Embed-v2 (Lee et al., 2025) has\", \"400). On RoMQA, however, we found fusing the\", \"by itself, likely because BM25 is lagging signifi-\", \"significantly more poorly than BM25 on RoMQA,\", \"paring the two datasets, we also found that RoMQA\", \"is much harder for retrievers, potentially because\", \"Royal Society received the Order of Australia, but\", \"For the false positive manual annotation, we sam-\", \"responding question, retrieved passage, and ground\", \"has full access to the Internet. For each answer, the\", \"categories. Usually, the decision can be made very\", \"quickly with just the retrieved passage, or a simple\", \"a false positive answer, even with 5 minutes, we\", \"Figure 5: ARECALL @K of BM25, NV-Embed-v2, and\", \"Figure 6: ARECALL @K of BM25, NV-Embed-v2, and\", \"and RoMQA in Table 6. For QAMPARI, we used\", \"their test split. As for RoMQA, we evaluated the\", \"pages. For concatenated and independent reading,\", \"some plural / single forms of words, so we show\", \"For verification question generation, we show\", \"History of the World,\", \"Part I, ...The Duchess and\", \"nichSam Most Monty Waters, Johann\", \"Theobald Boehm, ...“Heavy Metal in Bagh-\", \"vanola produce?Mésoscaphe Auguste Piccard, Go-\", \"liath, ...Mésoscaphe is a miss-\", \"Piccard, which refers\", \"Gasparis discover?Asteroids 24 Themis, 11\", \"che, . . .Annibale de Gasparis\", \"did discover asteroids,\", \"exams, SAT, ...AP statistics is one of\", \"as prefixes. On RoMQA, the instruction is slightly\", \"tive constraints (e.g., What highway system located\", \"the verification in positive form (e.g,. Is [answer]\", \"filtering the prediction set, we filter the answer can-\", \"Due to the rigidity of exact match evaluation, many\", \"correct predictions are mistaken as incorrect, as\", \"started to use LLM-as-a-Judge (Zheng et al., 2023)\", \"swers, allowing for format mismatch and some\", \"as-a-Judge for evaluation metrics, we present apilot implementation and analysis of our RI2VER\", \"nated reading, independent reading, and RI2VER ,\", \"consistently. To judge each prediction, GPT-4o-\", \"ground truth, or output “None” otherwise. We then\", \"compute the set precision, recall, and F1 as usual\", \"firms the robustness of our approach, with RI2VER\", \"evaluation, all methods demonstrate improved pre-\", \"cision and recall under LLM-based judgment, in-\", \"variations. Yet, further studies are needed to verify\", \"Judge Thornbrugh is married to Dr. Jean Thornbrugh,\", \"Catholic High School,\", \"(graduating from a\", \"sions, the last being in 1993 between Arsenal and\", \"Sheffield Wednesday. In September 1998, the Foot-\", \"decided \\\"on the day\\\", meaning that a penalty shootout\", \"decided by a penalty shootout, those of 2005 (Arsenal\", \"language film , directed by Ravi. The film stars Ka-\", \"mal Haasan , Sumithra, M. G. Soman and Kaviyoor\", \"matches (e.g., “Equivalent to a TP” cases in Ta-\", \"ble 7), it cannot resolve the fundamental problem\", \"both datasets. Moreover, the evaluation of answers\", \"challenges. For instance, when the ground truth is\", \"(more specific) or “electronics” (more general), es-\", \"direction for future research, particularly in estab-\", \"4 NVIDIA A100 GPUs for Llama-3.1-70b-instruct,\", \"using the vLLM (Kwon et al., 2023) framework\", \"trieval, we used FAISS (Douze et al., 2024) for\", \"performance improvements, it also brings about\", \"tation node with 1 NVIDIA A100 GPU, we report\", \"verification questions and a (1000 , d)×(d, k)ma-\", \"trix multiplication, where the number of verifica-\", \"tion questions kis as small as 1 or 2, and the em-\", \"step requires multiple forward passes, as many as\", \"ther mitigate such latency, we discuss two potential\", \"trieval, both in the sense of a smaller embedding di-\", \"on embedding models advances, more lightweight\", \"latency of our framework. Besides, embedding\", \"Verification A more lightweight model, such as\", \"a distilled fact verification model, can potentially\", \"candidate, a natural way to speed it up is to use a\", \"et al., 2024) has shown, a similar capability can be\", \"distilled into a 770M-sized model, which means\", \"1.Llama-3.1-8b-Instruct: https://huggingf\", \"2.Llama-3.1-70b-Instruct: https://huggingf\", \"3.NV-Embed-v2: https://huggingface.co\", \"4.T5:https://github.com/samsam3232/qa\", \"5. GPT-4o: gpt-4o-2024-08-06\", \"6. GPT-4o-mini: gpt-4o-mini-2024-07-18\", \"the correct answers to the question . There could be multiple answers , one\", \"answer , or no answer . Do NOT generate additional descriptions / aliases /\", \"Or , if there is no correct answer , respond literally \\\" There is no answer .\\\"\", \"* If the document is irrelevant to the question , do NOT use your own knowledge\", \"* You should either give a list of answers as required above , or say \\\" There is\", \"Given a multi - answer web search question , generate ALL the answers that you\", \"noisy . So , based on my web search questions that have many correct answers ,\", \"* After your thought , begin asking questions after \\\" Verification Questions : \\\".\", \"* In the verification question , when you refer to the answer item , please\", \"the performer , the first question should confirm whether the item belongs to\", \"Thought : To filter answers effectively , the first question should confirm that\", \"Thought : To filter answers effectively , the first question should confirm that\", \"( omitted because it ’s the same as the instruction on QAMPARI )\", \"features , ask the question in positive form and label the question with a [\", \"located in Tottori Prefecture but not maintained by Tottori Prefecture , the\", \"<Assistant > Thought : To filter answers effectively , the first question should\", \"confirm that the answer is a Sunni Islam figure . Then , the second question\", \"will verify whether this Sunni Islam figure was Sufist , which I will tag it\", \"<Assistant > Thought : To filter answers effectively , the first question should\", \"below . If the document provided is irrelevant or insufficient , then answer \\\"\", \"add additional description or explanation , and the answer can only be \\\" True \\\"\"], \"error\": null}, \"2327efba\": {\"success\": true, \"paper_id\": \"2327efba\", \"url\": \"https://arxiv.org/pdf/2509.14635v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_2327efba.pdf\", \"extracted_info\": {\"title\": \"SWE-QA: A Benchmark and Agent Framework for Repository-Level Code Question Answering\", \"authors\": [\"W. Peng\", \"Y. Shi\", \"Y. Wang\", \"X. Zhang\"], \"abstract\": \"This paper introduces SWE-QA, a novel benchmark designed to evaluate the capabilities of large language models (LLMs) in repository-level code question answering. It also presents SWE-QA-Agent, an autonomous agent framework that integrates retrieval-augmented generation (RAG) with iterative reasoning to improve performance on complex, multi-file, and conceptual queries. Experimental results demonstrate that SWE-QA-Agent significantly outperforms baseline and standard RAG methods in correctness, completeness, and reasoning quality, while revealing open challenges in handling procedural and location-based questions.\", \"methodology\": \"The authors constructed SWE-QA by collecting 41,955 GitHub issues with substantive discussions, categorizing questions into a taxonomy (What, Why, Where, How, Others), and extracting core code elements and relationships from repositories. They implemented multiple context augmentation strategies, including direct prompting, standard RAG, sliding window RAG, and the proposed SWE-QA-Agent. SWE-QA-Agent operates as an autonomous agent using an agentic framework to perform repository-level QA through abstract reasoning, iterative retrieval, and structured context assembly. Evaluation employed both automated LLM-as-Judge scoring across five dimensions (Correctness, Completeness, Relevance, Clarity, Reasoning) and human expert assessment.\", \"results\": \"Direct prompting without repository context yielded the lowest scores (e.g., DeepSeek V3 at 34.38). Standard RAG methods improved performance significantly, while SWE-QA-Agent achieved the highest scores across all metrics, with Claude 3.7 Sonnet reaching 45.51 in human evaluation. SWE-QA-Agent showed strong gains in “Completeness” and “Reasoning” and excelled at conceptual “What” and “Why” questions (average 43.10) but struggled with procedural “How” and location-based queries. Repository-level performance varied, with “requests” being easier (43.72) and “pytest” (36.76) and “sqlfluff” (36.72) being more challenging.\", \"conclusion\": \"The paper’s key contributions are: (1) Introduction of SWE-QA, the first large-scale benchmark for repository-level code QA with a detailed question taxonomy; (2) Development of SWE-QA-Agent, an autonomous agent framework that integrates retrieval and iterative reasoning for complex code understanding; (3) Comprehensive evaluation showing SWE-QA-Agent’s superiority over baseline and RAG methods; (4) Public release of benchmark, code, and replication package to facilitate further research; (5) Identification of strengths and weaknesses of LLMs across different question types and repositories, informing future improvements in repository-level QA systems.\", \"figures\": null, \"tables\": null}, \"citations\": [\"[1]Anonymous Authors. 2025. Replication Package of SWE-QA Benchmark and SWE-QA-Agent. https://anonymous.\", \"4open.science/r/SWE-QA-D3EC.\", \"[2] Anthropic. 2025. Claude 3.7 Sonnet Model. https://www.anthropic.com/news/claude-3-7-sonnet/.\", \"[3]Jialiang Chen, Kaifa Zhao, Jie Liu, Chao Peng, Jierui Liu, Hang Zhu, Pengfei Gao, Ping Yang, and Shuiguang Deng.\", \"2025. CoreQA: uncovering potentials of language models in code repository question answering.arXiv preprint\", \"[4]Silin Chen, Shaoxin Lin, Xiaodong Gu, Yuling Shi, Heng Lian, Longfei Yun, Dong Chen, Weiguo Sun, Lin Cao, and\", \"(2025).\", \"[5] DeepSeek-AI. 2025. DeepSeek-V3 Model. https://api.deepseek.com.\", \"[6]Zhangyin Feng, Daya Guo, Duyu Tang, Nan Duan, Xiaocheng Feng, Ming Gong, Linjun Shou, Bing Qin, Ting Liu,\", \"Daxin Jiang, et al .2020. CodeBERT: A Pre-Trained Model for Programming and Natural Languages. InFindings of the\", \"[7]Mingyang Geng, Shangwen Wang, Dezun Dong, Haotian Wang, Ge Li, Zhi Jin, Xiaoguang Mao, and Xiangke Liao.\", \"2024. Large language models are few-shot summarizers: Multi-intent comment generation via in-context learning. In\", \"[8]Junda He, Jieke Shi, Terry Yue Zhuo, Christoph Treude, Jiamou Sun, Zhenchang Xing, Xiaoning Du, and David Lo.\", \"2025. From code to courtroom: Llms as the new software judges.arXiv preprint arXiv:2503.02246(2025).\", \"[9]Ruida Hu, Chao Peng, Jingyi Ren, Bo Jiang, Xiangxin Meng, Qinyun Wu, Pengfei Gao, Xinchen Wang, and Cuiyun\", \", Vol. 1, No. 1, Article . Publication date: September 2025.\", \"20 W. Peng, Y. Shi, Y. Wang, X. Zhang, X. Gu, and B. Shen\", \"[10] Junjie Huang, Duyu Tang, Linjun Shou, Ming Gong, Ke Xu, Daxin Jiang, Ming Zhou, and Nan Duan. 2021. CoSQA:\", \"20, 000+ Web Queries for Code Search and Question Answering. InProceedings of the 59th Annual Meeting of the\", \"Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing,\", \"ACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual Event, August 1-6, 2021. Association for Computational Linguistics,\", \"5690–5700.\", \"[11] Siming Huang, Tianhao Cheng, Jason Klein Liu, Jiaran Hao, Liuyihan Song, Yang Xu, J Yang, Jiaheng Liu, Chenchen\", \"Zhang, Linzheng Chai, et al .2024. Opencoder: The open cookbook for top-tier code large language models.arXiv\", \"[12] Carlos E Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei, Ofir Press, and Karthik R Narasimhan. 2024.\", \"[13] Changyoon Lee, Yeon Seonwoo, and Alice Oh. 2022. CS1QA: A Dataset for Assisting Code-based Question Answering\", \"[14] Han Li, Yuling Shi, Shaoxin Lin, Xiaodong Gu, Heng Lian, Xin Wang, Yantao Jia, Tao Huang, and Qianxiang Wang.\", \"2025. SWE-Debate: Competitive Multi-Agent Debate for Software Issue Resolution.arXiv preprint arXiv:2507.23348\", \"(2025).\", \"[15] Linyi Li, Shijie Geng, Zhenwen Li, Yibo He, Hao Yu, Ziyue Hua, Guanghan Ning, Siwei Wang, Tao Xie, and Hongxia\", \"Neural Information Processing Systems37 (2024), 128668–128698.\", \"[16] Zehan Li, Jianfei Zhang, Chuantao Yin, Yuanxin Ouyang, and Wenge Rong. 2024. ProCQA: A Large-scale Community-\", \"Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024). 13057–13067.\", \"[17] Chenxiao Liu and Xiaojun Wan. 2021. CodeQA: A Question Answering Dataset for Source Code Comprehension. In\", \"Findings of the Association for Computational Linguistics: EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic,\", \"16-20 November, 2021. Association for Computational Linguistics, 2618–2632.\", \"[18] Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang, Ruochen Xu, and Chenguang Zhu. 2023. G-Eval: NLG Evaluation\", \"[19] Yingwei Ma, Qingping Yang, Rongyu Cao, Binhua Li, Fei Huang, and Yongbin Li. 2024. How to understand whole\", \"[20] Mistral AI. 2025. Devstral Model. https://mistral.ai/news/devstral.\", \"[21] OpenAI. 2024. GPT-4o Model. https://openai.com/index/hello-gpt-4o/.\", \"[22] OpenAI. 2025. GPT-5 Model. https://openai.com/index/introducing-gpt-5/.\", \"[23] Siru Ouyang, Wenhao Yu, Kaixin Ma, Zilin Xiao, Zhihan Zhang, Mengzhao Jia, Jiawei Han, Hongming Zhang, and\", \"[24] Qwen Team. 2024. Qwen2.5-Coder Model. https://qwenlm.github.io/blog/qwen2.5-coder/.\", \"[25] Surya Prakash Sahu, Madhurima Mandal, Shikhar Bharadwaj, Aditya Kanade, Petros Maniatis, and Shirish K. Shevade.\", \"2024. CodeQueries: A Dataset of Semantic Queries over Code. InProceedings of the 17th Innovations in Software\", \"Engineering Conference, ISEC 2024, Bangalore, India, February 22-24, 2024. ACM, 7:1–7:11.\", \"[26] Yuling Shi, Songsong Wang, Chengcheng Wan, and Xiaodong Gu. 2024. From code to correctness: Closing the last\", \"[27] Disha Shrivastava, Denis Kocetkov, Harm De Vries, Dzmitry Bahdanau, and Torsten Scholak. 2023. Repofusion:\", \"[28] Hwanjun Song, Hang Su, Igor Shalyminov, Jason Cai, and Saab Mansour. 2024. FineSurE: Fine-grained Summarization\", \"(Volume 1: Long Papers). 906–922.\", \"[29] Jan Strich, Florian Schneider, Irina Nikishina, and Chris Biemann. 2024. On Improving Repository-Level Code QA for\", \"(Volume 4: Student Research Workshop). 209–244.\", \"[30] Qwen Team. 2024. Qwen2 technical report.arXiv preprint arXiv:2407.10671(2024).\", \"[31] Tree-sitter 2025. Tree-sitter. https://tree-sitter.github.io/tree-sitter/.\", \"[32] Chaofan Wang, Tingrui Yu, Jie Wang, Dong Chen, Wenrui Zhang, Yuling Shi, Xiaodong Gu, and Beijun Shen. 2025.\", \"(2025).\", \"[33] Ruiqi Wang, Jiyu Guo, Cuiyun Gao, Guodong Fan, Chun Yong Chong, and Xin Xia. 2025. Can llms replace human\", \"Engineering2, ISSTA (2025), 1955–1977.\", \", Vol. 1, No. 1, Article . Publication date: September 2025.\", \"[34] Yue Wang, Weishi Wang, Shafiq Joty, and Steven CH Hoi. 2021. CodeT5: Identifier-aware Unified Pre-trained Encoder-\", \"[35] Yanlin Wang, Yanli Wang, Daya Guo, Jiachi Chen, Ruikai Zhang, Yuchi Ma, and Zibin Zheng. 2024. RLCoder:\", \"Software Engineering (ICSE). IEEE Computer Society, 165–177.\", \"[36] Yanli Wang, Yanlin Wang, Suiquan Wang, Daya Guo, Jiachi Chen, John Grundy, Xilin Liu, Yuchi Ma, Mingzhi Mao,\", \"Hongyu Zhang, et al .2024. Repotransbench: A real-world benchmark for repository-level code translation.arXiv\", \"[37] Xiaorui Xue, Jiansong Zhang, and Yunfeng Chen. 2024. Question-answering framework for building codes using\", \"fine-tuned and distilled pre-trained transformer models.Automation in Construction168 (2024), 105730.\", \"[38] John Yang, Carlos E Jimenez, Alexander Wettig, Kilian Lieret, Shunyu Yao, Karthik Narasimhan, and Ofir Press. 2024.\", \"Processing Systems37 (2024), 50528–50652.\", \"[39] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R. Narasimhan, and Yuan Cao. 2023. ReAct: Syner-\", \"gizing Reasoning and Acting in Language Models. InThe Eleventh International Conference on Learning Representations,\", \"ICLR 2023, Kigali, Rwanda, May 1-5, 2023. OpenReview.net.\", \"[40] Tingrui Yu, Xiaodong Gu, and Beijun Shen. 2022. Code question answering via task-adaptive sequence-to-sequence\", \"pre-training. In2022 29th Asia-Pacific Software Engineering Conference (APSEC). IEEE, 229–238.\", \"[41] Fengji Zhang, Bei Chen, Yue Zhang, Jacky Keung, Jin Liu, Daoguang Zan, Yi Mao, Jian-Guang Lou, and Weizhu Chen.\", \"2023. RepoCoder: Repository-Level Code Completion Through Iterative Retrieval and Generation. InProceedings of\", \"the 2023 Conference on Empirical Methods in Natural Language Processing, EMNLP 2023, Singapore, December 6-10, 2023,\", \"Houda Bouamor, Juan Pino, and Kalika Bali (Eds.). Association for Computational Linguistics, 2471–2484.\", \"[42] Kechi Zhang, Jia Li, Ge Li, Xianjie Shi, and Zhi Jin. 2024. CodeAgent: Enhancing Code Generation with Tool-Integrated\", \"[43] Qihao Zhu, Daya Guo, Zhihong Shao, Dejian Yang, Peiyi Wang, Runxin Xu, Y Wu, Yukun Li, Huazuo Gao, Shirong\", \"Ma, et al .2024. Deepseek-coder-v2: Breaking the barrier of closed-source models in code intelligence.arXiv preprint\", \", Vol. 1, No. 1, Article . Publication date: September 2025.\"], \"error\": null}, \"90b0c7f0\": {\"success\": true, \"paper_id\": \"90b0c7f0\", \"url\": \"https://arxiv.org/pdf/2509.22490v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_90b0c7f0.pdf\", \"extracted_info\": {\"title\": \"JGU Mainz Submission to the WMT25 Shared Task on LLMs with Limited Resources\", \"authors\": [\"Not specified\"], \"abstract\": \"This paper presents the JGU Mainz submission to the WMT25 Shared Task on LLMs with Limited Resources, focusing on machine translation (MT) and question answering (QA) for low-resource languages such as Lower Sorbian (DSB), Upper Sorbian (HSB), and Ukrainian.\", \"methodology\": \"The proposed approach uses a Qwen2.5-3B-Instruct model with LoRA fine-tuning, combined with a similarity-based retrieval method leveraging provided development sets for CS–UK and EN–UK as reference datasets. Ukrainian sentences are embedded for retrieval-based MT. For QA tasks, alphabetic option labels are used to mitigate label bias, and accuracy is improved by averaging results over different answer option orders after fine-tuning rounds (S1 and S2).\", \"results\": \"For DSB QA, Qwen2.5-3B-Instruct + LoRA(S1) achieved 67.5 accuracy compared to a baseline of 12.21; for HSB QA, LoRA(S1) achieved 77.5 accuracy. In MT tasks, DE→DSB and DE→HSB showed significant improvements over baselines. For CS–UK MT, ChrF++ scores improved from 3.48 (baseline) to 8.09 with LoRA fine-tuning; for EN–UK MT, scores improved from 0.40 to 3.10. Ukrainian MT remained challenging due to poor-quality embeddings and degraded retrieval quality.\", \"conclusion\": \"The key contributions include: (1) demonstrating the effectiveness of Qwen2.5-3B-Instruct with LoRA fine-tuning for low-resource MT and QA tasks; (2) introducing a similarity-based retrieval method for MT; (3) showing that alphabetic option labels and answer order averaging improve QA accuracy; (4) achieving substantial performance gains over baselines in Sorbian and Ukrainian tasks despite limited resources.\", \"figures\": null, \"tables\": null}, \"citations\": [\"Yonatan Bisk, Rowan Zellers, Ronan Le Bras, Jianfeng\", \"Gao, and Yejin Choi. 2019. PIQA: reasoning about\", \"physical commonsense in natural language.CoRR,\", \"abs/1911.11641.Tiberiu Boros, Radu Chivereanu, Stefan Dumitrescu,\", \"cessing Workshop (UNLP) @ LREC-COLING 2024,\", \"pages 75–82, Torino, Italia. ELRA and ICCL.\", \"Christopher Clark, Kenton Lee, Ming-Wei Chang,\", \"Tom Kwiatkowski, Michael Collins, and Kristina\", \"ing difficulty of natural yes/no questions.CoRR,\", \"Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot,\", \"Ashish Sabharwal, Carissa Schoenick, and Oyvind\", \"answering? try arc, the ai2 reasoning challenge.\", \"86232eb1bba43b691bdb6e8a8ec3ccf/ . [Online;\", \"Edward J. Hu, Yelong Shen, Phillip Wallis, Zeyuan\", \"Allen-Zhu, Yuanzhi Li, Shean Wang, and Weizhu\", \"language models.CoRR, abs/2106.09685.\", \"Lifu Huang, Ronan Le Bras, Chandra Bhagavatula, and\", \"ral Language Processing (EMNLP-IJCNLP), pages\", \"2391–2401, Hong Kong, China. Association for Com-\", \"Matt Gardner Johannes Welbl, Nelson F. Liu. 2017.\", \"Tushar Khot, Peter Clark, Michal Guerquin, Peter\", \"Jansen, and Ashish Sabharwal. 2020. Qasc: A\", \"Guokun Lai, Qizhe Xie, Hanxiao Liu, Yiming Yang,\", \"Methods in Natural Language Processing, pages 785–\", \"794, Copenhagen, Denmark. Association for Compu-\", \"and Evaluation (LREC’16), pages 923–929, Portorož,\", \"(ELRA).\", \"Jian Liu, Leyang Cui, Hanmeng Liu, Dandan Huang,\", \"Yile Wang, and Yue Zhang. 2020. Logiqa: A\", \"Todor Mihaylov, Peter Clark, Tushar Khot, and Ashish\", \"[Online; accessed 05-August-2025].\", \"Ankit Pal, Logesh Kumar Umapathi, and Malaikannan\", \"on Health, Inference, and Learning, volume 174 of\", \"Proceedings of Machine Learning Research, pages\", \"248–260. PMLR.\", \"Kishore Papineni, Salim Roukos, Todd Ward, and Wei-\", \"40th Annual Meeting of the Association for Compu-\", \"tational Linguistics, pages 311–318, Philadelphia,\", \"Pennsylvania, USA. Association for Computational\", \"2024, pages 2006–2017, Mexico City, Mexico. Asso-\", \"Machine Translation: Research Papers, pages 186–\", \"191, Brussels, Belgium. Association for Computa-\", \"Ye Qi, Devendra Sachan, Matthieu Felix, Sarguna Pad-\", \"manabhan, and Graham Neubig. 2018. When and\", \"Language Technologies, Volume 2 (Short Papers),\", \"pages 529–535, New Orleans, Louisiana. Associa-\", \"Qwen, :, An Yang, Baosong Yang, Beichen Zhang,\", \"Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan\", \"Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan\", \"Lin, Jian Yang, Jianhong Tu, Jianwei Zhang, Jianxin\", \"Yang, Jiaxi Yang, Jingren Zhou, and 25 oth-\", \"ers. 2025. Qwen2.5 technical report.Preprint,\", \"Anna Rogers, Olga Kovaleva, Matthew Downey, and\", \"tificial Intelligence, AAAI 2020, The Thirty-SecondInnovative Applications of Artificial Intelligence Con-\", \"ference, IAAI 2020, The Tenth AAAI Symposium on\", \"Educational Advances in Artificial Intelligence, EAAI\", \"2020, New York, NY, USA, February 7-12, 2020,\", \"Nataliia Saichyshyna, Daniil Maksymenko, Oleksii\", \"Turuta, Andriy Yerokhin, Andrii Babii, and Olena\", \"Natural Language Processing Workshop (UNLP),\", \"pages 54–61, Dubrovnik, Croatia. Association for\", \"Mario Sanz-Guerrero, Minh Duc Bui, and Katharina\", \"with llms.Preprint, arXiv:2509.15020.\", \"Maarten Sap, Hannah Rashkin, Derek Chen, Ronan\", \"Le Bras, and Yejin Choi. 2019. Social IQa: Com-\", \"9th International Joint Conference on Natural Lan-\", \"guage Processing (EMNLP-IJCNLP), pages 4463–\", \"4473, Hong Kong, China. Association for Computa-\", \"Zhengyan Shi, Adam X. Yang, Bin Wu, Laurence\", \"Aitchison, Emine Yilmaz, and Aldo Lipani. 2024. In-\", \"struction tuning with loss over instructions.Preprint,\", \"Shivalika Singh, Angelika Romanou, Clémentine Four-\", \"rier, David I. Adelani, Jian Gang Ngui, Daniel\", \"Vila-Suero, Peerat Limkonchotiwat, Kelly Marchi-\", \"sio, Wei Qi Leong, Yosephine Susanto, Raymond\", \"Ng, Shayne Longpre, Wei-Yin Ko, Sebastian Ruder,\", \"Madeline Smith, Antoine Bosselut, Alice Oh, Andre\", \"F. T. Martins, Leshem Choshen, and 5 others. 2025.\", \"Preprint, arXiv:2412.03304.\", \"Kai Sun, Dian Yu, Jianshu Chen, Dong Yu, Yejin Choi,\", \"sion.Preprint, arXiv:1902.00164.\", \"Alon Talmor, Jonathan Herzig, Nicholas Lourie, and\", \"edge.CoRR, abs/1811.00937.\", \"Armel Randy Zebaze, Benoît Sagot, and Rachel Baw-\", \"tional Linguistics: NAACL 2025, pages 1222–1252,\", \"Albuquerque, New Mexico. Association for Compu-\", \"Rowan Zellers, Ari Holtzman, Yonatan Bisk, Ali\", \"Farhadi, and Yejin Choi. 2019. Hellaswag: Can a\", \"Chujie Zheng, Hao Zhou, Fandong Meng, Jie Zhou,\", \"are not robust multiple choice selectors.Preprint,\"], \"error\": null}, \"d805edc2\": {\"success\": true, \"paper_id\": \"d805edc2\", \"url\": \"https://arxiv.org/pdf/2210.15133v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_d805edc2.pdf\", \"extracted_info\": {\"title\": \"Retrieval Oriented Masking for Pre-trained Language Models in Dense Passage Retrieval\", \"authors\": [\"Not specified in provided content\"], \"abstract\": \"Pre-trained language models (PTMs) have shown strong capabilities in generating text representations for dense passage retrieval. However, the commonly used random token masking method in MLM pre-training often masks stop-words or punctuation, which have minimal impact on retrieval performance. This paper proposes a retrieval-oriented masking (ROM) method that does not alter the architecture or learning objective of the original PTM, but instead focuses masking on more informative tokens. Experiments on MS MARCO Passage Ranking and Natural Questions datasets demonstrate significant improvements in retrieval performance.\", \"methodology\": \"The proposed ROM method computes term weights for tokens in a sentence to identify more informative words for masking during MLM pre-training. Term weights can be derived using unsupervised methods such as BPROP or supervised methods like DeepImpact. ROM preserves the uniform random masking probability but biases masking towards high-weight tokens. The approach is integrated into standard PTM pre-training without architectural changes. Experiments were conducted on MS MARCO Passage Ranking and Natural Questions datasets using dual-encoder architectures, with comparisons against strong baselines such as BM25, DeepCT, DocT5Query, GAR, and Condenser.\", \"results\": \"ROM achieved MRR@10 of 37.3 and R@1000 of 98.1 on MS MARCO, outperforming BM25 (MRR@10 18.6) and other baselines. The coROM variant further improved results to MRR@10 of 39.1 and R@1000 of 98.6. On Natural Questions, ROM and coROM also outperformed baselines in R@5, R@20, and R@100. Using supervised DeepImpact term weights slightly improved ROM performance (MRR@10 37.6, R@1000 98.2). T-tests confirmed statistical significance (p &lt; 0.05) of improvements over baselines.\", \"conclusion\": \"The key contributions are: 1) Identification of limitations in random token masking for dense passage retrieval pre-training; 2) Proposal of the retrieval-oriented masking (ROM) method to prioritize masking of informative tokens; 3) Demonstration that ROM can be integrated into existing PTMs without architectural changes; 4) Empirical evidence showing ROM significantly improves retrieval performance on benchmark datasets; 5) Analysis showing high-quality term weight computation further enhances ROM effectiveness.\", \"figures\": null, \"tables\": null}, \"citations\": [\"Wei-Cheng Chang, Felix X. Yu, Yin-Wen Chang, Yim-\", \"ing Yang, and Sanjiv Kumar. 2020. Pre-training\", \"8th International Conference on Learning Represen-\", \"tations, ICLR 2020, Addis Ababa, Ethiopia, April\", \"26-30, 2020 .\", \"Donghyun Choi, Myeongcheol Shin, Eunggyun Kim,\", \"IEEE Access , 9:112097–112103.\", \"mation Retrieval, SIGIR 2020, Virtual Event, China,\", \"July 25-30, 2020 , pages 1533–1536.\", \"Yixing Fan, Xiaohui Xie, Yinqiong Cai, Jia Chen,\", \"Xinyu Ma, Xiangsheng Li, Ruqing Zhang, Jiafeng\", \"Guo, and Yiqun Liu. 2021. Pre-training methods in\", \"information retrieval. CoRR , abs/2111.13853.\", \"Emily Fawcett, Michelle Helena van Velthoven, and\", \"in Natural Language Processing, EMNLP 2021, Vir-\", \"tual Event / Punta Cana, Dominican Republic, 7-11\", \"November, 2021 , pages 981–993.\", \"Linguistics (Volume 1: Long Papers), ACL 2022,\", \"Dublin, Ireland, May 22-27, 2022 , pages 2843–\", \"2853.\", \"Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick\", \"S. H. Lewis, Ledell Wu, Sergey Edunov, Danqi\", \"Chen, and Wen-tau Yih. 2020. Dense passage re-\", \"ods in Natural Language Processing, EMNLP 2020,\", \"Online, November 16-20, 2020 , pages 6769–6781.\", \"Tom Kwiatkowski, Jennimaria Palomaki, Olivia Red-\", \"ﬁeld, Michael Collins, Ankur P. Parikh, Chris Al-\", \"berti, Danielle Epstein, Illia Polosukhin, Jacob De-\", \"vlin, Kenton Lee, Kristina Toutanova, Llion Jones,\", \"Matthew Kelcey, Ming-Wei Chang, Andrew M. Dai,\", \"Jakob Uszkoreit, Quoc Le, and Slav Petrov. 2019.\", \"ing research. Trans. Assoc. Comput. Linguistics ,\", \"7:452–466.\", \"Kenton Lee, Ming-Wei Chang, and Kristina Toutanova.\", \"2019. Latent retrieval for weakly supervised open\", \"57th Conference of the Association for Computa-\", \"tional Linguistics, ACL 2019, Florence, Italy, July\", \"28- August 2, 2019, Volume 1: Long Papers , pages\", \"6086–6096.Jimmy Lin, Rodrigo Nogueira, and Andrew Yates.\", \"2021. Pretrained Transformers for Text Ranking:\", \"Dingkun Long, Qiong Gao, Kuan Zou, Guangwei Xu,\", \"Pengjun Xie, Ruijie Guo, Jian Xu, Guanjun Jiang,\", \"Luxi Xing, and Ping Yang. 2022. Multi-cpr: A multi\", \"domain chinese dataset for passage retrieval. CoRR ,\", \"Yuxiang Lu, Yiding Liu, Jiaxiang Liu, Yunsheng Shi,\", \"Zhengjie Huang, Shikun Feng, Yu Sun, Hao Tian,\", \"Hua Wu, Shuaiqiang Wang, Dawei Yin, and Haifeng\", \"dense passage retrieval. CoRR , abs/2205.09153.\", \"Yi Luan, Jacob Eisenstein, Kristina Toutanova, and\", \"Michael Collins. 2021. Sparse, dense, and atten-\", \"Comput. Linguistics , 9:329–345.\", \"Xinyu Ma, Jiafeng Guo, Ruqing Zhang, Yixing Fan,\", \"prediction. CoRR , abs/2204.10641.\", \"Xinyu Ma, Jiafeng Guo, Ruqing Zhang, Yixing Fan,\", \"Yingyan Li, and Xueqi Cheng. 2021. B-PROP: boot-\", \"and Development in Information Retrieval, Virtual\", \"Event, Canada, July 11-15, 2021 , pages 1318–1327.\", \"Antonio Mallia, Omar Khattab, Torsten Suel, and\", \"Development in Information Retrieval, Virtual Event,\", \"Canada, July 11-15, 2021 , pages 1723–1727.\", \"Yuning Mao, Pengcheng He, Xiaodong Liu, Yelong\", \"Shen, Jianfeng Gao, Jiawei Han, and Weizhu Chen.\", \"2021. Generation-augmented retrieval for open-\", \"59th Annual Meeting of the Association for Com-\", \"Joint Conference on Natural Language Processing,\", \"ACL/IJCNLP 2021, (Volume 1: Long Papers), Vir-\", \"tual Event, August 1-6, 2021 , pages 4089–4100.\", \"Tri Nguyen, Mir Rosenberg, Xia Song, Jianfeng Gao,\", \"Saurabh Tiwary, Rangan Majumder, and Li Deng.\", \"2016. MS MARCO: A human generated machine\", \"ral Information Processing Systems (NIPS 2016),\", \"Barcelona, Spain, December 9, 2016 .\", \"Yingqi Qu, Yuchen Ding, Jing Liu, Kai Liu, Ruiyang\", \"Ren, Wayne Xin Zhao, Daxiang Dong, Hua Wu, and\", \"2021 Conference of the North American Chapter\", \"Human Language Technologies, NAACL-HLT 2021,\", \"Online, June 6-11, 2021 , pages 5835–5847.\", \"Ruiyang Ren, Yingqi Qu, Jing Liu, Wayne Xin Zhao,\", \"Qiaoqiao She, Hua Wu, Haifeng Wang, and Ji rong\", \"ArXiv , abs/2110.07367.\", \"Xing Wu, Guangyuan Ma, Meng Lin, Zijia Lin,\", \"Zhongyuan Wang, and Songlin Hu. 2022. Contex-\", \"CoRR , abs/2208.07670.\", \"Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang,\", \"Jialin Liu, Paul N. Bennett, Junaid Ahmed, and\", \"Representations, ICLR 2021, Virtual Event, Austria,\", \"Shi Yu, Zhenghao Liu, Chenyan Xiong, Tao Feng, and\", \"Information Retrieval, Virtual Event, Canada, July\", \"11-15, 2021 , pages 829–838.\", \"Jingtao Zhan, Jiaxin Mao, Yiqun Liu, Jiafeng Guo,\", \"M. Zhang, and Shaoping Ma. 2021. Optimizing\", \"Hang Zhang, Yeyun Gong, Yelong Shen, Jiancheng\", \"Lv, Nan Duan, and Weizhu Chen. 2021. Adversar-\", \"ial retriever-ranker for dense text retrieval. CoRR ,\", \"Shunyu Zhang, Yaobo Liang, Ming Gong, Daxin Jiang,\", \"1: Long Papers), ACL 2022, Dublin, Ireland, May\", \"22-27, 2022 , pages 5990–6000.\", \"Yanzhao Zhang, Dingkun Long, Guangwei Xu, and\", \"reranking. arXiv preprint arXiv:2205.10569 .Yunchang Zhu, Liang Pang, Yanyan Lan, Huawei Shen,\", \"ods in Natural Language Processing, EMNLP 2021,\", \"Virtual Event / Punta Cana, Dominican Republic, 7-\", \"11 November, 2021 , pages 3615–3626.\"], \"error\": null}, \"2875dc88\": {\"success\": true, \"paper_id\": \"2875dc88\", \"url\": \"https://arxiv.org/pdf/2403.02901v2.pdf\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_2875dc88.pdf\", \"extracted_info\": {\"title\": \"LLM-Based Methods for Automatic Text Summarization: A Comprehensive Survey\", \"authors\": [\"Yang Zhang\", \"Hanlei Jin\", \"Dan Meng\", \"Jun Wang\", \"Jinghua Tan\"], \"abstract\": \"The exponential growth of textual content on the internet, alongside vast archives of news articles, has driven the need for efficient Automatic Text Summarization (ATS) systems. Previous surveys have largely focused on conventional ATS methods constrained by predefined generative paradigms. The advent of Large Language Models (LLMs) introduces unprecedented flexibility, enabling integration of extractive, abstractive, and hybrid summarization techniques without retraining or major architectural changes. This paper provides a comprehensive review of both conventional ATS approaches and recent advancements in LLM-based methods, and proposes a novel retrieval algorithm to efficiently collect relevant papers for ATS research.\", \"methodology\": \"The study employs a multi-stage methodology: (1) classification of ATS methods into conventional (extractive, abstractive, hybrid) and LLM-based categories; (2) detailed literature review of conventional ATS methods and LLM-based techniques, including prompt engineering, fine-tuning, and knowledge distillation; (3) development of an automated three-stage paper crawling and filtering algorithm using Google Scholar and other sources, incorporating synonym-enhanced search, relevance filtering via abstract and URL scraping, and categorization into predefined groups; (4) analysis of core ATS datasets and techniques for building new datasets using rule-based and LLM-based annotation; (5) examination of evaluation metrics for ATS, including overlap-based, similarity-based, and LLM-based metrics.\", \"results\": \"The survey reveals that LLM-based ATS methods achieve performance comparable to or exceeding human-crafted summaries in quality and factual consistency. Prompt engineering offers predictable and controllable outputs, fine-tuning enables domain adaptation, and knowledge distillation produces efficient smaller models. The proposed retrieval algorithm effectively collects and categorizes relevant ATS papers, ensuring comprehensive coverage. LLMs demonstrate flexibility in integrating extractive and abstractive paradigms, overcoming the inflexibility of conventional methods. The study also identifies challenges such as instruction adherence, task-specific knowledge incorporation, and variability in output quality.\", \"conclusion\": \"(1) Provides an updated and comprehensive review of ATS, covering both traditional and LLM-based methods; (2) Presents an in-depth analysis of LLM-based summarization techniques, including prompt engineering, fine-tuning, and knowledge distillation; (3) Proposes a novel, efficient paper retrieval algorithm adaptable to other domains; (4) Reviews core ATS datasets and outlines methodologies for building new datasets; (5) Discusses evaluation metrics for ATS, highlighting the potential of LLM-based metrics; (6) Identifies current challenges and future research directions to enhance the adaptability, scalability, and efficiency of LLM-based ATS systems.\", \"figures\": null, \"tables\": null}, \"citations\": [\"[1] K. SPARCK JONES, A statistical interpretation of term specificity and\", \"its application in retrieval, Journal of Documentation 28 (1972) 11–21.\", \"[2] S. Deerwester, S. T. Dumais, G. W. Furnas, T. K. Landauer,\", \"R. Harshman, Indexing by latent semantic analysis, Journal\", \"407. doi: https://doi.org/10.1002/(SICI)1097-4571(199009)\", \"41:6<391::AID-ASI1>3.0.CO;2-9 .\", \"[3] S. E. Robertson, S. Walker, S. Jones, M. Hancock-Beaulieu, M. Gatford,\", \"Okapi at trec-3, in: Text Retrieval Conference, 1994.\", \"[4] Y . Yamamoto, T. Takagi, A sentence classification system for multi\", \"biomedical literature summarization, in: 21st International Conference\", \"on Data Engineering Workshops (ICDEW’05), 2005, pp. 1163–1163.\", \"[5] M. Hu, B. Liu, Mining and summarizing customer reviews, in: Proceed-\", \"edge Discovery and Data Mining, 2004, p. 168–177. doi: 10.1145/\", \"1014052.1014073 .\", \"[6] F. Li, C. Han, M. Huang, X. Zhu, Y .-J. Xia, S. Zhang, H. Yu, Structure-\", \"aware review mining and summarization, in: Proceedings of the 23rd In-\", \"ternational Conference on Computational Linguistics, 2010, p. 653–661.\", \"[7] B. Liu, Y . Shi, Z. Wang, W. Wang, B. Shi, Dynamic incremental data\", \"summarization for hierarchical clustering, in: Advances in Web-Age\", \"Information Management, 2006, pp. 410–421.\", \"[8] S. Nassar, J. Sander, C. Cheng, Incremental and e ffective data sum-\", \"marization for dynamic hierarchical clustering, in: Proceedings of\", \"of Data, Association for Computing Machinery, 2004, p. 467–478.\", \"[9] S. Chopra, M. Auli, A. M. Rush, Abstractive sentence summarization\", \"with attentive recurrent neural networks, in: K. Knight, A. Nenkova,\", \"O. Rambow (Eds.), Proc. 2016 Conf. North American Chapter Assoc.\", \"Comput. Linguistics: Human Lang. Technol., Assoc. Comput. Lin-\", \"guistics, San Diego, California, 2016, pp. 93–98. doi: 10.18653/v1/\", \"[10] P. M. Hanunggul, S. Suyanto, The impact of local attention in lstm\", \"for abstractive text summarization, 2019 Int. Seminar on Res. of Inf.\", \"20\", \"[11] N. Nazari, M. A. Mahdavi, A survey on automatic text summarization,\", \"6139.1726 .\", \"[12] D. Suleiman, A. Awajan, Deep learning based abstractive text sum-\", \"marization: Approaches, datasets, evaluation measures, and challenges,\", \"[13] S. Gupta, S. K. Gupta, Abstractive summarization: An overview of\", \"the state of the art, Expert Syst. Appl. 121 (2019) 49–65. doi: https:\", \"[14] H. Lin, V . Ng, Abstractive summarization: A survey of the state of\", \"the art, Proc. AAAI Conf. Artif. Intell. 33 (2019) 9815–9822. doi: 10.\", \"1609/aaai.v33i01.33019815 .\", \"[15] P. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, G. Neubig, Pre-\", \"train, prompt, and predict: A systematic survey of prompting meth-\", \"ods in natural language processing, ACM Comput. Surv. 55 (2023).\", \"[16] S. Narayan, Y . Zhao, J. Maynez, G. Sim ˜oes, V . Nikolaev, R. Mc-\", \"Donald, Planning with learned entity prompts for abstractive sum-\", \"marization, Trans. Assoc. Comput. Linguistics 9 (2021) 1475–1492.\", \"[17] H. P. Luhn, The automatic creation of literature abstracts, IBM J. of\", \"[18] G. Salton, The SMART Retrieval System—Experiments in Automatic\", \"Document Processing, Prentice-Hall, Inc., USA, 1971.\", \"[19] G. Salton, C. Buckley, Term-weighting approaches in automatic text\", \"retrieval, Information Processing & Management 24 (1988) 513–523.\", \"[20] G. Salton, J. Allan, Selective text utilization and text traver-\", \"sal, International Journal of Human-Computer Studies 43\", \"(1995) 483–497. URL: https://www.sciencedirect.com/\", \"[21] G. Salton, J. Allan, C. Buckley, A. Singhal, Automatic analysis, theme\", \"generation, and summarization of machine-readable texts, Science 264\", \"(1994) 1421–1426. doi: 10.1126/science.264.5164.1421 .\", \"[22] G. Salton, A. Singhal, M. Mitra, C. Buckley, Automatic text struc-\", \"turing and summarization, Information Processing & Management 33\", \"(1997) 193–207. doi: https://doi.org/10.1016/S0306-4573(96)\", \"00062-3 , methods and Tools for the Automatic Construction of Hyper-\", \"[23] E. Hovy, C.-Y . Lin, Automated text summarization and the summarist\", \"system, in: Proceedings of a Workshop on Held at Baltimore, Maryland:\", \"October 13-15, 1998, TIPSTER ’98, Association for Computational Lin-\", \"guistics, USA, 1998, p. 197–214. doi: 10.3115/1119089.1119121 .\", \"[24] M. Mitra, A. Singhal, C. Buckley, Automatic text summarization by\", \"paragraph extraction, in: Intelligent Scalable Text Summarization, 1997.\", \"[25] H. P. Edmundson, New methods in automatic extracting, J. ACM 16\", \"(1969) 264–285. doi: 10.1145/321510.321519 .\", \"[26] S. Gerani, Y . Mehdad, G. Carenini, R. T. Ng, B. Nejat, Abstractive sum-\", \"marization of product reviews using discourse structure, in: Proceedings\", \"cessing (EMNLP), 2014, pp. 1602–1613. doi: 10.3115/v1/D14-1168 .\", \"[27] W. Li, Abstractive multi-document summarization with semantic in-\", \"formation extraction, in: Proceedings of the 2015 Conference on Em-\", \"pirical Methods in Natural Language Processing, 2015, pp. 1908–1913.\", \"[28] L. Hennig, W. Umbrath, R. Wetzker, An ontology-based approach to text\", \"summarization, in: Proceedings of the 2008 IEEE /WIC/ACM Interna-\", \"- V olume 03, 2008, p. 291–294. doi: 10.1109/WIIAT.2008.175 .\", \"[29] C.-S. Lee, Y .-J. Chen, Z.-W. Jian, Ontology-based fuzzy event extrac-\", \"tion agent for chinese e-news summarization, Expert Systems with\", \"[30] M. Gambhir, V . Gupta, Recent automatic text summarization tech-\", \"niques: a survey, Artificial Intelligence Review 47 (2017) 1–66.\", \"[31] G. Murray, G. Carenini, Summarizing spoken and written conversations,\", \"guage Processing, 2008, p. 773–782.\", \"[32] M. A. Fattah, A hybrid machine learning model for multi-documentsummarization, Applied Intelligence 40 (2014) 592–600. doi: 10.1007/\", \"[33] S. Teufel, M. Moens, Summarizing Scientific Articles: Experiments\", \"with Relevance and Rhetorical Status, Computational Linguistics 28\", \"(2002) 409–445. doi: 10.1162/089120102762671936 .\", \"[34] J. Goldstein, V . Mittal, J. Carbonell, M. Kantrowitz, Multi-document\", \"summarization by sentence extraction, in: Proceedings of the 2000\", \"NAACL-ANLPWorkshop on Automatic Summarization - V olume 4, As-\", \"sociation for Computational Linguistics, 2000, p. 40–48. doi: 10.3115/\", \"1117575.1117580 .\", \"[35] D. Shen, J.-T. Sun, H. Li, Q. Yang, Z. Chen, Document summarization\", \"using conditional random fields, in: Proceedings of the 20th Interna-\", \"tional Joint Conference on Artifical Intelligence, 2007, p. 2862–2867.\", \"[36] R. M. Aliguliyev, A new sentence similarity measure and sentence based\", \"extractive technique for automatic text summarization, Expert Systems\", \"1016/j.eswa.2008.11.022 .\", \"[37] Y . Lu, C. Zhai, N. Sundaresan, Rated aspect summarization of short\", \"comments, in: Proc. 18th Int. Conf. World Wide Web, WWW ’09, As-\", \"soc. for Comput. Machinery, New York, NY , USA, 2009, p. 131–140.\", \"[38] T. Copeck, N. Japkowicz, S. Szpakowicz, Text summarization as con-\", \"trolled search, in: R. Cohen, B. Spencer (Eds.), Advances in Artificial\", \"Intelligence, Springer Berlin Heidelberg, Berlin, Heidelberg, 2002, pp.\", \"268–280.\", \"[39] J.-Y . Delort, B. Bouchon-Meunier, M. Rifqi, Enhanced web docu-\", \"ment summarization using hyperlinks, in: Proceedings of the Four-\", \"teenth ACM Conference on Hypertext and Hypermedia, HYPER-\", \"TEXT ’03, Association for Computing Machinery, New York, NY ,\", \"USA, 2003, p. 208–215. URL: https://doi.org/10.1145/900051.\", \"900097 . doi: 10.1145/900051.900097 .\", \"[40] F. L. Wang, R. Kwan, S. L. Hung, Multi-document summarization for\", \"e-learning, in: Hybrid Learning and Education, Springer Berlin Heidel-\", \"berg, Berlin, Heidelberg, 2009, pp. 353–364.\", \"[41] M. Liu, W. Li, M. Wu, Q. Lu, Extractive summarization based on event\", \"term clustering, in: Proceedings of the 45th Annual Meeting of the ACL\", \"on Interactive Poster and Demonstration Sessions, 2007, p. 185–188.\", \"[42] R. Nallapati, B. Zhou, C. dos Santos, C. Guilcehre, B. Xiang, Abstrac-\", \"tive text summarization using sequence-to-sequence RNNs and beyond,\", \"in: S. Riezler, Y . Goldberg (Eds.), Proceedings of the 20th SIGNLL\", \"Conference on Computational Natural Language Learning, Association\", \"for Computational Linguistics, Berlin, Germany, 2016, pp. 280–290.\", \"[43] R. Nallapati, B. Xiang, B. Zhou, ‘sequence-to-sequence rnns for text\", \"summarization, in: Workshop of the 4th International Conference on\", \"Learning Representations, 2016.\", \"[44] S. Ma, X. Sun, J. Xu, H. Wang, W. Li, Q. Su, Improving semantic rel-\", \"summarization, in: Proceedings of the 55th Annual Meeting of the As-\", \"sociation for Computational Linguistics (V olume 2: Short Papers), 2017,\", \"[45] S. Song, H. Huang, T. Ruan, Abstractive text summarization using lstm-\", \"cnn based deep learning, Multimedia Tools and Applications 78 (2019)\", \"857–875. doi: 10.1007/s11042-018-5749-3 .\", \"[46] J. Cheng, M. Lapata, Neural summarization by extracting sentences and\", \"words, in: K. Erk, N. A. Smith (Eds.), Proceedings of the 54th An-\", \"1: Long Papers), Association for Computational Linguistics, Berlin,\", \"Germany, 2016, pp. 484–494. URL: https://aclanthology.org/\", \"[47] K. Zhang, W.-L. Chao, F. Sha, K. Grauman, Video summarization with\", \"long short-term memory, in: B. Leibe, J. Matas, N. Sebe, M. Welling\", \"(Eds.), Computer Vision – ECCV 2016, Springer International Publish-\", \"ing, Cham, 2016, pp. 766–782.\", \"[48] Q. Zhou, N. Yang, F. Wei, S. Huang, M. Zhou, T. Zhao, Neural doc-\", \"ument summarization by jointly learning to score and select sentences,\", \"putational Linguistics (V olume 1: Long Papers), 2018, pp. 654–663.\", \"[49] Z. Cao, F. Wei, W. Li, S. Li, Faithful to the original: Fact aware\", \"21\", \"neural abstractive summarization, Proceedings of the AAAI Confer-\", \"[50] Y . Liu, M. Lapata, Text summarization with pretrained encoders, in:\", \"Natural Language Processing (EMNLP-IJCNLP), 2019, pp. 3730–3740.\", \"[51] L. Huang, S. Cao, N. Parulian, H. Ji, L. Wang, E fficient attentions\", \"for long document summarization, in: Proceedings of the 2021 Con-\", \"tational Linguistics: Human Language Technologies, 2021, pp. 1419–\", \"1436. doi: 10.18653/v1/2021.naacl-main.112 .\", \"[52] M. Zhong, Y . Liu, Y . Xu, C. Zhu, M. Zeng, Dialoglm: Pre-trained model\", \"for long dialogue understanding and summarization, Proceedings of the\", \"[53] I. Cachola, K. Lo, A. Cohan, D. Weld, TLDR: Extreme summarization\", \"of scientific documents, in: T. Cohn, Y . He, Y . Liu (Eds.), Findings\", \"of the Association for Computational Linguistics: EMNLP 2020, As-\", \"sociation for Computational Linguistics, Online, 2020, pp. 4766–4777.\", \"[54] Y . Liu, Fine-tune bert for extractive summarization, 2019. URL: https:\", \"[55] X. Zhang, F. Wei, M. Zhou, HIBERT: Document level pre-training\", \"of hierarchical bidirectional transformers for document summarization,\", \"Computational Linguistics, 2019, pp. 5059–5069. doi: 10.18653/v1/\", \"[56] J. Zhang, Y . Zhao, M. Saleh, P. J. Liu, Pegasus: pre-training with ex-\", \"tracted gap-sentences for abstractive summarization, in: Proceedings of\", \"the 37th International Conference on Machine Learning, 2020.\", \"[57] Z. Yang, C. Zhu, R. Gmyr, M. Zeng, X. Huang, E. Darve, TED: A pre-\", \"denoising, in: Findings of the Association for Computational Linguis-\", \"tics: EMNLP 2020, 2020, pp. 1865–1874. doi: 10.18653/v1/2020.\", \"[58] T. Yu, Z. Liu, P. Fung, AdaptSum: Towards low-resource domain adap-\", \"tation for abstractive summarization, in: Proceedings of the 2021 Con-\", \"tational Linguistics: Human Language Technologies, 2021, pp. 5892–\", \"5904. doi: 10.18653/v1/2021.naacl-main.471 .\", \"[59] M. Zhong, P. Liu, Y . Chen, D. Wang, X. Qiu, X. Huang, Extractive sum-\", \"marization as text matching, in: Proceedings of the 58th Annual Meeting\", \"of the Association for Computational Linguistics, 2020, pp. 6197–6208.\", \"[60] L. Zhang, R. Negrinho, A. Ghosh, V . Jagannathan, H. R. Hassanzadeh,\", \"T. Schaaf, M. R. Gormley, Leveraging pretrained models for automatic\", \"summarization of doctor-patient conversations, in: Findings of the Asso-\", \"ciation for Computational Linguistics: EMNLP 2021, 2021, pp. 3693–\", \"3712. doi: 10.18653/v1/2021.findings-emnlp.313 .\", \"[61] H. Hayashi, P. Budania, P. Wang, C. Ackerson, R. Neervannan, G. Neu-\", \"big, WikiAsp: A Dataset for Multi-domain Aspect-based Summariza-\", \"tion, Transactions of the Association for Computational Linguistics 9\", \"(2021) 211–225. doi: 10.1162/tacl_a_00362 .\", \"[62] A. Ghadimi, H. Beigy, Hybrid multi-document summarization using\", \"pre-trained language models, Expert Syst. Appl. 192 (2022). doi: 10.\", \"1016/j.eswa.2021.116292 .\", \"[63] P. Hartl, U. Kruschwitz, Applying automatic text summarization for\", \"fake news detection, in: Proceedings of the Thirteenth Language\", \"Resources and Evaluation Conference, 2022, pp. 2702–2713. URL:\", \"[64] W. Xiao, G. Carenini, Extractive summarization of long documents\", \"by combining global and local context, in: K. Inui, J. Jiang, V . Ng,\", \"X. Wan (Eds.), EMNLP-IJCNLP, Assoc. Comput. Linguistics, Hong\", \"Kong, China, 2019, pp. 3011–3021. doi: 10.18653/v1/D19-1298 .\", \"[65] T. Shi, Y . Keneshloo, N. Ramakrishnan, C. K. Reddy, Neural abstrac-\", \"tive text summarization with sequence-to-sequence models, ACM /IMS\", \"[66] H. Zogan, I. Razzak, S. Jameel, G. Xu, Depressionnet: Learning multi-modalities with user post summarization for depression detection on so-\", \"cial media, in: Proceedings of the 44th International ACM SIGIR Con-\", \"ference on Research and Development in Information Retrieval, 2021,\", \"[67] N. Li, B. Kang, T. D. Bie, Skillgpt: a restful api service for skill ex-\", \"traction and standardization using a large language model, 2023. URL:\", \"[68] N. Mishra, G. Sahu, I. Calixto, A. Abu-Hanna, I. Laradji, LLM\", \"aided semi-supervision for e fficient extractive dialog summarization,\", \"in: H. Bouamor, J. Pino, K. Bali (Eds.), Findings of the Asso-\", \"ciation for Computational Linguistics: EMNLP 2023, Association\", \"for Computational Linguistics, Singapore, 2023, pp. 10002–10009.\", \"[69] P. He, B. Peng, S. Wang, Y . Liu, R. Xu, H. Hassan, Y . Shi, C. Zhu,\", \"W. Xiong, M. Zeng, J. Gao, X. Huang, Z-code ++: A pre-trained lan-\", \"guage model optimized for abstractive summarization, in: A. Rogers,\", \"J. Boyd-Graber, N. Okazaki (Eds.), Proceedings of the 61st Annual\", \"1: Long Papers), Association for Computational Linguistics, Toronto,\", \"Canada, 2023, pp. 5095–5112. URL: https://aclanthology.org/\", \"2023.acl-long.279 . doi: 10.18653/v1/2023.acl-long.279 .\", \"[70] Y .-N. Chuang, R. Tang, X. Jiang, X. Hu, Spec: A soft prompt-\", \"in clinical notes summarization, Journal of Biomedical Informat-\", \"[71] M. Ravaut, S. Joty, N. Chen, Summareranker: A multi-task\", \"tion, in: Proceedings of the 60th Annual Meeting of the As-\", \"sociation for Computational Linguistics (V olume 1: Long Papers),\", \"Association for Computational Linguistics, 2022, pp. 4504–4524.\", \"18653/v1/2022.acl-long.309 .\", \"[72] A. Ghadimi, H. Beigy, Hybrid multi-document summarization us-\", \"ing pre-trained language models, Expert Systems with Applica-\", \"[73] N. Moratanch, S. Chitrakala, A survey on extractive text summarization,\", \"in: 2017 International Conference on Computer, Communication and\", \"Signal Processing (ICCCSP), 2017, pp. 1–6. doi: 10.1109/ICCCSP.\", \"2017.7944061 .\", \"[74] T. Mikolov, M. Karafi ´at, L. Burget, J. Cernock `y, S. Khudanpur, Recur-\", \"rent neural network based language model., in: Interspeech, volume 2,\", \"Makuhari, 2010, pp. 1045–1048.\", \"[75] A. Vaswani, N. M. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.\", \"Gomez, L. Kaiser, I. Polosukhin, Attention is all you need, in: NIPS,\", \"2017.\", \"[76] W. S. El-Kassas, C. R. Salama, A. A. Rafea, H. K. Mohamed, Auto-\", \"matic text summarization: A comprehensive survey, Expert Syst. Appl.\", \"165 (2021) 113679. doi: https://doi.org/10.1016/j.eswa.2020.\", \"113679 .\", \"[77] J. Zheng, M. A. Fischer, Bim-gpt: a prompt-based virtual assis-\", \"tant framework for bim information retrieval, ArXiv abs /2304.09333\", \"(2023). URL: https://api.semanticscholar.org/CorpusID:\", \"258213067 .\", \"[78] S. Gholamrezazadeh, M. A. Salehi, B. Gholamzadeh, A comprehensive\", \"survey on text summarization systems, in: 2009 2nd Int. Conf. Comput.\", \"Sci. and its Appl., IEEE, 2009, pp. 1–6.\", \"[79] V . Gupta, G. S. Lehal, A survey of text summarization extractive tech-\", \"niques, J. of Emerg. Technol. in Web Intell. 2 (2010) 258–268.\", \"[80] Moratanch, N. and Chitrakala, S., A survey on extractive text summa-\", \"rization, in: 2017 Int. Conf. Comput., Commun. and Signal Process.\", \"(ICCCSP), 2017, pp. 1–6. doi: 10.1109/ICCCSP.2017.7944061 .\", \"[81] M. Kirmani, N. Manzoor Hakak, M. Mohd, M. Mohd, Hybrid text sum-\", \"marization: A survey, in: K. Ray, T. K. Sharma, S. Rawat, R. K. Saini,\", \"A. Bandyopadhyay (Eds.), Soft Comput.: Theories and Appl., Springer\", \"Singap., Singap., 2019, pp. 63–73.\", \"[82] A. A. Syed, F. L. Gaol, T. Matsuo, A survey of the state-of-the-art\", \"22\", \"models in neural abstractive text summarization, IEEE Access 9 (2021)\", \"13248–13265. doi: 10.1109/ACCESS.2021.3052783 .\", \"[83] M. F. Mridha, A. A. Lima, K. Nur, S. C. Das, M. Hasan, M. M. Kabir,\", \"A survey of automatic text summarization: Progress, process and chal-\", \"lenges, IEEE Access 9 (2021) 156043–156070. doi: 10.1109/ACCESS.\", \"2021.3129786 .\", \"[84] H. Y . Koh, J. Ju, M. Liu, S. Pan, An empirical survey on long document\", \"summarization: Datasets, models, and metrics, ACM Comput. Surv. 55\", \"(2022). doi: 10.1145/3545176 .\", \"[85] H. Chen, X. Liu, D. Yin, J. Tang, A survey on dialogue sys-\", \"tems: Recent advances and new frontiers, SIGKDD Explor. Newsl.\", \"19 (2017) 25–35. URL: https://doi.org/10.1145/3166054.\", \"3166058 . doi: 10.1145/3166054.3166058 .\", \"[86] Q. Li, Y . Chen, J. Wang, Y . Chen, H. Chen, Web media and stock\", \"tive, IEEE Trans. on Knowl. and Data Eng. 30 (2018) 381–399.\", \"[87] A. Kanapala, S. Pal, R. Pamula, Text summarization from legal docu-\", \"ments: a survey, Artif. Intell. Review 51 (2019) 371–402. doi: 10.1007/\", \"[88] Y . Liu, T. Safavi, A. Dighe, D. Koutra, Graph summarization methods\", \"and applications: A survey, ACM Comput. Surv. 51 (2018). doi: 10.\", \"1145/3186727 .\", \"[89] N. Ibrahim Altmami, M. El Bachir Menai, Automatic summarization\", \"of scientific articles: A survey, J. of King Saud Univ. - Comput. and\", \"[90] X. Feng, X. Feng, B. Qin, A survey on dialogue summarization: Re-\", \"cent advances and new frontiers, in: L. D. Raedt (Ed.), Proceedings\", \"gence, IJCAI-22, International Joint Conferences on Artificial Intelli-\", \"gence Organization, 2022, pp. 5453–5460. URL: https://doi.org/\", \"10.24963/ijcai.2022/764 . doi: 10.24963/ijcai.2022/764 , sur-\", \"[91] C. Ma, W. E. Zhang, M. Guo, H. Wang, Q. Z. Sheng, Multi-document\", \"summarization via deep learning techniques: A survey, ACM Comput.\", \"[92] R. Jain, A. Jangra, S. Saha, A. Jatowt, A survey on medical document\", \"summarization, 2022. arXiv:2212.01669 .\", \"[93] P. Bhattacharya, K. Hiware, S. Rajgaria, N. Pochhi, K. Ghosh, S. Ghosh,\", \"judgments, in: L. Azzopardi, B. Stein, N. Fuhr, P. Mayr, C. Hau ff,\", \"D. Hiemstra (Eds.), Advances in Inf. Retrieval, Springer Int. Publishing,\", \"Cham, 2019, pp. 413–428.\", \"[94] D. Jain, M. D. Borah, A. Biswas, Summarization of legal documents:\", \"Where are we now and the way forward, Comput. Sci. Review 40 (2021)\", \"100388. doi: https://doi.org/10.1016/j.cosrev.2021.100388 .\", \"[95] S. Dutta, V . Chandra, K. Mehra, S. Ghatak, A. K. Das, S. Ghosh, Sum-\", \"tive summarization algorithms, in: A. Abraham, P. Dutta, J. K. Mandal,\", \"A. Bhattacharya, S. Dutta (Eds.), Emerg. Technol. Data Mining and Inf.\", \"Security, Springer Singap., Singap., 2019, pp. 859–872.\", \"[96] Z. Zheng, O. Zhang, C. Borgs, J. T. Chayes, O. M. Yaghi, Chatgpt chem-\", \"istry assistant for text mining and the prediction of mof synthesis, Jour-\", \"3c05819 . arXiv:https://doi.org/10.1021/jacs.3c05819 ,\", \"[97] Y . Zhao, R. Joshi, T. Liu, M. Khalman, M. Saleh, P. J. Liu, Slic-\", \"hf: Sequence likelihood calibration with human feedback, ???? URL:\", \"[98] Y . Xu, R. Xu, D. Iter, Y . Liu, S. Wang, C. Zhu, M. Zeng, Inher-\", \"itSumm: A general, versatile and compact summarizer by distilling\", \"from GPT, in: H. Bouamor, J. Pino, K. Bali (Eds.), Findings of the\", \"Association for Computational Linguistics: EMNLP 2023, Associa-\", \"tion for Computational Linguistics, Singapore, 2023, pp. 13879–13892.\", \"[99] X. Feng, X. Feng, B. Qin, X. Geng, Dialogue discourse-aware graph\", \"model and data augmentation for meeting summarization, in: Z.-H.\", \"Zhou (Ed.), Proc. 30th IJCAI, IJCAI-21, IJCAI Org., 2021, pp. 3808–3814. doi: 10.24963/ijcai.2021/524 , main Track.\", \"[100] X. Liu, S. Zang, C. Zhang, X. Chen, Y . Ding, Clts +: A new chinese\", \"long text summarization dataset with abstractive summaries, in: Int.\", \"Conf. Artif. Neural Networks, Springer, 2022, pp. 73–84.\", \"[101] A. Asi, S. Wang, R. Eisenstadt, D. Geckt, Y . Kuper, Y . Mao, R. Ro-\", \"nen, An end-to-end dialogue summarization system for sales calls,\", \"in: A. Loukina, R. Gangadharaiah, B. Min (Eds.), Proc. 2022 Conf.\", \"Technol.: Industry Track, Assoc. Comput. Linguistics, Hybrid: Seat-\", \"tle, Washington +Online, 2022, pp. 45–53. doi: 10.18653/v1/2022.\", \"[102] D. Gra ff, J. Kong, K. Chen, K. Maeda, English gigaword, Linguistic\", \"Data Consortium, Philadelphia 4 (2003) 34.\", \"[103] D. Harman, P. Over, The e ffects of human variation in duc summariza-\", \"tion evaluation, in: Text Summarization Branches Out, 2004, pp. 10–17.\", \"[104] K. M. Hermann, T. Kocisky, E. Grefenstette, L. Espeholt, W. Kay,\", \"M. Suleyman, P. Blunsom, Teaching machines to read and comprehend,\", \"[105] B. Hu, Q. Chen, F. Zhu, LCSTS: A large scale Chinese short text sum-\", \"marization dataset, in: L. M `arquez, C. Callison-Burch, J. Su (Eds.),\", \"EMNLP, Assoc. Comput. Linguistics, Lisbon, Portugal, 2015, pp. 1967–\", \"1972. doi: 10.18653/v1/D15-1229 .\", \"[106] A. Cohan, F. Dernoncourt, D. S. Kim, T. Bui, S. Kim, W. Chang, N. Go-\", \"harian, A discourse-aware attention model for abstractive summariza-\", \"tion of long documents, in: M. Walker, H. Ji, A. Stent (Eds.), Proc.\", \"2018 Conf. North American Chapter Assoc. Comput. Linguistics: Hu-\", \"man Lang. Technol., V olume 2 (Short Papers), Assoc. Comput. Linguis-\", \"tics, New Orleans, Louisiana, 2018, pp. 615–621. doi: 10.18653/v1/\", \"[107] S. Narayan, S. B. Cohen, M. Lapata, Don’t give me the details, just\", \"summarization, in: E. Rilo ff, D. Chiang, J. Hockenmaier, J. Tsujii\", \"(Eds.), EMNLP, Assoc. Comput. Linguistics, Brussels, Belgium, 2018,\", \"[108] M. Grusky, M. Naaman, Y . Artzi, Newsroom: A dataset of 1.3 mil-\", \"lion summaries with diverse extractive strategies, ???? URL: http:\", \"[109] M. Koupaee, W. Y . Wang, Wikihow: A large scale text summarization\", \"dataset, ArXiv abs /1810.09305 (2018).\", \"[110] A. Fabbri, I. Li, T. She, S. Li, D. Radev, Multi-news: A large-\", \"model, in: A. Korhonen, D. Traum, L. M `arquez (Eds.), Proc. 57th Annu.\", \"Meeting Assoc. Comput. Linguistics, Assoc. Comput. Linguistics, Flo-\", \"rence, Italy, 2019, pp. 1074–1084. doi: 10.18653/v1/P19-1102 .\", \"[111] B. Gliwa, I. Mochol, M. Biesek, A. Wawer, SAMSum corpus: A human-\", \"annotated dialogue dataset for abstractive summarization, in: L. Wang,\", \"J. C. K. Cheung, G. Carenini, F. Liu (Eds.), Proceedings of the 2nd\", \"Workshop on New Frontiers in Summarization, Association for Compu-\", \"tational Linguistics, Hong Kong, China, 2019, pp. 70–79. URL: https:\", \"[112] E. Sharma, C. Li, L. Wang, Bigpatent: A large-scale dataset for abstrac-\", \"tive and coherent summarization, ???? URL: http://arxiv.org/\", \"[113] M. Yasunaga, J. Kasai, R. Zhang, A. R. Fabbri, I. Li, D. Friedman,\", \"D. R. Radev, Scisummnet: A large annotated corpus and content-impact\", \"models for scientific paper summarization with citation networks, Proc.\", \"[114] A. Kornilova, V . Eidelman, Billsum: A corpus for automatic summa-\", \"rization of us legislation, ???? URL: http://arxiv.org/abs/1910.\", \"00523 . doi: 10.18653/v1/D19-5406 .arXiv:1910.00523 .\", \"[115] F. Ladhak, E. Durmus, C. Cardie, K. McKeown, Wikilingua: A new\", \"benchmark dataset for cross-lingual abstractive summarization, ????\", \"[116] T. Scialom, P.-A. Dray, S. Lamprier, B. Piwowarski, J. Staiano, Mlsum:\", \"The multilingual summarization corpus, ???? URL: http://arxiv.\", \"[117] T. Hasan, A. Bhattacharjee, M. S. Islam, K. Samin, Y .-F. Li, Y .-B.\", \"Kang, M. S. Rahman, R. Shahriyar, Xl-sum: Large-scale multilin-\", \"gual abstractive summarization for 44 languages, ???? URL: http:\", \"23\", \"[118] Y . Chen, Y . Liu, L. Chen, Y . Zhang, DialogSum: A real-life scenario\", \"dialogue summarization dataset, in: C. Zong, F. Xia, W. Li, R. Nav-\", \"igli (Eds.), Findings of the Association for Computational Linguistics:\", \"ACL-IJCNLP 2021, Association for Computational Linguistics, Online,\", \"2021, pp. 5062–5074. URL: https://aclanthology.org/2021.\", \"[119] C. Zhu, Y . Liu, J. Mei, M. Zeng, Mediasum: A large-scale media inter-\", \"view dataset for dialogue summarization, ???? URL: http://arxiv.\", \"[120] W. Kry ´sci´nski, N. Rajani, D. Agarwal, C. Xiong, D. Radev, Booksum: A\", \"collection of datasets for long-form narrative summarization, ???? URL:\", \"[121] M. Chen, Z. Chu, S. Wiseman, K. Gimpel, SummScreen: A dataset\", \"for abstractive screenplay summarization, in: S. Muresan, P. Nakov,\", \"A. Villavicencio (Eds.), Proceedings of the 60th Annual Meeting of the\", \"Association for Computational Linguistics (V olume 1: Long Papers),\", \"Association for Computational Linguistics, Dublin, Ireland, 2022, pp.\", \"8602–8615. URL: https://aclanthology.org/2022.acl-long.\", \"589. doi: 10.18653/v1/2022.acl-long.589 .\", \"[122] Z. Cao, C. Chen, W. Li, S. Li, F. Wei, M. Zhou, Tgsum:\", \"Build tweet guided multi-document summarization dataset, Proceed-\", \"10376 . doi: 10.1609/aaai.v30i1.10376 .\", \"[123] M.-T. Nguyen, D. V . Lai, P.-K. Do, D.-V . Tran, M.-L. Nguyen, VSoLSC-\", \"text summarization, in: K. Hasida, K.-F. Wong, N. Calzorari, K.-S. Choi\", \"(Eds.), Proceedings of the 12th Workshop on Asian Language Resources\", \"(ALR12), The COLING 2016 Organizing Committee, Osaka, Japan,\", \"2016, pp. 38–48. URL: https://aclanthology.org/W16-5405 .\", \"[124] M.-T. Nguyen, C.-X. Tran, D.-V . Tran, M.-L. Nguyen, Solscsum:\", \"tion, in: Proceedings of the 25th ACM International on Confer-\", \"ence on Information and Knowledge Management, CIKM ’16, As-\", \"sociation for Computing Machinery, New York, NY , USA, 2016, p.\", \"2409–2412. URL: https://doi.org/10.1145/2983323.2983376 .\", \"[125] P. Li, L. Bing, W. Lam, Reader-aware multi-document summarization:\", \"An enhanced model and the first dataset, ???? URL: http://arxiv.\", \"[126] K. Kurniawan, S. Louvan, Indosum: A new benchmark dataset for in-\", \"donesian text summarization, ???? URL: http://arxiv.org/abs/\", \"1810.05334 .arXiv:1810.05334 .\", \"[127] D. de Vargas Feij ´o, V . P. Moreira, Rulingbr: A summarization dataset\", \"for legal texts, in: A. Villavicencio, V . Moreira, A. Abad, H. Caseli,\", \"P. Gamallo, C. Ramisch, H. Gonc ¸alo Oliveira, G. H. Paetzold (Eds.),\", \"Computational Processing of the Portuguese Language, Springer Inter-\", \"national Publishing, Cham, 2018, pp. 255–264.\", \"[128] M. Straka, N. Mediankin, T. Kocmi, Z. ˇZabokrtsk ´y, V . Hude ˇcek,\", \"J. Haji ˇc, SumeCzech: Large Czech news-based summarization dataset,\", \"in: N. Calzolari, K. Choukri, C. Cieri, T. Declerck, S. Goggi, K. Hasida,\", \"H. Isahara, B. Maegaard, J. Mariani, H. Mazo, A. Moreno, J. Odijk,\", \"S. Piperidis, T. Tokunaga (Eds.), Proceedings of the Eleventh Interna-\", \"tional Conference on Language Resources and Evaluation (LREC 2018),\", \"European Language Resources Association (ELRA), Miyazaki, Japan,\", \"2018. URL: https://aclanthology.org/L18-1551 .\", \"[129] G. Lev, M. Shmueli-Scheuer, J. Herzig, A. Jerbi, D. Konopnicki, Talk-\", \"summarization based on conference talks, ???? URL: http://arxiv.\", \"[130] V .-H. Nguyen, T.-C. Nguyen, M.-T. Nguyen, N. X. Hoai, Vnds: A viet-\", \"namese dataset for summarization, in: 2019 6th NAFOSTED Confer-\", \"ence on Information and Computer Science (NICS), 2019, pp. 375–380.\", \"[131] D. G. Ghalandari, C. Hokamp, N. T. Pham, J. Glover, G. Ifrim, A large-\", \"rent events portal, ???? URL: http://arxiv.org/abs/2005.10070 .\", \"[132] Y . Lu, Y . Dong, L. Charlin, Multi-xscience: A large-scale dataset for\", \"extreme multi-document summarization of scientific articles, ???? URL:\", \"http://arxiv.org/abs/2010.14235 .arXiv:2010.14235 .[133] S. Kulkarni, S. Chammas, W. Zhu, F. Sha, E. Ie, Aquamuse:\", \"summarization, ???? URL: http://arxiv.org/abs/2010.12694 .\", \"[134] I. Gusev, Dataset for automatic summarization of russian news, in:\", \"A. Filchenkov, J. Kauttonen, L. Pivovarova (Eds.), Artificial Intelligence\", \"and Natural Language, Springer International Publishing, Cham, 2020,\", \"[135] F. Koto, J. H. Lau, T. Baldwin, Liputan6: A large-scale indonesian\", \"dataset for text summarization, ???? URL: http://arxiv.org/abs/\", \"2011.00679 .arXiv:2011.00679 .\", \"[136] A. Roush, A. Balaji, DebateSum: A large-scale argument mining and\", \"summarization dataset, in: E. Cabrio, S. Villata (Eds.), Proceedings of\", \"the 7th Workshop on Argument Mining, Association for Computational\", \"Linguistics, Online, 2020, pp. 1–7. URL: https://aclanthology.\", \"[137] K.-H. Huang, C. Li, K.-W. Chang, Generating sports news from live\", \"commentary: A Chinese dataset for sports game summarization, in:\", \"K.-F. Wong, K. Knight, H. Wu (Eds.), Proceedings of the 1st Con-\", \"ural Language Processing, Association for Computational Linguistics,\", \"Suzhou, China, 2020, pp. 609–615. URL: https://aclanthology.\", \"[138] X. Liu, C. Zhang, X. Chen, Y . Cao, J. Li, Clts: A new chinese long text\", \"summarization dataset, in: X. Zhu, M. Zhang, Y . Hong, R. He (Eds.),\", \"Natural Language Processing and Chinese Computing, volume 12430,\", \"Springer International Publishing, 2020, pp. 531–542. URL: http://\", \"1007/978-3-030-60450-9_42 .\", \"[139] D. Antognini, B. Faltings, GameWikiSum: a novel large multi-\", \"document summarization dataset, in: N. Calzolari, F. B ´echet, P. Blache,\", \"K. Choukri, C. Cieri, T. Declerck, S. Goggi, H. Isahara, B. Maegaard,\", \"J. Mariani, H. Mazo, A. Moreno, J. Odijk, S. Piperidis (Eds.), Proceed-\", \"ings of the Twelfth Language Resources and Evaluation Conference,\", \"European Language Resources Association, Marseille, France, 2020,\", \"820.\", \"[140] H. Hayashi, P. Budania, P. Wang, C. Ackerson, R. Neervan-\", \"nan, G. Neubig, Wikiasp: A dataset for multi-domain aspect-based\", \"summarization, ???? URL: http://arxiv.org/abs/2011.07832 .\", \"[141] R. Meng, K. Thaker, L. Zhang, Y . Dong, X. Yuan, T. Wang, D. He,\", \"for long scientific documents, ???? URL: http://arxiv.org/abs/\", \"2106.00130 .arXiv:2106.00130 .\", \"[142] V . Gupta, P. Bharti, P. Nokhiz, H. Karnick, Sumpubmed: Summarization\", \"dataset of pubmed scientific articles, in: Proceedings of the 59th Annual\", \"Research Workshop, Association for Computational Linguistics, 2021,\", \"30. doi: 10.18653/v1/2021.acl-srw.30 .\", \"[143] G. Feigenblat, C. Gunasekara, B. Sznajder, S. Joshi, D. Konopnicki,\", \"R. Aharonov, TWEETSUMM - a dialog summarization dataset for\", \"customer service, in: M.-F. Moens, X. Huang, L. Specia, S. W.-\", \"t. Yih (Eds.), Findings of the Association for Computational Lin-\", \"guistics: EMNLP 2021, Association for Computational Linguistics,\", \"Punta Cana, Dominican Republic, 2021, pp. 245–260. URL: https:\", \"[144] H. Lin, L. Ma, J. Zhu, L. Xiang, Y . Zhou, J. Zhang, C. Zong, CSDS:\", \"marization, in: M.-F. Moens, X. Huang, L. Specia, S. W.-t. Yih\", \"(Eds.), Proceedings of the 2021 Conference on Empirical Methods in\", \"Natural Language Processing, Association for Computational Linguis-\", \"tics, Online and Punta Cana, Dominican Republic, 2021, pp. 4436–\", \"4451. URL: https://aclanthology.org/2021.emnlp-main.365 .\", \"[145] A. Bhattacharjee, T. Hasan, W. U. Ahmad, Y .-F. Li, Y .-B. Kang,\", \"R. Shahriyar, CrossSum: Beyond English-centric cross-lingual sum-\", \"24\", \"marization for 1,500 +language pairs, in: A. Rogers, J. Boyd-Graber,\", \"N. Okazaki (Eds.), Proceedings of the 61st Annual Meeting of the As-\", \"sociation for Computational Linguistics (V olume 1: Long Papers), As-\", \"sociation for Computational Linguistics, Toronto, Canada, 2023, pp.\", \"2541–2564. URL: https://aclanthology.org/2023.acl-long.\", \"143. doi: 10.18653/v1/2023.acl-long.143 .\", \"[146] X. Fu, J. Wang, Z. Yang, MM-A VS: A full-scale dataset for\", \"multi-modal summarization, in: K. Toutanova, A. Rumshisky,\", \"L. Zettlemoyer, D. Hakkani-Tur, I. Beltagy, S. Bethard, R. Cotterell,\", \"T. Chakraborty, Y . Zhou (Eds.), Proceedings of the 2021 Conference\", \"Linguistics: Human Language Technologies, Association for Com-\", \"putational Linguistics, Online, 2021, pp. 5922–5926. URL: https:\", \"2021.naacl-main.473 .\", \"[147] V . Parikh, V . Mathur, P. Mehta, N. Mittal, P. Majumder, Law-\", \"summarization, ???? URL: http://arxiv.org/abs/2110.01188 .\", \"[148] M. Khalman, Y . Zhao, M. Saleh, Forumsum: A multi-speaker\", \"conversation summarization dataset, in: Findings of the Associa-\", \"tion for Computational Linguistics: EMNLP 2021, Association for\", \"Computational Linguistics, 2021, pp. 4592–4599. URL: https://\", \"[149] A. Pasquali, R. Campos, A. Ribeiro, B. Santana, A. Jorge, A. Jatowt,\", \"Tls-covid19: A new annotated corpus for timeline summarization, in:\", \"D. Hiemstra, M.-F. Moens, J. Mothe, R. Perego, M. Potthast, F. Sebas-\", \"tiani (Eds.), Advances in Information Retrieval, volume 12656, Springer\", \"International Publishing, 2021, pp. 497–512. URL: https://link.\", \"978-3-030-72113-8_33 .\", \"[150] A. Dusart, K. Pinel-Sauvagnat, G. Hubert, Issumset: a tweet sum-\", \"marization dataset hidden in a trec track, in: Proceedings of the\", \"36th Annual ACM Symposium on Applied Computing, SAC ’21,\", \"Association for Computing Machinery, New York, NY , USA, 2021,\", \"[151] M. Zhao, S. Yan, B. Liu, X. Zhong, Q. Hao, H. Chen, D. Niu, B. Long,\", \"W. Guo, Qbsum: A large-scale query-based document summariza-\", \"tion dataset from real-world applications, Computer Speech & Lan-\", \"[152] J. Wang, F. Meng, Z. Lu, D. Zheng, Z. Li, J. Qu, J. Zhou, Clid-\", \"tion, in: Y . Goldberg, Z. Kozareva, Y . Zhang (Eds.), Proceed-\", \"guage Processing, Association for Computational Linguistics, Abu\", \"Dhabi, United Arab Emirates, 2022, pp. 7716–7729. URL: https:\", \"2022.emnlp-main.526 .\", \"[153] A. Wang, R. Y . Pang, A. Chen, J. Phang, S. R. Bowman, SQuAL-\", \"ITY: Building a long-document summarization dataset the hard way, in:\", \"Y . Goldberg, Z. Kozareva, Y . Zhang (Eds.), Proceedings of the 2022\", \"Conference on Empirical Methods in Natural Language Processing,\", \"Association for Computational Linguistics, Abu Dhabi, United Arab\", \"Emirates, 2022, pp. 1139–1156. URL: https://aclanthology.org/\", \"2022.emnlp-main.75 . doi: 10.18653/v1/2022.emnlp-main.75 .\", \"[154] D. Aumiller, A. Chouhan, M. Gertz, EUR-lex-sum: A multi- and\", \"main, in: Y . Goldberg, Z. Kozareva, Y . Zhang (Eds.), Proceed-\", \"guage Processing, Association for Computational Linguistics, Abu\", \"Dhabi, United Arab Emirates, 2022, pp. 7626–7639. URL: https:\", \"2022.emnlp-main.519 .\", \"[155] M. Maddela, M. Kulkarni, D. Preotiuc-Pietro, EntSUM: A data set\", \"for entity-centric extractive summarization, in: S. Muresan, P. Nakov,\", \"A. Villavicencio (Eds.), Proceedings of the 60th Annual Meeting of the\", \"Association for Computational Linguistics (V olume 1: Long Papers),Association for Computational Linguistics, Dublin, Ireland, 2022, pp.\", \"3355–3366. URL: https://aclanthology.org/2022.acl-long.\", \"237. doi: 10.18653/v1/2022.acl-long.237 .\", \"[156] D. Aumiller, M. Gertz, Klexikon: A german dataset for joint summariza-\", \"tion and simplification, ???? URL: http://arxiv.org/abs/2201.\", \"07198 .arXiv:2201.07198 .\", \"[157] S. Poddar, A. M. Samad, R. Mukherjee, N. Ganguly, S. Ghosh, Caves: A\", \"cerns towards covid vaccines, ???? URL: http://arxiv.org/abs/\", \"2204.13746 .arXiv:2204.13746 .\", \"[158] R. Mukherjee, A. Bohra, A. Banerjee, S. Sharma, M. Hegde, A. Shaikh,\", \"S. Shrivastava, K. Dasgupta, N. Ganguly, S. Ghosh, P. Goyal, Ectsum: A\", \"call transcripts, ???? URL: http://arxiv.org/abs/2210.12467 .\", \"[159] S. A. Bahrainian, S. Feucht, C. Eickho ff, NEWTS: A corpus for news\", \"topic-focused summarization, in: S. Muresan, P. Nakov, A. Villavi-\", \"cencio (Eds.), Findings of the Association for Computational Linguis-\", \"tics: ACL 2022, Association for Computational Linguistics, Dublin, Ire-\", \"land, 2022, pp. 493–503. URL: https://aclanthology.org/2022.\", \"[160] Z. Chen, M. Varma, X. Wan, C. Langlotz, J.-B. Delbrouck, Toward\", \"anatomies and modalities, in: A. Rogers, J. Boyd-Graber, N. Okazaki\", \"(Eds.), Proceedings of the 61st Annual Meeting of the Association\", \"for Computational Linguistics (V olume 2: Short Papers), Association\", \"for Computational Linguistics, Toronto, Canada, 2023, pp. 469–484.\", \"18653/v1/2023.acl-short.41 .\", \"[161] E. Clark, S. Rijhwani, S. Gehrmann, J. Maynez, R. Aharoni, V . Niko-\", \"laev, T. Sellam, A. Siddhant, D. Das, A. Parikh, SEAHORSE: A\", \"multilingual, multifaceted dataset for summarization evaluation, in:\", \"H. Bouamor, J. Pino, K. Bali (Eds.), Proceedings of the 2023 Con-\", \"ference on Empirical Methods in Natural Language Processing, As-\", \"sociation for Computational Linguistics, Singapore, 2023, pp. 9397–\", \"9413. URL: https://aclanthology.org/2023.emnlp-main.584 .\", \"[162] Y . Hu, T. Ganter, H. Deilamsalehy, F. Dernoncourt, H. Foroosh, F. Liu,\", \"Meetingbank: A benchmark dataset for meeting summarization, ????\", \"[163] J. Lin, H. Hua, M. Chen, Y . Li, J. Hsiao, C. Ho, J. Luo, Videoxum:\", \"Cross-modal visual and textural summarization of videos, IEEE Trans-\", \"3335875 .\", \"[164] C. Zhu, Z. Yang, R. Gmyr, M. Zeng, X. Huang, Make lead bias in your\", \"favor: A simple and e ffective method for news summarization, 2020.\", \"[165] X. Feng, X. Feng, L. Qin, B. Qin, T. Liu, Language model as an an-\", \"notator: Exploring DialoGPT for dialogue summarization, in: C. Zong,\", \"F. Xia, W. Li, R. Navigli (Eds.), Proc. 59th Annu. Meeting Assoc. Com-\", \"(V olume 1: Long Papers), Assoc. Comput. Linguistics, Online, 2021,\", \"[166] Y . Zhang, S. Sun, M. Galley, Y .-C. Chen, C. Brockett, X. Gao, J. Gao,\", \"J. Liu, B. Dolan, DIALOGPT : Large-scale generative pre-training\", \"for conversational response generation, in: A. Celikyilmaz, T.-H. Wen\", \"(Eds.), Proc. 58th Annu. Meeting Assoc. Comput. Linguistics: System\", \"Demonstrations, Assoc. Comput. Linguistics, Online, 2020, pp. 270–\", \"278. doi: 10.18653/v1/2020.acl-demos.30 .\", \"[167] B. Chintagunta, N. Katariya, X. Amatriain, A. Kannan, Medically aware\", \"GPT-3 as a data generator for medical dialogue summarization, in:\", \"C. Shivade, R. Gangadharaiah, S. Gella, S. Konam, S. Yuan, Y . Zhang,\", \"P. Bhatia, B. Wallace (Eds.), Proc. 2nd Workshop on Natural Lang. Pro-\", \"cess. for Medical Conversations, Assoc. Comput. Linguistics, Online,\", \"2021, pp. 66–76. doi: 10.18653/v1/2021.nlpmc-1.9 .\", \"[168] A. Liu, S. Swayamdipta, N. A. Smith, Y . Choi, Wanli: Worker and\", \"ai collaboration for natural language inference dataset creation, arXiv\", \"[169] Z. Ji, N. Lee, R. Frieske, T. Yu, D. Su, Y . Xu, E. Ishii, Y . J. Bang,\", \"A. Madotto, P. Fung, Survey of hallucination in natural language gener-\", \"ation, ACM Comput. Surveys 55 (2023) 1–38.\", \"25\", \"[170] T. Goyal, G. Durrett, Annotating and modeling fine-grained factuality\", \"in summarization, in: K. Toutanova, A. Rumshisky, L. Zettlemoyer,\", \"D. Hakkani-Tur, I. Beltagy, S. Bethard, R. Cotterell, T. Chakraborty,\", \"Y . Zhou (Eds.), Proc. 2021 Conf. North American Chapter Assoc. Com-\", \"put. Linguistics: Human Lang. Technol., Assoc. Comput. Linguistics,\", \"Online, 2021, pp. 1449–1462. doi: 10.18653/v1/2021.naacl-main.\", \"114.\", \"[171] W. Kryscinski, B. McCann, C. Xiong, R. Socher, Evaluating the\", \"factual consistency of abstractive text summarization, in: B. Web-\", \"ber, T. Cohn, Y . He, Y . Liu (Eds.), Proceedings of the 2020 Confer-\", \"ence on Empirical Methods in Natural Language Processing (EMNLP),\", \"Association for Computational Linguistics, Online, 2020, pp. 9332–\", \"9346. URL: https://aclanthology.org/2020.emnlp-main.750 .\", \"[172] T. Goyal, G. Durrett, Evaluating factuality in generation with\", \"dependency-level entailment, in: Findings Assoc. Comput. Linguistics:\", \"EMNLP, 2020, pp. 3592–3603.\", \"[173] V . Balachandran, H. Hajishirzi, W. Cohen, Y . Tsvetkov, Correcting di-\", \"language model infilling, in: Y . Goldberg, Z. Kozareva, Y . Zhang (Eds.),\", \"ral Language Processing, Association for Computational Linguistics,\", \"Abu Dhabi, United Arab Emirates, 2022, pp. 9818–9830. URL: https:\", \"2022.emnlp-main.667 .\", \"[174] T. V odolazova, E. Lloret, R. Mu ˜noz, M. Palomar, The role of statisti-\", \"cal and semantic features in single-document extractive summarization,\", \"[175] H. Saif, M. Fern ´andez, Y . He, H. Alani, On stopwords, filtering and data\", \"sparsity for sentiment analysis of twitter, in: Int. Conf. Lang. Resources\", \"and Evaluation, 2014.\", \"[176] E. Charniak, Statistical techniques for natural language parsing, AI Mag.\", \"18 (1997) 33–43. URL: https://doi.org/10.1609/aimag.v18i4.\", \"1320 . doi: 10.1609/aimag.v18i4.1320 .\", \"[177] M. Y . Nuzumlali, A. ¨Ozg¨ur, Analyzing stemming approaches for turkish\", \"multi-document summarization, in: Conf. EMNLP, 2014.\", \"[178] E. Galiotou, N. N. Karanikolas, C. Tsoulloftas, On the e ffect of stem-\", \"ming algorithms on extractive summarization: a case study, in: Panhel-\", \"lenic Conf. Inform., 2013.\", \"[179] L. Hickman, S. Thapa, L. Tay, M. Cao, P. Srinivasan, Text pre-\", \"recommendations, Organizational Res. Methods 25 (2022) 114–146.\", \"[180] J.-M. Torres-Moreno, Beyond stemming and lemmatization: Ultra-\", \"stemming to improve automatic text summarization, ArXiv\", \"[181] V . K. Gupta, T. J. Siddiqui, Multi-document summarization using sen-\", \"tence clustering, in: 2012 4th Int. Conf. Intell. Human Comput. Interac-\", \"tion (IHCI), IEEE, 2012, pp. 1–5.\", \"[182] G. Moro, L. Ragazzi, Semantic self-segmentation for abstractive sum-\", \"marization of long documents in low-resource regimes, in: AAAI Conf.\", \"Artif. Intell., 2022.\", \"[183] J. Wang, J. Tan, H. Jin, S. Qi, Unsupervised graph-clustering learn-\", \"ing framework for financial news summarization, 2021 Int. Conf. Data\", \"[184] R. Sennrich, B. Haddow, A. Birch, Neural machine translation of rare\", \"words with subword units, in: K. Erk, N. A. Smith (Eds.), Proc. 54th\", \"Annu. Meeting Assoc. Comput. Linguistics (V olume 1: Long Papers),\", \"Assoc. Comput. Linguistics, Berlin, Germany, 2016, pp. 1715–1725.\", \"[185] Y . Wu, M. Schuster, Z. Chen, Q. V . Le, M. Norouzi, W. Macherey,\", \"M. Krikun, Y . Cao, Q. Gao, K. Macherey, J. Klingner, A. Shah, M. John-\", \"son, X. Liu, L. Kaiser, S. Gouws, Y . Kato, T. Kudo, H. Kazawa,\", \"K. Stevens, G. Kurian, N. Patil, W. Wang, C. Young, J. R. Smith,\", \"J. Riesa, A. Rudnick, O. Vinyals, G. S. Corrado, M. Hughes, J. Dean,\", \"human and machine translation, ArXiv abs /1609.08144 (2016).\", \"[186] H. He, J. D. Choi, The stem cell hypothesis: Dilemma behind multi-task\", \"learning with transformer encoders, in: EMNLP, Assoc. Comput. Lin-\", \"guistics, Online and Punta Cana, Dominican Republic, 2021, pp. 5555–\", \"5577.[187] R. Mihalcea, P. Tarau, TextRank: Bringing order into text, in: D. Lin,\", \"D. Wu (Eds.), EMNLP, Assoc. Comput. Linguistics, Barcelona, Spain,\", \"2004, pp. 404–411.\", \"[188] G. Erkan, D. R. Radev, Lexrank: graph-based lexical centrality as\", \"salience in text summarization, J. Artif. Int. Res. 22 (2004) 457–479.\", \"[189] D. Gillick, B. Favre, A scalable global model for summarization, in:\", \"J. Clarke, S. Riedel (Eds.), Proc. Workshop on Integer Linear Program-\", \"ming for Natural Lang. Process., Assoc. Comput. Linguistics, Boulder,\", \"Colorado, 2009, pp. 10–18.\", \"[190] K. Gunaratna, K. Thirunarayan, A. Sheth, Faces: Diversity-aware en-\", \"tity summarization using incremental hierarchical conceptual clustering,\", \"9180 .\", \"[191] Y . Zhang, Y . Xia, Y . Liu, W. Wang, Clustering sentences with den-\", \"sity peaks for multi-document summarization, in: R. Mihalcea, J. Chai,\", \"A. Sarkar (Eds.), Proc. 2015 Conf. North American Chapter Assoc.\", \"Comput. Linguistics: Human Lang. Technol., Assoc. Comput. Lin-\", \"guistics, Denver, Colorado, 2015, pp. 1262–1267. doi: 10.3115/v1/\", \"[192] M. M. Haider, M. A. Hossin, H. R. Mahi, H. Arif, Automatic text sum-\", \"marization using gensim word2vec and k-means clustering algorithm,\", \"in: 2020 IEEE Region 10 Symposium (TENSYMP), IEEE, 2020, pp.\", \"283–286.\", \"[193] J.-Y . Yeh, H.-R. Ke, W.-P. Yang, I.-H. Meng, Text summarization using\", \"a trainable summarizer and latent semantic analysis, Inf. Process. &\", \"2004.04.003 , an Asian Digital Libraries Perspective.\", \"[194] A. Haghighi, L. Vanderwende, Exploring content models for multi-\", \"document summarization, in: Proc. of human Lang. Technol.: The\", \"2009 Annu. Conf. North American Chapter Assoc. Comput. Linguistics,\", \"2009, pp. 362–370.\", \"[195] Y . Chali, S. A. Hasan, S. R. Joty, A svm-based ensemble approach\", \"to multi-document summarization, in: Y . Gao, N. Japkowicz (Eds.),\", \"Advances in Artificial Intelligence, Springer Berlin Heidelberg, Berlin,\", \"Heidelberg, 2009, pp. 199–202.\", \"[196] Y . Ouyang, W. Li, S. Li, Q. Lu, Applying regression mod-\", \"els to query-focused multi-document summarization, Infor-\", \"2010.03.005 .\", \"[197] S. Abdel-Salam, A. Rafea, Performance study on extractive text sum-\", \"marization using bert models, Inf. 13 (2022) 67.\", \"[198] Q. Xie, J. A. Bishop, P. Tiwari, S. Ananiadou, Pre-trained language\", \"tion, Knowl.-Based Systems 252 (2022) 109460.\", \"[199] C. Lin, Z. Ouyang, J. Zhuang, J. Chen, H. Li, R. Wu, Improving code\", \"summarization with block-wise abstract syntax tree splitting, in: 2021\", \"(ICPC), 2021, pp. 184–195. doi: 10.1109/ICPC52881.2021.00026 .\", \"[200] Z. Tang, X. Shen, C. Li, J. Ge, L. Huang, Z. Zhu, B. Luo, Ast-trans: code\", \"summarization with e fficient tree-structured attention, in: Proceedings\", \"of the 44th International Conference on Software Engineering, ICSE\", \"’22, Association for Computing Machinery, New York, NY , USA, 2022,\", \"[201] K. Ganesan, C. Zhai, J. Han, Opinosis: a graph-based approach to\", \"abstractive summarization of highly redundant opinions, in: Proceed-\", \"ings of the 23rd International Conference on Computational Linguistics,\", \"2010, p. 340–348.\", \"[202] F. Liu, J. Flanigan, S. Thomson, N. Sadeh, N. A. Smith, Toward ab-\", \"stractive summarization using semantic representations, 2018. URL:\", \"[203] Y . Deng, W. Zhang, W. Xu, Y . Shen, W. Lam, Nonfactoid question an-\", \"inference, IEEE Transactions on Neural Networks and Learning Sys-\", \"[204] P.-E. Genest, G. Lapalme, Fully abstractive approach to guided sum-\", \"marization, in: H. Li, C.-Y . Lin, M. Osborne, G. G. Lee, J. C. Park\", \"(Eds.), Proceedings of the 50th Annual Meeting of the Association for\", \"Computational Linguistics (V olume 2: Short Papers), Association for\", \"26\", \"Computational Linguistics, Jeju Island, Korea, 2012, pp. 354–358. URL:\", \"[205] R. Nallapati, F. Zhai, B. Zhou, Summarunner: a recurrent neural net-\", \"work based sequence model for extractive summarization of documents,\", \"in: Proc. Thirty-1st AAAI Conf. Artif. Intell., AAAI’17, AAAI Press,\", \"2017, p. 3075–3081.\", \"[206] Q. Grail, J. Perez, E. Gaussier, Globalizing bert-based transformer ar-\", \"chitectures for long document summarization, in: Proc. 16th Conf. Eu-\", \"ropean chapter Assoc. Comput. Linguistics: Main volume, 2021, pp.\", \"1792–1810.\", \"[207] Z. Wang, Z. Duan, H. Zhang, C. Wang, L. Tian, B. Chen, M. Zhou,\", \"Friendly topic assistant for transformer based abstractive summarization,\", \"in: EMNLP, 2020, pp. 485–497.\", \"[208] J. Zhang, Y . Zhao, M. Saleh, P. J. Liu, Pegasus: pre-training with ex-\", \"tracted gap-sentences for abstractive summarization, in: Proc. 37th Int.\", \"Conf. Machine Learning, ICML’20, JMLR.org, 2020.\", \"[209] T. R. Goodwin, M. E. Savery, D. Demner-Fushman, Flight of the pega-\", \"abstractive summarization, Proc. of COLING. Int. Conf. Comput. Lin-\", \"[210] A. Pagnoni, A. R. Fabbri, W. Kry ´sci´nski, C.-S. Wu, Socratic pretrain-\", \"ing: Question-driven pretraining for controllable summarization, arXiv\", \"[211] E. Lloret, M. T. Rom ´a-Ferri, M. Palomar, Compendium: A text\", \"pers, Data & Knowledge Engineering 88 (2013) 164–175. URL:\", \"2013.08.005 .\", \"[212] A. P. Patil, S. Dalmia, S. Abu Ayub Ansari, T. Aul, V . Bhatnagar, Auto-\", \"matic text summarizer, in: 2014 International Conference on Advances\", \"in Computing, Communications and Informatics (ICACCI), 2014, pp.\", \"1530–1534. doi: 10.1109/ICACCI.2014.6968629 .\", \"[213] I. K. Bhat, M. Mohd, R. Hashmy, Sumitup: A hybrid single-document\", \"text summarizer, in: M. Pant, K. Ray, T. K. Sharma, S. Rawat, A. Bandy-\", \"opadhyay (Eds.), Soft Computing: Theories and Applications, Springer\", \"Singapore, Singapore, 2018, pp. 619–634.\", \"[214] S. Wang, X. Zhao, B. Li, B. Ge, D. Tang, Integrating extractive and\", \"abstractive models for long text summarization, in: 2017 IEEE Inter-\", \"national Congress on Big Data (BigData Congress), 2017, pp. 305–312.\", \"[215] T. K. Landauer, S. T. Dumais, Latent semantic analysis, Scholarpedia 3\", \"(2008) 4356.\", \"[216] D. M. Blei, A. Y . Ng, M. I. Jordan, Latent dirichlet allocation, J. of\", \"[217] L. Chen, Z. Li, W. He, G. Cheng, T. Xu, N. J. Yuan, E. Chen, Entity\", \"summarization via exploiting description complementarity and salience,\", \"8297–8309. doi: 10.1109/TNNLS.2022.3149047 .\", \"[218] Y . Zhang, J. Liao, J. Tang, W. D. Xiao, Y . Wang, Extractive document\", \"summarization based on hierarchical gru, 2018 Int. Conf. Robots &\", \"[219] B. Pang, E. Nijkamp, W. Kryscinski, S. Savarese, Y . Zhou, C. Xiong,\", \"Long document summarization with top-down and bottom-up inference,\", \"in: A. Vlachos, I. Augenstein (Eds.), Findings Assoc. Comput. Lin-\", \"guistics: EACL 2023, Assoc. Comput. Linguistics, Dubrovnik, Croatia,\", \"2023, pp. 1267–1284. doi: 10.18653/v1/2023.findings-eacl.94 .\", \"[220] U. Khandelwal, K. Clark, D. Jurafsky, L. Kaiser, Sample e fficient text\", \"summarization using a single pre-trained transformer, arXiv preprint\", \"[221] M. Lewis, Y . Liu, N. Goyal, M. Ghazvininejad, A. Mohamed, O. Levy,\", \"V . Stoyanov, L. Zettlemoyer, BART: Denoising sequence-to-sequence\", \"pre-training for natural language generation, translation, and compre-\", \"hension, in: D. Jurafsky, J. Chai, N. Schluter, J. Tetreault (Eds.),\", \"Proc. 58th Annu. Meeting Assoc. Comput. Linguistics, Assoc. Comput.\", \"Linguistics, Online, 2020, pp. 7871–7880. doi: 10.18653/v1/2020.\", \"[222] C. Ma, Z. Wu, J. Wang, S. Xu, Y . Wei, Z. Liu, F. Zeng, X. Jiang, L. Guo,\", \"X. Cai, S. Zhang, T. Zhang, D. Zhu, D. Shen, T. Liu, X. Li, An it-\", \"chatgpt, IEEE Transactions on Artificial Intelligence 5 (2024) 4163–4175. doi: 10.1109/TAI.2024.3364586 .\", \"[223] D. Edge, H. Trinh, N. Cheng, J. Bradley, A. Chao, A. Mody, S. Truitt,\", \"J. Larson, From local to global: A graph rag approach to query-focused\", \"summarization, 2024. URL: https://arxiv.org/abs/2404.16130 .\", \"[224] T. Ahmed, K. S. Pai, P. Devanbu, E. Barr, Automatic semantic augmen-\", \"tation of language model prompts (for code summarization), in: Pro-\", \"Engineering, ICSE ’24, Association for Computing Machinery, New\", \"York, NY , USA, 2024. URL: https://doi.org/10.1145/3597503.\", \"3639183 . doi: 10.1145/3597503.3639183 .\", \"[225] C.-Y . Su, C. McMillan, Distilled gpt for source code sum-\", \"marization, ???? URL: http://arxiv.org/abs/2308.14731 .\", \"[226] A. Ghosh, A. Acharya, R. Jain, S. Saha, A. Chadha, S. Sinha, Clip-\", \"tion in healthcare, ???? URL: http://arxiv.org/abs/2312.11541 .\", \"[227] J. Xiao, Y . Chen, Y . Ou, H. Yu, K. Shu, Y . Xiao, Baichuan2-sum:\", \"Instruction finetune baichuan2-7b model for dialogue summarization,\", \"in: 2024 International Joint Conference on Neural Networks (IJCNN),\", \"2024, pp. 1–8. doi: 10.1109/IJCNN60899.2024.10650513 .\", \"[228] P. Jiang, C. Xiao, Z. Wang, P. Bhatia, J. Sun, J. Han, TriSum: Learn-\", \"rationale, in: K. Duh, H. Gomez, S. Bethard (Eds.), Proceedings\", \"gies (V olume 1: Long Papers), Association for Computational Lin-\", \"guistics, Mexico City, Mexico, 2024, pp. 2805–2819. URL: https:\", \"2024.naacl-long.154 .\", \"[229] T. Siledar, R. Rangaraju, S. Muddu, S. Banerjee, A. Patil, S. Singh,\", \"M. Chelliah, N. Garera, S. Nath, P. Bhattacharyya, Product de-\", \"scription and QA assisted self-supervised opinion summarization, in:\", \"K. Duh, H. Gomez, S. Bethard (Eds.), Findings of the Association\", \"for Computational Linguistics: NAACL 2024, Association for Com-\", \"putational Linguistics, Mexico City, Mexico, 2024, pp. 2315–2332.\", \"[230] X. Wang, Y . Li, S. Feng, P. Yuan, B. Pan, H. Wang, Y . Hu, K. Li, Inte-\", \"for free-form language generation, in: L.-W. Ku, A. Martins, V . Sriku-\", \"mar (Eds.), Proceedings of the 62nd Annual Meeting of the Association\", \"for Computational Linguistics (V olume 1: Long Papers), Association\", \"for Computational Linguistics, Bangkok, Thailand, 2024, pp. 11782–\", \"11794. URL: https://aclanthology.org/2024.acl-long.634 .\", \"[231] J. Kumar, S. Chimalakonda, Code summarization without direct ac-\", \"neering, in: Proceedings of the 28th International Conference on\", \"Evaluation and Assessment in Software Engineering, EASE ’24, As-\", \"sociation for Computing Machinery, New York, NY , USA, 2024,\", \"[232] M. H. Sarkhoosh, S. Gautam, C. Midoglu, S. S. Sabet, P. Halvorsen,\", \"cial media, in: Proceedings of the 15th ACM Multimedia Systems\", \"Conference, MMSys ’24, Association for Computing Machinery, New\", \"York, NY , USA, 2024, p. 485–491. URL: https://doi.org/10.\", \"1145/3625468.3652197 . doi: 10.1145/3625468.3652197 .\", \"[233] T. Li, Z. Li, Y . Zhang, Improving faithfulness of large language models\", \"in summarization via sliding generation and self-consistency, in: N. Cal-\", \"zolari, M.-Y . Kan, V . Hoste, A. Lenci, S. Sakti, N. Xue (Eds.), Proceed-\", \"guistics, Language Resources and Evaluation (LREC-COLING 2024),\", \"ELRA and ICCL, Torino, Italia, 2024, pp. 8804–8817. URL: https:\", \"[234] S. Bhushan, E.-S. Jung, M. Lee, Unveiling the power of integration:\", \"Block diagram summarization through local-global fusion, in: L.-W.\", \"Ku, A. Martins, V . Srikumar (Eds.), Findings of the Association for\", \"Computational Linguistics ACL 2024, Association for Computational\", \"27\", \"Linguistics, Bangkok, Thailand and virtual meeting, 2024, pp. 13837–\", \"13856. URL: https://aclanthology.org/2024.findings-acl.\", \"822. doi: 10.18653/v1/2024.findings-acl.822 .\", \"[235] L. Zhang, B. Zou, J. Yi, A. Aw, Comprehensive abstractive com-\", \"ment summarization with dynamic clustering and chain of thought,\", \"in: L.-W. Ku, A. Martins, V . Srikumar (Eds.), Findings of the As-\", \"sociation for Computational Linguistics ACL 2024, Association for\", \"Computational Linguistics, Bangkok, Thailand and virtual meeting,\", \"2024, pp. 2884–2896. URL: https://aclanthology.org/2024.\", \"[236] J. Jung, P. West, L. Jiang, F. Brahman, X. Lu, J. Fisher, T. Sorensen,\", \"Y . Choi, Impossible distillation for paraphrasing and summarization:\", \"How to make high-quality lemonade out of small, low-quality model,\", \"in: K. Duh, H. Gomez, S. Bethard (Eds.), Proceedings of the 2024 Con-\", \"pers), Association for Computational Linguistics, Mexico City, Mexico,\", \"2024, pp. 4439–4454. URL: https://aclanthology.org/2024.\", \"[237] O. C. Thawakar, A. M. Shaker, S. S. Mullappilly, H. Cholakkal, R. M.\", \"Anwer, S. Khan, J. Laaksonen, F. Khan, XrayGPT: Chest radio-\", \"graphs summarization using large medical vision-language models, in:\", \"D. Demner-Fushman, S. Ananiadou, M. Miwa, K. Roberts, J. Tsujii\", \"(Eds.), Proceedings of the 23rd Workshop on Biomedical Natural Lan-\", \"guage Processing, Association for Computational Linguistics, Bangkok,\", \"Thailand, 2024, pp. 440–448. URL: https://aclanthology.org/\", \"2024.bionlp-1.35 . doi: 10.18653/v1/2024.bionlp-1.35 .\", \"[238] J. Liu, L. Li, T. Xiang, B. Wang, Y . Qian, Tcra-llm: Token\", \"cost reduction, ???? URL: http://arxiv.org/abs/2310.15556 .\", \"[239] F. Xu, W. Shi, E. Choi, RECOMP: Improving retrieval-augmented\", \"LMs with context compression and selective augmentation, in: The\", \"Twelfth International Conference on Learning Representations, 2024.\", \"[240] Y . Wang, Z. Zhang, R. Wang, Element-aware summarization with\", \"method, in: A. Rogers, J. Boyd-Graber, N. Okazaki (Eds.), Pro-\", \"putational Linguistics (V olume 1: Long Papers), Association for\", \"Computational Linguistics, Toronto, Canada, 2023, pp. 8640–8665.\", \"18653/v1/2023.acl-long.482 .\", \"[241] E. Jones, H. Palangi, C. Sim ˜oes, V . Chandrasekaran, S. Mukherjee,\", \"A. Mitra, A. Awadallah, E. Kamar, Teaching language models to hallu-\", \"cinate less with synthetic tasks, ???? URL: http://arxiv.org/abs/\", \"2310.06827 .arXiv:2310.06827 .\", \"[242] H. Xu, K. D. Ashley, Argumentative segmentation enhancement for\", \"legal summarization, in: ASAIL@ICAIL, 2023. URL: https://api.\", \"[243] M.-Q. Pham, S. Indurthi, S. Chollampatt, M. Turchi, Select, prompt,\", \"tions, in: H. Bouamor, J. Pino, K. Bali (Eds.), Proceedings of\", \"Processing, Association for Computational Linguistics, Singapore,\", \"2023, pp. 12257–12265. URL: https://aclanthology.org/2023.\", \"[244] M. Sclar, P. West, S. Kumar, Y . Tsvetkov, Y . Choi, Referee:\", \"through symbolic knowledge distillation, in: Y . Goldberg, Z. Kozareva,\", \"Y . Zhang (Eds.), Proceedings of the 2022 Conference on Empirical\", \"Methods in Natural Language Processing, Association for Computa-\", \"tional Linguistics, Abu Dhabi, United Arab Emirates, 2022, pp. 9649–\", \"9668. URL: https://aclanthology.org/2022.emnlp-main.655 .\", \"[245] A. Asi, S. Wang, R. Eisenstadt, D. Geckt, Y . Kuper, Y . Mao, R. Ro-\", \"nen, An end-to-end dialogue summarization system for sales calls,\", \"in: A. Loukina, R. Gangadharaiah, B. Min (Eds.), Proceedings of\", \"gies: Industry Track, Association for Computational Linguistics, Hy-brid: Seattle, Washington +Online, 2022, pp. 45–53. URL: https://\", \"2022.naacl-industry.6 .\", \"[246] R. Xu, C. Zhu, M. Zeng, Narrate dialogues for better summariza-\", \"tion, in: Y . Goldberg, Z. Kozareva, Y . Zhang (Eds.), Findings of the\", \"Association for Computational Linguistics: EMNLP 2022, Associa-\", \"tion for Computational Linguistics, Abu Dhabi, United Arab Emirates,\", \"2022, pp. 3565–3575. URL: https://aclanthology.org/2022.\", \"261.\", \"[247] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y . Hou, Y . Min, B. Zhang,\", \"J. Zhang, Z. Dong, Y . Du, C. Yang, Y . Chen, Z. Chen, J. Jiang, R. Ren,\", \"Y . Li, X. Tang, Z. Liu, P. Liu, J. Nie, J. rong Wen, A survey of large\", \"language models, ArXiv abs /2303.18223 (2023).\", \"[248] R. Shin, C. Lin, S. Thomson, C. Chen, S. Roy, E. A. Platanios, A. Pauls,\", \"D. Klein, J. Eisner, B. Van Durme, Constrained language models yield\", \"few-shot semantic parsers, in: EMNLP, Assoc. Comput. Linguistics,\", \"2021. doi: 10.18653/v1/2021.emnlp-main.608 .\", \"[249] Y . Zhou, K. Shi, W. Zhang, Y . Liu, Y . Zhao, A. Cohan, Odsum: New\", \"benchmarks for open domain multi-document summarization, 2023.\", \"[250] G. Adams, A. Fabbri, F. Ladhak, E. Lehman, N. Elhadad, From sparse\", \"to dense: GPT-4 summarization with chain of density prompting, in:\", \"Y . Dong, W. Xiao, L. Wang, F. Liu, G. Carenini (Eds.), Proc. 4th\", \"New Frontiers in Summarization Workshop, Assoc. Comput. Linguis-\", \"tics, Singap., 2023, pp. 68–74. doi: 10.18653/v1/2023.newsum-1.7 .\", \"[251] W. Xiao, Y . Xie, G. Carenini, P. He, Chatgpt-steered editing\", \"instructor for customization of abstractive summarization, 2023.\", \"[252] M. De Raedt, F. Godin, T. Demeester, C. Develder, IDAS: In-\", \"tent discovery with abstractive summarization, in: Y .-N. Chen,\", \"A. Rastogi (Eds.), Proceedings of the 5th Workshop on NLP for\", \"Conversational AI (NLP4ConvAI 2023), Association for Computa-\", \"tional Linguistics, Toronto, Canada, 2023, pp. 71–88. URL: https:\", \"2023.nlp4convai-1.7 .\", \"[253] Y . Li, L. Chen, A. Liu, K. Yu, L. Wen, Chatcite: Llm agent with hu-\", \"man workflow guidance for comparative literature summary, ArXiv\", \"[254] M. R. Parvez, W. Ahmad, S. Chakraborty, B. Ray, K.-W. Chang,\", \"Retrieval augmented code generation and summarization, in: M.-\", \"F. Moens, X. Huang, L. Specia, S. W.-t. Yih (Eds.), Findings of the\", \"Association for Computational Linguistics: EMNLP 2021, Associa-\", \"tion for Computational Linguistics, Punta Cana, Dominican Repub-\", \"lic, 2021, pp. 2719–2734. URL: https://aclanthology.org/2021.\", \"232.\", \"[255] S. S. Manathunga, Y . A. Illangasekara, Retrieval augmented generation\", \"data in medical education, ArXiv abs /2308.00479 (2023). URL: https:\", \"[256] S. Liu, J. Wu, J. Bao, W. Wang, N. Hovakimyan, C. G. Healey,\", \"Towards a robust retrieval-based summarization system, ArXiv\", \"[257] D. V . Veen, C. V . Uden, M. Attias, A. Pareek, C. Bl ¨uthgen, M. Po-\", \"lacin, W. Chiu, J.-B. Delbrouck, J. M. Z. Chaves, C. P. Langlotz, A. S.\", \"Chaudhari, J. M. Pauly, Radadapt: Radiology report summarization\", \"via lightweight domain adaptation of large language models, ArXiv\", \"[258] A. Brazinskas, R. Nallapati, M. Bansal, M. Dreyer, E fficient few-shot\", \"fine-tuning for opinion summarization, in: M. Carpuat, M.-C. de Marn-\", \"effe, I. V . Meza Ruiz (Eds.), Findings Assoc. Comput. Linguistics:\", \"NAACL 2022, Assoc. Comput. Linguistics, Seattle, United States, 2022,\", \"[259] S. Xu, X. Zhang, Y . Wu, F. Wei, Sequence level contrastive learning\", \"for text summarization, in: Proceedings of the AAAI conference on\", \"artificial intelligence, volume 36, 2022, pp. 11556–11565.\", \"[260] J. Gu, P. Salza, H. C. Gall, Assemble foundation models for automatic\", \"code summarization, ???? URL: http://arxiv.org/abs/2201.\", \"28\", \"05222 .arXiv:2201.05222 .\", \"[261] J. Ma, Y . Huang, L. Wang, X. Huang, H. Peng, Z. Yu, P. Yu, Aug-\", \"grounded training and prompting, ACM Trans. Asian Low-Resour.\", \"3675167 . doi: 10.1145/3675167 .\", \"[262] J. Jung, P. West, L. Jiang, F. Brahman, X. Lu, J. Fisher, T. Sorensen,\", \"Y . Choi, Impossible distillation: from low-quality model to high-quality\", \"dataset & model for summarization and paraphrasing, 2024. URL:\", \"[263] N. Houlsby, A. Giurgiu, S. Jastrzebski, B. Morrone, Q. De Laroussilhe,\", \"A. Gesmundo, M. Attariyan, S. Gelly, Parameter-e fficient transfer learn-\", \"ing for nlp, in: Int. Conf. Machine Learning, PMLR, 2019, pp. 2790–\", \"2799.\", \"[264] L. Tang, Z. Sun, B. Idnay, J. G. Nestor, A. Soroush, P. A. Elias, Z. Xu,\", \"Y . Ding, G. Durrett, J. F. Rousseau, C. Weng, Y . Peng, Evaluating\", \"large language models on medical evidence summarization, npj Digi-\", \"[265] M. T. R. Laskar, M. S. Bari, M. Rahman, M. A. H. Bhuiyan, S. Joty, J. X.\", \"Huang, A systematic study and comprehensive evaluation of chatgpt on\", \"benchmark datasets, arXiv preprint arXiv:2305.18486 (2023).\", \"[266] M. Ravaut, S. Joty, A. Sun, N. F. Chen, On context utilization in sum-\", \"marization with large language models, 2023. arXiv:2310.10570 .\", \"[267] L. Basyal, M. Sanghvi, Text summarization using large language mod-\", \"els: A comparative study of mpt-7b-instruct, falcon-7b-instruct, and\", \"openai chat-gpt models, 2023. arXiv:2310.10449 .\", \"[268] T. Goyal, J. J. Li, G. Durrett, News summarization and evaluation in the\", \"era of gpt-3, 2023. arXiv:2209.12356 .\", \"[269] N. Stiennon, L. Ouyang, J. Wu, D. Ziegler, R. Lowe, C. V oss, A. Rad-\", \"ford, D. Amodei, P. F. Christiano, Learning to summarize with human\", \"feedback, Advances in Neural Inf. Process. Systems 33 (2020) 3008–\", \"3021.\", \"[270] J. Wu, L. Ouyang, D. M. Ziegler, N. Stiennon, R. Lowe, J. Leike,\", \"P. Christiano, Recursively summarizing books with human feedback,\", \"2021. arXiv:2109.10862 .\", \"[271] Z. Jiang, F. F. Xu, J. Araki, G. Neubig, How can we know what language\", \"models know?, Trans. Assoc. Comput. Linguistics 8 (2020) 423–438.\", \"[272] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. Chi, Q. V . Le,\", \"D. Zhou, et al., Chain-of-thought prompting elicits reasoning in large\", \"language models, Advances in Neural Inf. Process. Systems 35 (2022)\", \"24824–24837.\", \"[273] Z. Xi, W. Chen, X. Guo, W. He, Y . Ding, B. Hong, M. Zhang, J. Wang,\", \"S. Jin, E. Zhou, R. Zheng, X. Fan, X. Wang, L. Xiong, Y . Zhou,\", \"W. Wang, C. Jiang, Y . Zou, X. Liu, Z. Yin, S. Dou, R. Weng, W. Cheng,\", \"Q. Zhang, W. Qin, Y . Zheng, X. Qiu, X. Huang, T. Gui, The rise\", \"and potential of large language model based agents: A survey, 2023.\", \"[274] H. Li, Y . Su, D. Cai, Y . Wang, L. Liu, A survey on retrieval-augmented\", \"text generation, arXiv preprint arXiv:2202.01110 (2022).\", \"[275] J. Gou, B. Yu, S. J. Maybank, D. Tao, Knowledge distillation: A survey,\", \"[276] G. Hinton, O. Vinyals, J. Dean, Distilling the knowledge in a neural\", \"network, stat 1050 (2015) 9.\", \"[277] Y . Xu, R. Xu, D. Iter, Y . Liu, S. Wang, C. Zhu, M. Zeng, Inheritsumm: A\", \"general, versatile and compact summarizer by distilling from gpt, 2023.\", \"[278] M. Sclar, P. West, S. Kumar, Y . Tsvetkov, Y . Choi, Referee:\", \"through symbolic knowledge distillation, in: Y . Goldberg, Z. Kozareva,\", \"Y . Zhang (Eds.), EMNLP, Assoc. Comput. Linguistics, Abu Dhabi,\", \"United Arab Emirates, 2022, pp. 9649–9668. doi: 10.18653/v1/2022.\", \"[279] C.-Y . Lin, Rouge: A package for automatic evaluation of summaries,\", \"in: Text summarization branches out, 2004, pp. 74–81.\", \"[280] K. Papineni, S. Roukos, T. Ward, W.-J. Zhu, Bleu: a method for auto-\", \"matic evaluation of machine translation, in: Proc. 40th Annu. Meeting\", \"on Assoc. Comput. Linguistics - ACL ’02, Assoc. Comput. Linguistics,\", \"2001, p. 311. doi: 10.3115/1073083.1073135 .\", \"[281] S. Banerjee, A. Lavie, METEOR: An automatic metric for MT evalua-\", \"tion with improved correlation with human judgments, in: J. Goldstein,\", \"A. Lavie, C.-Y . Lin, C. V oss (Eds.), Proceedings of the ACL Workshopon Intrinsic and Extrinsic Evaluation Measures for Machine Translation\", \"and/or Summarization, Association for Computational Linguistics, Ann\", \"Arbor, Michigan, 2005, pp. 65–72. URL: https://aclanthology.\", \"[282] F. Jelinek, R. L. Mercer, L. R. Bahl, J. K. Baker, Perplexity—a\", \"measure of the di fficulty of speech recognition tasks, The Journal of\", \"[283] T. Zhang*, V . Kishore*, F. Wu*, K. Q. Weinberger, Y . Artzi, Bertscore:\", \"Evaluating text generation with bert, in: Int. Conf. Learning Represen-\", \"[284] W. Yuan, G. Neubig, P. Liu, Bartscore: Evaluating generated text as\", \"text generation, in: M. Ranzato, A. Beygelzimer, Y . Dauphin, P. Liang,\", \"J. W. Vaughan (Eds.), Advances in Neural Information Processing Sys-\", \"tems, volume 34, Curran Associates, Inc., 2021, pp. 27263–27277.\", \"2021/file/e4d2b6e6fdeca3e60e0f1a62fee3d9dd-Paper.pdf .\", \"[285] T. Sellam, D. Das, A. Parikh, BLEURT: Learning robust metrics for\", \"text generation, in: D. Jurafsky, J. Chai, N. Schluter, J. Tetreault\", \"(Eds.), Proceedings of the 58th Annual Meeting of the Association for\", \"Computational Linguistics, Association for Computational Linguistics,\", \"Online, 2020, pp. 7881–7892. URL: https://aclanthology.org/\", \"2020.acl-main.704 . doi: 10.18653/v1/2020.acl-main.704 .\", \"[286] T. Niu, S. Yavuz, Y . Zhou, N. S. Keskar, H. Wang, C. Xiong, Un-\", \"supervised paraphrasing with pretrained language models, in: M.-\", \"F. Moens, X. Huang, L. Specia, S. W.-t. Yih (Eds.), Proceedings\", \"Processing, Association for Computational Linguistics, Online and\", \"Punta Cana, Dominican Republic, 2021, pp. 5136–5150. URL: https:\", \"2021.emnlp-main.417 .\", \"[287] P. Laban, T. Schnabel, P. N. Bennett, M. A. Hearst, SummaC: Re-\", \"tion, Transactions of the Association for Computational Linguis-\", \"[288] L. Ermakova, J. V . Cossu, J. Mothe, A survey on evaluation of sum-\", \"marization methods, Inf. Process. & Manage. 56 (2019) 1794–1814.\", \"[289] S. Gehrmann, Y . Deng, A. Rush, Bottom-up abstractive summariza-\", \"tion, in: E. Rilo ff, D. Chiang, J. Hockenmaier, J. Tsujii (Eds.), EMNLP,\", \"Assoc. Comput. Linguistics, Brussels, Belgium, 2018, pp. 4098–4109.\", \"[290] M. Peyrard, A simple theoretical model of importance for summa-\", \"rization, in: A. Korhonen, D. Traum, L. M `arquez (Eds.), Proceed-\", \"ings 57th Annu. Meeting Assoc. Comput. Linguistics, Assoc. Comput.\", \"Linguistics, Florence, Italy, 2019, pp. 1059–1073. doi: 10.18653/v1/\", \"[291] C.-Y . Lin, F. Och, Looking for a few good metrics: Rouge and its eval-\", \"uation, in: Ntcir workshop, 2004.\", \"[292] M. Gao, J. Ruan, R. Sun, X. Yin, S. Yang, X. Wan, Human-like summa-\", \"rization evaluation with chatgpt, 2023. arXiv:2304.02554 .\", \"[293] S. Jain, V . Keshava, S. M. Sathyendra, P. Fernandes, P. Liu, G. Neubig,\", \"C. Zhou, Multi-dimensional evaluation of text summarization with in-\", \"context learning, 2023. arXiv:2306.01200 .\", \"[294] N. Wu, M. Gong, L. Shou, S. Liang, D. Jiang, Large language\", \"models are diverse role-players for summarization evaluation, 2023.\", \"[295] Y . Chang, K. Lo, T. Goyal, M. Iyyer, Booookscore: A systematic\", \"exploration of book-length summarization in the era of llms, 2023.\", \"[296] Z. Luo, Q. Xie, S. Ananiadou, Chatgpt as a factual inconsistency evalu-\", \"ator for text summarization, 2023. arXiv:2303.15621 .\", \"[297] D. Tam, A. Mascarenhas, S. Zhang, S. Kwan, M. Bansal, C. Ra ffel, Eval-\", \"summarization, in: Findings Assoc. Comput. Linguistics: ACL 2023,\", \"2023, pp. 5220–5255.\", \"[298] Z. Gekhman, J. Herzig, R. Aharoni, C. Elkind, I. Szpektor, Trueteacher:\", \"Learning factual consistency evaluation with large language models,\", \"29\", \"[299] Q. Jia, S. Ren, Y . Liu, K. Q. Zhu, Zero-shot faithfulness evaluation for\", \"text summarization with foundation language model, in: The 2023 Conf.\", \"[300] R. Barzilay, K. R. McKeown, Sentence fusion for multidocument news\", \"summarization, Computational Linguistics 31 (2005) 297–328. doi: 10.\", \"1162/089120105774321091 .\", \"[301] K. R. McKeown, R. Barzilay, D. Evans, V . Hatzivassiloglou, J. L. Kla-\", \"vans, A. Nenkova, C. Sable, B. Schi ffman, S. Sigelman, Tracking and\", \"summarizing news on a daily basis with columbia’s newsblaster, in:\", \"Proc. 2nd Int. Conf. Human Lang. Technol. Res., HLT ’02, Morgan\", \"Kaufmann Publishers Inc., San Francisco, CA, USA, 2002, p. 280–285.\", \"[302] D. Gholipour Ghalandari, G. Ifrim, Examining the state-of-the-art in\", \"news timeline summarization, in: D. Jurafsky, J. Chai, N. Schluter,\", \"J. Tetreault (Eds.), Proc. 58th Annu. Meeting Assoc. Comput. Lin-\", \"guistics, Assoc. Comput. Linguistics, Online, 2020, pp. 1322–1334.\", \"[303] F. Ladhak, B. Li, Y . Al-Onaizan, K. McKeown, Exploring content se-\", \"lection in summarization of novel chapters, in: D. Jurafsky, J. Chai,\", \"N. Schluter, J. Tetreault (Eds.), Proc. 58th Annu. Meeting Assoc. Com-\", \"put. Linguistics, Assoc. Comput. Linguistics, Online, 2020, pp. 5043–\", \"5054. doi: 10.18653/v1/2020.acl-main.453 .\", \"[304] C. An, M. Zhong, Y . Chen, D. Wang, X. Qiu, X. Huang, Enhancing sci-\", \"entific papers summarization with citation graph, Proceedings of the\", \"17482 . doi: 10.1609/aaai.v35i14.17482 .\", \"[305] P. Veli ˇckovi ´c, G. Cucurull, A. Casanova, A. Romero, P. Li `o, Y . Ben-\", \"gio, Graph attention networks, in: Int. Conf. Learning Representations,\", \"2018.\", \"[306] S. Qi, L. Li, Y . Li, J. Jiang, D. Hu, Y . Li, Y . Zhu, Y . Zhou, M. Litvak,\", \"N. Vanetik, Sapgraph: Structure-aware extractive summarization for\", \"scientific papers with heterogeneous graph, in: Proc. 2nd Conf. Asia-\", \"Natural Lang. Process., 2022, pp. 575–586.\", \"[307] C. Shen, F. Liu, F. Weng, T. Li, A participant-based approach for event\", \"summarization using twitter streams, in: Proc. 2013 Conf. North Ameri-\", \"can Chapter Assoc. Comput. Linguistics: Human Lang. Technol., 2013,\", \"[308] D. Inouye, J. K. Kalita, Comparing twitter summarization algorithms for\", \"multiple post summaries, in: 2011 IEEE 3rd Int. Conf. privacy, security,\", \"risk and trust and 2011 IEEE 3rd Int. Conf. social Comput., IEEE, 2011,\", \"[309] L. P. Kumar, A. Kabiri, Meeting summarization: A survey of the state\", \"of the art, 2022. arXiv:2212.08206 .\", \"[310] Y . Mehdad, G. Carenini, R. T. Ng, Abstractive summarization of spoken\", \"and written conversations based on phrasal queries, in: K. Toutanova,\", \"H. Wu (Eds.), Proc. 52nd Annu. Meeting Assoc. Comput. Linguis-\", \"tics (V olume 1: Long Papers), Assoc. Comput. Linguistics, Baltimore,\", \"Maryland, 2014, pp. 1220–1230. doi: 10.3115/v1/P14-1115 .\", \"[311] P. Ganesh, S. Dingliwal, Restructuring conversations using dis-\", \"course relations for zero-shot abstractive dialogue summarization, ????\", \"[312] C. E. Kahn, C. P. Langlotz, E. S. Burnside, J. A. Carrino, D. S. Chan-\", \"nin, D. M. Hovsepian, D. L. Rubin, Toward best practices in radiol-\", \"ogy reporting, Radiology 252 (2009) 852–856. doi: 10.1148/radiol.\", \"2523081992 .\", \"[313] S. Sotudeh Gharebagh, N. Goharian, R. Filice, Attend to medical on-\", \"tologies: Content selection for clinical abstractive summarization, in:\", \"D. Jurafsky, J. Chai, N. Schluter, J. Tetreault (Eds.), Proc. 58th Annu.\", \"Meeting Assoc. Comput. Linguistics, Assoc. Comput. Linguistics, On-\", \"line, 2020, pp. 1899–1905. doi: 10.18653/v1/2020.acl-main.172 .\", \"[314] M. Adler, J. Berant, I. Dagan, Entailment-based text exploration with\", \"application to the health-care domain, in: M. Zhang (Ed.), Proc. ACL\", \"2012 System Demonstrations, Assoc. Comput. Linguistics, Jeju Island,\", \"Korea, 2012, pp. 79–84.\", \"[315] Y . Zhang, D. Merck, E. Tsai, C. D. Manning, C. Langlotz, Optimizing\", \"ogy reports, in: D. Jurafsky, J. Chai, N. Schluter, J. Tetreault (Eds.),\", \"Proc. 58th Annu. Meeting Assoc. Comput. Linguistics, Assoc. Comput.\", \"Linguistics, Online, 2020, pp. 5108–5120. doi: 10.18653/v1/2020.\", \"nance and Economics, China. He received his Ph.D. from the Graduate School\", \"of Informatics, Kyoto University in 2022. Before that, he received his Bach-\", \"University of Finance and Economics, China in 2023 as a lecturer. His research\", \"interests include text mining, text recommendation, and NLP for financial tech-\", \"Engineering at Southwestern University of Finance and Economics, Chengdu,\", \"search interests include text mining, text generation, and financial intelligence.\", \"nomics, Chengdu, China. Previously, she received her Ph.D. from Southwest\", \"Jiaotong University, Chengdu, China. Her research interests include intelligent\", \"finance, intelligent decision making, and uncertainty information processing.\", \"30\", \"nomics, China. Prior to his current appointment, he was a researcher at the\", \"Memorial University of Newfoundland in St. John’s, Canada, and he was\", \"awarded the National Scholarship in 2017. His research interests include NLP,\", \"social media, social network analysis, financial analysis, and business intelli-\", \"(Member, IEEE) Jinghua Tan received the B.S., M.S., and Ph.D. degrees from\", \"the Southwestern University of Finance and Economics, Chengdu, China. She\", \"ing scholar at the Memorial University of Newfoundland in St. John’s, Canada\", \"31\"], \"error\": null}, \"d396b0e6\": {\"success\": true, \"paper_id\": \"d396b0e6\", \"url\": \"https://arxiv.org/pdf/2402.12001.pdf\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_d396b0e6.pdf\", \"extracted_info\": {\"title\": \"Extractive Knowledge Graph Summarization: A Survey\", \"authors\": [\"Not explicitly provided in the excerpt\"], \"abstract\": \"With the continuous growth of large Knowledge Graphs (KGs), extractive KG summarization becomes a critical task. This survey presents a taxonomy for existing methods from its interdisciplinary studies and lays out future directions based on an extensive and comparative review.\", \"methodology\": \"The paper systematically reviews existing applications, approaches, and evaluation methods for extractive KG summarization. It distinguishes extractive summarization from related paradigms such as grouping-based summarization and ontology summarization. The authors categorize methods into pattern coverage-based summarization and query-biased summarization, analyzing techniques such as biased sampling, node/edge ranking, combinatorial optimization, and graph neural network-based approaches. The review also considers evaluation metrics like coverage of data patterns, preservation of query answers, and user studies.\", \"results\": \"The survey identifies two main categories of extractive KG summarization methods: (1) pattern coverage-based summarization, which focuses on maximizing coverage of data patterns or query answers, and (2) query-biased summarization, which tailors summaries to user needs or queries. It highlights the strengths and limitations of various approaches, including their scalability, adaptability to user preferences, and applicability to large-scale KGs. The review also notes the increasing role of deep learning, particularly graph neural networks, in recent methods.\", \"conclusion\": \"The paper’s key contributions include: (1) providing a comprehensive taxonomy of extractive KG summarization methods, (2) distinguishing extractive summarization from related paradigms, (3) systematically comparing methods across applications and evaluation strategies, (4) identifying research gaps such as the lack of labeled data and the need for semi-supervised approaches, and (5) outlining future research directions leveraging deep learning and joint summarization across multiple KGs.\", \"figures\": null, \"tables\": null}, \"citations\": [\"[Baiet al. , 2008 ]Xi Bai, Renaud Delbru, and Giovanni\", \"gines. In Proc. OTM, Part II , pages 1304–1318, 2008.\", \"[Cebiric et al. , 2019 ]Sejla Cebiric, Franc ¸ois Goasdou ´e,\", \"Haridimos Kondylakis, Dimitris Kotzinos, Ioana\", \"Manolescu, Georgia Troullinou, and Mussab Zneika.\", \"Summarizing semantic graphs: a survey. VLDB J. ,\", \"28(3):295–327, 2019.\", \"[Chapman et al. , 2020 ]Adriane Chapman, Elena Simperl,\", \"Laura Koesten, George Konstantinidis, Luis-Daniel\", \"Ib´a˜nez, Emilia Kacprzak, and Paul Groth. Dataset search:\", \"a survey. VLDB J. , 29(1):251–272, 2020.\", \"[Chen et al. , 2019 ]Jinchi Chen, Xiaxia Wang, Gong Cheng,\", \"Evgeny Kharlamov, and Yuzhong Qu. Towards more us-\", \"generation. In Proc. CIKM , pages 2445–2448, 2019.\", \"[Chen et al. , 2023 ]Qiaosheng Chen, Zixian Huang, Zhiyang\", \"Zhang, Weiqing Luo, Tengteng Lin, Qing Shi, and Gong\", \"dataset search. In Proc. ISWC, Part I , pages 23–40, 2023.\", \"[Cheng and Kharlamov, 2017 ]Gong Cheng and Evgeny\", \"IEEE BigData , pages 1698–1700, 2017.\", \"[Cheng et al. , 2017a ]Gong Cheng, Cheng Jin, Wentao Ding,\", \"Danyun Xu, and Yuzhong Qu. Generating illustrative snip-\", \"pets for open data on the Web. In Proc. WSDM , pages\", \"151–159, 2017.\", \"[Cheng et al. , 2017b ]Gong Cheng, Fei Shao, and Yuzhong\", \"semantic associations. IEEE Trans. Knowl. Data Eng. ,\", \"29(11):2388–2401, 2017.\", \"[Cheng et al. , 2020 ]Gong Cheng, Shuxin Li, Ke Zhang, and\", \"ISWC, Part I , pages 110–127, 2020.\", \"[Cheng, 2020 ]Gong Cheng. Relationship search over\", \"knowledge graphs. SIGWEB Newsl. , 2020(Summer):3:1–\", \"3:8, 2020.\", \"[Ellefi et al. , 2018 ]Mohamed Ben Ellefi, Zohra Bellahsene,\", \"John G. Breslin, Elena Demidova, Stefan Dietze, Julian\", \"Szymanski, and Konstantin Todorov. RDF dataset profil-\", \"ing - a survey of features, methods, vocabularies and ap-\", \"plications. Semantic Web , 9(5):677–705, 2018.\", \"[Fanet al. , 2014 ]Wenfei Fan, Xin Wang, and Yinghui Wu.\", \"ICDE , pages 184–195, 2014.\", \"[Guo and Wang, 2021 ]Jimao Guo and Yi Wang. Summariz-\", \"InProc. ICSS , pages 51–58, 2021.[Heling and Acosta, 2020 ]Lars Heling and Maribel Acosta.\", \"based on sampling. In Proc. ESWC , pages 157–175, 2020.\", \"[Heling and Acosta, 2023 ]Lars Heling and Maribel Acosta.\", \"plication to SPARQL query planning. Semantic Web ,\", \"14(3):491–526, 2023.\", \"[Hogan et al. , 2022 ]Aidan Hogan, Eva Blomqvist, Michael\", \"Cochez, Claudia d’Amato, Gerard de Melo, Clau-\", \"dio Gutierrez, Sabrina Kirrane, Jos ´e Emilio Labra\", \"Gayo, Roberto Navigli, Sebastian Neumaier, Axel-\", \"Cyrille Ngonga Ngomo, Axel Polleres, Sabbir M. Rashid,\", \"Anisa Rula, Lukas Schmelzeisen, Juan F. Sequeda, Stef-\", \"fen Staab, and Antoine Zimmermann. Knowledge graphs.\", \"ACM Comput. Surv. , 54(4):71:1–71:37, 2022.\", \"[Huang et al. , 2019 ]Zixian Huang, Shuxin Li, Gong Cheng,\", \"Evgeny Kharlamov, and Yuzhong Qu. MiCRon: making\", \"sense of news via relationship subgraphs. In Proc. CIKM ,\", \"pages 2901–2904, 2019.\", \"[Ihler, 1991 ]Edmund Ihler. The complexity of approximat-\", \"ing the class Steiner tree problem. In Proc. WG , pages\", \"85–96, 1991.\", \"[Jiang et al. , 2012 ]Xiaowei Jiang, Xiang Zhang, Wei Gui,\", \"Feifei Gao, Peng Wang, and Fengbo Zhou. Summarizing\", \"InProc. ADMA , pages 564–576, 2012.\", \"[Kellou-Menouer et al. , 2022 ]Kenza Kellou-Menouer,\", \"Nikolaos Kardoulakis, Georgia Troullinou, Zoubida\", \"Kedad, Dimitris Plexousakis, and Haridimos Kondylakis.\", \"A survey on semantic schema discovery. VLDB J. ,\", \"31(4):675–710, 2022.\", \"[Koesten et al. , 2017 ]Laura M. Koesten, Emilia Kacprzak,\", \"Jenifer Fay Alys Tennison, and Elena Simperl. The trials\", \"on information seeking behaviour. In Proc. CHI , pages\", \"1277–1289, 2017.\", \"[Lalithsena et al. , 2016 ]Sarasi Lalithsena, Pavan Kapani-\", \"pathi, and Amit P. Sheth. Harnessing relationships for\", \"use case. In Proc. IEEE BigData , pages 706–715, 2016.\", \"[Lalithsena et al. , 2017 ]Sarasi Lalithsena, Sujan Perera, Pa-\", \"van Kapanipathi, and Amit P. Sheth. Domain-specific hier-\", \"InProc. IEEE BigData , pages 666–675, 2017.\", \"[Liet al. , 2016 ]Jia Li, Yang Cao, and Xudong Liu. Approx-\", \"imating graph pattern queries using views. In Proc. CIKM ,\", \"[Liet al. , 2020 ]Shuxin Li, Zixian Huang, Gong Cheng,\", \"Evgeny Kharlamov, and Kalpa Gunaratna. Enriching doc-\", \"uments with compact, representative, relevant knowledge\", \"graphs. In Proc. IJCAI , pages 1748–1754, 2020.\", \"[Lissandrini et al. , 2022 ]Matteo Lissandrini, Davide Mot-\", \"tin, Katja Hose, and Torben Bach Pedersen. Knowledge\", \"graph exploration systems: are we lost? In Proc. CIDR ,\", \"2022.\", \"[Liuet al. , 2018 ]Yike Liu, Tara Safavi, Abhilash Dighe, and\", \"cations: A survey. ACM Comput. Surv. , 51(3):62:1–62:34,\", \"2018.\", \"[Liuet al. , 2019 ]Daxin Liu, Gong Cheng, Qingxia Liu, and\", \"RDF datasets. ACM Trans. Web , 13(4):19:1–19:38, 2019.\", \"[Liuet al. , 2021 ]Qingxia Liu, Gong Cheng, Kalpa Gu-\", \"naratna, and Yuzhong Qu. Entity summarization: State of\", \"the art and future challenges. J. Web Semant. , 69:100647,\", \"2021.\", \"[Montoya et al. , 2017 ]Gabriela Montoya, Hala Skaf-Molli,\", \"federated SPARQL queries. In Proc. ISWC, Part I , pages\", \"471–489, 2017.\", \"[Mynarz et al. , 2016 ]Jindrich Mynarz, Marek Dud ´as, Paolo\", \"Tomeo, and V ojtech Sv ´atek. Generating examples of paths\", \"Track of SEMANTiCS and SuCCESS , 2016.\", \"[Panet al. , 2023 ]Jeff Z. Pan, Simon Razniewski, Jan-\", \"Christoph Kalo, Sneha Singhania, Jiaoyan Chen, Stefan\", \"Dietze, Hajira Jabeen, Janna Omeliyanenko, Wen Zhang,\", \"Matteo Lissandrini, Russa Biswas, Gerard de Melo, An-\", \"gela Bonifati, Edlira Vakaj, Mauro Dragoni, and Damien\", \"Opportunities and challenges. TGDK , 1(1):2:1–2:38,\", \"2023.\", \"[Peng et al. , 2023 ]Ciyuan Peng, Feng Xia, Mehdi Naseri-\", \"parsa, and Francesco Osborne. Knowledge graphs: Oppor-\", \"tunities and challenges. Artif. Intell. Rev. , 56(11):13071–\", \"13102, 2023.\", \"[Pouriyeh et al. , 2019 ]Seyedamin Pouriyeh, Mehdi Allah-\", \"yari, Qingxia Liu, Gong Cheng, Hamid Reza Arabnia,\", \"Maurizio Atzori, Farid Ghareh Mohammadi, and Krys J.\", \"and beyond. Int. J. Semantic Comput. , 13(2):259–283,\", \"2019.\", \"[Rietveld et al. , 2014 ]Laurens Rietveld, Rinke Hoekstra,\", \"Stefan Schlobach, and Christophe Gu ´eret. Structural prop-\", \"pling. In Proc. ISWC, Part II , pages 81–96, 2014.\", \"[Safavi et al. , 2019 ]Tara Safavi, Caleb Belth, Lukas Faber,\", \"Davide Mottin, Emmanuel M ¨uller, and Danai Koutra.\", \"cloud to your pocket. In Proc. ICDM , pages 528–537,\", \"2019.\", \"[Scherp et al. , 2023 ]Ansgar Scherp, David Richerby, Till\", \"Blume, Michael Cochez, and Jannik Rau. Structural sum-\", \"marization of semantic graphs using quotients. TGDK ,\", \"1(1):12:1–12:25, 2023.\", \"[Shiet al. , 2020 ]Yuxuan Shi, Gong Cheng, and Evgeny\", \"static and dynamic hub labelings. In Proc. WWW , pages\", \"235–245, 2020.[Shiet al. , 2021a ]Yuxuan Shi, Gong Cheng, Trung-Kien\", \"Tran, Evgeny Kharlamov, and Yulin Shen. Efficient com-\", \"based knowledge graph exploration. In Proc. WWW , pages\", \"1410–1421, 2021.\", \"[Shiet al. , 2021b ]Yuxuan Shi, Gong Cheng, Trung-Kien\", \"Tran, Jie Tang, and Evgeny Kharlamov. Keyword-based\", \"Steiner trees. In Proc. IJCAI , pages 1555–1562, 2021.\", \"[Sundara et al. , 2010 ]Seema Sundara, Medha Atre,\", \"Vladimir Kolovski, Souripriya Das, Zhe Wu, Eugene In-\", \"seok Chong, and Jagannathan Srinivasan. Visualizing\", \"large-scale RDF data using subsets, summaries, and\", \"sampling in oracle. In Proc. ICDE , pages 1048–1059,\", \"2010.\", \"[Vassiliou et al. , 2023 ]Giannis Vassiliou, Fanouris Aleviza-\", \"kis, Nikolaos Papadakis, and Haridimos Kondylakis.\", \"iSummary: workload-based, personalized summaries for\", \"knowledge graphs. In Proc. ESWC , pages 192–208, 2023.\", \"[Vrandecic and Kr ¨otzsch, 2014 ]Denny Vrandecic and\", \"knowledgebase. Commun. ACM , 57(10):78–85, 2014.\", \"[Wang et al. , 2019 ]Xiaxia Wang, Gong Cheng, and Evgeny\", \"search. In Proc. PROFILES & SEMEX , pages 1–6, 2019.\", \"[Wang et al. , 2021 ]Xiaxia Wang, Gong Cheng, Tengteng\", \"Lin, Jing Xu, Jeff Z. Pan, Evgeny Kharlamov, and\", \"for RDF datasets. In Proc. ISWC , pages 3–20, 2021.\", \"[Wang et al. , 2022 ]Xiaxia Wang, Tengteng Lin, Weiqing\", \"Luo, Gong Cheng, and Yuzhong Qu. CKGSE: A proto-\", \"Intell. , 4(1):41–65, 2022.\", \"[Wang et al. , 2023 ]Xiaxia Wang, Gong Cheng, Jeff Z. Pan,\", \"Evgeny Kharlamov, and Yuzhong Qu. BANDAR: bench-\", \"search. IEEE Trans. Knowl. Data Eng. , 35(2):1227–1241,\", \"2023.\", \"[Wang, 2017 ]Xin Wang. Answering graph pattern matching\", \"using views: A revisit. In Proc. DEXA, Part I , pages 65–\", \"80, 2017.\", \"[Yang et al. , 2017 ]Shuo Yang, Lei Zou, Zhongyuan Wang,\", \"Jun Yan, and Ji-Rong Wen. Efficiently answering technical\", \"questions - A knowledge graph approach. In Proc. AAAI ,\", \"pages 3111–3118, 2017.\", \"[Zhang et al. , 2023 ]Ke Zhang, Xiaoqing Wang, and Gong\", \"lem. In Proc. WWW , pages 199–209, 2023.\", \"[Zhao et al. , 2020 ]Yang Zhao, Jiajun Zhang, Yu Zhou, and\", \"chine translation. In Proc. IJCAI , pages 4039–4045, 2020.\"], \"error\": null}, \"6ba10310\": {\"success\": true, \"paper_id\": \"6ba10310\", \"url\": \"https://arxiv.org/pdf/2204.11190.pdf\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_6ba10310.pdf\", \"extracted_info\": {\"title\": \"Knowledge, Embedding Methods and Architectures\", \"authors\": [\"Yutong Qu\", \"Wei Emma Zhang\", \"Jian Yang\", \"Lingfei Wu\", \"Jia Wu\"], \"abstract\": \"Knowledge-aware methods have significantly advanced various natural language processing applications over recent decades. This paper focuses on methodologies that embed knowledge into document summarizers and proposes novel taxonomies to recapitulate knowledge and knowledge embeddings from the perspective of document summarization.\", \"methodology\": \"The paper surveys and categorizes existing document summarization methods that incorporate knowledge, including both extractive and abstractive approaches for single and multiple documents. It introduces a taxonomy of knowledge types (native, lexical, semantic, domain, common-sense, ontological, topical) and embedding methods (text embeddings, graph embeddings, entity embeddings, relation embeddings, etc.). Representative models are analyzed based on their architectures (e.g., Transformer, Encoder-Decoder, GNN, RNN, LSTM) and embedding strategies (Word2Vec, GloVe, TF-IDF, BERT, etc.).\", \"results\": \"The survey compiles a comprehensive list of state-of-the-art document summarization models that integrate various forms of knowledge and embedding techniques. It presents detailed tables mapping models to their knowledge usage, embedding methods, and architectures, highlighting trends such as the increasing use of pretrained language models and graph-based embeddings in summarization tasks.\", \"conclusion\": \"The key contributions are: (1) Providing a systematic survey of knowledge embedding methodologies in document summarization; (2) Introducing a novel taxonomy for categorizing knowledge and embedding methods specific to summarization tasks; (3) Mapping representative models to their knowledge types, embedding strategies, and architectures; (4) Identifying research trends and future directions, such as integrating multiple knowledge sources, enhancing factual consistency, and exploring prompting strategies for knowledge embedding in summarization.\", \"figures\": null, \"tables\": null}, \"citations\": [\"[1] C. Ma, W. E. Zhang, M. Guo, H. Wang, Q. Z. Sheng, Multi-document\", \"Summarization via Deep Learning Techniques: A Survey, ACM Computing\", \"[2] W. S. El-Kassas, C. R. Salama, A. A. Rafea, H. K. Mohamed, Automatic\", \"text summarization: A comprehensive survey, ESWA 165 (2021) 113679.\", \"[3] R. Ferreira, L. de Souza Cabral, F. L. G. de Freitas, R. D. Lins, G. P.\", \"e Silva, S. J. Simske, L. Favaro, A multi-document summarization system\", \"based on statistics and linguistic treatment, ESWA 41 (2014) 5780{5787.\", \"[4] A. Hogan, E. Blomqvist, M. Cochez, C. d'Amato, G. D. Melo, C. Gutier-\", \"rez, S. Kirrane, J. E. L. Gayo, R. Navigli, S. Neumaier, A.-C. N. Ngomo,\", \"A. Polleres, S. M. Rashid, A. Rula, L. Schmelzeisen, J. Sequeda, S. Staab,\", \"A. Zimmermann, Knowledge graphs, ACM Computing Surveys 54 (2022)\", \"1{37. doi: 10.1145/3447772 .\", \"22\", \"[5] S. Gao, X. Chen, Z. Ren, D. Zhao, R. Yan, From Standard Summarization\", \"to New Tasks and Beyond: Summarization with Manifold Information, in:\", \"IJCAI, 2021, pp. 4854{4860. doi: 10.48550/arXiv.2005.04684 .\", \"[6] X. Han, T. Lv, Z. Hu, X. Wang, C. Wang, Text Summarization Using\", \"FrameNet-Based Semantic Graph Model, Scienti\\fc Programming 2016\", \"(2016) 1{10. doi: 10.1155/2016/5130603 .\", \"[7] M. Yasunaga, R. Zhang, K. Meelu, A. Pareek, K. Srinivasan, D. Radev,\", \"Graph-based Neural Multi-Document Summarization, in: CoNLL, 2017,\", \"[8] J. Tan, X. Wan, J. Xiao, Abstractive Document Summarization with a\", \"Graph-Based Attentional Neural Model, in: ACL, 2017, pp. 1171{1181.\", \"[9] B. Gunel, C. Zhu, M. Zeng, X. Huang, Mind The Facts: Knowledge-\", \"Boosted Coherent Abstractive Text Summarization, in: NeurIPS, 2019,\", \"[10] X. Ji, W. Zhao, SKGSUM: Abstractive Document Summarization with\", \"Semantic Knowledge Graphs, in: IJCNN, 2021, pp. 1{8. doi: 10.1109/\", \"[11] T. Tang, T. Yuan, X. Tang, D. Chen, Incorporating External Knowledge\", \"into Unsupervised Graph Model for Document Summarization, Electronics\", \"9 (2020) 1{13. doi: 10.3390/electronics9091520 .\", \"[12] W. Wu, W. Li, X. Xiao, J. Liu, Z. Cao, S. Li, H. Wu, H. Wang, BASS:\", \"Boosting Abstractive Summarization with Uni\\fed Semantic Graph, in:\", \"ACL-IJCNLP, 2021, pp. 6052{6067. doi: 10.18653/v1/2021.acl-long.\", \"472.\", \"[13] M. Chen, W. Li, J. Liu, X. Xiao, H. Wu, H. Wang, SgSum: Transforming\", \"Multi-document Summarization into Sub-graph Selection, in: EMNLP,\", \"2021, pp. 4063{4074. doi: 10.18653/v1/2021.emnlp-main.333 .\", \"23\", \"[14] Q. Wang, Z. Mao, B. Wang, L. Guo, Knowledge Graph Embedding: A\", \"Survey of Approaches and Applications, IEEE TKDE 29 (2017) 2724{\", \"2743. doi: 10.1109/TKDE.2017.2754499 .\", \"[15] H. Cai, V. W. Zheng, K. C.-C. Chang, A Comprehensive Survey of Graph\", \"Embedding: Problems, Techniques, and Applications, IEEE TKDE 30\", \"(2018) 1616{1637. doi: 10.1109/TKDE.2018.2807452 .\", \"[16] M. Xu, Understanding Graph Embedding Methods and Their Applications,\", \"[17] S. Ji, S. Pan, E. Cambria, P. Marttinen, P. S. Yu, A Survey on Knowledge\", \"Graphs: Representation, Acquisition and Applications, IEEE TNNLS 33\", \"(2022) 494{514. doi: 10.1109/TNNLS.2021.3070843 .\", \"[18] S. Takase, J. Suzuki, N. Okazaki, T. Hirao, M. Nagata, Neural Headline\", \"Generation on Abstract Meaning Representation, in: EMNLP, 2016, pp.\", \"1054{1059. doi: 10.18653/v1/D16-1112 .\", \"[19] Y. Liu, M. Lapata, Text Summarization with Pretrained Encoders, in:\", \"EMNLP-IJCNLP, 2019, pp. 3730{3740. doi: 10.18653/v1/D19-1387 .\", \"[20] H. Zhang, J. Cai, J. Xu, J. Wang, Pretraining-Based Natural Language\", \"Generation for Text Summarization, in: CoNLL, 2019, pp. 789{797. doi: 10.\", \"18653/v1/K19-1074 .\", \"[21] R. Koncel-Kedziorski, D. Bekal, Y. Luan, M. Lapata, H. Hajishirzi,\", \"Text Generation from Knowledge Graphs with Graph Transformers, in:\", \"NAACL-HLT, 2019, pp. 2284{2293. doi: 10.18653/v1/N19-1238 .\", \"[22] D. T. Anh, N. T. T. Trang, Abstractive Text Summarization Using Pointer-\", \"Generator Networks With Pre-Trained Word Embedding, in: SoICT, 2019,\", \"[23] J. Guan, Y. Wang, M. Huang, Story Ending Generation with Incremental\", \"Encoding and Commonsense Knowledge, in: AAAI-IAAI-EAAI, 2019, pp.\", \"6473{{6480. doi: 10.1609/aaai.v33i01.33016473 .\", \"24\", \"[24] H. Jin, T. Wang, X. Wan, SemSUM: Semantic Dependency Guided Neural\", \"Abstractive Summarization, in: AAAI, 2020, pp. 8026{8033. doi: 10.1609/\", \"[25] H. Ji, P. Ke, S. Huang, F. Wei, X. Zhu, M. Huang, Language Genera-\", \"tion with Multi-Hop Reasoning on Commonsense Knowledge Graph, in:\", \"EMNLP, 2020, pp. 725{736. doi: 10.18653/v1/2020.emnlp-main.54 .\", \"[26] J. You, C. Hu, H. Kamigaito, H. Takamura, M. Okumura, Abstractive Doc-\", \"ument Summarization with Word Embedding Reconstruction, in: RANLP,\", \"2021, pp. 1586{1596. doi: 10.26615/978-954-452-072-4_178 .\", \"[27] C. Zhu, W. Hinthorn, R. Xu, Q. Zeng, M. Zeng, X. Huang, M. Jiang, En-\", \"hancing Factual Consistency of Abstractive Summarization, in: NAACL-\", \"HLT, 2021, pp. 718{733. doi: 10.18653/v1/2021.naacl-main.58 .\", \"[28] A. Fan, C. Gardent, C. Braud, A. Bordes, Using Local Knowledge Graph\", \"Construction to Scale Seq2Seq Models to Multi-Document Inputs, in:\", \"EMNLP-IJCNLP, 2019, pp. 4186{4196. doi: 10.18653/v1/D19-1428 .\", \"[29] J. Zhang, Y. Zhao, M. Saleh, P. J. Liu, PEGASUS: Pre-training with\", \"Extracted Gap-sentences for Abstractive Summarization, in: ICML, 2020,\", \"[30] L. Huang, L. Wu, L. Wang, Knowledge Graph-Augmented Abstractive\", \"Summarization with Semantic-Driven Cloze Reward, in: ACL, 2020, pp.\", \"5094{5107. doi: 10.18653/v1/2020.acl-main.457 .\", \"[31] R. Pasunuru, M. Liu, M. Bansal, S. Ravi, M. Dreyer, E\\u000eciently Summariz-\", \"ing Text and Graph Encodings of Multi-Document Clusters, in: NAACL-\", \"HLT, 2021, pp. 4768{4779. doi: 10.18653/v1/2021.naacl-main.380 .\", \"[32] H. Zhou, W. Ren, G. Liu, B. Su, W. Lu, Entity-Aware Abstractive Multi-\", \"Document Summarization, in: ACL-IJCNLP, 2021, pp. 351{362. doi: 10.\", \"18653/v1/2021.findings-acl.30 .\", \"25\", \"[33] C. Zhang, S. Sah, T. Nguyen, D. K. Peri, A. C. Loui, C. Salvaggio, R. W.\", \"Ptucha, Semantic Sentence Embeddings for Paraphrasing and Text Sum-\", \"marization, IEEE GlobalSIP (2017) 705{709. doi: 10.1109/GlobalSIP.\", \"2017.8309051 .\", \"[34] X. Zhang, F. Wei, M. Zhou, HIBERT: Document Level Pre-training of\", \"Hierarchical Bidirectional Transformers for Document Summarization, in:\", \"ACL, 2019, pp. 5059{5069. doi: 10.18653/v1/P19-1499 .\", \"[35] R. Yuan, Z. Wang, W. Li, Fact-level Extractive Summarization with Hi-\", \"erarchical Graph Mask on BERT, in: COLING, 2020, pp. 5629{5639.\", \"[36] Y. J. Huang, S. Kurohashi, Extractive Summarization Considering Dis-\", \"course and Coreference Relations based on Heterogeneous Graph, in:\", \"EACL, 2021, pp. 3046{3052. doi: 10.18653/v1/2021.eacl-main.265 .\", \"[37] P. Cui, L. Hu, Y. Liu, Enhancing Extractive Text Summarization with\", \"Topic-Aware Graph Neural Networks, in: COLING, 2020, pp. 5360{5371.\", \"[38] J. Xu, Z. Gan, Y. Cheng, J. Liu, Discourse-Aware Neural Extractive Text\", \"Summarization, in: ACL, 2020, pp. 5021{5031. doi: 10.18653/v1/2020.\", \"[39] X. Zheng, A. Sun, J. Li, K. Muthuswamy, Subtopic-driven Multi-Document\", \"Summarization, in: EMNLP-IJCNLP, 2019, pp. 3153{3162. doi: 10.18653/\", \"[40] D. Wang, P. Liu, Y. Zheng, X. Qiu, X. Huang, Heterogeneous Graph\", \"Neural Networks for Extractive Document Summarization, in: ACL, 2020,\", \"[41] G. Erkan, D. R. Radev, LexRank: Graph-Based Lexical Centrality as\", \"Salience in Text Summarization, Journal of Arti\\fcial Intelligence Research\", \"22 (2004) 457{479. doi: 10.48550/arXiv.1109.2128 .\", \"26\", \"[42] W. Li, X. Xiao, J. Liu, H. Wu, H. Wang, J. Du, Leveraging Graph to\", \"Improve Abstractive Multi-Document Summarization, in: ACL, 2020, pp.\", \"6232{6243. doi: 10.18653/v1/2020.acl-main.555 .\", \"[43] J. Flanigan, S. Thomson, J. Carbonell, C. Dyer, N. A. Smith, A Discrim-\", \"inative Graph-Based Parser for the Abstract Meaning Representation, in:\", \"ACL, 2014, pp. 1426{1436. doi: 10.3115/v1/P14-1134 .\", \"[44] K. M. Hermann, T. Ko\\u0014 cisk\\u0013 y, E. Grefenstette, L. Espeholt, W. Kay, M. Su-\", \"leyman, P. Blunsom, Teaching Machines to Read and Comprehend, in:\", \"NeurIPS, 2015, pp. 1693{1701. doi: 10.48550/arXiv.1506.03340 .\", \"[45] T. Dozat, C. D. Manning, Deep Bia\\u000ene Attention for Neural Dependency\", \"Parsing, in: ICLR, 2017, pp. 1{8. doi: 10.48550/arXiv.1611.01734 .\", \"[46] Y. Ji, J. Eisenstein, Representation Learning for Text-level Discourse Pars-\", \"ing, in: ACL, 2014, pp. 13{24. doi: 10.3115/v1/P14-1002 .\", \"[47] G. A. Miller, WordNet: A Lexical Database for English, Communications\", \"[48] J. Ruppenhofer, M. Ellsworth, M. R. L. Petruck, C. R. Johnson, J. Schef-\", \"fczyk, FrameNet II: Extended theory and practice, FrameNet Project\", \"(2006).\", \"[49] R. Speer, C. Havasi, Representing General Relational Knowledge in Con-\", \"ceptNet 5, in: LREC, 2012, pp. 3679{3686.\", \"[50] D. Vrande\\u0014 ci\\u0013 c, M. Kr otzsch, Wikidata: A Free Collaborative Knowledge-\", \"base, Communications of the ACM 57 (2014) 78{85. doi: 10.1145/2629489 .\", \"[51] G. Angeli, M. J. J. Premkumar, C. D. Manning, Leveraging Linguistic\", \"Structure For Open Domain Information Extraction, in: ACL-IJCNLP,\", \"2015, pp. 344{354. doi: 10.3115/v1/P15-1034 .\", \"27\", \"[52] G. Stanovsky, J. Michael, L. Zettlemoyer, I. Dagan, Supervised Open In-\", \"formation Extraction, in: NAACL-HLT, 2018, pp. 885{895. doi: 10.18653/\", \"[53] D. M. Blei, A. Y. Ng, M. I. Jordan, Latent Dirichlet Allocation, Journal\", \"[54] Y. Miao, E. Grefenstette, P. Blunsom, Discovering Discrete Latent Topics\", \"with Neural Variational Inference, in: ICML, volume 70, 2017, pp. 2410{\", \"2419. doi: 10.48550/arXiv.1706.00359 .\", \"[55] Y. Liu, Y. Wan, L. He, H. Peng, P. S. Yu, KG-BART: Knowledge Graph-\", \"Augmented BART for Generative Commonsense Reasoning, in: AAAI,\", \"volume 35, 2021, pp. 6418{6425. doi: 10.48550/arXiv.2009.12677 .\", \"[56] F. Liu, J. Flanigan, S. Thomson, N. Sadeh, N. A. Smith, Toward Abstrac-\", \"tive Summarization Using Semantic Representations, in: NAACL-HLT,\", \"2015, pp. 1077{1086. doi: 10.3115/v1/N15-1114 .\", \"[57] A. Bordes, N. Usunier, A. Garcia-Dur\\u0013 an, J. Weston, O. Yakhnenko, Trans-\", \"lating Embeddings for Modeling Multi-Relational Data, in: NeurIPS, vol-\", \"ume 26, 2013, pp. 2787{2795.\", \"[58] A. Abdi, N. Idris, R. M. Alguliyev, R. M. Aliguliyev, Query-based\", \"word expansion, Soft Computing 21 (2017) 1785{1801. doi: 10.1007/\", \"[59] Y. Xie, F. Sun, Y. Deng, Y. Li, B. Ding, Factual Consistency Evaluation\", \"for Text Summarization via Counterfactual Estimation, in: EMNLP, 2021,\", \"[60] S. Jain, M. van Zuylen, H. Hajishirzi, I. Beltagy, SciREX: A Challenge\", \"Dataset for Document-Level Information Extraction, in: ACL, 2020, pp.\", \"7506{7516. doi: 10.18653/v1/2020.acl-main.670 .\", \"28\", \"[61] Z. Wu, R. Koncel-Kedziorski, M. Ostendorf, H. Hajishirzi, Extracting\", \"Summary Knowledge Graphs from Long Documents, arXiv abs/2009.09162\", \"(2020) 1{8. doi: 10.48550/arXiv.2009.09162 .\", \"[62] S. Pai, L. Costabello, Learning Embeddings from Knowledge Graphs With\", \"Numeric Edge Attributes, in: IJCAI, 2021, pp. 2869{2875. doi: 10.24963/\", \"[63] E. Sharma, L. Huang, Z. Hu, L. Wang, An Entity-Driven Framework for\", \"Abstractive Summarization, in: EMNLP-IJCNLP, 2019, pp. 3280{3291.\", \"[64] P. Liu, W. Yuan, J. Fu, Z. Jiang, H. Hayashi, G. Neubig, Pre-train, Prompt,\", \"guage Processing, arXiv preprint arXiv:2107.13586 (2021).\", \"29\"], \"error\": null}, \"40559559\": {\"success\": true, \"paper_id\": \"40559559\", \"url\": \"https://arxiv.org/pdf/2306.08302v3\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_40559559.pdf\", \"extracted_info\": {\"title\": \"Unifying Large Language Models and Knowledge Graphs: A Roadmap\", \"authors\": [\"Shirui Pan\", \"Lin\"], \"abstract\": \"Large language models (LLMs), such as ChatGPT and GPT-4, are making new waves in natural language processing and artificial intelligence due to their emergent abilities and generalizability. However, LLMs face challenges in factual accuracy, inference, and interpretability. Knowledge graphs (KGs), while strong in storing structured facts and enabling symbolic reasoning, are difficult to construct and evolve. This paper explores the complementary nature of LLMs and KGs and proposes a roadmap for their unification.\", \"methodology\": \"The paper conducts a comprehensive survey and taxonomy of existing methods that integrate LLMs and KGs. It categorizes approaches into KG-enhanced LLMs, LLM-augmented KGs, and synergized LLM-KG frameworks. For each category, representative methods are analyzed, including pre-training, inference-time integration, interpretability enhancement, KG embedding, KG completion, KG construction, KG-to-text generation, and KG-based question answering. Comparative analysis is provided alongside discussions of strengths, limitations, and application scenarios.\", \"results\": \"The study finds that KG-enhanced LLM pre-training can inject large amounts of structured knowledge but struggles with updating facts without retraining, while inference-time integration allows dynamic updates but may underutilize knowledge. LLM-augmented KG methods improve KG completeness and embedding quality by leveraging LLMs’ contextual understanding. Synergized frameworks combining LLM and KG reasoning achieve more interpretable and accurate outputs. Experimental evidence shows improved performance in QA, reasoning, and knowledge representation tasks when LLMs and KGs are jointly utilized.\", \"conclusion\": \"The key contributions of the paper include: (1) Proposing a unified taxonomy for integrating LLMs and KGs; (2) Summarizing representative methods across KG-enhanced LLMs, LLM-augmented KGs, and synergized frameworks; (3) Identifying strengths, weaknesses, and application scenarios for each integration approach; (4) Highlighting challenges such as factual hallucination, knowledge updating, and multi-modal alignment; (5) Suggesting future research directions, including efficient knowledge editing, robust hallucination detection, and cross-modal entity alignment.\", \"figures\": null, \"tables\": null}, \"citations\": [\"[1] J. Devlin, M.-W. Chang, K. Lee, and K. Toutanova, “Bert: Pre-\", \"standing,” arXiv preprint arXiv:1810.04805 , 2018.\", \"[2] Y. Liu, M. Ott, N. Goyal, J. Du, M. Joshi, D. Chen, O. Levy,\", \"M. Lewis, L. Zettlemoyer, and V . Stoyanov, “Roberta: A ro-\", \"bustly optimized bert pretraining approach,” arXiv preprint\", \"arXiv:1907.11692 , 2019.\", \"[3] C. Raffel, N. Shazeer, A. Roberts, K. Lee, S. Narang, M. Matena,\", \"Y. Zhou, W. Li, and P . J. Liu, “Exploring the limits of transfer\", \"learning with a unified text-to-text transformer,” The Journal of\", \"Machine Learning Research , vol. 21, no. 1, pp. 5485–5551, 2020.\", \"[4] D. Su, Y. Xu, G. I. Winata, P . Xu, H. Kim, Z. Liu, and P . Fung,\", \"guage model fine-tuning,” in Proceedings of the 2nd Workshop on\", \"Machine Reading for Question Answering , 2019, pp. 203–211.\", \"[5] M. Lewis, Y. Liu, N. Goyal, M. Ghazvininejad, A. Mohamed,\", \"O. Levy, V . Stoyanov, and L. Zettlemoyer, “Bart: Denoising\", \"tion, translation, and comprehension,” in ACL , 2020, pp. 7871–\", \"7880.\", \"[6] J. Li, T. Tang, W. X. Zhao, and J.-R. Wen, “Pretrained lan-\", \"guage models for text generation: A survey,” arXiv preprint\", \"arXiv:2105.10311 , 2021.\", \"[7] J. Wei, Y. Tay, R. Bommasani, C. Raffel, B. Zoph, S. Borgeaud,\", \"D. Yogatama, M. Bosma, D. Zhou, D. Metzler et al. , “Emergent\", \"abilities of large language models,” Transactions on Machine Learn-\", \"[8] K. Malinka, M. Pere ˇs´ıni, A. Firc, O. Huj ˇn´ak, and F. Janu ˇs, “On\", \"to obtain a university degree?” arXiv preprint arXiv:2303.11146 ,\", \"2023.\", \"[9] Z. Li, C. Wang, Z. Liu, H. Wang, S. Wang, and C. Gao, “Cctest:\", \"Testing and repairing code completion systems,” ICSE , 2023.\", \"[10] J. Liu, C. Liu, R. Lv, K. Zhou, and Y. Zhang, “Is chatgpt a good rec-\", \"ommender? a preliminary study,” arXiv preprint arXiv:2304.10149 ,\", \"2023.\", \"[11] W. X. Zhao, K. Zhou, J. Li, T. Tang, X. Wang, Y. Hou, Y. Min,\", \"B. Zhang, J. Zhang, Z. Dong et al. , “A survey of large language\", \"models,” arXiv preprint arXiv:2303.18223 , 2023.\", \"[12] X. Qiu, T. Sun, Y. Xu, Y. Shao, N. Dai, and X. Huang, “Pre-trained\", \"models for natural language processing: A survey,” Science China\", \"Technological Sciences , vol. 63, no. 10, pp. 1872–1897, 2020.\", \"[13] J. Yang, H. Jin, R. Tang, X. Han, Q. Feng, H. Jiang, B. Yin, and\", \"X. Hu, “Harnessing the power of llms in practice: A survey on\", \"chatgpt and beyond,” arXiv preprint arXiv:2304.13712 , 2023.\", \"[14] F. Petroni, T. Rockt ¨aschel, S. Riedel, P . Lewis, A. Bakhtin, Y. Wu,\", \"and A. Miller, “Language models as knowledge bases?” in\", \"EMNLP-IJCNLP , 2019, pp. 2463–2473.\", \"[15] Z. Ji, N. Lee, R. Frieske, T. Yu, D. Su, Y. Xu, E. Ishii, Y. J. Bang,\", \"A. Madotto, and P . Fung, “Survey of hallucination in natural\", \"language generation,” ACM Computing Surveys , vol. 55, no. 12,\", \"[16] H. Zhang, H. Song, S. Li, M. Zhou, and D. Song, “A survey of\", \"language models,” arXiv preprint arXiv:2201.05337 , 2022.\", \"JOURNAL OF LATEX CLASS FILES, VOL. ??, NO. ??, MONTH 20YY 22\", \"[17] M. Danilevsky, K. Qian, R. Aharonov, Y. Katsis, B. Kawas, and\", \"P . Sen, “A survey of the state of explainable ai for natural\", \"language processing,” arXiv preprint arXiv:2010.00711 , 2020.\", \"[18] J. Wang, X. Hu, W. Hou, H. Chen, R. Zheng, Y. Wang, L. Yang,\", \"H. Huang, W. Ye, X. Geng et al. , “On the robustness of chatgpt: An\", \"adversarial and out-of-distribution perspective,” arXiv preprint\", \"arXiv:2302.12095 , 2023.\", \"[19] S. Ji, S. Pan, E. Cambria, P . Marttinen, and S. Y. Philip, “A\", \"survey on knowledge graphs: Representation, acquisition, and\", \"applications,” IEEE TNNLS , vol. 33, no. 2, pp. 494–514, 2021.\", \"[20] D. Vrande ˇci´c and M. Kr ¨otzsch, “Wikidata: a free collaborative\", \"knowledgebase,” Communications of the ACM , vol. 57, no. 10, pp.\", \"78–85, 2014.\", \"[21] S. Hu, L. Zou, and X. Zhang, “A state-transition framework to\", \"answer complex questions over knowledge base,” in EMNLP ,\", \"2018, pp. 2098–2108.\", \"[22] J. Zhang, B. Chen, L. Zhang, X. Ke, and H. Ding, “Neural,\", \"symbolic and neural-symbolic reasoning on knowledge graphs,”\", \"AI Open , vol. 2, pp. 14–35, 2021.\", \"[23] B. Abu-Salih, “Domain-specific knowledge graphs: A survey,”\", \"Journal of Network and Computer Applications , vol. 185, p. 103076,\", \"2021.\", \"[24] T. Mitchell, W. Cohen, E. Hruschka, P . Talukdar, B. Yang, J. Bet-\", \"teridge, A. Carlson, B. Dalvi, M. Gardner, B. Kisiel, K. Jayant,\", \"L. Ni, M. Kathryn, M. Thahir, N. Ndapandula, P . Emmanouil,\", \"R. Alan, S. Mehdi, S. Burr, W. Derry, G. Abhinav, C. Xi, S. Abul-\", \"hair, and W. Joel, “Never-ending learning,” Communications of the\", \"ACM , vol. 61, no. 5, pp. 103–115, 2018.\", \"[25] L. Zhong, J. Wu, Q. Li, H. Peng, and X. Wu, “A comprehen-\", \"sive survey on automatic knowledge graph construction,” arXiv\", \"preprint arXiv:2302.05019 , 2023.\", \"[26] L. Yao, C. Mao, and Y. Luo, “Kg-bert: Bert for knowledge graph\", \"completion,” arXiv preprint arXiv:1909.03193 , 2019.\", \"[27] L. Luo, Y.-F. Li, G. Haffari, and S. Pan, “Normalizing flow-\", \"based neural process for few-shot knowledge graph completion,”\", \"[28] Y. Bang, S. Cahyawijaya, N. Lee, W. Dai, D. Su, B. Wilie, H. Love-\", \"nia, Z. Ji, T. Yu, W. Chung et al. , “A multitask, multilingual,\", \"multimodal evaluation of chatgpt on reasoning, hallucination,\", \"and interactivity,” arXiv preprint arXiv:2302.04023 , 2023.\", \"[29] X. Wang, J. Wei, D. Schuurmans, Q. Le, E. Chi, and D. Zhou, “Self-\", \"models,” arXiv preprint arXiv:2203.11171 , 2022.\", \"[30] O. Golovneva, M. Chen, S. Poff, M. Corredor, L. Zettlemoyer,\", \"M. Fazel-Zarandi, and A. Celikyilmaz, “Roscoe: A suite of metrics\", \"for scoring step-by-step reasoning,” ICLR , 2023.\", \"[31] F. M. Suchanek, G. Kasneci, and G. Weikum, “Yago: a core of\", \"semantic knowledge,” in WWW , 2007, pp. 697–706.\", \"[32] A. Carlson, J. Betteridge, B. Kisiel, B. Settles, E. Hruschka, and\", \"T. Mitchell, “Toward an architecture for never-ending language\", \"learning,” in Proceedings of the AAAI conference on artificial intelli-\", \"gence , vol. 24, no. 1, 2010, pp. 1306–1313.\", \"[33] A. Bordes, N. Usunier, A. Garcia-Duran, J. Weston, and\", \"O. Yakhnenko, “Translating embeddings for modeling multi-\", \"relational data,” NeurIPS , vol. 26, 2013.\", \"[34] G. Wan, S. Pan, C. Gong, C. Zhou, and G. Haffari, “Reasoning\", \"graph reasoning,” in AAAI , 2021, pp. 1926–1932.\", \"[35] Z. Zhang, X. Han, Z. Liu, X. Jiang, M. Sun, and Q. Liu, “ERNIE:\", \"Enhanced language representation with informative entities,” in\", \"ACL , 2019, pp. 1441–1451.\", \"[36] W. Liu, P . Zhou, Z. Zhao, Z. Wang, Q. Ju, H. Deng, and P . Wang,\", \"graph,” in AAAI , 2020, pp. 2901–2908.\", \"[37] Y. Liu, Y. Wan, L. He, H. Peng, and P . S. Yu, “KG-BART: knowl-\", \"soning,” in AAAI , 2021, pp. 6418–6425.\", \"[38] B. Y. Lin, X. Chen, J. Chen, and X. Ren, “KagNet: Knowledge-\", \"aware graph networks for commonsense reasoning,” in EMNLP-\", \"IJCNLP , 2019, pp. 2829–2839.\", \"[39] D. Dai, L. Dong, Y. Hao, Z. Sui, B. Chang, and F. Wei,\", \"“Knowledge neurons in pretrained transformers,” arXiv preprint\", \"arXiv:2104.08696 , 2021.\", \"[40] X. Wang, T. Gao, Z. Zhu, Z. Zhang, Z. Liu, J. Li, and J. Tang,\", \"trained language representation,” Transactions of the Association\", \"for Computational Linguistics , vol. 9, pp. 176–194, 2021.[41] I. Melnyk, P . Dognin, and P . Das, “Grapher: Multi-stage knowl-\", \"edge graph construction using pretrained language models,” in\", \"[42] P . Ke, H. Ji, Y. Ran, X. Cui, L. Wang, L. Song, X. Zhu, and\", \"M. Huang, “JointGT: Graph-text joint representation learning for\", \"text generation from knowledge graphs,” in ACL Finding , 2021,\", \"[43] J. Jiang, K. Zhou, W. X. Zhao, and J.-R. Wen, “Unikgqa: Unified\", \"over knowledge graph,” ICLR 2023 , 2023.\", \"[44] M. Yasunaga, A. Bosselut, H. Ren, X. Zhang, C. D. Manning, P . S.\", \"Liang, and J. Leskovec, “Deep bidirectional language-knowledge\", \"graph pretraining,” NeurIPS , vol. 35, pp. 37 309–37 323, 2022.\", \"[45] N. Choudhary and C. K. Reddy, “Complex logical reasoning over\", \"knowledge graphs using large language models,” arXiv preprint\", \"arXiv:2305.01157 , 2023.\", \"[46] S. Wang, Z. Wei, J. Xu, and Z. Fan, “Unifying structure reasoning\", \"and language model pre-training for complex reasoning,” arXiv\", \"preprint arXiv:2301.08913 , 2023.\", \"[47] C. Zhen, Y. Shang, X. Liu, Y. Li, Y. Chen, and D. Zhang, “A\", \"survey on knowledge-enhanced pre-trained language models,”\", \"arXiv preprint arXiv:2212.13428 , 2022.\", \"[48] X. Wei, S. Wang, D. Zhang, P . Bhatia, and A. Arnold, “Knowl-\", \"survey,” arXiv preprint arXiv:2110.08455 , 2021.\", \"[49] D. Yin, L. Dong, H. Cheng, X. Liu, K.-W. Chang, F. Wei, and\", \"J. Gao, “A survey of knowledge-intensive nlp with pre-trained\", \"language models,” arXiv preprint arXiv:2202.08772 , 2022.\", \"[50] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N.\", \"Gomez, Ł. Kaiser, and I. Polosukhin, “Attention is all you need,”\", \"NeurIPS , vol. 30, 2017.\", \"[51] Z. Lan, M. Chen, S. Goodman, K. Gimpel, P . Sharma, and R. Sori-\", \"cut, “Albert: A lite bert for self-supervised learning of language\", \"representations,” in ICLR , 2019.\", \"[52] K. Clark, M.-T. Luong, Q. V . Le, and C. D. Manning, “Electra: Pre-\", \"training text encoders as discriminators rather than generators,”\", \"arXiv preprint arXiv:2003.10555 , 2020.\", \"[53] K. Hakala and S. Pyysalo, “Biomedical named entity recognition\", \"with multilingual bert,” in Proceedings of the 5th workshop on\", \"BioNLP open shared tasks , 2019, pp. 56–61.\", \"[54] Y. Tay, M. Dehghani, V . Q. Tran, X. Garcia, J. Wei, X. Wang,\", \"H. W. Chung, D. Bahri, T. Schuster, S. Zheng et al. , “Ul2: Unifying\", \"language learning paradigms,” in ICLR , 2022.\", \"[55] V . Sanh, A. Webson, C. Raffel, S. Bach, L. Sutawika, Z. Alyafeai,\", \"A. Chaffin, A. Stiegler, A. Raja, M. Dey et al. , “Multitask\", \"prompted training enables zero-shot task generalization,” in\", \"[56] B. Zoph, I. Bello, S. Kumar, N. Du, Y. Huang, J. Dean, N. Shazeer,\", \"and W. Fedus, “St-moe: Designing stable and transferable sparse\", \"expert models,” URL https://arxiv. org/abs/2202.08906 , 2022.\", \"[57] A. Zeng, X. Liu, Z. Du, Z. Wang, H. Lai, M. Ding, Z. Yang, Y. Xu,\", \"W. Zheng, X. Xia, W. L. Tam, Z. Ma, Y. Xue, J. Zhai, W. Chen,\", \"Z. Liu, P . Zhang, Y. Dong, and J. Tang, “GLM-130b: An open\", \"bilingual pre-trained model,” in ICLR , 2023.\", \"[58] L. Xue, N. Constant, A. Roberts, M. Kale, R. Al-Rfou, A. Siddhant,\", \"A. Barua, and C. Raffel, “mt5: A massively multilingual pre-\", \"trained text-to-text transformer,” in NAACL , 2021, pp. 483–498.\", \"[59] T. Brown, B. Mann, N. Ryder, M. Subbiah, J. D. Kaplan, P . Dhari-\", \"wal, A. Neelakantan, P . Shyam, G. Sastry, A. Askell et al. ,\", \"“Language models are few-shot learners,” Advances in neural\", \"information processing systems , vol. 33, pp. 1877–1901, 2020.\", \"[60] L. Ouyang, J. Wu, X. Jiang, D. Almeida, C. Wainwright,\", \"P . Mishkin, C. Zhang, S. Agarwal, K. Slama, A. Ray et al. ,\", \"feedback,” NeurIPS , vol. 35, pp. 27 730–27 744, 2022.\", \"[61] H. Touvron, T. Lavril, G. Izacard, X. Martinet, M.-A. Lachaux,\", \"T. Lacroix, B. Rozi `ere, N. Goyal, E. Hambro, F. Azhar et al. ,\", \"“Llama: Open and efficient foundation language models,” arXiv\", \"preprint arXiv:2302.13971 , 2023.\", \"[62] E. Saravia, “Prompt Engineering Guide,” https://github.com/\", \"dair-ai/Prompt-Engineering-Guide, 2022, accessed: 2022-12.\", \"[63] J. Wei, X. Wang, D. Schuurmans, M. Bosma, F. Xia, E. H. Chi, Q. V .\", \"Le, D. Zhou et al. , “Chain-of-thought prompting elicits reasoning\", \"in large language models,” in NeurIPS .\", \"[64] S. Li, Y. Gao, H. Jiang, Q. Yin, Z. Li, X. Yan, C. Zhang, and B. Yin,\", \"“Graph reasoning for question answering with triplet retrieval,”\", \"JOURNAL OF LATEX CLASS FILES, VOL. ??, NO. ??, MONTH 20YY 23\", \"[65] Y. Wen, Z. Wang, and J. Sun, “Mindmap: Knowledge graph\", \"prompting sparks graph of thoughts in large language models,”\", \"arXiv preprint arXiv:2308.09729 , 2023.\", \"[66] K. Bollacker, C. Evans, P . Paritosh, T. Sturge, and J. Taylor, “Free-\", \"human knowledge,” in SIGMOD , 2008, pp. 1247–1250.\", \"[67] S. Auer, C. Bizer, G. Kobilarov, J. Lehmann, R. Cyganiak, and\", \"Z. Ives, “Dbpedia: A nucleus for a web of open data,” in The\", \"Semantic Web: 6th International Semantic Web Conference . Springer,\", \"2007, pp. 722–735.\", \"[68] B. Xu, Y. Xu, J. Liang, C. Xie, B. Liang, W. Cui, and Y. Xiao, “Cn-\", \"dbpedia: A never-ending chinese knowledge extraction system,”\", \"Applications of Applied Intelligent Systems . Springer, 2017, pp.\", \"428–438.\", \"[69] P . Hai-Nyzhnyk, “Vikidia as a universal multilingual online\", \"encyclopedia for children,” The Encyclopedia Herald of Ukraine ,\", \"[70] F. Ilievski, P . Szekely, and B. Zhang, “Cskg: The commonsense\", \"knowledge graph,” Extended Semantic Web Conference (ESWC) ,\", \"2021.\", \"[71] R. Speer, J. Chin, and C. Havasi, “Conceptnet 5.5: An open\", \"multilingual graph of general knowledge,” in Proceedings of the\", \"AAAI conference on artificial intelligence , vol. 31, no. 1, 2017.\", \"[72] H. Ji, P . Ke, S. Huang, F. Wei, X. Zhu, and M. Huang, “Language\", \"edge graph,” in EMNLP , 2020, pp. 725–736.\", \"[73] J. D. Hwang, C. Bhagavatula, R. Le Bras, J. Da, K. Sakaguchi,\", \"A. Bosselut, and Y. Choi, “(comet-) atomic 2020: On symbolic\", \"and neural commonsense knowledge graphs,” in AAAI , vol. 35,\", \"no. 7, 2021, pp. 6384–6392.\", \"[74] H. Zhang, X. Liu, H. Pan, Y. Song, and C. W.-K. Leung, “Aser:\", \"A large-scale eventuality knowledge graph,” in Proceedings of the\", \"web conference 2020 , 2020, pp. 201–211.\", \"[75] H. Zhang, D. Khashabi, Y. Song, and D. Roth, “Transomcs: from\", \"linguistic graphs to commonsense knowledge,” in IJCAI , 2021,\", \"[76] Z. Li, X. Ding, T. Liu, J. E. Hu, and B. Van Durme, “Guided\", \"generation of cause and effect,” in IJCAI , 2020.\", \"[77] O. Bodenreider, “The unified medical language system (umls): in-\", \"tegrating biomedical terminology,” Nucleic acids research , vol. 32,\", \"no. suppl 1, pp. D267–D270, 2004.\", \"[78] Y. Liu, Q. Zeng, J. Ordieres Mer ´e, and H. Yang, “Anticipating\", \"approach,” Complexity , vol. 2019, 2019.\", \"[79] Y. Zhu, W. Zhou, Y. Xu, J. Liu, Y. Tan et al. , “Intelligent learning\", \"for knowledge graph towards geological data,” Scientific Program-\", \"ming , vol. 2017, 2017.\", \"[80] W. Choi and H. Lee, “Inference of biomedical relations among\", \"chemicals, genes, diseases, and symptoms using knowledge rep-\", \"resentation learning,” IEEE Access , vol. 7, pp. 179 373–179 384,\", \"2019.\", \"[81] F. Farazi, M. Salamanca, S. Mosbach, J. Akroyd, A. Eibeck,\", \"L. K. Aditya, A. Chadzynski, K. Pan, X. Zhou, S. Zhang et al. ,\", \"operability,” ACS omega , vol. 5, no. 29, pp. 18 342–18 348, 2020.\", \"[82] X. Wu, T. Jiang, Y. Zhu, and C. Bu, “Knowledge graph for china’s\", \"genealogy,” IEEE TKDE , vol. 35, no. 1, pp. 634–646, 2023.\", \"[83] X. Zhu, Z. Li, X. Wang, X. Jiang, P . Sun, X. Wang, Y. Xiao, and\", \"N. J. Yuan, “Multi-modal knowledge graph construction and\", \"application: A survey,” IEEE TKDE , 2022.\", \"[84] S. Ferrada, B. Bustos, and A. Hogan, “Imgpedia: a linked dataset\", \"with content-based analysis of wikimedia images,” in The Seman-\", \"tic Web–ISWC 2017 . Springer, 2017, pp. 84–93.\", \"[85] Y. Liu, H. Li, A. Garcia-Duran, M. Niepert, D. Onoro-Rubio,\", \"and D. S. Rosenblum, “Mmkg: multi-modal knowledge graphs,”\", \"inThe Semantic Web: 16th International Conference, ESWC 2019,\", \"Portoroˇ z, Slovenia, June 2–6, 2019, Proceedings 16 . Springer, 2019,\", \"[86] M. Wang, H. Wang, G. Qi, and Q. Zheng, “Richpedia: a large-\", \"scale, comprehensive multi-modal knowledge graph,” Big Data\", \"Research , vol. 22, p. 100159, 2020.\", \"[87] B. Shi, L. Ji, P . Lu, Z. Niu, and N. Duan, “Knowledge aware\", \"semantic concept expansion for image-text matching.” in IJCAI ,\", \"[88] S. Shah, A. Mishra, N. Yadati, and P . P . Talukdar, “Kvqa:\", \"Knowledge-aware visual question answering,” in AAAI , vol. 33,\", \"no. 01, 2019, pp. 8876–8884.[89] R. Sun, X. Cao, Y. Zhao, J. Wan, K. Zhou, F. Zhang, Z. Wang, and\", \"K. Zheng, “Multi-modal knowledge graphs for recommender\", \"systems,” in CIKM , 2020, pp. 1405–1414.\", \"[90] S. Deng, C. Wang, Z. Li, N. Zhang, Z. Dai, H. Chen, F. Xiong,\", \"M. Yan, Q. Chen, M. Chen, J. Chen, J. Z. Pan, B. Hooi, and\", \"H. Chen, “Construction and applications of billion-scale pre-\", \"trained multimodal business knowledge graph,” in ICDE , 2023.\", \"[91] C. Rosset, C. Xiong, M. Phan, X. Song, P . Bennett, and S. Tiwary,\", \"“Knowledge-aware language model pretraining,” arXiv preprint\", \"arXiv:2007.00655 , 2020.\", \"[92] P . Lewis, E. Perez, A. Piktus, F. Petroni, V . Karpukhin, N. Goyal,\", \"H. K ¨uttler, M. Lewis, W.-t. Yih, T. Rockt ¨aschel, S. Riedel,\", \"and D. Kiela, “Retrieval-augmented generation for knowledge-\", \"intensive nlp tasks,” in NeurIPS , vol. 33, 2020, pp. 9459–9474.\", \"[93] Y. Zhu, X. Wang, J. Chen, S. Qiao, Y. Ou, Y. Yao, S. Deng, H. Chen,\", \"and N. Zhang, “Llms for knowledge graph construction and\", \"reasoning: Recent capabilities and future opportunities,” arXiv\", \"preprint arXiv:2305.13168 , 2023.\", \"[94] Z. Zhang, X. Liu, Y. Zhang, Q. Su, X. Sun, and B. He, “Pretrain-\", \"guage models,” in EMNLP Finding , 2020, pp. 259–266.\", \"[95] A. Kumar, A. Pandey, R. Gadia, and M. Mishra, “Building\", \"entity-aware relationships,” in 2020 IEEE International Conference\", \"on Computing, Power and Communication Technologies (GUCON) .\", \"IEEE, 2020, pp. 310–315.\", \"[96] X. Xie, N. Zhang, Z. Li, S. Deng, H. Chen, F. Xiong, M. Chen,\", \"and H. Chen, “From discrimination to generation: Knowledge\", \"graph completion with generative transformer,” in WWW , 2022,\", \"[97] Z. Chen, C. Xu, F. Su, Z. Huang, and Y. Dou, “Incorporating\", \"temporal relation prediction,” SIGIR , 2023.\", \"[98] D. Zhu, J. Chen, X. Shen, X. Li, and M. Elhoseiny, “Minigpt-4:\", \"language models,” arXiv preprint arXiv:2304.10592 , 2023.\", \"[99] M. Warren, D. A. Shamma, and P . J. Hayes, “Knowledge engi-\", \"neering with image data in real-world settings,” in AAAI , ser.\", \"CEUR Workshop Proceedings, vol. 2846, 2021.\", \"[100] R. Thoppilan, D. De Freitas, J. Hall, N. Shazeer, A. Kul-\", \"shreshtha, H.-T. Cheng, A. Jin, T. Bos, L. Baker, Y. Du et al. ,\", \"“Lamda: Language models for dialog applications,” arXiv\", \"preprint arXiv:2201.08239 , 2022.\", \"[101] Y. Sun, S. Wang, S. Feng, S. Ding, C. Pang, J. Shang, J. Liu,\", \"X. Chen, Y. Zhao, Y. Lu et al. , “Ernie 3.0: Large-scale knowledge\", \"tion,” arXiv preprint arXiv:2107.02137 , 2021.\", \"[102] T. Shen, Y. Mao, P . He, G. Long, A. Trischler, and W. Chen,\", \"resentation learning,” in EMNLP , 2020, pp. 8980–8994.\", \"[103] D. Zhang, Z. Yuan, Y. Liu, F. Zhuang, H. Chen, and H. Xiong,\", \"model for e-commerce,” arXiv preprint arXiv:2009.02835 , 2020.\", \"[104] S. Li, X. Li, L. Shang, C. Sun, B. Liu, Z. Ji, X. Jiang, and Q. Liu,\", \"edge,” in EMNLP , 2022, pp. 11 118–11 131.\", \"[105] M. Kang, J. Baek, and S. J. Hwang, “Kala: Knowledge-augmented\", \"language model adaptation,” in NAACL , 2022, pp. 5144–5167.\", \"[106] W. Xiong, J. Du, W. Y. Wang, and V . Stoyanov, “Pretrained en-\", \"model,” in ICLR , 2020.\", \"[107] T. Sun, Y. Shao, X. Qiu, Q. Guo, Y. Hu, X. Huang, and Z. Zhang,\", \"ding,” in Proceedings of the 28th International Conference on Com-\", \"putational Linguistics , 2020, pp. 3660–3670.\", \"[108] T. Zhang, C. Wang, N. Hu, M. Qiu, C. Tang, X. He, and J. Huang,\", \"guage model for natural language understanding,” in AAAI ,\", \"2022, pp. 11 703–11 711.\", \"[109] J. Wang, W. Huang, M. Qiu, Q. Shi, H. Wang, X. Li, and M. Gao,\", \"ral language understanding,” in Proceedings of the 2022 Conference\", \"on Empirical Methods in Natural Language Processing , 2022, pp.\", \"3164–3177.\", \"[110] H. Ye, N. Zhang, S. Deng, X. Chen, H. Chen, F. Xiong, X. Chen,\", \"and H. Chen, “Ontology-enhanced prompt-tuning for few-shot\", \"learning,” in Proceedings of the ACM Web Conference 2022 , 2022,\", \"JOURNAL OF LATEX CLASS FILES, VOL. ??, NO. ??, MONTH 20YY 24\", \"[111] H. Luo, Z. Tang, S. Peng, Y. Guo, W. Zhang, C. Ma, G. Dong,\", \"M. Song, W. Lin et al. , “Chatkbqa: A generate-then-retrieve frame-\", \"large language models,” arXiv preprint arXiv:2310.08975 , 2023.\", \"[112] L. Luo, Y.-F. Li, G. Haffari, and S. Pan, “Reasoning on graphs:\", \"Faithful and interpretable large language model reasoning,”\", \"arXiv preprint arxiv:2310.01061 , 2023.\", \"[113] R. Logan, N. F. Liu, M. E. Peters, M. Gardner, and S. Singh,\", \"language modeling,” in ACL , 2019, pp. 5962–5971.\", \"[114] K. Guu, K. Lee, Z. Tung, P . Pasupat, and M.-W. Chang, “Realm:\", \"Retrieval-augmented language model pre-training,” in ICML ,\", \"2020.\", \"[115] Y. Wu, Y. Zhao, B. Hu, P . Minervini, P . Stenetorp, and S. Riedel,\", \"intensive NLP tasks,” in EMNLP , 2022, pp. 5184–5196.\", \"[116] L. Luo, J. Ju, B. Xiong, Y.-F. Li, G. Haffari, and S. Pan, “Chatrule:\", \"graph reasoning,” arXiv preprint arXiv:2309.01538 , 2023.\", \"[117] J. Wang, Q. Sun, N. Chen, X. Li, and M. Gao, “Boosting language\", \"models reasoning with chain-of-knowledge prompting,” arXiv\", \"preprint arXiv:2306.06427 , 2023.\", \"[118] Z. Jiang, F. F. Xu, J. Araki, and G. Neubig, “How can we know\", \"Computational Linguistics , vol. 8, pp. 423–438, 2020.\", \"[119] T. Shin, Y. Razeghi, R. L. Logan IV , E. Wallace, and S. Singh, “Au-\", \"tomatically generated prompts,” arXiv preprint arXiv:2010.15980 ,\", \"2020.\", \"[120] Z. Meng, F. Liu, E. Shareghi, Y. Su, C. Collins, and N. Collier,\", \"cal knowledge of pre-trained language models,” arXiv preprint\", \"arXiv:2110.08173 , 2021.\", \"[121] L. Luo, T.-T. Vu, D. Phung, and G. Haffari, “Systematic assess-\", \"ment of factual knowledge in large language models,” in EMNLP ,\", \"2023.\", \"[122] V . Swamy, A. Romanou, and M. Jaggi, “Interpreting language\", \"models through knowledge graph extraction,” arXiv preprint\", \"arXiv:2111.08546 , 2021.\", \"[123] S. Li, X. Li, L. Shang, Z. Dong, C. Sun, B. Liu, Z. Ji, X. Jiang,\", \"and Q. Liu, “How pre-trained language models capture fac-\", \"tual knowledge? a causal-inspired analysis,” arXiv preprint\", \"arXiv:2203.16747 , 2022.\", \"[124] H. Tian, C. Gao, X. Xiao, H. Liu, B. He, H. Wu, H. Wang, and\", \"F. Wu, “SKEP: Sentiment knowledge enhanced pre-training for\", \"sentiment analysis,” in ACL , 2020, pp. 4067–4076.\", \"[125] W. Yu, C. Zhu, Y. Fang, D. Yu, S. Wang, Y. Xu, M. Zeng, and\", \"M. Jiang, “Dict-BERT: Enhancing language model pre-training\", \"with dictionary,” in ACL , 2022, pp. 1907–1918.\", \"[126] T. McCoy, E. Pavlick, and T. Linzen, “Right for the wrong reasons:\", \"Diagnosing syntactic heuristics in natural language inference,” in\", \"ACL , 2019, pp. 3428–3448.\", \"[127] D. Wilmot and F. Keller, “Memory and knowledge augmented\", \"language models for inferring salience in long-form stories,” in\", \"EMNLP , 2021, pp. 851–865.\", \"[128] L. Adolphs, S. Dhuliawala, and T. Hofmann, “How to query\", \"language models?” arXiv preprint arXiv:2108.01928 , 2021.\", \"[129] M. Sung, J. Lee, S. Yi, M. Jeon, S. Kim, and J. Kang, “Can language\", \"models be biomedical knowledge bases?” in EMNLP , 2021, pp.\", \"4723–4734.\", \"[130] A. Mallen, A. Asai, V . Zhong, R. Das, H. Hajishirzi, and\", \"D. Khashabi, “When not to trust language models: Investigating\", \"memories,” arXiv preprint arXiv:2212.10511 , 2022.\", \"[131] M. Yasunaga, H. Ren, A. Bosselut, P . Liang, and J. Leskovec, “QA-\", \"for question answering,” in NAACL , 2021, pp. 535–546.\", \"[132] M. Nayyeri, Z. Wang, M. Akter, M. M. Alam, M. R. A. H.\", \"Rony, J. Lehmann, S. Staab et al. , “Integrating knowledge graph\", \"spaces,” arXiv preprint arXiv:2208.02743 , 2022.\", \"[133] N. Huang, Y. R. Deshpande, Y. Liu, H. Alberts, K. Cho,\", \"C. Vania, and I. Calixto, “Endowing language models with\", \"multimodal knowledge graph representations,” arXiv preprint\", \"arXiv:2206.13163 , 2022.\", \"[134] M. M. Alam, M. R. A. H. Rony, M. Nayyeri, K. Mohiuddin, M. M.\", \"Akter, S. Vahdati, and J. Lehmann, “Language model guided\", \"knowledge graph embeddings,” IEEE Access , vol. 10, pp. 76 008–\", \"76 020, 2022.[135] X. Wang, Q. He, J. Liang, and Y. Xiao, “Language models as\", \"knowledge embeddings,” arXiv preprint arXiv:2206.12617 , 2022.\", \"[136] N. Zhang, X. Xie, X. Chen, S. Deng, C. Tan, F. Huang,\", \"X. Cheng, and H. Chen, “Reasoning through memorization:\", \"Nearest neighbor knowledge graph embeddings,” arXiv preprint\", \"arXiv:2201.05575 , 2022.\", \"[137] X. Xie, Z. Li, X. Wang, Y. Zhu, N. Zhang, J. Zhang, S. Cheng,\", \"B. Tian, S. Deng, F. Xiong, and H. Chen, “Lambdakg: A library\", \"[138] B. Kim, T. Hong, Y. Ko, and J. Seo, “Multi-task learning for knowl-\", \"edge graph completion with pre-trained language models,” in\", \"COLING , 2020, pp. 1737–1743.\", \"[139] X. Lv, Y. Lin, Y. Cao, L. Hou, J. Li, Z. Liu, P . Li, and J. Zhou,\", \"reliable evaluation and a reasonable approach,” in ACL , 2022, pp.\", \"3570–3581.\", \"[140] J. Shen, C. Wang, L. Gong, and D. Song, “Joint language semantic\", \"and structure embedding for knowledge graph completion,” in\", \"COLING , 2022, pp. 1965–1978.\", \"[141] B. Choi, D. Jang, and Y. Ko, “MEM-KGC: masked entity model for\", \"knowledge graph completion with pre-trained language model,”\", \"IEEE Access , vol. 9, pp. 132 025–132 032, 2021.\", \"[142] B. Choi and Y. Ko, “Knowledge graph extension with a pre-\", \"trained language model via unified learning method,” Knowl.\", \"Based Syst. , vol. 262, p. 110245, 2023.\", \"[143] B. Wang, T. Shen, G. Long, T. Zhou, Y. Wang, and Y. Chang,\", \"knowledge graph completion,” in WWW , 2021, pp. 1737–1748.\", \"[144] L. Wang, W. Zhao, Z. Wei, and J. Liu, “Simkgc: Simple contrastive\", \"els,” in ACL , 2022, pp. 4281–4294.\", \"[145] D. Li, M. Yi, and Y. He, “Lp-bert: Multi-task pre-training\", \"knowledge graph bert for link prediction,” arXiv preprint\", \"arXiv:2201.04843 , 2022.\", \"[146] A. Saxena, A. Kochsiek, and R. Gemulla, “Sequence-to-sequence\", \"knowledge graph completion and question answering,” in ACL ,\", \"2022, pp. 2814–2828.\", \"[147] C. Chen, Y. Wang, B. Li, and K. Lam, “Knowledge is flat: A\", \"completion,” in COLING , 2022, pp. 4005–4017.\", \"[148] M. E. Peters, M. Neumann, M. Iyyer, M. Gardner, C. Clark, K. Lee,\", \"and L. Zettlemoyer, “Deep contextualized word representations,”\", \"inNAACL , 2018, pp. 2227–2237.\", \"[149] H. Yan, T. Gui, J. Dai, Q. Guo, Z. Zhang, and X. Qiu, “A unified\", \"generative framework for various NER subtasks,” in ACL , 2021,\", \"[150] Y. Onoe and G. Durrett, “Learning to denoise distantly-labeled\", \"data for entity typing,” in NAACL , 2019, pp. 2407–2417.\", \"[151] Y. Onoe, M. Boratko, A. McCallum, and G. Durrett, “Modeling\", \"fine-grained entity types with box embeddings,” in ACL , 2021,\", \"[152] B. Z. Li, S. Min, S. Iyer, Y. Mehdad, and W. Yih, “Efficient one-\", \"pass end-to-end entity linking for questions,” in EMNLP , 2020,\", \"[153] T. Ayoola, S. Tyagi, J. Fisher, C. Christodoulopoulos, and A. Pier-\", \"leoni, “Refined: An efficient zero-shot-capable approach to end-\", \"to-end entity linking,” in NAACL , 2022, pp. 209–220.\", \"[154] M. Joshi, O. Levy, L. Zettlemoyer, and D. S. Weld, “BERT for\", \"coreference resolution: Baselines and analysis,” in EMNLP , 2019,\", \"[155] M. Joshi, D. Chen, Y. Liu, D. S. Weld, L. Zettlemoyer, and\", \"O. Levy, “Spanbert: Improving pre-training by representing and\", \"predicting spans,” Trans. Assoc. Comput. Linguistics , vol. 8, pp.\", \"64–77, 2020.\", \"[156] A. Caciularu, A. Cohan, I. Beltagy, M. E. Peters, A. Cattan,\", \"and I. Dagan, “CDLM: cross-document language modeling,” in\", \"EMNLP , 2021, pp. 2648–2662.\", \"[157] A. Cattan, A. Eirew, G. Stanovsky, M. Joshi, and I. Dagan, “Cross-\", \"document coreference resolution over predicted mentions,” in\", \"ACL , 2021, pp. 5100–5107.\", \"[158] Y. Wang, Y. Shen, and H. Jin, “An end-to-end actor-critic-based\", \"neural coreference resolution system,” in IEEE International Con-\", \"ference on Acoustics, Speech and Signal Processing, ICASSP 2021,\", \"Toronto, ON, Canada, June 6-11, 2021 , 2021, pp. 7848–7852.\", \"[159] P . Shi and J. Lin, “Simple BERT models for relation extraction and\", \"semantic role labeling,” CoRR , vol. abs/1904.05255, 2019.\", \"JOURNAL OF LATEX CLASS FILES, VOL. ??, NO. ??, MONTH 20YY 25\", \"[160] S. Park and H. Kim, “Improving sentence-level relation extraction\", \"through curriculum learning,” CoRR , vol. abs/2107.09332, 2021.\", \"[161] Y. Ma, A. Wang, and N. Okazaki, “DREEAM: guiding attention\", \"with evidence for improving document-level relation extraction,”\", \"inEACL , 2023, pp. 1963–1975.\", \"[162] Q. Guo, Y. Sun, G. Liu, Z. Wang, Z. Ji, Y. Shen, and X. Wang, “Con-\", \"on bert,” in Web Information Systems and Applications: 18th Inter-\", \"national Conference, WISA 2021, Kaifeng, China, September 24–26,\", \"2021, Proceedings 18 . Springer, 2021, pp. 323–334.\", \"[163] J. Han, N. Collier, W. Buntine, and E. Shareghi, “Pive: Prompt-\", \"capability of llms,” arXiv preprint arXiv:2305.12392 , 2023.\", \"[164] A. Bosselut, H. Rashkin, M. Sap, C. Malaviya, A. Celikyilmaz,\", \"and Y. Choi, “Comet: Commonsense transformers for knowledge\", \"graph construction,” in ACL , 2019.\", \"[165] S. Hao, B. Tan, K. Tang, H. Zhang, E. P . Xing, and Z. Hu, “Bertnet:\", \"els,” arXiv preprint arXiv:2206.14268 , 2022.\", \"[166] P . West, C. Bhagavatula, J. Hessel, J. Hwang, L. Jiang, R. Le Bras,\", \"X. Lu, S. Welleck, and Y. Choi, “Symbolic knowledge distillation:\", \"from general language models to commonsense models,” in\", \"NAACL , 2022, pp. 4602–4625.\", \"[167] L. F. R. Ribeiro, M. Schmitt, H. Sch ¨utze, and I. Gurevych, “Investi-\", \"gating pretrained language models for graph-to-text generation,”\", \"for Conversational AI , 2021, pp. 211–227.\", \"[168] J. Li, T. Tang, W. X. Zhao, Z. Wei, N. J. Yuan, and J.-R. Wen,\", \"language models,” in ACL , 2021, pp. 1558–1568.\", \"[169] A. Colas, M. Alvandipour, and D. Z. Wang, “GAP: A graph-\", \"generation,” in Proceedings of the 29th International Conference on\", \"Computational Linguistics , 2022, pp. 5755–5769.\", \"[170] Z. Jin, Q. Guo, X. Qiu, and Z. Zhang, “GenWiki: A dataset of\", \"1.3 million content-sharing text and graphs for unsupervised\", \"graph-to-text generation,” in Proceedings of the 28th International\", \"Conference on Computational Linguistics , 2020, pp. 2398–2409.\", \"[171] W. Chen, Y. Su, X. Yan, and W. Y. Wang, “KGPT: Knowledge-\", \"grounded pre-training for data-to-text generation,” in EMNLP ,\", \"2020, pp. 8635–8648.\", \"[172] D. Lukovnikov, A. Fischer, and J. Lehmann, “Pretrained trans-\", \"formers for simple question answering over knowledge graphs,”\", \"Conference, Auckland, New Zealand, October 26–30, 2019, Proceed-\", \"ings, Part I 18 . Springer, 2019, pp. 470–486.\", \"[173] D. Luo, J. Su, and S. Yu, “A bert-based approach with relation-\", \"aware attention for knowledge base question answering,” in\", \"IJCNN . IEEE, 2020, pp. 1–8.\", \"[174] N. Hu, Y. Wu, G. Qi, D. Min, J. Chen, J. Z. Pan, and Z. Ali, “An\", \"edge graph question answering,” arXiv preprint arXiv:2303.10368 ,\", \"2023.\", \"[175] Y. Xu, C. Zhu, R. Xu, Y. Liu, M. Zeng, and X. Huang, “Fusing\", \"swering,” in ACL , 2021, pp. 1201–1207.\", \"[176] M. Zhang, R. Dai, M. Dong, and T. He, “Drlk: Dynamic hierar-\", \"question answering,” in EMNLP , 2022, pp. 5123–5133.\", \"[177] Z. Hu, Y. Xu, W. Yu, S. Wang, Z. Yang, C. Zhu, K.-W. Chang, and\", \"Y. Sun, “Empowering language models with knowledge graph\", \"reasoning for open-domain question answering,” in EMNLP ,\", \"2022, pp. 9562–9581.\", \"[178] X. Zhang, A. Bosselut, M. Yasunaga, H. Ren, P . Liang, C. D. Man-\", \"ning, and J. Leskovec, “Greaselm: Graph reasoning enhanced\", \"language models,” in ICLR , 2022.\", \"[179] X. Cao and Y. Liu, “Relmkg: reasoning with pre-trained language\", \"models and knowledge graphs for complex question answering,”\", \"Applied Intelligence , pp. 1–15, 2022.\", \"[180] X. Huang, J. Zhang, D. Li, and P . Li, “Knowledge graph embed-\", \"ding based question answering,” in WSDM , 2019, pp. 105–113.\", \"[181] H. Wang, F. Zhang, X. Xie, and M. Guo, “Dkn: Deep knowledge-\", \"aware network for news recommendation,” in WWW , 2018, pp.\", \"1835–1844.\", \"[182] B. Yang, S. W.-t. Yih, X. He, J. Gao, and L. Deng, “Embedding\", \"bases,” in ICLR , 2015.[183] W. Xiong, M. Yu, S. Chang, X. Guo, and W. Y. Wang, “One-shot\", \"relational learning for knowledge graphs,” in EMNLP , 2018, pp.\", \"1980–1990.\", \"[184] P . Wang, J. Han, C. Li, and R. Pan, “Logic attention based\", \"bedding,” in AAAI , vol. 33, no. 01, 2019, pp. 7152–7159.\", \"[185] Y. Lin, Z. Liu, M. Sun, Y. Liu, and X. Zhu, “Learning entity\", \"and relation embeddings for knowledge graph completion,” in\", \"Proceedings of the AAAI conference on artificial intelligence , vol. 29,\", \"[186] C. Chen, Y. Wang, A. Sun, B. Li, and L. Kwok-Yan, “Dipping plms\", \"completion via conditional soft prompting,” in ACL , 2023.\", \"[187] J. Lovelace and C. P . Ros ´e, “A framework for adapting pre-\", \"trained language models to knowledge graph completion,” in\", \"Language Processing, EMNLP 2022, Abu Dhabi, United Arab Emi-\", \"rates, December 7-11, 2022 , 2022, pp. 5937–5955.\", \"[188] J. Fu, L. Feng, Q. Zhang, X. Huang, and P . Liu, “Larger-context\", \"2021 Conference of the North American Chapter of the Association for\", \"Computational Linguistics: Human Language Technologies, NAACL-\", \"HLT 2021, Online, June 6-11, 2021 , 2021, pp. 1463–1475.\", \"[189] X. Liu, K. Ji, Y. Fu, Z. Du, Z. Yang, and J. Tang, “P-tuning\", \"across scales and tasks,” CoRR , vol. abs/2110.07602, 2021.\", \"[190] J. Yu, B. Bohnet, and M. Poesio, “Named entity recognition as\", \"dependency parsing,” in ACL , 2020, pp. 6470–6476.\", \"[191] F. Li, Z. Lin, M. Zhang, and D. Ji, “A span-based model for\", \"joint overlapped and discontinuous named entity recognition,”\", \"inACL , 2021, pp. 4814–4828.\", \"[192] C. Tan, W. Qiu, M. Chen, R. Wang, and F. Huang, “Boundary\", \"recognition,” in The Thirty-Fourth AAAI Conference on Artificial\", \"Intelligence, AAAI 2020, The Thirty-Second Innovative Applications\", \"of Artificial Intelligence Conference, IAAI 2020, The Tenth AAAI\", \"Symposium on Educational Advances in Artificial Intelligence, EAAI\", \"2020, New York, NY, USA, February 7-12, 2020 , 2020, pp. 9016–9023.\", \"[193] Y. Xu, H. Huang, C. Feng, and Y. Hu, “A supervised multi-head\", \"self-attention network for nested named entity recognition,” in\", \"Thirty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2021,\", \"ligence, IAAI 2021, The Eleventh Symposium on Educational Advances\", \"in Artificial Intelligence, EAAI 2021, Virtual Event, February 2-9,\", \"2021 , 2021, pp. 14 185–14 193.\", \"[194] J. Yu, B. Ji, S. Li, J. Ma, H. Liu, and H. Xu, “S-NER: A concise\", \"and efficient span-based model for named entity recognition,”\", \"Sensors , vol. 22, no. 8, p. 2852, 2022.\", \"[195] Y. Fu, C. Tan, M. Chen, S. Huang, and F. Huang, “Nested named\", \"entity recognition with partially-observed treecrfs,” in AAAI ,\", \"2021, pp. 12 839–12 847.\", \"[196] C. Lou, S. Yang, and K. Tu, “Nested named entity recognition\", \"as latent lexicalized constituency parsing,” in Proceedings of the\", \"60th Annual Meeting of the Association for Computational Linguistics\", \"(Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May 22-27,\", \"2022 , 2022, pp. 6183–6198.\", \"[197] S. Yang and K. Tu, “Bottom-up constituency parsing and nested\", \"named entity recognition with pointer networks,” in Proceedings\", \"Linguistics (Volume 1: Long Papers), ACL 2022, Dublin, Ireland, May\", \"22-27, 2022 , 2022, pp. 2403–2416.\", \"[198] F. Li, Z. Lin, M. Zhang, and D. Ji, “A span-based model for\", \"joint overlapped and discontinuous named entity recognition,”\", \"on Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long\", \"Papers), Virtual Event, August 1-6, 2021 , 2021, pp. 4814–4828.\", \"[199] Q. Liu, H. Lin, X. Xiao, X. Han, L. Sun, and H. Wu, “Fine-grained\", \"entity typing via label reasoning,” in Proceedings of the 2021\", \"Conference on Empirical Methods in Natural Language Processing,\", \"EMNLP 2021, Virtual Event / Punta Cana, Dominican Republic, 7-11\", \"November, 2021 , 2021, pp. 4611–4622.\", \"[200] H. Dai, Y. Song, and H. Wang, “Ultra-fine entity typing with\", \"weak supervision from a masked language model,” in Proceedings\", \"Language Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers),\", \"Virtual Event, August 1-6, 2021 , 2021, pp. 1790–1799.\", \"JOURNAL OF LATEX CLASS FILES, VOL. ??, NO. ??, MONTH 20YY 26\", \"[201] N. Ding, Y. Chen, X. Han, G. Xu, X. Wang, P . Xie, H. Zheng,\", \"Z. Liu, J. Li, and H. Kim, “Prompt-learning for fine-grained entity\", \"typing,” in Findings of the Association for Computational Linguistics:\", \"EMNLP 2022, Abu Dhabi, United Arab Emirates, December 7-11,\", \"2022 , 2022, pp. 6888–6901.\", \"[202] W. Pan, W. Wei, and F. Zhu, “Automatic noisy label correction\", \"for fine-grained entity typing,” in Proceedings of the Thirty-First\", \"International Joint Conference on Artificial Intelligence, IJCAI 2022,\", \"Vienna, Austria, 23-29 July 2022 , 2022, pp. 4317–4323.\", \"[203] B. Li, W. Yin, and M. Chen, “Ultra-fine entity typing with indi-\", \"rect supervision from natural language inference,” Trans. Assoc.\", \"Comput. Linguistics , vol. 10, pp. 607–622, 2022.\", \"[204] S. Broscheit, “Investigating entity knowledge in BERT with sim-\", \"ple neural end-to-end entity linking,” CoRR , vol. abs/2003.05473,\", \"2020.\", \"[205] N. D. Cao, G. Izacard, S. Riedel, and F. Petroni, “Autoregressive\", \"entity retrieval,” in 9th ICLR, ICLR 2021, Virtual Event, Austria,\", \"May 3-7, 2021 , 2021.\", \"[206] N. D. Cao, L. Wu, K. Popat, M. Artetxe, N. Goyal, M. Plekhanov,\", \"L. Zettlemoyer, N. Cancedda, S. Riedel, and F. Petroni, “Mul-\", \"tilingual autoregressive entity linking,” Trans. Assoc. Comput.\", \"Linguistics , vol. 10, pp. 274–290, 2022.\", \"[207] N. D. Cao, W. Aziz, and I. Titov, “Highly parallel autoregressive\", \"entity linking with discriminative correction,” in Proceedings of\", \"Processing, EMNLP 2021, Virtual Event / Punta Cana, Dominican\", \"Republic, 7-11 November, 2021 , 2021, pp. 7662–7669.\", \"[208] K. Lee, L. He, and L. Zettlemoyer, “Higher-order coreference\", \"resolution with coarse-to-fine inference,” in NAACL , 2018, pp.\", \"687–692.\", \"[209] T. M. Lai, T. Bui, and D. S. Kim, “End-to-end neural coreference\", \"resolution revisited: A simple yet effective baseline,” in IEEE\", \"International Conference on Acoustics, Speech and Signal Processing,\", \"ICASSP 2022, Virtual and Singapore, 23-27 May 2022 , 2022, pp.\", \"8147–8151.\", \"[210] W. Wu, F. Wang, A. Yuan, F. Wu, and J. Li, “Corefqa: Coreference\", \"resolution as query-based span prediction,” in Proceedings of the\", \"58th Annual Meeting of the Association for Computational Linguistics,\", \"ACL 2020, Online, July 5-10, 2020 , 2020, pp. 6953–6963.\", \"[211] T. M. Lai, H. Ji, T. Bui, Q. H. Tran, F. Dernoncourt, and W. Chang,\", \"semantics into event coreference resolution,” in Proceedings of the\", \"2021 Conference of the North American Chapter of the Association for\", \"Computational Linguistics: Human Language Technologies, NAACL-\", \"HLT 2021, Online, June 6-11, 2021 , 2021, pp. 3491–3499.\", \"[212] Y. Kirstain, O. Ram, and O. Levy, “Coreference resolution without\", \"span representations,” in Proceedings of the 59th Annual Meeting of\", \"tional Joint Conference on Natural Language Processing, ACL/IJCNLP\", \"2021, (Volume 2: Short Papers), Virtual Event, August 1-6, 2021 ,\", \"2021, pp. 14–19.\", \"[213] R. Thirukovalluru, N. Monath, K. Shridhar, M. Zaheer,\", \"M. Sachan, and A. McCallum, “Scaling within document corefer-\", \"ence to long texts,” in Findings of the Association for Computational\", \"Linguistics: ACL/IJCNLP 2021, Online Event, August 1-6, 2021 , ser.\", \"Findings of ACL, vol. ACL/IJCNLP 2021, 2021, pp. 3921–3931.\", \"[214] I. Beltagy, M. E. Peters, and A. Cohan, “Longformer: The long-\", \"document transformer,” CoRR , vol. abs/2004.05150, 2020.\", \"[215] C. Alt, M. H ¨ubner, and L. Hennig, “Improving relation extraction\", \"by pre-trained language representations,” in 1st Conference on\", \"Automated Knowledge Base Construction, AKBC 2019, Amherst, MA,\", \"USA, May 20-22, 2019 , 2019.\", \"[216] L. B. Soares, N. FitzGerald, J. Ling, and T. Kwiatkowski, “Match-\", \"ing the blanks: Distributional similarity for relation learning,” in\", \"ACL , 2019, pp. 2895–2905.\", \"[217] S. Lyu and H. Chen, “Relation classification with entity type\", \"restriction,” in Findings of the Association for Computational Lin-\", \"guistics: ACL/IJCNLP 2021, Online Event, August 1-6, 2021 , ser.\", \"Findings of ACL, vol. ACL/IJCNLP 2021, 2021, pp. 390–395.\", \"[218] J. Zheng and Z. Chen, “Sentence-level relation extraction via\", \"contrastive learning with descriptive relation prompts,” CoRR ,\", \"vol. abs/2304.04935, 2023.\", \"[219] H. Wang, C. Focke, R. Sylvester, N. Mishra, and W. Y. Wang,\", \"“Fine-tune bert for docred with two-step process,” CoRR , vol.\", \"abs/1909.11898, 2019.\", \"[220] H. Tang, Y. Cao, Z. Zhang, J. Cao, F. Fang, S. Wang, and P . Yin,\", \"“HIN: hierarchical inference network for document-level relationextraction,” in P AKDD , ser. Lecture Notes in Computer Science,\", \"vol. 12084, 2020, pp. 197–209.\", \"[221] D. Wang, W. Hu, E. Cao, and W. Sun, “Global-to-local neural\", \"networks for document-level relation extraction,” in Proceedings\", \"Processing, EMNLP 2020, Online, November 16-20, 2020 , 2020, pp.\", \"3711–3721.\", \"[222] S. Zeng, Y. Wu, and B. Chang, “SIRE: separate intra- and\", \"tion,” in Findings of the Association for Computational Linguistics:\", \"ACL/IJCNLP 2021, Online Event, August 1-6, 2021 , ser. Findings of\", \"ACL, vol. ACL/IJCNLP 2021, 2021, pp. 524–534.\", \"[223] G. Nan, Z. Guo, I. Sekulic, and W. Lu, “Reasoning with latent\", \"structure refinement for document-level relation extraction,” in\", \"ACL , 2020, pp. 1546–1557.\", \"[224] S. Zeng, R. Xu, B. Chang, and L. Li, “Double graph based\", \"reasoning for document-level relation extraction,” in Proceedings\", \"Processing, EMNLP 2020, Online, November 16-20, 2020 , 2020, pp.\", \"1630–1640.\", \"[225] N. Zhang, X. Chen, X. Xie, S. Deng, C. Tan, M. Chen, F. Huang,\", \"L. Si, and H. Chen, “Document-level relation extraction as se-\", \"mantic segmentation,” in IJCAI , 2021, pp. 3999–4006.\", \"[226] O. Ronneberger, P . Fischer, and T. Brox, “U-net: Convolutional\", \"networks for biomedical image segmentation,” in Medical Image\", \"18th International Conference Munich, Germany, October 5 - 9, 2015,\", \"Proceedings, Part III , ser. Lecture Notes in Computer Science, vol.\", \"9351, 2015, pp. 234–241.\", \"[227] W. Zhou, K. Huang, T. Ma, and J. Huang, “Document-level rela-\", \"pooling,” in AAAI , 2021, pp. 14 612–14 620.\", \"[228] C. Gardent, A. Shimorina, S. Narayan, and L. Perez-Beltrachini,\", \"“The WebNLG challenge: Generating text from RDF data,” in\", \"Generation , 2017, pp. 124–133.\", \"[229] J. Guan, Y. Wang, and M. Huang, “Story ending generation with\", \"incremental encoding and commonsense knowledge,” in AAAI ,\", \"2019, pp. 6473–6480.\", \"[230] H. Zhou, T. Young, M. Huang, H. Zhao, J. Xu, and X. Zhu,\", \"graph attention,” in IJCAI , 2018, pp. 4623–4629.\", \"[231] M. Kale and A. Rastogi, “Text-to-text pre-training for data-to-text\", \"tasks,” in Proceedings of the 13th International Conference on Natural\", \"Language Generation , 2020, pp. 97–102.\", \"[232] M. Mintz, S. Bills, R. Snow, and D. Jurafsky, “Distant supervision\", \"for relation extraction without labeled data,” in ACL , 2009, pp.\", \"1003–1011.\", \"[233] A. Saxena, A. Tripathi, and P . Talukdar, “Improving multi-hop\", \"base embeddings,” in ACL , 2020, pp. 4498–4507.\", \"[234] Y. Feng, X. Chen, B. Y. Lin, P . Wang, J. Yan, and X. Ren, “Scalable\", \"answering,” in EMNLP , 2020, pp. 1295–1309.\", \"[235] Y. Yan, R. Li, S. Wang, H. Zhang, Z. Daoguang, F. Zhang, W. Wu,\", \"and W. Xu, “Large-scale relation learning for question answering\", \"over knowledge bases with pre-trained language models,” in\", \"EMNLP , 2021, pp. 3653–3660.\", \"[236] J. Zhang, X. Zhang, J. Yu, J. Tang, J. Tang, C. Li, and H. Chen,\", \"base question answering,” in ACL (Volume 1: Long Papers) , 2022,\", \"[237] J. Jiang, K. Zhou, Z. Dong, K. Ye, W. X. Zhao, and J.-R. Wen,\", \"reason over structured data,” arXiv preprint arXiv:2305.09645 ,\", \"2023.\", \"[238] H. Zhu, H. Peng, Z. Lyu, L. Hou, J. Li, and J. Xiao, “Pre-training\", \"knowledge into a unified representation,” Expert Systems with\", \"Applications , vol. 215, p. 119369, 2023.\", \"[239] C. Feng, X. Zhang, and Z. Fei, “Knowledge solver: Teaching llms\", \"to search for domain knowledge from knowledge graphs,” arXiv\", \"preprint arXiv:2309.03118 , 2023.\", \"[240] J. Sun, C. Xu, L. Tang, S. Wang, C. Lin, Y. Gong, H.-Y. Shum,\", \"and J. Guo, “Think-on-graph: Deep and responsible reasoning\", \"of large language model with knowledge graph,” arXiv preprint\", \"arXiv:2307.07697 , 2023.\", \"JOURNAL OF LATEX CLASS FILES, VOL. ??, NO. ??, MONTH 20YY 27\", \"[241] B. He, D. Zhou, J. Xiao, X. Jiang, Q. Liu, N. J. Yuan, and T. Xu,\", \"pre-trained language models,” in EMNLP , 2020, pp. 2281–2290.\", \"[242] Y. Su, X. Han, Z. Zhang, Y. Lin, P . Li, Z. Liu, J. Zhou, and M. Sun,\", \"wards enhanced pre-trained language models,” AI Open , vol. 2,\", \"[243] D. Yu, C. Zhu, Y. Yang, and M. Zeng, “JAKET: joint pre-training of\", \"knowledge graph and language understanding,” in AAAI , 2022,\", \"[244] X. Wang, P . Kapanipathi, R. Musa, M. Yu, K. Talamadupula,\", \"I. Abdelaziz, M. Chang, A. Fokoue, B. Makni, N. Mattei, and\", \"M. Witbrock, “Improving natural language inference using exter-\", \"nal knowledge in the science questions domain,” in AAAI , 2019,\", \"[245] Y. Sun, Q. Shi, L. Qi, and Y. Zhang, “JointLK: Joint reasoning\", \"question answering,” in NAACL , 2022, pp. 5049–5060.\", \"[246] X. Liu, H. Yu, H. Zhang, Y. Xu, X. Lei, H. Lai, Y. Gu, H. Ding,\", \"K. Men, K. Yang et al. , “Agentbench: Evaluating llms as agents,”\", \"arXiv preprint arXiv:2308.03688 , 2023.\", \"[247] Y. Wang, N. Lipka, R. A. Rossi, A. Siu, R. Zhang, and T. Derr,\", \"swering,” arXiv preprint arXiv:2308.11730 , 2023.\", \"[248] A. Zeng, M. Liu, R. Lu, B. Wang, X. Liu, Y. Dong, and J. Tang,\", \"“Agenttuning: Enabling generalized agent abilities for llms,”\", \"2023.\", \"[249] W. Kry ´sci´nski, B. McCann, C. Xiong, and R. Socher, “Evaluating\", \"the factual consistency of abstractive text summarization,” arXiv\", \"preprint arXiv:1910.12840 , 2019.\", \"[250] Z. Ji, Z. Liu, N. Lee, T. Yu, B. Wilie, M. Zeng, and P . Fung, “Rho\", \"(\\\\ρ): Reducing hallucination in open-domain dialogues with\", \"knowledge grounding,” arXiv preprint arXiv:2212.01588 , 2022.\", \"[251] S. Feng, V . Balachandran, Y. Bai, and Y. Tsvetkov, “Factkb: Gen-\", \"with factual knowledge,” arXiv preprint arXiv:2305.08281 , 2023.\", \"[252] Y. Yao, P . Wang, B. Tian, S. Cheng, Z. Li, S. Deng, H. Chen, and\", \"N. Zhang, “Editing large language models: Problems, methods,\", \"and opportunities,” arXiv preprint arXiv:2305.13172 , 2023.\", \"[253] Z. Li, N. Zhang, Y. Yao, M. Wang, X. Chen, and H. Chen,\", \"models,” arXiv preprint arXiv:2310.02129 , 2023.\", \"[254] R. Cohen, E. Biran, O. Yoran, A. Globerson, and M. Geva,\", \"models,” arXiv preprint arXiv:2307.12976 , 2023.\", \"[255] S. Diao, Z. Huang, R. Xu, X. Li, Y. Lin, X. Zhou, and T. Zhang,\", \"“Black-box prompt learning for pre-trained language models,”\", \"arXiv preprint arXiv:2201.08531 , 2022.\", \"[256] T. Sun, Y. Shao, H. Qian, X. Huang, and X. Qiu, “Black-box tuning\", \"for language-model-as-a-service,” in International Conference on\", \"Machine Learning . PMLR, 2022, pp. 20 841–20 855.\", \"[257] X. Chen, A. Shrivastava, and A. Gupta, “NEIL: extracting visual\", \"knowledge from web data,” in IEEE International Conference on\", \"Computer Vision, ICCV 2013, Sydney, Australia, December 1-8, 2013 ,\", \"2013, pp. 1409–1416.\", \"[258] M. Warren and P . J. Hayes, “Bounding ambiguity: Experiences\", \"with an image annotation system,” in Proceedings of the 1st Work-\", \"shop on Subjectivity, Ambiguity and Disagreement in Crowdsourcing ,\", \"ser. CEUR Workshop Proceedings, vol. 2276, 2018, pp. 41–54.\", \"[259] Z. Chen, Y. Huang, J. Chen, Y. Geng, Y. Fang, J. Z. Pan, N. Zhang,\", \"and W. Zhang, “Lako: Knowledge-driven visual estion answer-\", \"ing via late knowledge-to-text injection,” 2022.\", \"[260] R. Girdhar, A. El-Nouby, Z. Liu, M. Singh, K. V . Alwala, A. Joulin,\", \"and I. Misra, “Imagebind: One embedding space to bind them\", \"all,” in ICCV , 2023, pp. 15 180–15 190.\", \"[261] J. Zhang, Z. Yin, P . Chen, and S. Nichele, “Emotion recognition\", \"tutorial and review,” Information Fusion , vol. 59, pp. 103–126,\", \"2020.\", \"[262] H. Zhang, B. Wu, X. Yuan, S. Pan, H. Tong, and J. Pei, “Trust-\", \"worthy graph neural networks: Aspects, methods and trends,”\", \"arXiv:2205.07424 , 2022.\", \"[263] T. Wu, M. Caccia, Z. Li, Y.-F. Li, G. Qi, and G. Haffari, “Pretrained\", \"language model in continual learning: A comparative study,” in\", \"[264] X. L. Li, A. Kuncoro, J. Hoffmann, C. de Masson d’Autume,\", \"P . Blunsom, and A. Nematzadeh, “A systematic investigation of\", \"commonsense knowledge in large language models,” in Proceed-\", \"Processing , 2022, pp. 11 838–11 855.[265] Y. Zheng, H. Y. Koh, J. Ju, A. T. Nguyen, L. T. May, G. I. Webb, and\", \"S. Pan, “Large language models for scientific synthesis, inference\", \"and explanation,” arXiv preprint arXiv:2310.07984 , 2023.\", \"[266] B. Min, H. Ross, E. Sulem, A. P . B. Veyseh, T. H. Nguyen, O. Sainz,\", \"E. Agirre, I. Heintz, and D. Roth, “Recent advances in natural\", \"survey,” ACM Computing Surveys , vol. 56, no. 2, pp. 1–40, 2023.\", \"[267] J. Wei, M. Bosma, V . Zhao, K. Guu, A. W. Yu, B. Lester, N. Du,\", \"A. M. Dai, and Q. V . Le, “Finetuned language models are zero-\", \"shot learners,” in International Conference on Learning Representa-\", \"[268] Y. Zhang, Y. Li, L. Cui, D. Cai, L. Liu, T. Fu, X. Huang, E. Zhao,\", \"Y. Zhang, Y. Chen, L. Wang, A. T. Luu, W. Bi, F. Shi, and S. Shi,\", \"language models,” arXiv preprint arXiv:2309.01219 , 2023.\", \"In this section, we introduce the pros and cons of LLMs and\", \"and KGs in Fig. 1, respectively.\", \"scale corpora, which contain a large amount of gen-\", \"eral knowledge, such as commonsense knowledge\", \"[264] and factual knowledge [14]. Such knowledge\", \"Therefore, LLMs can be used in many natural lan-\", \"guage processing tasks, such as question answering\", \"[4], machine translation [5], and text generation [6].\", \"ity, which can be applied to various downstream\", \"finetuning on multi-task data [3], LLMs achieve great\", \"erating from a probability model, which is an in-\", \"from the probability distribution, which is difficult to\", \"JOURNAL OF LATEX CLASS FILES, VOL. ??, NO. ??, MONTH 20YY 28\", \"tural format (i.e., triples), which can be understand-\", \"curated or validated by experts, which are more\", \"in KGs is also deterministic, which can provide deci-\", \"bolic reasoning ability, which provides an inter-\", \"often incomplete, which limits the ability of KGs to\", \"KGs model the structure of knowledge, but ignore\", \"tion in KGs is often ignored in KG-related tasks, such\", \"•Unseen Facts [27]: KGs are dynamically changing,\"], \"error\": null}, \"b3d472d1\": {\"success\": true, \"paper_id\": \"b3d472d1\", \"url\": \"https://arxiv.org/pdf/1908.02146v2\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_b3d472d1.pdf\", \"extracted_info\": {\"title\": \"Knowledge Query Network for Interpretable Knowledge Tracing\", \"authors\": [\"Not specified in provided content\"], \"abstract\": \"Knowledge Tracing (KT) aims to model and trace the evolving knowledge state of students as they solve sequences of problems. Existing KT methods either suffer from low prediction accuracy or lack interpretability. This paper proposes a novel KT model that improves prediction performance while providing intuitive explanations of knowledge interactions.\", \"methodology\": \"The authors propose a Knowledge Query Network (KQN) architecture, introducing the concept of probabilistic skill similarity to generalize and interpret knowledge interactions. The model uses a recurrent neural network (RNN) layer (GRU) combined with a multilayer perceptron (MLP) for prediction tasks. Experiments were conducted on four datasets (ASSIST2009, ASSIST2015, Statics2011, Synthetic-5) for tasks including correctness prediction, knowledge interaction visualization, skill clustering, and skill similarity measurement. Hyperparameters such as hidden state sizes and optimization with Adam were tuned for performance evaluation.\", \"results\": \"KQN achieved higher AUC scores than existing models (IRT, BKT, DKVMN, DKT) across all datasets: ASSIST2009 (82.32%), ASSIST2015 (73.40%), Statics2011 (83.20%), Synthetic-5 (82.81%). Clustering tasks showed high Adjusted Rand Index (ARI) scores, and Mantel tests confirmed statistically significant correlations (p=0.001) between skill similarity measures and ground truth distances.\", \"conclusion\": \"(1) KQN outperforms previous KT models in prediction accuracy across multiple datasets. (2) The model provides interpretable visualizations of knowledge interactions. (3) Probabilistic skill similarity enables effective skill clustering and similarity measurement. (4) The approach demonstrates strong generalization across diverse educational datasets.\", \"figures\": null, \"tables\": null}, \"citations\": [\"[1]John R. Anderson, C. Franklin Boyle, Albert T. Corbett, and Matthew W. Lewis.\", \"1990. Cognitive Modeling and Intelligent Tutoring. Artif. Intell. 42, 1 (Feb. 1990),\", \"7–49. https://doi.org/10.1016/0004-3702(90)90093-F\", \"[2]Hao Cen, Kenneth Koedinger, and Brian Junker. 2006. Learning factors analysis–a\", \"Conference on Intelligent Tutoring Systems . Springer, 164–175.\", \"[3]Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau,\", \"Fethi Bougares, Holger Schwenk, and Yoshua Bengio. 2014. Learning Phrase\", \"[4]Mingyu Feng, Neil Heffernan, and Kenneth Koedinger. 2009. Addressing the\", \"Modeling and User-Adapted Interaction 19, 3 (2009), 243–266.\", \"[5]Alex Graves, Greg Wayne, and Ivo Danihelka. 2014. Neural Turing Machines.\", \"[6]Sepp Hochreiter and Jürgen Schmidhuber. 1997. Long short-term memory. Neural\", \"Computation 9, 8 (1997), 1735–1780.\", \"[7]Lawrence Hubert and Phipps Arabie. 1985. Comparing partitions. Journal of\", \"Classification 2, 1 (1985), 193–218.\", \"[8]Charles Lee Hulin, Fritz Drasgow, and Charles K Parsons. 1983. Item response\", \"[9]Andreas M Kaplan and Michael Haenlein. 2016. Higher education and the digital\", \"revolution: About MOOCs, SPOCs, social media, and the Cookie Monster. Business\", \"Horizons 59, 4 (2016), 441–450.\", \"[10] Mohammad Khajah, Robert V Lindsey, and Michael C Mozer. 2016. How deep is\", \"[11] Diederik P Kingma and Jimmy Ba. 2014. Adam: A method for stochastic opti-\", \"[12] Kenneth R Koedinger, Ryan SJd Baker, Kyle Cunningham, Alida Skogsholm, Brett\", \"Leber, and John Stamper. 2010. A data repository for the EDM community: The\", \"9\", \"PSLC DataShop. Handbook of educational data mining 43 (2010), 43–56.\", \"[13] Pierre Legendre and Louis Legendre. 1998. Numerical Ecology, Volume 24,\", \"(Developments in Environmental Modelling).\", \"[14] Vinod Nair and Geoffrey E Hinton. 2010. Rectified linear units improve re-\", \"[15] Hyacinth S Nwana. 1990. Intelligent tutoring systems: an overview. Artificial\", \"Intelligence Review 4, 4 (1990), 251–277.\", \"[16] Philip I Pavlik, Hao Cen, and Kenneth R Koedinger. 2009. Performance Fac-\", \"[17] Radek Pelánek. 2017. Bayesian knowledge tracing, logistic models, and beyond:\", \"Interaction 27, 3-5 (2017), 313–350.\", \"[18] Chris Piech, Jonathan Bassen, Jonathan Huang, Surya Ganguli, Mehran Sahami,\", \"Leonidas J Guibas, and Jascha Sohl-Dickstein. 2015. Deep knowledge tracing. In\", \"[19] Nitish Srivastava, Geoffrey Hinton, Alex Krizhevsky, Ilya Sutskever, and Ruslan\", \"overfitting. Journal of Machine Learning Research 15, 1 (2014), 1929–1958.\", \"[20] Jason Weston, Sumit Chopra, and Antoine Bordes. 2014. Memory networks.\", \"[21] Kevin H Wilson, Yan Karklin, Bojian Han, and Chaitanya Ekanadham. 2016.\", \"[22] Xiaolu Xiong, Siyuan Zhao, Eric Van Inwegen, and Joseph Beck. 2016. Going\", \"[23] Chun-Kit Yeung and Dit-Yan Yeung. 2018. Addressing two problems in deep\", \"Fifth Annual ACM Conference on Learning at Scale . ACM, 5.\", \"[24] Michael V Yudelson, Kenneth R Koedinger, and Geoffrey J Gordon. 2013. Indi-\", \"Artificial Intelligence in Education . Springer, 171–180.\", \"[25] Wojciech Zaremba, Ilya Sutskever, and Oriol Vinyals. 2014. Recurrent neural\", \"[26] Jiani Zhang, Xingjian Shi, Irwin King, and Dit-Yan Yeung. 2017. Dynamic key-\", \"10\"], \"error\": null}, \"1e02aebc\": {\"success\": true, \"paper_id\": \"1e02aebc\", \"url\": \"https://arxiv.org/pdf/2311.17771v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_1e02aebc.pdf\", \"extracted_info\": {\"title\": \"Enhanced Centroid Method for Multi-Document Summarization with Multilingual Capabilities\", \"authors\": [\"Not specified\"], \"abstract\": \"The centroid method is a simple approach for extractive multi-document summarization, and many improvements to its pipeline have been proposed. In this work, we refine the centroid method further, leading to improved results. We demonstrate these improvements on several multi-document summarization datasets, including in a multilingual scenario.\", \"methodology\": \"The proposed approach enhances the traditional centroid method through two main stages: (1) using multilingual sentence embeddings to represent document clusters, enabling summarization across multiple languages; (2) applying a beam search (BS) followed by a greedy search (GS) for sentence selection. Additionally, a centroid estimation model (CeRA and CeRAI) is introduced, which predicts the centroid from reference summaries to improve sentence ranking. The methodology is evaluated on four English datasets (Multi-News, WCEP-10, TAC2008, DUC2004) and multilingual datasets (CrossSum, CrossSum-ZS) using ROUGE metrics. Comparisons are made against existing centroid-based methods and baselines.\", \"results\": \"In monolingual settings, BS alone outperforms the Gholipour Ghalandari (2017) baseline across all datasets, with further gains from the centroid estimation models (CeRA, CeRAI). In multilingual settings, CeRA and CeRAI achieve superior ROUGE-2 recall scores compared to all other methods, performing well even in zero-shot scenarios. The \\\"Oracle centroid\\\" results indicate the potential upper bound of the method. The improvements are consistent across datasets, with notable performance boosts in harder summarization scenarios.\", \"conclusion\": \"The key contributions are: (1) an enhanced centroid method incorporating multilingual sentence embeddings for cross-lingual multi-document summarization; (2) a novel two-stage sentence selection pipeline combining beam search and greedy search; (3) introduction of a centroid estimation model (CeRA, CeRAI) that predicts centroids from reference summaries, improving extractive summarization quality; (4) demonstration of strong performance across multiple monolingual and multilingual datasets, including zero-shot settings; (5) provision of a robust, competitive, and relatively simple extractive summarization approach despite increased computational complexity.\", \"figures\": null, \"tables\": null}, \"citations\": [\"51st Annual Meeting of the Association for Compu-\", \"tational Linguistics (Volume 1: Long Papers) , pages\", \"196–206, Sofia, Bulgaria. Association for Computa-\", \"Abdelkrime Aries, Djamel Eddine Zegour, and\", \"course and Dialogue , pages 237–244, Prague, Czech\", \"Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E.\", \"Abhik Bhattacharjee, Tahmid Hasan, Wasi Uddin Ah-\", \"mad, Yuan-Fang Li, Yong-Bin Kang, and Rifat\", \"cross-lingual summarization for 1,500+ language\", \"ume 1: Long Papers) , pages 2541–2564, Toronto,\", \"Steven Bird, Ewan Klein, and Edward Loper. 2009. Nat-\", \"with the natural language toolkit . \\\"O’Reilly Media,\", \"Ziqiang Cao, Furu Wei, Li Dong, Sujian Li, and Ming\", \"intelligence , volume 29.\", \"MMR, diversity-based reranking for reordering doc-\", \"retrieval , pages 335–336.\", \"Sangwoo Cho, Chen Li, Dong Yu, Hassan Foroosh, and\", \"on New Frontiers in Summarization , pages 98–103,\", \"Hong Kong, China. Association for Computational\", \"Jacob Devlin, Ming-Wei Chang, Kenton Lee, and\", \"nologies, Volume 1 (Long and Short Papers) , pages\", \"4171–4186, Minneapolis, Minnesota. Association for\", \"Alexander Fabbri, Irene Li, Tianwei She, Suyi Li, and\", \"Linguistics , pages 1074–1084, Florence, Italy. Asso-\", \"Angela Fan, Shruti Bhosale, Holger Schwenk, Zhiyi\", \"Ma, Ahmed El-Kishky, Siddharth Goyal, Mandeep\", \"Baines, Onur Celebi, Guillaume Wenzek, Vishrav\", \"Chaudhary, et al. 2021. Beyond english-centric multi-\", \"Learning Research , 22(1):4839–4886.\", \"Demian Gholipour Ghalandari, Chris Hokamp,\", \"Nghia The Pham, John Glover, and Georgiana Ifrim.\", \"2020. A large-scale multi-document summarization\", \"Workshop on New Frontiers in Summarization , pages\", \"85–90, Copenhagen, Denmark. Association for Com-\", \"Demian Gholipour Ghalandari, Chris Hokamp,\", \"Nghia The Pham, John Glover, and Georgiana Ifrim.\", \"2020. A large-scale multi-document summarization\", \"Association for Computational Linguistics , pages\", \"1302–1308, Online. Association for Computational\", \"2013 MultiLing workshop. In Proceedings of the\", \"document Summarization , pages 20–28, Sofia, Bul-\", \"George Giannakopoulos, Jeff Kubina, John Conroy,\", \"Josef Steinberger, Benoit Favre, Mijail Kabadjov,\", \"Udo Kruschwitz, and Massimo Poesio. 2015. Mul-\", \"and multi-documents, on-line fora, and call-center\", \"and Dialogue , pages 270–274, Prague, Czech Repub-\", \"Daniel Gillick, Benoit Favre, and Dilek Hakkani-Tür.\", \"2008. The ICSI summarization system at TAC 2008.\", \"Tahmid Hasan, Abhik Bhattacharjee, Md. Saiful Is-\", \"lam, Kazi Mubasshir, Yuan-Fang Li, Yong-Bin Kang,\", \"M. Sohel Rahman, and Rifat Shahriyar. 2021. XL-\", \"for Computational Linguistics: ACL-IJCNLP 2021 ,\", \"pages 4693–4703, Online. Association for Computa-\", \"Computational Linguistics , pages 712–721, Gothen-\", \"burg, Sweden. Association for Computational Lin-\", \"Taiwen Huang, Lei Li, and Yazhao Zhang. 2016. Mul-\", \"on Naturally Annotated Big Data , pages 299–312,\", \"Hanqi Jin, Tianming Wang, and Xiaojun Wan. 2020.\", \"ciation for Computational Linguistics , pages 6244–\", \"6254, Online. Association for Computational Lin-\", \"Salima Lamsiyah, Abdelkader El Mahdaouy, Bernard\", \"Espinasse, and Saïd El Alaoui Ouatik. 2021. An\", \"tence embeddings. Expert Systems with Applications ,\", \"167:114152.\", \"tion Branches Out , pages 74–81, Barcelona, Spain.\", \"tilingual Multi-document Summarization , pages 45–\", \"49, Sofia, Bulgaria. Association for Computational\", \"ciation for Computational Linguistics , pages 5070–\", \"5081, Florence, Italy. Association for Computational\", \"ropean Conference on Information Retrieval , pages\", \"557–564. Springer.\", \"Afonso Mendes, Shashi Narayan, Sebastião Miranda,\", \"Zita Marinho, André F. T. Martins, and Shay B. Co-\", \"Linguistics: Human Language Technologies, Volume\", \"1 (Long and Short Papers) , pages 3955–3966, Min-\", \"neapolis, Minnesota. Association for Computational\", \"Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-\", \"rado, and Jeff Dean. 2013. Distributed representa-\", \"tems, volume 26. Curran Associates, Inc.\", \"Shashi Narayan, Shay B. Cohen, and Mirella Lapata.\", \"2018. Ranking sentences for extractive summariza-\", \"Human Language Technologies, Volume 1 (Long Pa-\", \"pers) , pages 1747–1759, New Orleans, Louisiana.\", \"Matthew E. Peters, Mark Neumann, Mohit Iyyer, Matt\", \"Gardner, Christopher Clark, Kenton Lee, and Luke\", \"nologies, Volume 1 (Long Papers) , pages 2227–2237,\", \"New Orleans, Louisiana. Association for Computa-\", \"Dragomir R. Radev, Hongyan Jing, and Malgorzata\", \"of multiple documents: sentence extraction, utility-\", \"based evaluation, and user studies. In NAACL-ANLP\", \"2000 Workshop: Automatic Summarization .\", \"Gaetano Rossiello, Pierpaolo Basile, and Giovanni Se-\", \"Types and Genres , pages 12–21, Valencia, Spain. As-\", \"Krysta Svore, Lucy Vanderwende, and Christopher\", \"Learning (EMNLP-CoNLL) , pages 448–457, Prague,\", \"ing and Computational Natural Language Learning ,\", \"pages 233–243, Jeju Island, Korea. Association for\", \"Wen Xiao, Iz Beltagy, Giuseppe Carenini, and Arman\", \"ume 1: Long Papers) , pages 5245–5263, Dublin,\", \"Yinfei Yang, Daniel Cer, Amin Ahmad, Mandy Guo,\", \"Jax Law, Noah Constant, Gustavo Hernandez Abrego,\", \"Steve Yuan, Chris Tar, Yun-hsuan Sung, Brian Strope,\", \"Computational Linguistics: System Demonstrations ,\", \"pages 87–94, Online. Association for Computational\", \"Require: Cluster D, centroid ˆc, summary budget\", \"ℓ, number of sentences nto pre-select, beam\", \"sizeB, number of candidates Tfor greedy\", \"1:Dn←select-first (D, n)\", \"2:π, π next, πbs←empty list\", \"3:while∃b:length (πnext[b])< ℓdo:▷Beam\", \"4: πnext←BSstep(π, D n, B,ˆc)(4)\", \"5: if∃b:length (πnext[b])> ℓthen\", \"6: πbs.append (π)\", \"7: end if\", \"8: π← ∀πnext[b] :length (πnext[b])≤ℓ\", \"9:end while\", \"10:πbest←highest-scored Bstates in πbs(sorted)\", \"11:forb= 1,2, . . . , B do: ▷Greedy Search\", \"12: t←0\", \"13: D′\", \"14: while t < T do:\", \"15: s∗←arg max\", \"s∈D′ncos sim( eπbest[b]∪{s},ˆc)\", \"16: π′\", \"17: iflength (π′\", \"18: πbest[b]←π′\", \"19: t←0\", \"20: else:\", \"21: t←t+ 1\", \"22: end if\", \"23: D′\", \"24: end while\", \"25:end for\", \"26:return S←highest-scored state in πbest\", \"et al., 2019) is a large-scale dataset for MDS of\", \"into training, validation, and test splits. There is a\", \"4BSstepdenotes a step of the usual beam search algorithm.\", \"Details omitted for brevity.WCEP-10 This dataset (Ghalandari et al., 2020;\", \"Xiao et al., 2022) consists of short human-written\", \"reference summary, and there are at most 10 doc-\", \"clusters, all of which are used for testing.\", \"set consists of 48 news clusters, each with 10 re-\", \"els in a multilingual context, we have adapted\", \"the CrossSum dataset (Bhattacharjee et al., 2023)\", \"cross-lingual summarization, this dataset offers\", \"rization dataset XL-Sum (Hasan et al., 2021). No-\", \"tably, these pairings were established using an au-\", \"tomatic similarity metric, resulting in many pairs\", \"stories, rendering it well-suited MDS.\", \"To tailor this dataset for our specific task, we be-\", \"of the languages. Subsequently, we aggregated the\", \"documents into clusters, taking into account their\", \"pairings. For instance, if document Awas paired\", \"document C, then A,B, and Cwould belong to\", \"lingual reference summaries for each cluster, we\", \"words. We have built training, validation, and test\", \"sets using data in English, Spanish, and French, and\", \"another test set using data in Portuguese, Russian,\", \"5https://tac.nist.gov\", \"6https://duc.nist.gov\", \"parison, all the models we evaluated used\", \"the same sentence representations, specifi-\", \"cally, sentence embeddings obtained from the\", \"sentence encoder (Yang et al., 2020).\", \"For monolingual datasets, the documents were\", \"NLTK library (Bird et al., 2009). For CrossSum,\", \"sentence selection (Algorithm 1), the data goes\", \"through a second processing step, during which\", \"When evaluating models in CrossSum, we trans-\", \"(Fan et al., 2021).\", \"all models: 230 words for the Multi-News dataset,\", \"100 words for TAC2008, DUC2004 and CrossSum,\", \"News validation set. For the number of sentences n,\", \"width Bvalues 1,5, and 9 were examined, and\", \"regarding the number of candidates T, values 1,5,\", \"R2-R on this validation set were n= 9,B=5, and\", \"T=9. In all of our experiments, these were the\", \"7https://huggingface.co/sentence-transformers/\", \"8https://pypi.org/project/icu-tokenizer\", \"9We used ROUGE 1.5.5 toolkit with the following argu-\", \"batch size = 2,learning rate = 5×10−4, and num-\", \"models used early stopping, where the stopping\", \"ization (Ba et al., 2016) was applied on the input\", \"Train en, es, fr 6541 2 −10 38.5 ±28.8 52.5±16.1\", \"Val en, es, fr 889 2 −6 34.4 ±27.4 52.3±15.5\", \"Test en, es, fr 853 2 −6 36.6 ±35.4 52.2±16.2\", \"Test-ZS pt, ru, tr 933 2 −5 23.4 ±21.1 60.2±20.8\"], \"error\": null}, \"c9e9d0c1\": {\"success\": true, \"paper_id\": \"c9e9d0c1\", \"url\": \"https://arxiv.org/pdf/2505.22950.pdf\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_c9e9d0c1.pdf\", \"extracted_info\": {\"title\": \"StrucSum: Structure-Aware Prompting for Zero-Shot Extractive Summarization with Large Language Models\", \"authors\": [\"Not explicitly provided in excerpt\"], \"abstract\": \"Large language models (LLMs) have shown strong performance in zero-shot summarization but often struggle with capturing document-level structure. This work introduces StrucSum, a structure-aware prompting framework for extractive summarization that leverages graph-based representations of sentence relationships to improve summary quality and factual consistency. While designed for extractive summarization, the approach is model-agnostic and can be extended to abstractive summarization in future work.\", \"methodology\": \"The proposed method, StrucSum, models zero-shot extractive summarization as a sentence selection task enhanced by structural cues. Documents are represented as sentence-level graphs (TAGs) encoding semantic proximity and discourse-level relationships. Three structure-aware prompting strategies are introduced: Neighbor-Aware Prompting (NAP), Coreference-Aware Prompting (CAP), and Content Graph Masking (CGM). These prompts are fed into LLMs (e.g., GPT4o, LLaMA3-70B) to guide sentence selection. Experiments are conducted on three long-document summarization datasets (ArXiv, PubMed, Multi-News), comparing against unsupervised extractive methods (LexRank, TextRank, PacSum) and vanilla LLM prompting. Evaluation metrics include ROUGE, BERTScore, FactCC, SummaC, and human evaluation on fluency, informativeness, and faithfulness.\", \"results\": \"Across all datasets, StrucSum with structure-aware prompting consistently outperforms both unsupervised extractive methods and vanilla LLM prompting. NAP achieves the strongest overall results, improving ROUGE-2, ROUGE-L, and BERTScore, as well as factual consistency metrics (FactCC, SummaC). On human evaluation, NAP yields higher scores in fluency, informativeness, faithfulness, and overall quality. Structural cues alone (graph-only setting) improve performance over random baselines but cannot match text-based results. NAP and CAP increase input length by 50–60% and 15–18%, respectively, while CGM offers a more efficient option with slightly lower gains.\", \"conclusion\": \"The key contributions are: (1) Introduction of StrucSum, a structure-aware prompting framework for zero-shot extractive summarization with LLMs; (2) Development of three prompting strategies (NAP, CAP, CGM) that incorporate document-level structural signals; (3) Comprehensive evaluation on multiple long-document summarization datasets showing consistent improvements in summary quality and factual consistency; (4) Analysis of factual reliability, human evaluation, and efficiency trade-offs; (5) Demonstration that structural cues enhance LLM summarization but cannot fully replace textual content.\", \"figures\": null, \"tables\": null}, \"citations\": [\"1https://openai.com/index/openai-api/\", \"2https://build.nvidia.com/models\", \"Table 2: Performance on ArXiv, PubMed, and Multi-News evaluated by ROUGE-2 (R-2), ROUGE-L (R-L), and\", \"FactCC (Kry ´sci´nski et al., 2019), a classifier-based\", \"maries, and SummaC (Laban et al., 2022), which\", \"ral language inference models. Finally, we report\", \"G-Eval (Liu et al., 2023), a GPT-based evalua-\", \"across multiple dimensions, including coherence,\", \"consistency, fluency, and relevance. G-Eval offers\", \"tences as the summary, reflecting positional bias.\", \"LexRank (Erkan and Radev, 2004) builds a sim-\", \"centrality. TextRank (Mihalcea and Tarau, 2004)\", \"Sum (Zheng and Lapata, 2019) incorporates posi-\", \"tion and polarity to assign edge weights, improving\", \"Implementation Details To construct the TAG,\", \"sentences ( k), similarity threshold for TAG construction\", \"(θ), and centrality coverage ratio in CGM ( ρ).\", \"4.2 Summary Quality Evaluation\", \"marization datasets: ArXiv, PubMed, and Multi-\", \"tractive methods and LLM-based approaches, with\", \"and structure-aware prompting. Across all datasets,\", \"over vanilla LLM prompting, highlighting the value\", \"Among unsupervised baselines, Lead performs\", \"LexRank, TextRank, and PacSum offer varying de-\", \"grees of improvement, but all are outperformed\", \"For LLMs, Neighbor-Aware Prompting (NAP)\", \"Aware Prompting (CAP) also brings notable gains,\", \"off in input length. Across models, GPT-4o-mini\", \"LLMs, especially for long-form documents.\", \"4.3 Summary Faithfulness Evaluation\", \"from source sentences, prior work has shown that\", \"they can still suffer from factual inconsistencies,\", \"tence combinations (Zhang et al., 2023b). To assess\", \"under different prompting strategies, we evaluate\", \"(Table 4). We report results using two factual con-\", \"sistency metrics, namely FactCC (Kry ´sci´nski et al.,\", \"2019) and SummaC (Laban et al., 2022), as well\", \"as G-Eval (Liu et al., 2023), which averages scores\", \"across coherence, consistency, fluency, and rele-\", \"As shown in Table 4, incorporating structural in-\", \"ing. Among all strategies, NAP achieves the high-\", \"est scores across both datasets, demonstrating its\", \"ence. CAP also brings consistent gains, while\", \"Overall, these results suggest that structural\", \"prompting, particularly NAP, significantly im-\", \"4.4 Human Evaluation\", \"dataset using a 1–5 scale for Fluency, Informative-\", \"ness, Faithfulness, and Overall quality. As shown\", \"in Table 5, all proposed strategies (NAP, CAP,\", \"CGM) outperform vanilla prompting, with NAPDataset System FactCC SummaC G-Eval\", \"metrics (FactCC, SummaC) and one general-purpose\", \"Table 5: Human evaluation (1–5 scale) on fluency, infor-\", \"mativeness, faithfulness, and overall quality for GPT4o-\", \"Overall quality (e.g., NAP: 3.74 vs. Vanilla:\", \"3.30) aligns with the gains observed in the holis-\", \"tic G-Eval metric (Table 4). Furthermore, the im-\", \"proved human-rated Faithfulness (e.g., NAP: 3.95\", \"5 Analysis\", \"5.1 Hyperparameter Sensitivity\", \"method here as an example, while the other two\", \"(k) and the graph construction similarity threshold\", \"(θ). Figure 3 illustrates these results, where dif-\", \"shown in Figure 3, the best ROUGE-Avg scores\", \"Figure 4: Normalized prompt lengths for vanilla, NAP,\", \"CAP, and CGM strategies across ArXiv, PubMed, and\", \"(k) and a similarity threshold ( θ) between 0.7 and\", \"0.8. Overall, the results suggest that our method\", \"5.2 Token Usage Analysis\", \"et al., 2025). Figure 4 shows the normal-\", \"strategies—Neighbor-Aware Prompting (NAP),\", \"Centrality-Aware Prompting (CAP), and Centrality-\", \"text, NAP and CAP increase input length by ap-\", \"proximately 50–60% and 15–18%, respectively. In\", \"contrast, CGM, reduces token usage by 40–50%\", \"and 4.3). Therefore, CGM can be considered as an\", \"the graph-only setting using GPT4o-mini. In this setting,\", \"5.3 Structure-Only Prompt Format Analysis\", \"information without access to sentence content, we\", \"neighbor lists (TNL), which list each sentence’s\", \"text; numeric adjacency matrices (NAM), dense\", \"tence pairs; and binary adjacency matrices (BAM),\", \"As shown in Table 6, TNL consistently out-\", \"However, its performance remains lower than sys-\", \"sentence content (for example, NAP achieves 14.59\", \"Overall, these results suggest that in LLM-based\", \"summarization, structural cues, although helpful,\", \"6 Conclusion\", \"This paper presents StrucSum, a prompting-based\", \"complementary strategies: NAP, CAP and CGM,\", \"both summary quality and factual consistency, with\", \"NAP achieving the most consistent gains. Overall,\", \"test set, we evaluate a representative subset of 200\", \"on small subsets (Goyal et al., 2023; Zhang et al.,\", \"2024b). As large-scale evaluations remain resource-\", \"intensive under current LLM APIs, we leave full-\", \"port, its scale is limited. A broader human study,\", \"especially involving domain experts, may provide\", \"StrucSum does not involve any fine-tuning, as it\", \"deployment, though it may limit task-specific per-\", \"prompting and several unsupervised baselines,\", \"aware prompting in a consistent zero-shot context,\", \"Finally, our experiments are conducted in En-\", \"glish and on a selected set of LLMs (e.g., GPT-4o,\", \"guages, domains, and additional model families is\", \"Xiuying Chen, Mingzhe Li, Shen Gao, Rui Yan, Xin\", \"Gao, and Xiangliang Zhang. 2022. Scientific pa-\", \"Empirical Methods in Natural Language Processing ,\", \"pages 4053–4062, Abu Dhabi, United Arab Emirates.\", \"Anshuman Chhabra, Hadi Askari, and Prasant Moha-\", \"from the perspective of position bias. Preprint ,\", \"Arman Cohan, Franck Dernoncourt, Doo Soon Kim,\", \"Trung Bui, Seokhwan Kim, Walter Chang, and Nazli\", \"tional Linguistics: Human Language Technologies,\", \"Volume 2 (Short Papers) , pages 615–621, New Or-\", \"leans, Louisiana. Association for Computational Lin-\", \"Peng Cui, Le Hu, and Yuanchao Liu. 2020. Enhancing\", \"national Conference on Computational Linguistics ,\", \"pages 5360–5371, Barcelona, Spain (Online). Inter-\", \"Alexander Fabbri, Irene Li, Tianwei She, Suyi Li, and\", \"Linguistics , pages 1074–1084, Florence, Italy. Asso-\", \"Tanya Goyal, Junyi Jessy Li, and Greg Durrett. 2023.\", \"gpt-3. Preprint , arXiv:2209.12356.\", \"Hanqi Jin, Tianming Wang, and Xiaojun Wan. 2020.\", \"ciation for Computational Linguistics , pages 6244–\", \"6254, Online. Association for Computational Lin-\", \"Huan Yee Koh, Jiaxin Ju, Ming Liu, and Shirui Pan.\", \"2022. An empirical survey on long document sum-\", \"marization: Datasets, models, and metrics. ACM\", \"Comput. Surv. , 55(8).\", \"Takeshi Kojima, Shixiang Shane Gu, Machel Reid, Yu-\", \"taka Matsuo, and Yusuke Iwasawa. 2023. Large\", \"language models are zero-shot reasoners. Preprint ,\", \"Wojciech Kry ´sci´nski, Bryan McCann, Caiming Xiong,\", \"sistency of abstractive text summarization. Preprint ,\", \"Philippe Laban, Tobias Schnabel, Paul N. Bennett, and\", \"tational Linguistics , 10:163–177.\", \"Wei Li, Xinyan Xiao, Jiachen Liu, Hua Wu, Haifeng\", \"Wang, and Junping Du. 2020. Leveraging graph\", \"the Association for Computational Linguistics , pages\", \"6232–6243, Online. Association for Computational\", \"tion Branches Out , pages 74–81, Barcelona, Spain.\", \"Yang Liu, Dan Iter, Yichong Xu, Shuohang Wang,\", \"Ruochen Xu, and Chenguang Zhu. 2023. G-eval:\", \"ment. Preprint , arXiv:2303.16634.\", \"Qianren Mao, Hongdong Zhu, Junnan Liu, Cheng Ji,\", \"Hao Peng, Jianxin Li, Lihong Wang, and Zheng\", \"Retrieval , SIGIR ’22, page 2617–2622, New York,\", \"NY , USA. Association for Computing Machinery.\", \"processing , pages 404–411.\", \"Xiao Pu, Mingqi Gao, and Xiaojun Wan. 2023.\", \"Summarization is (almost) dead. Preprint ,\", \"Qian Ruan, Malte Ostendorff, and Georg Rehm. 2022.\", \"with hierarchical structure information. Preprint ,\", \"Pranab Sahoo, Ayush Kumar Singh, Sriparna Saha,\", \"Vinija Jain, Samrat Mondal, and Aman Chadha.\", \"2025. A systematic survey of prompt engineering in\", \"Preprint , arXiv:2402.07927.\", \"Hwanjun Song, Hang Su, Igor Shalyminov, Jason Cai,\", \"summarization evaluation using llms. Preprint ,\", \"arXiv:2407.00908.Danqing Wang, Pengfei Liu, Yining Zheng, Xipeng Qiu,\", \"the Association for Computational Linguistics , pages\", \"6209–6219, Online. Association for Computational\", \"Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\", \"Bosma, Brian Ichter, Fei Xia, Ed Chi, Quoc Le, and\", \"its reasoning in large language models. Preprint ,\", \"shift in abstractive text summarization. Preprint ,\", \"Haopeng Zhang, Xiao Liu, and Jiawei Zhang. 2022.\", \"Processing , pages 10167–10176, Abu Dhabi, United\", \"Haopeng Zhang, Xiao Liu, and Jiawei Zhang. 2023a.\", \"tion for Computational Linguistics: EMNLP 2023 ,\", \"Haopeng Zhang, Philip S. Yu, and Jiawei Zhang. 2024a.\", \"tistical methods to large language models. Preprint ,\", \"Shiyue Zhang, David Wan, and Mohit Bansal. 2023b.\", \"1: Long Papers) , pages 2153–2174, Toronto, Canada.\", \"Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.\", \"Weinberger, and Yoav Artzi. 2020. Bertscore:\", \"Evaluating text generation with bert. Preprint ,\", \"Tianyi Zhang, Faisal Ladhak, Esin Durmus, Percy Liang,\", \"Kathleen McKeown, and Tatsunori B. Hashimoto.\", \"2024b. Benchmarking large language models for\", \"for Computational Linguistics , 12:39–57.\", \"Chenlong Zhao, Xiwen Zhou, Xiaopeng Xie, and Yong\", \"tional Linguistics: NAACL 2024 , pages 714–726.\", \"2025 Conference of the Nations of the Americas\", \"Long Papers) , pages 2050–2073, Albuquerque, New\", \"In this section, we provide representative prompt\", \"this paper, including vanilla prompting and the\", \"three structure-aware strategies: NAP, CAP, and\", \"On average, select around 4 key sentences.\", \"Return a list of selected sentence indices in JSON, for\", \"{\\\"selected_sentences\\\": [1, 3, 5]}\", \"On average, select around 4 key sentences.\", \"- 1-hop Neighbors: Sentence 2, 4, 7, 10...\", \"- 1-hop Neighbors: Sentence 1, 3, 6, 11...\", \"- 1-hop Neighbors: Sentence 2, 5, 9, 13...\", \"Return a list of selected sentence indices in JSON, for\", \"{\\\"selected_sentences\\\": [1, 3, 5]}\", \"On average, select around 4 key sentences.\", \"Return a list of selected sentence indices in JSON, for\", \"{\\\"selected_sentences\\\": [1, 3, 5]}\", \"On average, select around 4 key sentences.\", \"[ Masked Sentences: 2, 3, 5, 6, 8, 10, ... ]\", \"Return a list of selected sentence indices in JSON, for\", \"{\\\"selected_sentences\\\": [1, 3, 5]}\"], \"error\": null}, \"60cc7541\": {\"success\": true, \"paper_id\": \"60cc7541\", \"url\": \"https://arxiv.org/pdf/2509.20461v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_60cc7541.pdf\", \"extracted_info\": {\"title\": \"Conformal Importance Summarization: Coverage Guarantees for Extractive and Hybrid Summarization\", \"authors\": [\"Not specified in provided content\"], \"abstract\": \"Automatic summarization systems have advanced rapidly with large language models (LLMs), yet they still lack guarantees for retaining critical information in high-stakes domains. This paper introduces Conformal Importance Summarization, a model-agnostic method that calibrates sentence-level importance scores to produce summaries with user-specified error (α) and recall (β) rates. The method integrates seamlessly with black-box LLMs and requires only a small calibration set. Experiments on established summarization benchmarks demonstrate empirical importance coverage matching theoretical guarantees, and quantify the utility of the approach.\", \"methodology\": \"The proposed method uses conformal prediction to calibrate sentence-level importance scores, enabling control over coverage and recall in extractive summarization. It is model-agnostic and can be applied to both classical NLP methods and modern LLMs. Importance scoring functions are designed using either LLM-based scoring or graph-based methods (e.g., Cosine Similarity Centrality, LexRank, GUSUM). The framework supports user-specific preferences by tailoring thresholds based on a small labeled calibration set. Experiments are conducted on five datasets (ECTSum, CSDS, CNN/DM, TLDR-AIC, MTS-Dialog) using multiple scoring methods, with evaluations in terms of coverage, recall, conciseness, and AUPRC. Ablation studies examine the effects of α, β, labeling methods, and calibration set size. A hybrid extractive-abstractive pipeline is also tested, combining the conformal extractive step with LLM-based abstractive synthesis.\", \"results\": \"Empirical results confirm that the method achieves coverage within theoretical bounds across datasets and scoring functions. Higher α reduces recall, while higher β increases summary length. Compared to non-conformal baselines, the method offers fine-grained control over recall and conciseness. LLM-based scoring (Gemini 2.5 Flash) achieves the highest AUPRC and strong conciseness performance. Ablations show robustness to different labeling methods and calibration set sizes, with as few as 50 labeled examples yielding comparable results. The hybrid extractive-abstractive approach retains coverage guarantees while producing more fluent summaries than pure extractive methods, outperforming direct abstractive summarization in controlled recall scenarios.\", \"conclusion\": \"Introduces Conformal Importance Summarization, the first method to provide distribution-free coverage guarantees for extractive summarization; Enables user control over error and recall rates; Works with both LLMs and classical NLP methods; Demonstrates strong empirical performance across multiple datasets; Shows robustness to small calibration sets and different labeling methods; Proposes a hybrid extractive-abstractive pipeline that combines coverage guarantees with improved fluency; Validates that recent LLMs are effective for sentence-level importance scoring.\", \"figures\": null, \"tables\": null}, \"citations\": [\"[1] Josh Achiam et al. GPT-4 Technical Report.arXiv:2303.08774, 2023.\", \"[2]Anastasios N. Angelopoulos and Stephen Bates. A gentle introduction to conformal prediction\", \"and distribution-free uncertainty quantification.arXiv:2107.07511, 2021.\", \"[3] Anastasios N. Angelopoulos, Stephen Bates, Michael Jordan, and Jitendra Malik. Uncertainty\", \"Representations, 2021.\", \"[4]Anastasios Nikolas Angelopoulos, Stephen Bates, Adam Fisch, Lihua Lei, and Tal Schuster.\", \"Conformal risk control. InThe Twelfth International Conference on Learning Representations,\", \"2024.\", \"[5]Elham Asgari, Nina Montaña-Brown, Magda Dubois, Saleh Khalil, Jasmine Balloch, and Do-\", \"cal text summarisation.npj Digital Medicine, 8(1), 2024. doi: 10.1038/s41746-025-01670-7.\", \"[6]Shrestha Basu Mallick and Logan Kilpatrick. Gemini 2.0: Flash, Flash-Lite and Pro. https:\", \"//developers.googleblog.com/en/gemini-2-family-expands/ , February 2025. Ac-\", \"[7]Asma Ben Abacha, Wen-wai Yim, Yadan Fan, and Thomas Lin. An empirical study of clinical\", \"the European Chapter of the Association for Computational Linguistics, pages 2291–2302.\", \"Association for Computational Linguistics, 2023. doi: 10.18653/v1/2023.eacl-main.168.\", \"[8]Samuel R. Bowman, Gabor Angeli, Christopher Potts, and Christopher D. Manning. A large\", \"ence on Empirical Methods in Natural Language Processing, pages 632–642. Association for\", \"Computational Linguistics, 2015. doi: 10.18653/v1/D15-1075.\", \"[9]Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\", \"Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, Sandhini Agarwal, Ariel\", \"Herbert-V oss, Gretchen Krueger, Tom Henighan, Rewon Child, Aditya Ramesh, Daniel Ziegler,\", \"Jeffrey Wu, Clemens Winter, Chris Hesse, Mark Chen, Eric Sigler, Mateusz Litwin, Scott\", \"Gray, Benjamin Chess, Jack Clark, Christopher Berner, Sam McCandlish, Alec Radford, Ilya\", \"Sutskever, and Dario Amodei. Language models are few-shot learners. InAdvances in Neural\", \"Information Processing Systems, volume 33, pages 1877–1901, 2020.\", \"[10] Evgeny Burnaev and Vladimir V ovk. Efficiency of conformalized ridge regression. InProceed-\", \"ings of The 27th Conference on Learning Theory, volume 35, pages 605–622, 2014.\", \"[11] Isabel Cachola, Kyle Lo, Arman Cohan, and Daniel Weld. TLDR: Extreme summarization of\", \"2020, pages 4766–4777. Association for Computational Linguistics, 2020. doi: 10.18653/v1/\", \"2020.findings-emnlp.428.\", \"[12] Yapei Chang, Kyle Lo, Tanya Goyal, and Mohit Iyyer. Booookscore: A systematic exploration\", \"Learning Representations, 2024.\", \"[13] Yen-Chun Chen and Mohit Bansal. Fast abstractive summarization with reinforce-selected sen-\", \"Linguistics (Volume 1: Long Papers), pages 675–686, 2018. doi: 10.18653/v1/P18-1063.\", \"[14] John J. Cherian, Isaac Gibbs, and Emmanuel J. Candès. Large language model validity via\", \"enhanced conformal prediction methods. InAdvances in Neural Information Processing Systems,\", \"volume 37, pages 114812–114842, 2024.\", \"11\", \"[15] Aakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam\", \"Roberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, Parker\", \"Schuh, Kensen Shi, Sasha Tsvyashchenko, Joshua Maynez, Abhishek Rao, Parker Barnes,\", \"Yi Tay, Noam Shazeer, Vinodkumar Prabhakaran, Emily Reif, Nan Du, Ben Hutchinson,\", \"Reiner Pope, James Bradbury, Jacob Austin, Michael Isard, Guy Gur-Ari, Pengcheng Yin,\", \"Toju Duke, Anselm Levskaya, Sanjay Ghemawat, Sunipa Dev, Henryk Michalewski, Xavier\", \"Garcia, Vedant Misra, Kevin Robinson, Liam Fedus, Denny Zhou, Daphne Ippolito, David\", \"Luan, Hyeontaek Lim, Barret Zoph, Alexander Spiridonov, Ryan Sepassi, David Dohan, Shivani\", \"Agrawal, Mark Omernick, Andrew M. Dai, Thanumalayan Sankaranarayana Pillai, Marie Pellat,\", \"Aitor Lewkowycz, Erica Moreira, Rewon Child, Oleksandr Polozov, Katherine Lee, Zongwei\", \"Zhou, Xuezhi Wang, Brennan Saeta, Mark Diaz, Orhan Firat, Michele Catasta, Jason Wei,\", \"Kathy Meier-Hellstern, Douglas Eck, Jeff Dean, Slav Petrov, and Noah Fiedel. PaLM: Scaling\", \"Language Modeling with Pathways.Journal of Machine Learning Research, 24(240):1–113,\", \"2023.\", \"[16] Jesse C. Cresswell, Yi Sui, Bhargava Kumar, and Noël V ouitsis. Conformal Prediction Sets\", \"Machine Learning, volume 235, pages 9439–9457, 2024.\", \"[17] Jesse C. Cresswell, Bhargava Kumar, Yi Sui, and Mouloud Belbahri. Conformal Prediction\", \"Representations, 2025.\", \"[18] Emma Croxford, Yanjun Gao, Nicholas Pellegrino, Karen Wong, Graham Wills, Elliot First,\", \"Frank Liao, Cherodeep Goswami, Brian Patterson, and Majid Afshar. Current and future state\", \"of evaluation of large language models for medical summarization tasks.npj Health Systems, 2\", \"(1):6, 2025.\", \"[19] Emma Croxford, Yanjun Gao, Nicholas Pellegrino, Karen K. Wong, Graham Wills, Elliot First,\", \"Miranda Schnier, Kyle Burton, Cris G. Ebby, Jillian Gorskic, Matthew Kalscheur, Samy Khalil,\", \"Marie Pisani, Tyler Rubeor, Peter Stetson, Frank Liao, Cherodeep Goswami, Brian Patterson,\", \"Association, pages 1050–1060, 2025.\", \"[20] Daniel Deutsch, Rotem Dror, and Dan Roth. On the limitations of reference-free evaluations\", \"Language Processing, pages 10960–10977. Association for Computational Linguistics, 2022.\", \"[21] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: Pre-training of\", \"Human Language Technologies, Volume 1 (Long and Short Papers), 2019. doi: 10.18653/v1/\", \"[22] Günes Erkan and Dragomir R Radev. Lexrank: Graph-based lexical centrality as salience in\", \"text summarization.Journal of Artificial Intelligence Research, 22:457–479, 2004.\", \"[23] Naihe Feng, Yi Sui, Shiyi Hou, Jesse C. Cresswell, and Ga Wu. Response quality assessment\", \"Retrieval, page 2832–2836, 2025. ISBN 9798400715921. doi: 10.1145/3726302.3730244.\", \"[24] Sebastian Gehrmann, Yuntian Deng, and Alexander Rush. Bottom-Up Abstractive Summa-\", \"Processing, 2018. doi: 10.18653/v1/D18-1443.\", \"[25] Shilpa Ghatnekar, Adam Faletsky, and Vinod E Nambudiri. Digital scribe utility and barriers to\", \"implementation in clinical practice: A scoping review.Health and Technology, 11(4):803–809,\", \"2021.\", \"12\", \"[26] Tuba Gokhan, Phillip Smith, and Mark Lee. GUSUM: Graph-based Unsupervised Summariza-\", \"Graph-based Methods for Natural Language Processing, pages 44–53. Association for Compu-\", \"tational Linguistics, 2022.\", \"[27] Shuai Gong, Zhenfang Zhu, Jiangtao Qi, Chunling Tong, Qiang Lu, and Wenqing Wu. Improving\", \"extractive document summarization with sentence centrality.PLOS ONE, 17(7):1–16, 07 2022.\", \"[28] Google Developers. Developers can now start building with Gemini 2.5 Flash. https://\", \"blog.google/products/gemini/gemini-2-5-flash-preview/ , April 2025. Accessed\", \"[29] Aaron Grattafiori et al. The Llama 3 Herd of Models.arXiv:2407.21783, 2024.\", \"[30] Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu,\", \"Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in\", \"llms via reinforcement learning.arXiv:2501.12948, 2025.\", \"[31] Chirag Gupta, Arun K. Kuchibhotla, and Aaditya Ramdas. Nested conformal prediction\", \"and quantile out-of-bag ensemble methods.Pattern Recognition, 127:108496, 2022. ISSN\", \"0031-3203. doi: 10.1016/j.patcog.2021.108496.\", \"[32] Karl Moritz Hermann, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa\", \"Suleyman, and Phil Blunsom. Teaching machines to read and comprehend. InAdvances in\", \"Neural Information Processing Systems, volume 28, 2015.\", \"[33] Jianguo Huang, Huajun Xi, Linjun Zhang, Huaxiu Yao, Yue Qiu, and Hongxin Wei. Conformal\", \"Conference on Machine Learning, 2024.\", \"[34] Ambedkar Kanapala, Sukomal Pal, and Rajendra Pamula. Text summarization from legal\", \"documents: A survey.Artificial Intelligence Review, 51:371–402, 2019.\", \"[35] Huan Yee Koh, Jiaxin Ju, Ming Liu, and Shirui Pan. An empirical survey on long document\", \"summarization: Datasets, models, and metrics.ACM Comput. Surv., 55(8), December 2022.\", \"[36] Wojciech Kryscinski, Bryan McCann, Caiming Xiong, and Richard Socher. Evaluating the\", \"on Empirical Methods in Natural Language Processing (EMNLP), pages 9332–9346, 2020. doi:\", \"10.18653/v1/2020.emnlp-main.750.\", \"[37] Bhawesh Kumar, Charlie Lu, Gauri Gupta, Anil Palepu, David Bellamy, Ramesh Raskar, and\", \"answering.arXiv:2305.18404, 2023.\", \"[38] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman\", \"Goyal, Heinrich Küttler, Mike Lewis, Wen-tau Yih, Tim Rocktäschel, Sebastian Riedel, and\", \"Advances in Neural Information Processing Systems, volume 33, pages 9459–9474, 2020.\", \"[39] Chin-Yew Lin. ROUGE: A package for automatic evaluation of summaries. InText Summariza-\", \"tion Branches Out, pages 74–81, Barcelona, Spain, July 2004. Association for Computational\", \"[40] Haitao Lin, Liqun Ma, Junnan Zhu, Lu Xiang, Yu Zhou, Jiajun Zhang, and Chengqing Zong.\", \"Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing,\", \"pages 4436–4451, 2021. doi: 10.18653/v1/2021.emnlp-main.365.\", \"[41] Yang Liu and Mirella Lapata. Text summarization with pretrained encoders. InProceedings\", \"International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages\", \"3730–3740, 2019. doi: 10.18653/v1/D19-1387.\", \"13\", \"[42] Yang Liu and Mirella Lapata. Text summarization with pretrained encoders. InProceedings\", \"International Joint Conference on Natural Language Processing (EMNLP-IJCNLP), pages\", \"3730–3740, 2019. doi: 10.18653/v1/D19-1387.\", \"[43] Soundouss Messoudi, Sébastien Destercke, and Sylvain Rousseau. Copula-based conformal\", \"prediction for multi-target regression.Pattern Recognition, 120:108101, 2021. ISSN 0031-3203.\", \"[44] Rada Mihalcea and Paul Tarau. TextRank: Bringing order into text. InProceedings of the\", \"2004 Conference on Empirical Methods in Natural Language Processing, pages 404–411.\", \"Association for Computational Linguistics, July 2004.\", \"[45] Christopher Mohri and Tatsunori Hashimoto. Language models with conformal factuality\", \"guarantees. InProceedings of the 41st International Conference on Machine Learning, 2024.\", \"[46] Rajdeep Mukherjee, Abhinav Bohra, Akash Banerjee, Soumya Sharma, Manjunath Hegde,\", \"Afreen Shaikh, Shivani Shrivastava, Koustuv Dasgupta, Niloy Ganguly, Saptarshi Ghosh, and\", \"Natural Language Processing, pages 10893–10906, 2022. doi: 10.18653/v1/2022.emnlp-main.\", \"748.\", \"[47] OpenAI. GPT-4o mini: Advancing cost-efficient intelligence. https://openai.com/index/\", \"gpt-4o-mini-advancing-cost-efficient-intelligence/ , 2025. Accessed May 15,\", \"2025.\", \"[48] Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. The PageRank citation\", \"ranking: Bringing order to the web. Technical report, Stanford Infolab, 1999.\", \"[49] Arjun Panickssery, Samuel R. Bowman, and Shi Feng. LLM Evaluators Recognize and Favor\", \"Their Own Generations. InAdvances in Neural Information Processing Systems, volume 37,\", \"pages 68772–68802, 2024.\", \"[50] Romain Paulus, Caiming Xiong, and Richard Socher. A deep reinforced model for abstractive\", \"summarization. InInternational Conference on Learning Representations, 2018.\", \"[51] David Preti, Cristina Giannone, Andrea Favalli, and Raniero Romagnoli. Automatic Summa-\", \"rization of Legal Texts, Extractive Summarization using LLMs.Ital-IA 2024: 4th National\", \"Conference on Artificial Intelligence, 2024.\", \"[52] Victor Quach, Adam Fisch, Tal Schuster, Adam Yala, Jae Ho Sohn, Tommi S. Jaakkola, and\", \"Learning Representations, 2024.\", \"[53] Juan Ramirez-Orta and Evangelos Milios. Unsupervised document summarization using pre-\", \"Scholarly Document Processing, pages 110–115. Association for Computational Linguistics,\", \"2021. doi: 10.18653/v1/2021.sdp-1.14.\", \"[54] Nils Reimers and Iryna Gurevych. Sentence-BERT: Sentence Embeddings using Siamese\", \"(EMNLP-IJCNLP), pages 3982–3992. Association for Computational Linguistics, 2019. doi:\", \"10.18653/v1/D19-1410.\", \"[55] Yaniv Romano, Evan Patterson, and Emmanuel Candès. Conformalized quantile regression. In\", \"Advances in Neural Information Processing Systems, volume 32, 2019.\", \"[56] Yaniv Romano, Matteo Sesia, and Emmanuel Candès. Classification with valid and adaptive\", \"coverage. InAdvances in Neural Information Processing Systems, volume 33, 2020.\", \"14\", \"[57] Maxon Rubin-Toles, Maya Gambhir, Keshav Ramji, Aaron Roth, and Surbhi Goel. Conformal\", \"on Learning Representations, 2025.\", \"[58] Victor Sanh, Albert Webson, Colin Raffel, Stephen Bach, Lintang Sutawika, Zaid Alyafeai,\", \"Antoine Chaffin, Arnaud Stiegler, Arun Raja, Manan Dey, M Saiful Bari, Canwen Xu, Urmish\", \"Thakker, Shanya Sharma Sharma, Eliza Szczechla, Taewoon Kim, Gunjan Chhablani, Nihal\", \"Nayak, Debajyoti Datta, Jonathan Chang, Mike Tian-Jian Jiang, Han Wang, Matteo Manica,\", \"Sheng Shen, Zheng Xin Yong, Harshit Pandey, Rachel Bawden, Thomas Wang, Trishala\", \"Neeraj, Jos Rozen, Abheesht Sharma, Andrea Santilli, Thibault Fevry, Jason Alan Fries, Ryan\", \"Teehan, Teven Le Scao, Stella Biderman, Leo Gao, Thomas Wolf, and Alexander M Rush.\", \"on Learning Representations, 2022.\", \"[59] Glenn Shafer and Vladimir V ovk. A tutorial on conformal prediction.Journal of Machine\", \"Learning Research, 9(3), 2008.\", \"[60] Shreya J. Shah, Trevor Crowell, Yejin Jeong, Anna Devon-Sand, Margaret Smith, Betsy Yang,\", \"Stephen P. Ma, April S. Liang, Clarissa Delahaie, Caroline Hsia, Tait Shanafelt, Michael A.\", \"Pfeffer, Christopher Sharp, Steven Lin, and Patricia Garcia. Physician Perspectives on Ambient\", \"AI Scribes.JAMA Network Open, 8(3):e251904–e251904, 2025.\", \"[61] Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N Gomez,\", \"Łukasz Kaiser, and Illia Polosukhin. Attention is all you need. InAdvances in Neural Informa-\", \"tion Processing Systems, volume 30, 2017.\", \"[62] Vladimir V ovk, Alexander Gammerman, and Glenn Shafer.Algorithmic Learning in a Random\", \"World. Springer, 2005.\", \"[63] Jason Wei, Maarten Bosma, Vincent Zhao, Kelvin Guu, Adams Wei Yu, Brian Lester, Nan\", \"Du, Andrew M. Dai, and Quoc V Le. Finetuned language models are zero-shot learners. In\", \"International Conference on Learning Representations, 2022.\", \"[64] An Yang, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu, Chengyuan\", \"Li, Dayiheng Liu, Fei Huang, Haoran Wei, Huan Lin, Jian Yang, Jianhong Tu, Jianwei Zhang,\", \"Jianxin Yang, Jiaxi Yang, Jingren Zhou, Junyang Lin, Kai Dang, Keming Lu, Keqin Bao, Kexin\", \"Yang, Le Yu, Mei Li, Mingfeng Xue, Pei Zhang, Qin Zhu, Rui Men, Runji Lin, Tianhao Li,\", \"Tianyi Tang, Tingyu Xia, Xingzhang Ren, Xuancheng Ren, Yang Fan, Yang Su, Yichang Zhang,\", \"Yu Wan, Yuqiong Liu, Zeyu Cui, Zhenru Zhang, and Zihan Qiu. Qwen2.5 Technical Report.\", \"arXiv:2412.15115, 2024.\", \"[65] An Yang, Anfeng Li, Baosong Yang, Beichen Zhang, Binyuan Hui, Bo Zheng, Bowen Yu,\", \"Chang Gao, Chengen Huang, Chenxu Lv, Chujie Zheng, Dayiheng Liu, Fan Zhou, Fei Huang,\", \"Feng Hu, Hao Ge, Haoran Wei, Huan Lin, Jialong Tang, Jian Yang, Jianhong Tu, Jianwei Zhang,\", \"Jianxin Yang, Jiaxi Yang, Jing Zhou, Jingren Zhou, Junyang Lin, Kai Dang, Keqin Bao, Kexin\", \"Yang, Le Yu, Lianghao Deng, Mei Li, Mingfeng Xue, Mingze Li, Pei Zhang, Peng Wang, Qin\", \"Zhu, Rui Men, Ruize Gao, Shixuan Liu, Shuang Luo, Tianhao Li, Tianyi Tang, Wenbiao Yin,\", \"Xingzhang Ren, Xinyu Wang, Xinyu Zhang, Xuancheng Ren, Yang Fan, Yang Su, Yichang\", \"Zhang, Yinger Zhang, Yu Wan, Yuqiong Liu, Zekun Wang, Zeyu Cui, Zhenru Zhang, Zhipeng\", \"Zhou, and Zihan Qiu. Qwen3 technical report, 2025.\", \"[66] Haopeng Zhang, Philip S Yu, and Jiawei Zhang. A systematic survey of text summarization:\", \"From statistical methods to large language models.ACM Computing Surveys, 2024.\", \"[67] Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Peter Liu. PEGASUS: Pre-training with\", \"Conference on Machine Learning, volume 119, pages 11328–11339, 2020.\", \"[68] Tianyi Zhang, Faisal Ladhak, Esin Durmus, Percy Liang, Kathleen McKeown, and Tatsunori B\", \"Association for Computational Linguistics, 12:39–57, 2024.\", \"15\", \"have been written from different perspectives (e.g. author, reviewer), a total of 1143 samples, and\", \"•TLDR-Full: This version of SciTLDR uses the full text of a scientific paper as the input, making\", \"inputs much larger and summaries a much smaller fraction of the long-text. Otherwise, processing\", \"and patients. Hence, certain sentences require context for correct interpretation. To accommodate\", \"this, each question from the doctor and all subsequent patient responses were merged into a single\", \"sentence unit, following the pattern \\\"Doctor:questions. Patient:answers\\\". If a sample input\", \"contained two or fewer sentences after this merge, the entire sample is removed from the dataset;\", \"1129 samples remained after this filtering.\", \"Dialog is released under a Creative Commons Attribution 4.0 International license. Hence, our usages\", \"rbe available, which could be abstractive rather than extractive. The output of the algorithm is an\", \"First, for a long-text xwe compute a similarity score Vbetween each sentence ciand the reference\", \"summary, then sort sentences by score in descending order. We then iterate through the ranked\", \"combined extractive summary to rincreases by at least δ. Mathematically, if the current extractive\", \"curr;r), the sentencec iis added toy∗\", \"After one iteration through the sentences in x, we return y∗\", \"Input:Sentencesx= [c 1, . . . , c p], reference summaryr, scoring functionV(·;·), thresholdδ\", \"Sort indices by descendingvgiving the permutationπ= [π 1, . . . , π n];\", \"16\", \"extractive summarization where sentence-level labels were not available, we provided input sentences\", \"as separate strings to GPT-4o mini, along with the existing summary text from the dataset. The\", \", corresponding to each input claim, should be either 0 or 1, indicating\", \"whether the corresponding claim, or the information it carries, is indeed\", \"included in the actual summary. For example, if claim_1’s information is\", \"contained in the summary, then label_1 should be 1; if information carried in\", \"claim_3 cannot be found in the summary text, then label_3 should be 0.\", \"rization, the source text was provided to an LLM along with the individual sentences from that text as\", \"Please evaluate the importance of each input claim in the original text, based on\", \"should be a two decimal float number ranged between 0 and 1, indicating how\", \"For example, if claim 1’s information is highly aligned with that of the input\", \"text, and very likely to be included in the summary, then score 1 should be\", \"close to 1, say greater than 0.8; if information carried in claim 3 is trivial\", \"or only remotely related to the central message of the text, and is not worthy\", \"of inclusion in the summary, then score 3 should be close to 0, say less than\", \"0.2.\", \"We also experimented with prompting the LLM to give binary scores R(ci;y∗), rather than floats.\", \"Evaluate the importance of each input claim in the original text, based on how the\", \"should be either 0 or 1, indicating whether the corresponding input claim is\", \"summary. For example, if claim 1’s information is highly aligned with that of\", \"the input text, and very likely to be included in the summary, then score 1\", \"17\", \"related to the central message of the text, and is not worthy of inclusion in\", \"the summary, then score 3 should be 0.\", \"the LLM as to what type of information was important for a given dataset, ten examples from the\", \"- Use your own words and phrasing (abstractive, not extractive)\", \"ment and summary synthesis, we applied abstractive summarization with an LLM as a post-processing\", \"- Improve flow, coherence, and readability\", \"Sentence-level Recall Estimation.Unlike for extractive summaries, determining if an abstractive\", \"summary has retained a specific piece of important information requires a judgement call. Hence,\", \"18\", \"To supplement the results in Section 5.1, here we show the empirical coverage obtained by all methods\", \"all datapoints fall within the bounds for all plots, with occasional small deviations due to the inherent\", \"19\", \"(a) Cosine Similarity Centrality\", \"(b) Sentence Centrality\", \"(c) GUSUM\", \"(d) GPT-4o mini\", \"(e) Llama 3\", \"(f) Qwen 3\", \"(g) Gemini 2.0 Flash-Lite\", \"(h) Gemini 2.5 Flash\", \"coverage, on the CNN/DM dataset. Dashed lines show theoretical bounds given in Theorem 1. Results\", \"20\", \"(a) Cosine Similarity Centrality\", \"(b) Sentence Centrality\", \"(c) GUSUM\", \"(d) LexRank\", \"(e) Llama 3\", \"(f) Qwen 3\", \"(g) Gemini 2.0 Flash-Lite\", \"(h) Gemini 2.5 Flash\", \"coverage, on the CSDS dataset. Dashed lines show theoretical bounds given in Theorem 1. Results\", \"21\", \"(a) Cosine Similarity Centrality\", \"(b) Sentence Centrality\", \"(c) GUSUM\", \"(d) LexRank\", \"(e) GPT-4o mini\", \"(f) Llama 3\", \"(g) Qwen 3\", \"(h) Gemini 2.0 Flash-Lite\", \"(i) Gemini 2.5 Flash\", \"coverage, on the TLDR-AIC dataset. Dashed lines show theoretical bounds given in Theorem 1.\", \"22\", \"(a) Cosine Similarity Centrality\", \"(b) Sentence Centrality\", \"(c) GUSUM\", \"(d) GPT-4o mini\", \"(e) Llama 3\", \"(f) Qwen 3\", \"(g) Gemini 2.0 Flash-Lite\", \"(h) Gemini 2.5 Flash\", \"achieving coverage, on MTS dataset. Dashed lines show theoretical bounds given in Theorem 1.\", \"23\", \"(a) Cosine Similarity Centrality\", \"(b) Sentence Centrality\", \"(c) GUSUM\", \"(d) LexRank\", \"(e) GPT-4o mini\", \"(f) Llama 3\", \"(g) Qwen 3\", \"(h) Gemini 2.0 Flash-Lite\", \"(i) Gemini 2.5 Flash\", \"achieving coverage, on the ECT dataset. Dashed lines show theoretical bounds given in Theorem 1.\", \"24\", \"and methods5, analogous to Figure 3 in Section 5.1. The trend is similar, with higher αleading to\", \"lower recall of important content. We notice that for TLDR-AIC and CNN/DM, many of the lines\", \"long-texts for these datasets, making someβvalues effectively equivalent for thosex.\", \"5Due to computational constraints, we only compute this plot for LexRank on the CNN/DM dataset\", \"25\", \"(a) Cosine Similarity Centrality\", \"(b) Sentence Centrality\", \"(c) GUSUM\", \"(d) LexRank\", \"(e) GPT-4o mini\", \"(f) Llama 3\", \"(g) Qwen 3\", \"(h) Gemini 2.0 FlashLite\", \"(i) Gemini 2.5 Flash\", \"Figure 12: Target error rate αversus empirical recall B(y;y∗)of important sentences in summaries,\", \"empirical recall possible, making some values ofβequivalent.\", \"26\", \"(a) Cosine Similarity Centrality\", \"(b) Sentence Centrality\", \"(c) GUSUM\", \"(d) GPT-4o mini\", \"(e) Llama 3\", \"(f) Qwen 3\", \"(g) Gemini 2.0 Flash-Lite\", \"(h) Gemini 2.5 Flash\", \"Figure 13: Target error rate αversus empirical recall B(y;y∗)of important sentences in summaries,\", \"27\", \"(a) Cosine Similarity Centrality\", \"(b) Sentence Centrality\", \"(c) GUSUM\", \"(d) GPT-4o mini\", \"(e) Llama 3\", \"(f) Qwen 3\", \"(g) Gemini 2.0 Flash-Lite\", \"(h) Gemini 2.5 Flash\", \"Figure 14: Target error rate αversus empirical recall B(y;y∗)of important sentences in summaries,\", \"small number of ground-truth sentences, meaning there are only a few discrete levels of empirical\", \"recall possible, making some values ofβequivalent.\", \"28\", \"(a) Cosine Similarity Centrality\", \"(b) Sentence Centrality\", \"(c) GUSUM\", \"(d) GPT-4o mini\", \"(e) Llama 3\", \"(f) Qwen 3\", \"(g) Gemini 2.0 Flash-Lite\", \"(h) Gemini 2.5 Flash\", \"Figure 15: Target error rate αversus empirical recall B(y;y∗)of important sentences in summaries,\", \"empirical recall possible, making some values ofβequivalent.\", \"29\", \"(a) Cosine Similarity Centrality\", \"(b) Sentence Centrality\", \"(c) GUSUM\", \"(d) GPT-4o mini\", \"(e) Llama 3\", \"(f) Qwen 3\", \"(g) Gemini 2.0 Flash-Lite\", \"(h) Gemini 2.5 Flash\", \"Figure 16: Target error rate αversus empirical recall B(y;y∗)of important sentences in summaries,\", \"30\", \"Figures 17 - 20 show the conciseness, the proportion of sentences removed, based on the choice of β\", \"for all datasets and methods6, analogous to Figure 4 in Section 5.1. Once again, the trend is highly\", \"similar across settings, with higherβleading to a smaller reduction in length.\", \"6Due to computational constraints, we only compute this plot for LexRank on the CNN/DM dataset\", \"31\", \"(a) Cosine Similarity Centrality\", \"(b) Sentence Centrality\", \"(c) GUSUM\", \"(d) LexRank\", \"(e) GPT-4o mini\", \"(f) Llama 3\", \"(g) Qwen 3\", \"(h) Gemini 2.0 Flash-Lite\", \"(i) Gemini 2.5 Flash\", \"(a) Cosine Similarity Centrality\", \"(b) Sentence Centrality\", \"(c) GUSUM\", \"(d) GPT-4o mini\", \"(e) Llama 3\", \"(f) Qwen 3\", \"(g) Gemini 2.0 Flash-Lite\", \"(h) Gemini 2.5 Flash\", \"33\", \"(a) Cosine Similarity Centrality\", \"(b) Sentence Centrality\", \"(c) GUSUM\", \"(d) GPT-4o mini\", \"(e) Llama 3\", \"(f) Qwen 3\", \"(g) Gemini 2.0 Flash-Lite\", \"(h) Gemini 2.5 Flash\", \"34\", \"(a) Cosine Similarity Centrality\", \"(b) Sentence Centrality\", \"(c) GUSUM\", \"(d) GPT-4o mini\", \"(e) Llama 3\", \"(f) Qwen 3\", \"(g) Gemini 2.0 Flash-Lite\", \"(h) Gemini 2.5 Flash\", \"35\", \"(a) Cosine Similarity Centrality\", \"(b) Sentence Centrality\", \"(c) GUSUM\", \"(d) GPT-4o mini\", \"(e) Llama 3\", \"(f) Qwen 3\", \"(g) Gemini 2.0 Flash-Lite\", \"(h) Gemini 2.5 Flash\", \"36\", \"Table 3: Performance comparison of importance scoring methods, measured in AUPRC of claim\", \"Table 4: Performance comparison of importance scoring methods, measured in conciseness of\", \"using labels generated from ROUGE scores, rather than cosine similarity, using Algorithm 1. Since\", \"we only use this algorithm for CNN/DM and SciTLDR, we only display results for CNN/DM and\", \"in terms of AUPRC, and Gemini 2.5 Flash still performs very well in terms of sentence reduction\", \"Throughout the paper, we used a fixed calibration set size of n= 100 samples to demonstrate that the\", \"method can operate with very little labeled data. However, in some regimes the availability of labeled\", \"data can be extremely limited, so in this section we test our method with even fewer calibration\", \"coverage guarantee is famously “valid in finite samples”, meaning that it holds statistically for any\", \"37\", \"1−α n= 25n= 50n= 75n= 100 n= 25n= 50n= 75n= 100\", \"0.60 0.61 0.61 0.60 0.61 0.09 0.07 0.05 0.05\", \"0.65 0.65 0.67 0.66 0.65 0.09 0.07 0.06 0.05\", \"0.70 0.73 0.71 0.71 0.70 0.09 0.06 0.05 0.05\", \"0.75 0.77 0.77 0.75 0.75 0.09 0.06 0.05 0.05\", \"0.80 0.81 0.81 0.80 0.80 0.08 0.05 0.05 0.04\", \"0.85 0.89 0.86 0.86 0.85 0.06 0.05 0.04 0.04\", \"0.90 0.92 0.90 0.91 0.90 0.05 0.04 0.03 0.03\", \"0.95 0.96 0.96 0.96 0.95 0.04 0.03 0.02 0.02\", \"25 0.28 0.09\", \"50 0.31 0.08\", \"75 0.32 0.08\", \"100 0.33 0.05\", \"finite calibration dataset. In practice, ncontrols the variance of the coverage viewed as a random\", \"variable over the calibration data. For a textbook-style explanation of these details, see Section 3.2 of\", \"[2].\", \"function to generate results on the ECTSum dataset, shown in Table 5. As guaranteed by Theorem 1,\", \"the minimum coverage 1−α by a bit more, because the upper bound of 1−α+1\", \"looser with n, but we still find all values within theoretical bounds (for example,1\", \"25+1≈0.04 , and\", \"1\", \"50+1≈0.02 ). The primary reason to increase nis to reduce the variance of the empirical coverage\", \"Given that we find the coverage guarantee to be satisfied, we can also check the main metric of our\", \"removed). In Table 6 we find little difference in the performance when using 50to100samples,\", \"although variance is increased on smaller datasets. Overall, this ablation demonstrates that our\", \"comparison between extractive summarization with our conformal method, abstractive summarization\", \"with an LLM, and our hybrid proposal of applying abstractive summarization to our extractive sum-\", \"mary, this time with Gemini 2.5 Flash used for both conformal scoring, and abstractive summarization.\", \"38\", \"Figure 22: Comparison between extractive summarization with our method, abstractive summariza-\", \"tion with an LLM, and our hybrid proposal on ECTSum. Here the target coverage is 1−α= 0.8 ,\", \"the conformal approach uses Gemini 2.5 Flash scoring, and the abstractive model is also Gemini 2.5\", \"39\"], \"error\": null}, \"62ab4514\": {\"success\": true, \"paper_id\": \"62ab4514\", \"url\": \"https://arxiv.org/pdf/1606.07965v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_62ab4514.pdf\", \"extracted_info\": {\"title\": \"Summarizing Decisions in Spoken Meetings\", \"authors\": [\"Not specified in provided content\"], \"abstract\": \"This paper addresses the problem of summarizing decisions in spoken meetings, aiming to produce concise decision abstracts for each meeting decision. The authors explore and compare token-level and dialogue act-level automatic summarization methods using both unsupervised and supervised learning frameworks. In the supervised setting, decision-related dialogue acts (DRDAs) are assumed to be identified, and summarization methods are applied to generate short, informative abstracts.\", \"methodology\": \"The study uses the AMI meeting corpus as the dataset. It first clusters decision-related dialogue acts (DRDAs) using unsupervised methods (TF-IDF similarity, LDA topic modeling) and supervised methods (SVM, Maximum Entropy) for pairwise similarity classification. Summarization is then performed at both the dialogue act (DA) level and token level using unsupervised approaches (longest DA, prototype DA) and supervised learning (SVM, CRF), with and without discourse context. ROUGE-1 is used for evaluation, and experiments are conducted with true clusterings and system-generated clusterings.\", \"results\": \"All proposed clustering methods outperform baselines. LDA topic modeling outperforms TF-IDF among unsupervised methods, while SVM and MaxEnt yield comparable results in supervised clustering. For summarization, adding discourse context improves performance when true DRDA clusterings are available. Token-level summarization outperforms DA-level summarization in true clustering scenarios, but DA-level performs better when clusterings are noisy. ROUGE-1 scores show modest improvements with supervised methods over unsupervised ones.\", \"conclusion\": \"The paper is the first to explore and compare token-level and dialogue act-level supervised and unsupervised methods for decision summarization in meetings. It demonstrates that clustering DRDAs improves summarization quality, that discourse context can boost performance, and that token-level summarization can outperform DA-level under certain conditions. The work provides a systematic evaluation framework for decision summarization in spoken meetings and offers insights into the trade-offs between different summarization granularities and learning approaches.\", \"figures\": null, \"tables\": null}, \"citations\": [\"uation Workshop on Linguistics Coreference , pages\", \"563–566.\", \"Satanjeev Banerjee, CarolynPenstein Ros´ e, and Alexan-\", \"ing recording and playback system, and the beneﬁt of\", \"Adam L. Berger, Vincent J. Della Pietra, and Stephen\", \"to natural language processing. Comput. Linguist. ,\", \"22:39–71,March.\", \"David M. Blei, Andrew Y. Ng, and Michael I. Jordan.\", \"2003. Latent dirichlet allocation. J. Mach. Learn.\", \"Res.,3:993–1022,March.\", \"Trung H. Bui, Matthew Frampton, John Dowding, and\", \"DIAL2009Conference ,pages235–243.\", \"Anne Hendrik Buist, Wessel Kraaij, and Stephan Raaij-\", \"Jean Carletta, Simone Ashby, Sebastien Bourban,\", \"Mike Flynn, Thomas Hain, Jaroslav Kadlec, Vasilis\", \"Karaiskos, Wessel Kraaij, Melissa Kronenthal, Guil-\", \"laume Lathoud, Mike Lincoln, Agnes Lisowska, and\", \"ComputationalLinguisticsconference ,pages26–33.\", \"Raquel Fern´ andez, Matthew Frampton, John Dowding,\", \"AnishAdukuzhiyil,PatrickEhlen,andStanleyPeters.\", \"2008a. Identifying relevant phrases to summarize de-\", \"cisions in spoken meetings. INTERSPEECH-2008,\", \"Raquel Fern´ andez, Matthew Frampton, Patrick Ehlen,\", \"Matthew Purver, and Stanley Peters. 2008b. Mod-\", \"courseandDialogue ,pages156–163.\", \"MatthewFrampton,JiaHuang,TrungHuuBui,andStan-\", \"Processing: Volume3-Volume3 ,pages1133–1141.\", \"MethodsinNaturalLanguageProcessing ,pages364–\", \"372.\", \"ingformultimodalinteraction ,pages168–179.\", \"features. In Claire N´ edellec and C´ eline Rouveirol,\", \"editors,Machine Learning: ECML-98 , volume 1398,\", \"chapter19,pages137–142.Berlin/Heidelberg.\", \"ogy-Volume1 ,pages71–78.\", \"marization . MITPress, Cambridge,MA,USA.\", \"course Parsing and Summarization . MITPress, Cam-\", \"M. Marneffe, B. Maccartney, and C. Manning. 2006.\", \"Structure Parses. In Proceedings of LREC-06 , pages\", \"449–454.\", \"mationbaseddistance. J.Multivar.Anal. ,98:873–895,\", \"Gabriel Murray, Steve Renals, and Jean Carletta. 2005.\", \"Speech Communication and Technology , pages 593–\", \"596.\", \"Gerard Salton, Amit Singhal, Mandar Mitra, and Chris\", \"summarization. Inf. Process. Manage. , 33:193–207,\", \"ings.Semiotica ,8(4):289–327.\", \"Shasha Xie, Yang Liu, and Hui Lin. 2008. Evaluating\", \"Comput.Linguist. ,28:447–485,December.\"], \"error\": null}, \"c174c97c\": {\"success\": true, \"paper_id\": \"c174c97c\", \"url\": \"https://arxiv.org/pdf/2110.01159v2\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_c174c97c.pdf\", \"extracted_info\": {\"title\": \"TLDR9+ and TLDRHQ: Large-Scale Datasets for Extreme Abstractive Summarization of Reddit Posts\", \"authors\": [\"Sajad Sotudeh\", \"Arman Cohan\", \"Nazli Goharian\"], \"abstract\": \"Recent models in developing summarization systems consist of millions of parameters. This paper introduces two large-scale datasets, TLDR9+ and TLDRHQ, specifically designed for extreme abstractive summarization of Reddit posts. TLDR9+ contains over 9 million instances, more than twice the size of previous datasets, while TLDRHQ is a high-quality subset of 1.7 million instances obtained through heuristic filtering and human annotation. These datasets aim to facilitate research in both extractive and abstractive summarization.\", \"methodology\": \"The authors collected Reddit posts containing TLDR-style summaries from publicly available Reddit data dumps. TLDR9+ was created by extracting over 9 million post-summary pairs. A heuristic filtering method, supported by human annotation, was applied to remove low-quality instances, resulting in TLDRHQ with 1.7 million high-quality samples. The datasets were split into training, validation, and test sets. Several state-of-the-art extractive and abstractive summarization models, including BERTSUMEXT, BERTSUMABS, and BART, were benchmarked on both datasets using ROUGE metrics. Abstractiveness and novel n-gram statistics were also analyzed.\", \"results\": \"TLDR9+ contains 9,227,437 instances, while TLDRHQ contains 1,671,099 high-quality instances. On TLDRHQ, the ORACLE-EXT model achieved ROUGE-1 of 45.29%, ROUGE-2 of 25.47%, and ROUGE-L of 36.86%. Abstractive models such as BART generated more novel n-grams and exhibited higher abstractiveness compared to extractive models. The performance gap between extractive and abstractive models was significant, indicating the challenging nature of extreme abstractive summarization.\", \"conclusion\": \"The paper contributes two large-scale datasets for extreme abstractive summarization: TLDR9+ and TLDRHQ. TLDRHQ is a high-quality subset curated through heuristic filtering and human annotation. The datasets support both extractive and abstractive summarization research, provide benchmark results using state-of-the-art models, and offer detailed analysis of abstractiveness and n-gram novelty. These resources aim to advance summarization research, particularly in handling noisy, user-generated content.\", \"figures\": null, \"tables\": null}, \"citations\": [\"A. Althnian, D. AlSaeed, Heyam H. Al-Baity,\", \"Amani K. Samha, Alanoud Bin Dris, Najla Alza-\", \"kari, A. A. Elwafa, and H. Kurdi. 2021. Impact of\", \"Jason Baumgartner, Savvas Zannettou, Brian Kee-\", \"gan, Megan Squire, and J. Blackburn. 2020. The\", \"E. M. Bennet, R. Alpert, and A. C. Goldstein. 1954.\", \"tioning*. Public Opinion Quarterly , 18(3):303–308.\", \"Isabel Cachola, Kyle Lo, Arman Cohan, and Daniel S.\", \"Sangwoo Cho, Kaiqiang Song, Chen Li, Dong Yu,\", \"H. Foroosh, and Fei Liu. 2020. Better highlight-\", \"Arman Cohan, Franck Dernoncourt, Doo Soon Kim,\", \"Trung Bui, Seokhwan Kim, W. Chang, and Nazli\", \"Yue Dong, Yikang Shen, E. Crawford, H. V . Hoof, and\", \"Sebastian Gehrmann, Y . Deng, and Alexander M.\", \"Sebastian Gehrmann, Zachary M. Ziegler, and Alexan-\", \"David Graff, Junbo Kong, Ke Chen, and Kazuaki\", \"Consortium, Philadelphia , 4(1):34.\", \"Matt Grenander, Yue Dong, J. C. K. Cheung, and An-\", \"Max Grusky, M. Naaman, and Yoav Artzi. 2018. News-\", \"term memory. Neural Computation , 9:1735–1780.\", \"Chris Kedzie, K. McKeown, and Hal Daumé. 2018.\", \"marization. In EMNLP .Byeongchang Kim, Hyunwoo Kim, and Gunhee Kim.\", \"2019. Abstractive summarization of reddit posts\", \"A method for stochastic optimization. CoRR ,\", \"tion. ArXiv , abs/1910.00523.\", \"Ankit Kumar, Piyush Makhija, and Anuj Gupta. 2020.\", \"Logan Lebanoff, Franck Dernoncourt, Doo Soon Kim,\", \"Lidan Wang, W. Chang, and Fei Liu. 2020. Learn-\", \"M. Lewis, Yinhan Liu, Naman Goyal, Marjan\", \"Ghazvininejad, A. Mohamed, Omer Levy, V . Stoy-\", \"anov, and Luke Zettlemoyer. 2020. Bart: Denoising\", \"guage generation, translation, and comprehension.\", \"Sean MacAvaney, Sajad Sotudeh, Arman Cohan, Nazli\", \"Goharian, Ish A. Talati, and Ross W. Filice. 2019.\", \"Ramesh Nallapati, Feifei Zhai, and Bowen Zhou. 2017.\", \"Marcin Namysl, Sven Behnke, and J. Kohler. 2020.\", \"Shashi Narayan, Shay B. Cohen, and Mirella Lapata.\", \"2018. Don’t give me the details, just the summary!\", \"Shashi Narayan, Joshua Maynez, Jakub Adámek,\", \"Daniele Pighin, Blavz Bratanivc, and Ryan T. Mc-\", \"Alexander M. Rush, Harvard Seas, S. Chopra, and\", \"A. See, Peter J. Liu, and Christopher D. Manning.\", \"2017. Get to the point: Summarization with pointer-\", \"Eva Sharma, Chen Li, and L. Wang. 2019. Bigpatent:\", \"Sajad Sotudeh, Arman Cohan, and Nazli Goharian.\", \"2021a. On generating extended summaries of long\", \"Sajad Sotudeh, Arman Cohan, and Nazli Goharian.\", \"2021b. On generating extended summaries of long\", \"documents. SDU@AAAI , abs/2012.14136.\", \"Sajad Sotudeh, Nazli Goharian, and R. Filice. 2020a.\", \"Sajad Sotudeh, Tong Xiang, Hao-Ren Yao, Sean MacA-\", \"vaney, Eugene Yang, Nazli Goharian, and Ophir\", \"Ashish Vaswani, Noam M. Shazeer, Niki Parmar,\", \"Jakob Uszkoreit, Llion Jones, Aidan N. Gomez,\", \"Lukasz Kaiser, and Illia Polosukhin. 2017. Atten-\", \"tion is all you need. ArXiv , abs/1706.03762.\", \"Michael Völske, Martin Potthast, Shahbaz Syed, and\", \"Thomas Wolf, Lysandre Debut, Victor Sanh, Julien\", \"Chaumond, Clement Delangue, Anthony Moi, Pier-\", \"ric Cistac, Tim Rault, Rémi Louf, Morgan Funtow-\", \"icz, Joe Davison, Sam Shleifer, Patrick von Platen,\", \"Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu,\", \"Teven Le Scao, Sylvain Gugger, Mariama Drame,\", \"Quentin Lhoest, and Alexander M. Rush. 2020.\", \"System Demonstrations , pages 38–45, Online. Asso-\", \"solutions. Journal of Physics: Conference Series ,\", \"1168:022022.\", \"Jingqing Zhang, Yao Zhao, Mohammad Saleh, and Pe-\", \"Chenguang Zhu, Ziyi Yang, R. Gmyr, Michael Zeng,\"], \"error\": null}, \"04e369ed\": {\"success\": true, \"paper_id\": \"04e369ed\", \"url\": \"https://arxiv.org/pdf/1909.13705v1\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_04e369ed.pdf\", \"extracted_info\": {\"title\": \"Data-Dependent Analysis of Neural Extractive Summarization Methods\", \"authors\": [\"Not specified in provided content\"], \"abstract\": \"In this paper, we take stock of the current state of summarization datasets and explore how different training methods affect model performance. By taking a typical dataset as an example, we rethink the process of model design based on prior experience, aiming to improve neural extractive summarization systems through better understanding of dataset characteristics and learning strategies.\", \"methodology\": \"The study analyzes multiple summarization datasets (CNN/DM, arXiv, PubMed, DUC2002, NYT50, Newsroom) and compares different neural extractive summarization methods in terms of network architectures, training schemas, and use of pre-trained knowledge. Experiments include multi-domain learning, constituent/style factor analysis, and cross-dataset evaluations. Models tested include LSTM and Transformer architectures with and without pre-trained embeddings (Word2Vec, BERT). Performance is measured using ROUGE scores, coverage rates (PCR, CCR), and dataset-specific density/compression metrics.\", \"results\": \"Key findings include: (1) Dividing the training set based on domain significantly improves performance; (2) BERT enhances results but is not universally effective; (3) Dataset biases lead to performance differences in cross-dataset settings; (4) High-density datasets concentrate salient information, improving summarization accuracy; (5) Pre-trained word vectors generally improve performance, but benefits diminish with increased sample difficulty; (6) Simple domain tagging can boost both base and state-of-the-art models.\", \"conclusion\": \"The paper provides a data-dependent understanding of neural extractive summarization, highlighting the importance of dataset characteristics in model performance. Contributions include: (1) Demonstrating the impact of domain-based training partitioning; (2) Showing limitations of BERT in certain contexts; (3) Identifying dataset bias effects in cross-domain generalization; (4) Proposing simple yet effective domain tagging; (5) Offering insights into how density and compression influence summarization quality; (6) Presenting comparative evaluations across multiple datasets and learning methods to guide future research.\", \"figures\": null, \"tables\": null}, \"citations\": [\"Devansh Arpit, Stanisław Jastrzebski, Nicolas Ballas,\", \"David Krueger, Emmanuel Bengio, Maxinder S Kan-\", \"wal, Tegan Maharaj, Asja Fischer, Aaron Courville,\", \"Yoshua Bengio, et al. 2017. A closer look at\", \"Learning-Volume 70 , pages 233–242. JMLR. org.\", \"Asli Celikyilmaz, Antoine Bosselut, Xiaodong He, and\", \"2018 Conference of the North American Chapter of\", \"man Language Technologies, Volume 1 (Long Pa-\", \"pers) , volume 1, pages 1662–1675.\", \"(Volume 1: Long Papers) , volume 1, pages 675–686.\", \"Long Papers) , volume 1, pages 484–494.\", \"Arman Cohan, Franck Dernoncourt, Doo Soon Kim,\", \"Trung Bui, Seokhwan Kim, Walter Chang, and Nazli\", \"tional Linguistics: Human Language Technologies,\", \"Volume 2 (Short Papers) , pages 615–621.\", \"Jacob Devlin, Ming-Wei Chang, Kenton Lee, and\", \"ing. arXiv preprint arXiv:1810.04805 .Li Dong, Nan Yang, Wenhui Wang, Furu Wei,\", \"Xiaodong Liu, Yu Wang, Jianfeng Gao, Ming\", \"Zhou, and Hsiao-Wuen Hon. 2019. Uniﬁed\", \"Sebastian Gehrmann, Yuntian Deng, and Alexander\", \"cal Methods in Natural Language Processing , pages\", \"4098–4109.\", \"Max Grusky, Mor Naaman, and Yoav Artzi. 2018.\", \"2018 Conference of the North American Chapter of\", \"man Language Technologies, Volume 1 (Long Pa-\", \"pers) , volume 1, pages 708–719.\", \"Luheng He, Kenton Lee, Mike Lewis, and Luke Zettle-\", \"tional Linguistics (Volume 1: Long Papers) , vol-\", \"ume 1, pages 473–483.\", \"Long short-term memory. Neural computation ,\", \"9(8):1735–1780.\", \"Papers) , volume 1, pages 142–151.\", \"Taehee Jung, Dongyeop Kang, Lucas Mentch, and Ed-\", \"marization. CoRR , abs/1903.10318.\", \"Tomas Mikolov, Kai Chen, Greg Corrado, and Jef-\", \"Pramod Kaushik Mudrakarta, Ankur Taly, Mukund\", \"Sundararajan, and Kedar Dhamdhere. 2018. Did\", \"Computational Linguistics (Volume 1: Long Papers) ,\", \"Ramesh Nallapati, Feifei Zhai, and Bowen Zhou. 2017.\", \"Ramesh Nallapati, Bowen Zhou, Cicero dos Santos,\", \"C ¸ a glar Gulc ¸ehre, and Bing Xiang. 2016. Abstrac-\", \"rnns and beyond. CoNLL 2016 , page 280.\", \"Shashi Narayan, Shay B Cohen, and Mirella Lapata.\", \"2018. Ranking sentences for extractive summariza-\", \"Human Language Technologies, Volume 1 (Long Pa-\", \"pers) , volume 1, pages 1747–1759.\", \"Matthew Peters, Mark Neumann, Mohit Iyyer, Matt\", \"Gardner, Christopher Clark, Kenton Lee, and Luke\", \"of NAACL , volume 1, pages 2227–2237.\", \"corpus. Linguistic Data Consortium, Philadelphia ,\", \"6(12):e26752.\", \"Ludwig Schmidt, Shibani Santurkar, Dimitris Tsipras,\", \"Kunal Talwar, and Aleksander Madry. 2018. Adver-\", \"Advances in Neural Information Processing Systems ,\", \"Abigail See, Peter J Liu, and Christopher D Manning.\", \"2017. Get to the point: Summarization with pointer-\", \"Linguistics (Volume 1: Long Papers) , volume 1,\", \"Mukund Sundararajan, Ankur Taly, and Qiqi Yan. 2017.\", \"Machine Learning-Volume 70 , pages 3319–3328.\", \"Ashish Vaswani, Noam Shazeer, Jakob Parmar, Llion\", \"Jones, Aidan N Gomez, Łukasz Kaiser, and Illia\", \"Danqing Wang, Pengfei Liu, Ming Zhong, Jie Fu,\", \"Xipeng Qiu, and Xuanjing Huang. 2019. Exploring\", \"Chiyuan Zhang, Samy Bengio, Moritz Hardt, Ben-\", \"jamin Recht, and Oriol Vinyals. 2016. Understand-\", \"Ming Zhong, Pengfei Liu, Danqing Wang, Xipeng Qiu,\", \"guistics , pages 1049–1058, Florence, Italy. Associa-\", \"Qingyu Zhou, Nan Yang, Furu Wei, Shaohan Huang,\", \"Ming Zhou, and Tiejun Zhao. 2018. Neural docu-\", \"guistics (Volume 1: Long Papers) , volume 1, pages\", \"654–663.\"], \"error\": null}, \"3794020a\": {\"success\": false, \"paper_id\": \"3794020a\", \"url\": \"https://link.springer.com/content/pdf/10.1007/s10772-025-10215-y.pdf\", \"pdf_path\": null, \"extracted_info\": null, \"error\": \"download failed: invalid PDF content type: text/html; charset=utf-8\"}, \"ea96a96f\": {\"success\": true, \"paper_id\": \"ea96a96f\", \"url\": \"https://arxiv.org/pdf/2010.06792v2\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_ea96a96f.pdf\", \"extracted_info\": {\"title\": \"Knowledge-Enhanced Weakly Supervised Aspect-Based Abstractive Summarization\", \"authors\": [\"Not specified in provided content\"], \"abstract\": \"Given a document and a target aspect (e.g., a topic of interest), aspect-based abstractive summarization attempts to generate a summary with respect to the aspect. Previous studies usually suffer from the lack of direct supervision for this task. This paper proposes a weak supervision construction method and an aspect modeling scheme, both integrating rich external knowledge sources such as ConceptNet and Wikipedia, to improve summarization performance.\", \"methodology\": \"The authors propose a weakly supervised approach for aspect-based abstractive summarization by leveraging external knowledge bases (ConceptNet, Wikipedia) to construct pseudo-supervision data. They fine-tune a pre-trained BART model using this weak supervision and compare it against fully supervised baselines. Experiments are conducted on real news articles (All The News corpus) and synthetic datasets (MA-News) to evaluate performance and domain adaptation efficiency.\", \"results\": \"On the MA-News test set, the proposed BART Weak-Sup model outperforms the previous best model (SF) with ROUGE scores of approximately 28 (ROUGE-1), despite using only weak supervision. The fully supervised BART model with 280K examples achieves the highest scores (ROUGE-1: 41.90), but the weakly supervised model shows strong performance with significantly less labeled data. Domain adaptation experiments demonstrate that adding weak supervision improves performance across varying sizes of supervised training data.\", \"conclusion\": \"This work introduces a novel weakly supervised method for aspect-based abstractive summarization that integrates external knowledge sources to generate supervision signals. The approach achieves competitive results with minimal labeled data, demonstrates strong domain adaptation capabilities, and provides a framework for summarizing documents on arbitrary relevant aspects. The findings suggest potential for further integration of richer external knowledge and supervision forms.\", \"figures\": null, \"tables\": null}, \"citations\": [\"John M Conroy, Judith D Schlesinger, and Dianne P\", \"COLING/ACL , pages 152–159.\", \"DUC , volume 2005, pages 1–12.\", \"query-focused summarization. In COLING/ACL ,\", \"summarization. In EMNLP , pages 3711–3720.\", \"rization. In ACL, pages 6263–6273, Florence, Italy.\", \"Karl Moritz Hermann, Tomas Kocisky, Edward Grefen-\", \"stette, Lasse Espeholt, Will Kay, Mustafa Suleyman,\", \"and comprehend. In NeurIPS , pages 1693–1701.\", \"rizing customer reviews. In KDD , pages 168–177.\", \"Zhiting Hu, Xuezhe Ma, Zhengzhong Liu, Eduard\", \"Hovy, and Eric Xing. 2016. Harnessing deep neu-\", \"Zhiting Hu, Haoran Shi, Bowen Tan, Wentao Wang,\", \"Zichao Yang, Tiancheng Zhao, Junxian He, Lianhui\", \"Qin, Di Wang, et al. 2019a. Texar: A modularized,\", \"versatile, and extensible toolkit for text generation.\", \"InACL 2019, System Demonstrations .\", \"Zhiting Hu, Bowen Tan, Russ R Salakhutdinov, Tom M\", \"Mitchell, and Eric P Xing. 2019b. Learning data\", \"Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan\", \"Salakhutdinov, and Eric P Xing. 2017. Toward con-\", \"attention. In NAACL , pages 1697–1705.\", \"Wojciech Kryscinski, Nitish Shirish Keskar, Bryan Mc-\", \"Cann, Caiming Xiong, and Richard Socher. 2019.\", \"Mike Lewis, Yinhan Liu, Naman Goyal, Mar-\", \"jan Ghazvininejad, Abdelrahman Mohamed, Omer\", \"Levy, Ves Stoyanov, and Luke Zettlemoyer. 2019.\", \"for natural language generation, translation, and\", \"tion. In COLING , pages 495–501.\", \"Yan Liu, Sheng-hua Zhong, and Wenjie Li. 2012.\", \"Ramesh Nallapati, Bowen Zhou, Caglar Gulcehre,\", \"Bing Xiang, et al. 2016. Abstractive text summariza-\", \"Shashi Narayan, Shay B Cohen, and Mirella Lapata.\", \"2018. Don’t give me the details, just the summary!\", \"Myle Ott, Sergey Edunov, Alexei Baevski, Angela\", \"Fan, Sam Gross, Nathan Ng, David Grangier, and\", \"Michael Auli. 2019. fairseq: A fast, extensible\", \"Haoruo Peng, Yangqiu Song, and Dan Roth. 2016.\", \"pervision. In EMNLP , pages 392–402.\", \"Natural language processing and text mining , pages\", \"9–28. Springer.\", \"Alexander Ratner, Stephen H Bach, Henry Ehrenberg,\", \"Jason Fries, Sen Wu, and Christopher Ré. 2017.\", \"Abigail See, Peter J Liu, and Christopher D Manning.\", \"2017. Get to the point: Summarization with pointer-\", \"Rico Sennrich, Barry Haddow, and Alexandra Birch.\", \"2016. Improving neural machine translation models\", \"with monolingual data. In ACL, pages 86–96.\", \"Robyn Speer, Joshua Chin, and Catherine Havasi. 2017.\", \"text classiﬁcation tasks. In EMNLP , pages 6383–\", \"6389.\", \"Yujia Xie, Tianyi Zhou, Yi Mao, and Weizhu Chen.\", \"2020. Conditional self-attention for query-based\", \"Daniel M Ziegler, Nisan Stiennon, Jeffrey Wu, Tom B\", \"Brown, Alec Radford, Dario Amodei, Paul Chris-\", \"tiano, and Geoffrey Irving. 2019. Fine-tuning lan-\", \"We use Adam optimizer with \\f= (0:9;0:999);\\u000f= 10\\u00008, a weight decay of 0.01, and an initial learning\", \"rate of 3e-5. For generation, we use beam search decoding with a width of 4 and a length penalty of 2. All\", \"Document In an exclusive interview with Breitbart News, Republican presidential nominee Donald Trump blasted Bill Clinton’s\", \"the people that are living there. I think it’s crazy,” Trump told Breitbart on Thursday. “I mean, these people are getting started —\", \"I think it’s a very, very hard place to get your start. ” “We shouldn’t have them [i. e. Syrian refugees] in the country,” Trump\", \"who they are. The whole thing is ridiculous. Number one: we should build safe zones over in Syria, that’s what we should\", \"have, and we should have the Gulf states fund them. It’s just crazy. We ought to be building safe zones in Syria and not taking\", \"into refugees in their own country. “There are plenty of people in Detroit who you could almost look at as refugees,” Carson\", \"said. “I mean, we need to take care of our own people. We need to create jobs for them. ” Clinton’s suggestion that the U. S.\", \"billionaire and mass migration enthusiast, Hamdi Ulukaya. “The truth is that the big loser in this over the long run is going to be\", \"Syria. This [i. e. the Syrian migrant crisis] is an enormous opportunity for Americans,” Clinton said in February. “Detroit has 10,\", \"000 empty, structurally sound houses — 10, 000. And lot of jobs are to be had repairing those houses. Detroit just came out\", \"or Syrian refugees think it’s a pretty good deal. ” During the discussion, Clinton praised Ulukaya for his efforts to ﬁll his yogurt\", \"community just like in . . . Twin Falls, [Idaho]” where Ulukaya’s yogurt factory is based. Clinton’s controversial suggestion\", \"During his Wednesday immigration policy address, Trump challenged the media to begin asking Hillary Clinton to explain her\", \"will affect Americans and their security . . . These are matters of for our country and its people, and we deserve answers from\", \"Hillary Clinton . . . What we do know, despite the total lack of media curiosity, is that Hillary Clinton promises a radical amnesty\", \"combined with a radical reduction in immigration enforcement. The result will be millions of more illegal immigrants, thousands\", \"of more violent crimes, and total chaos and lawlessness. According to Pew polling data, Hillary Clinton’s plan to expand\", \"opposing immigration. According to a September 2015 Rasmussen survey, 85 percent black voters oppose Clinton’s refugee\", \"agenda to admit more than 100, 000 Middle Eastern refugees — with less than one percent of black voters (. 56 percent) in favor\", \"Summary: Chobani billionaire and mass migration enthusiast, Hamdi Ulukaya, suggested that the U.S. should take in more\", \"refugees to ﬁll jobs like in his yogurt plant in Twin Falls, Idaho, where his factory is based.\", \"black voters oppose the plan to admit more than 100,000 middle eastern refugees to the country.\", \"Document the palestinian authority ofﬁcially became the 123rd member of the international criminal court on wednesday, a step\", \"at the hague, in the netherlands, where the court is based. the palestinians signed the icc’s founding rome statute in january, when\", \"they also accepted its jurisdiction over alleged crimes committed \\\"in the occupied palestinian territory, including east jerusalem,\", \"since june 13, 2014.\\\" later that month, the icc opened a preliminary examination into the situation in palestinian territories,\", \"paving the way for possible war crimes investigations against israelis. as members of the court, palestinians may be subject to\", \"counter-charges as well. israel and the united states, neither of which is an icc member, opposed the palestinians’ efforts to join\", \"the body. but palestinian foreign minister riad al-malki, speaking at wednesday’s ceremony, said it was a move toward greater\", \"justice. \\\"as palestine formally becomes a state party to the rome statute today, the world is also a step closer to ending a long\", \"era of impunity and injustice,\\\" he said, according to an icc news release. \\\" indeed, today brings us closer to our shared goals\", \"of justice and peace.\\\" judge kuniko ozaki, a vice president of the icc, said acceding to the treaty was just the ﬁrst step for the\", \"palestinians. \\\"as the rome statute today enters into force for the state of palestine, palestine acquires all the rights as well as\", \"responsibilities that come with being a state party to the statute. these are substantive commitments, which cannot be taken\", \"lightly,\\\" she said. rights group human rights watch welcomed the development. \\\"governments seeking to penalize palestine for\", \"joining the icc should immediately end their pressure, and countries that support universal acceptance of the court’s treaty should\", \"speak out to welcome its membership,\\\" said balkees jarrah, international justice counsel for the group. \\\"what’s objectionable is\", \"the attempts to undermine international justice, not palestine’s decision to join a treaty to which over 100 countries around the\", \"world are members.\\\" in january, when the preliminary icc examination was opened, israeli prime minister benjamin netanyahu\", \"described it as an outrage, saying the court was overstepping its boundaries. the united states also said it \\\"strongly\\\" disagreed\", \"with the court’s decision. \\\"as we have said repeatedly, we do not believe that palestine is a state and therefore we do not believe\", \"that it is eligible to join the icc,\\\" the state department said in a statement. it urged the warring sides to resolve their differences\", \"peace,\\\" it said. but the icc begs to differ with the deﬁnition of a state for its purposes and refers to the territories as \\\"palestine.\\\"\", \"while a preliminary examination is not a formal investigation, it allows the court to review evidence and determine whether to\", \"and impartiality.\\\" the war between israel and hamas militants in gaza last summer left more than 2,000 people dead. the inquiry\", \"will include alleged war crimes committed since june. the international criminal court was set up in 2002 to prosecute genocide,\", \"crimes against humanity and war crimes. cnn’s vasco cotovio, kareem khadder and faith karimi contributed to this report.\", \"Summary: israel and the u.s. opposed the palestinians’ efforts to join the court, which is based in the netherlands. palestinian\", \"Document Around 1980, Bill Gates gave Microsoft, the company he founded, a : ”A computer on every desk and in every home.\", \"”’ ”But Microsoft CEO Satya Nadella, who in 1992 and rose to the top job in 2014, thinks Gates’ famous mission had a big ﬂaw.”\", \"’”When I joined the company in 1992, we used to talk about our mission as putting a PC in every home, and by the end of the\", \"decade we have done that, at least in the developed world,” Nadella told published on Monday. ”It always bothered me that we\", \"confused an enduring mission with a temporal goal. ”’ ”In other words, Nadella is saying that Gates’ vision for the future of\", \"In the 2000s, under former CEO Steve Ballmer, Microsoft became better known for its efforts to than for innovating.” ’Nadella\", \"believes in making Microsoft more driven by a sense of purpose — in 2015, he said was ”to empower every person and every\", \"organization on the planet to achieve more.” And he has encouraged the company .’ ”Under Nadella, Microsoft has taken the\", \"focus off Windows and the PC and pinned its hopes to the rise of its Azure and Ofﬁce 365 products, as the company’s older\", \"businesses stagnate. While this approach hasn’t translated to huge revenue growth, it has revitalized the company’s image.”\", \"”Gates told USA Today that he enjoys working with Nadella, serving his successor as a special adviser and helping guide the\", \"company’s investments in technology as it competes with Apple, Google, and Amazon.”\", \"Summary: In the 2000s, under former CEO Steve Ballmer, Microsoft became better known for its efforts to than for innovating.\", \"under Nadella, Microsoft has taken the focus off Windows and the PC and pinned its hopes to the rise of its Azure and Ofﬁce\", \"365 products.\", \"Summary: Gates says he enjoys working with Nadella, serving as a special adviser and helping guide the company’s investments\", \"in technology as it competes with Apple, Google, and Amazon. ‘it always bothered me that we confused an enduring mission\", \"with a temporal goal,’ he said.\", \"world,” Gen. Hatem Magsosi, Iraq’s main explosives ofﬁcer, told The Wall Street Journal. “Trainees go to Raqqa, [Syria] then to\", \"@MargaretWSJ @BKesling pic. twitter. — WSJ Think Tank (@WSJThinkTank) April 1, 2016, They have found “ chemical\", \"also contained “ explosives and chemical weapons. ” However, ofﬁcials told the outlet they do not know how much of the facility\", \"reputation around Iraq for its science departments. ” A year ago, the Islamic State established “a research hub in the chemistry\", \"lab. ” The terrorist group kept the staff at the university, many who “specialized in organic, industrial and analytical chemistry.\", \"joined in 2004. Ofﬁcials put him in prison, but released him in 2012. Then he traveled to Syria, where he eventually joined the\", \"reports: During the same time frame, there has been a surge in Islamic State’s use of bombs that mix chemical precursors into an\", \"explosive powdery substance known as triacetone triperoxide, or TATP, both in Iraq and Europe. It isn’t clear how many of these\", \"weapons, if any, can be traced to research or training conducted in Mosul. Gen. Magsosi says that his units called explosives the\", \"“Satan Recipe” because they are very hard to detect and they are usually so lethal. The Islamic State captured Mosul, Iraq’s\", \"second largest city, in June 2014. Since then, they have destroyed libraries and buildings at the university. Kurdish outlet Rudaw\", \"reported last October that the group destroyed the university’s Faculty of Agriculture buildings. In December 2014, ISIS raided\", \"the Central Library of Mosul to destroy all books. ‘These books promote inﬁdelity and call for disobeying Allah,” announced a\", \"The terrorists destroyed “Iraq newspapers dating to the early 20th century, maps and books from the Ottoman Empire, and book\", \"collections contributed by about 100 of Mosul’s establishment families. ” After that raid, the ISIS militants targeted the library at\", \"University of Mosul history professor, who spoke on condition he not be named because of his fear of the Islamic State, said the\", \"archives of a Sunni Muslim library, the library of the Latin Church and Monastery of the Dominican Fathers, and the Mosul\", \"Museum Library with works dating back to 5000 BC. Citing reports by the locals who live near these libraries, the professor\", \"also targeted the public library, which was home to more than 8, 000 rare books and manuscripts. Elderly residents begged the\", \"Summary: Chemistry lab at Mosul University used to make bombs used by ISIS jihadists throughout the region, ofﬁcials say.\", \"ISIS used one part of the university for explosives and another for suicide bombs, sources say.\", \"weapons, if any, can be traced to research or training conducted in the university.\", \"Summary: Book collections destroyed in front of students at university library in Mosul, Iraq. ISIS has destroyed libraries and\", \"buildings at the university since it captured the city in June 2014, including one with works dating back to 5000 BC. Ofﬁcials say\"], \"error\": null}, \"15577de3\": {\"success\": true, \"paper_id\": \"15577de3\", \"url\": \"https://arxiv.org/pdf/1805.06266v2\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_15577de3.pdf\", \"extracted_info\": {\"title\": \"A Unified Model for Extractive and Abstractive Summarization using Inconsistency Loss\", \"authors\": [\"Wan-Ting Hsu\", \"Chieh-Kai Lin\", \"Ming-Ying Lee\", \"Kerui Min\", \"Jing Tang\", \"Min\"], \"abstract\": \"We propose a unified model combining the strengths of extractive and abstractive summarization. The extractive component provides sentence-level attention to capture important content, while the abstractive component uses word-level dynamic attention to generate coherent and readable summaries. A novel inconsistency loss is introduced to penalize mismatches between sentence-level and word-level attention, improving factual accuracy and coherence. Experiments on the CNN/Daily Mail dataset show that our model achieves state-of-the-art ROUGE scores and outperforms strong baselines in both informativity and readability.\", \"methodology\": \"The proposed approach integrates an extractor and an abstracter into a unified architecture. The extractor selects informative sentences using sentence-level attention, while the abstracter generates summaries using word-level attention. An inconsistency loss function is introduced to align sentence-level and word-level attention, reducing spurious focus and improving coherence. Training is performed in two settings: (1) two-stage training, where the extractor is trained first and its output is fed to the abstracter, and (2) end-to-end training, where both components are jointly optimized using a combined loss function (Lext, Labs, Lcov, Linc). Evaluation is conducted on the CNN/Daily Mail dataset using ROUGE metrics and human assessments.\", \"results\": \"On the CNN/Daily Mail dataset, the unified model achieves higher ROUGE scores than state-of-the-art baselines. End-to-end training with inconsistency loss yields the best performance, with ROUGE-1, ROUGE-2, and ROUGE-L scores surpassing pointer-generator and DeepRL models. Human evaluation shows that the model improves informativity, conciseness, and readability compared to baselines. The inconsistency rate is significantly reduced (from 0.198 to 0.042) when using the inconsistency loss.\", \"conclusion\": \"We propose a unified summarization model that combines sentence-level attention from extractive methods with word-level attention from abstractive methods. The introduction of a novel inconsistency loss improves alignment between the two attention mechanisms, enhancing factual accuracy and coherence. Our approach achieves state-of-the-art performance on the CNN/Daily Mail dataset in both automatic and human evaluations, demonstrating superior informativity, conciseness, and readability compared to existing methods.\", \"figures\": null, \"tables\": null}, \"citations\": [], \"error\": null}, \"de83958d\": {\"success\": true, \"paper_id\": \"de83958d\", \"url\": \"https://arxiv.org/pdf/2310.10981v3\", \"pdf_path\": \"cache\\\\pdfs\\\\paper_de83958d.pdf\", \"extracted_info\": {\"title\": \"InstructDS: Instructive Dialogue Summarization with Query-Dialogue-Summary Triples\", \"authors\": [\"Not specified in provided content\"], \"abstract\": \"Conventional dialogue summarization methods directly generate summaries without considering user-specific interests, which limits their adaptability to diverse user needs. This work introduces InstructDS, an instructive dialogue summarization model that incorporates user preferences through query-based summarization. The method leverages large language models’ question generation and answering capabilities to synthesize query-dialogue-summary (QDS) triples, enabling more controllable and user-oriented summaries. Experiments on multiple datasets demonstrate that InstructDS outperforms state-of-the-art models, including larger models, in both automatic and human evaluations.\", \"methodology\": \"The proposed methodology synthesizes QDS triples using summary-anchored techniques. Two filtering methods—text-based and semantic-based—are applied to ensure quality and diversity of queries. The model is trained in a mixed paradigm combining dialogue summarization and reading comprehension tasks, leveraging LORA for parameter-efficient fine-tuning. The approach is evaluated on SAMSum, DialogSum, TODSum, and DREAM datasets without dataset-specific tuning, ensuring generalizability. Length augmentation techniques are also explored to improve summarization performance.\", \"results\": \"On the SAMSum dataset, InstructDS achieves higher ROUGE scores than BART, MV-BART, and Coref-BART. On DialogSum and TODSum, it significantly outperforms baselines, achieving ROUGE-1 scores of 47.8 and 89.3 respectively. In DREAM reading comprehension, InstructDS achieves competitive accuracy without in-domain training data. Human evaluations show that InstructDS produces more faithful, relevant, and informative summaries compared to baselines. Ablation studies confirm the benefits of synthesized QDS triples and length augmentation.\", \"conclusion\": \"Key contributions: (1) Propose InstructDS, the first instructive dialogue summarization model incorporating user preferences via query-based summarization; (2) Develop a method for synthesizing high-quality QDS triples using summary-anchored techniques and filtering; (3) Demonstrate that mixed training with summarization and comprehension tasks improves performance; (4) Achieve state-of-the-art results on multiple dialogue summarization benchmarks; (5) Show generalizability without dataset-specific tuning; (6) Provide insights into controllability and adaptability for user-focused summarization.\", \"figures\": null, \"tables\": null}, \"citations\": [\"Tom Brown, Benjamin Mann, Nick Ryder, Melanie\", \"Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind\", \"Neelakantan, Pranav Shyam, Girish Sastry, Amanda\", \"Askell, et al. 2020. Language models are few-shot\", \"systems , 33:1877–1901.\", \"Natural Language Processing (EMNLP) , pages 4106–\", \"4118, Online. Association for Computational Lin-\", \"Yulong Chen, Yang Liu, Liang Chen, and Yue Zhang.\", \"2021. DialogSum: A real-life scenario dialogue sum-\", \"for Computational Linguistics: ACL-IJCNLP 2021 ,\", \"pages 5062–5074, Online. Association for Computa-\", \"Hyung Won Chung, Le Hou, Shayne Longpre, Bar-\", \"ret Zoph, Yi Tay, William Fedus, Eric Li, Xuezhi\", \"Wang, Mostafa Dehghani, Siddhartha Brahma, et al.\", \"2022. Scaling instruction-finetuned language models.\", \"rization and Question Answering , pages 48–55.\", \"Pradeep Dasigi, Nelson F. Liu, Ana Marasovi ´c, Noah A.\", \"Smith, and Matt Gardner. 2019. Quoref: A read-\", \"2019 Conference on Empirical Methods in Natu-\", \"(EMNLP-IJCNLP) , pages 5925–5932, Hong Kong,\", \"Mingqi Gao, Jie Ruan, Renliang Sun, Xunjian Yin, Ship-\", \"ing Yang, and Xiaojun Wan. 2023a. Human-like sum-\", \"Mingqi Gao, Xiaojun Wan, Jia Su, Zhefeng Wang, and\", \"Bogdan Gliwa, Iwona Mochol, Maciej Biesek, and Alek-\", \"New Frontiers in Summarization , pages 70–79, Hong\", \"Kong, China. Association for Computational Linguis-\", \"Language Technology Workshop (SLT) , pages 735–\", \"742. IEEE.\", \"Junxian He, Wojciech Kryscinski, Bryan McCann,\", \"Nazneen Rajani, and Caiming Xiong. 2022. CTRL-\", \"pirical Methods in Natural Language Processing ,\", \"pages 5879–5915, Abu Dhabi, United Arab Emirates.\", \"Edward J Hu, yelong shen, Phillip Wallis, Zeyuan Allen-\", \"Zhu, Yuanzhi Li, Shean Wang, Lu Wang, and Weizhu\", \"Lifu Huang, Ronan Le Bras, Chandra Bhagavatula, and\", \"ral Language Processing (EMNLP-IJCNLP) , pages\", \"2391–2401, Hong Kong, China. Association for Com-\", \"Ridong Jiang, Wei Shi, Bin Wang, Chen Zhang, Yan\", \"Zhang, Chunlei Pan, Jung Jae Kim, and Haizhou Li.\", \"2023. Speech-aware multi-domain dialogue state\", \"nology Challenge , pages 105–112, Prague, Czech\", \"Mike Lewis, Yinhan Liu, Naman Goyal, Marjan\", \"Ghazvininejad, Abdelrahman Mohamed, Omer Levy,\", \"Veselin Stoyanov, and Luke Zettlemoyer. 2020.\", \"for natural language generation, translation, and com-\", \"ing of the Association for Computational Linguistics ,\", \"pages 7871–7880, Online. Association for Computa-\", \"tion Branches Out , pages 74–81, Barcelona, Spain.\", \"Junpeng Liu, Yanyan Zou, Hainan Zhang, Hongshen\", \"Chen, Zhuoye Ding, Caixia Yuan, and Xiaojie Wang.\", \"2021a. Topic-aware contrastive learning for abstrac-\", \"ciation for Computational Linguistics: EMNLP 2021 ,\", \"pages 1229–1243, Punta Cana, Dominican Republic.\", \"Processing , pages 92–106, Online and Punta Cana,\", \"logue , pages 407–418, Edinburgh, UK. Association\", \"Zhengyuan Liu, Ke Shi, and Nancy Chen. 2021b.\", \"Interest Group on Discourse and Dialogue , pages\", \"509–519, Singapore and Online. Association for\", \"Preksha Nema, Mitesh M. Khapra, Anirban Laha, and\", \"ume 1: Long Papers) , pages 1063–1072, Vancouver,\", \"Chengwei Qin, Aston Zhang, Zhuosheng Zhang, Jiaao\", \"Chen, Michihiro Yasunaga, and Diyi Yang. 2023. Is\", \"Colin Raffel, Noam Shazeer, Adam Roberts, Katherine\", \"Lee, Sharan Narang, Michael Matena, Yanqi Zhou,\", \"Wei Li, and Peter J Liu. 2020. Exploring the limits\", \"former. The Journal of Machine Learning Research ,\", \"21(1):5485–5551.\", \"Abigail See, Peter J. Liu, and Christopher D. Manning.\", \"2017. Get to the point: Summarization with pointer-\", \"Linguistics (Volume 1: Long Papers) , pages 1073–\", \"1083, Vancouver, Canada. Association for Computa-\", \"Guokan Shang, Wensi Ding, Zekun Zhang, Antoine Tix-\", \"ier, Polykarpos Meladianos, Michalis Vazirgiannis,\", \"Long Papers) , pages 664–674, Melbourne, Australia.\", \"Dan Su, Tiezheng Yu, and Pascale Fung. 2021. Im-\", \"IJCNLP 2021 , pages 3124–3131, Online. Association\", \"for Computational Linguistics.Kai Sun, Dian Yu, Jianshu Chen, Dong Yu, Yejin Choi,\", \"tational Linguistics , 7:217–231.\", \"Xiangru Tang, Arjun Nair, Borui Wang, Bingyao Wang,\", \"Jai Desai, Aaron Wade, Haoran Li, Asli Celikyil-\", \"maz, Yashar Mehdad, and Dragomir Radev. 2022.\", \"tional Linguistics: Human Language Technologies ,\", \"pages 5657–5668, Seattle, United States. Association\", \"Yi Tay, Mostafa Dehghani, Vinh Q Tran, Xavier Gar-\", \"cia, Jason Wei, Xuezhi Wang, Hyung Won Chung,\", \"Dara Bahri, Tal Schuster, Steven Zheng, et al. 2022.\", \"Jesse Vig, Alexander Fabbri, Wojciech Kryscinski,\", \"Chien-Sheng Wu, and Wenhao Liu. 2022. Exploring\", \"guistics: NAACL 2022 , pages 1455–1468, Seattle,\", \"Bin Wang, Zhengyuan Liu, Xin Huang, Fangkai Jiao,\", \"Yang Ding, Ai Ti Aw, and Nancy F Chen. 2023a.\", \"Bin Wang, Chen Zhang, Chengwei Wei, and Haizhou\", \"Bin Wang, Chen Zhang, Yan Zhang, Yiming Chen, and\", \"ural Language Processing , pages 4897–4908, Abu\", \"Dhabi, United Arab Emirates. Association for Com-\", \"Peiyi Wang, Lei Li, Liang Chen, Dawei Zhu, Binghuai\", \"Lin, Yunbo Cao, Qi Liu, Tianyu Liu, and Zhifang Sui.\", \"2023b. Large language models are not fair evaluators.\", \"Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa\", \"Liu, Noah A. Smith, Daniel Khashabi, and Hannaneh\", \"Yizhong Wang, Swaroop Mishra, Pegah Alipoormo-\", \"labashi, Yeganeh Kordi, Amirreza Mirzaei, Atharva\", \"Naik, Arjun Ashok, Arut Selvan Dhanasekaran,\", \"Anjana Arunkumar, David Stap, Eshaan Pathak,\", \"Giannis Karamanolakis, Haizhi Lai, Ishan Puro-\", \"hit, Ishani Mondal, Jacob Anderson, Kirby Kuznia,\", \"Krima Doshi, Kuntal Kumar Pal, Maitreya Patel,\", \"Mehrad Moradshahi, Mihir Parmar, Mirali Purohit,\", \"Neeraj Varshney, Phani Rohitha Kaza, Pulkit Verma,\", \"Ravsehaj Singh Puri, Rushang Karia, Savan Doshi,\", \"Shailaja Keyur Sampat, Siddhartha Mishra, Sujan\", \"Reddy A, Sumanta Patro, Tanay Dixit, and Xudong\", \"Empirical Methods in Natural Language Processing ,\", \"pages 5085–5109, Abu Dhabi, United Arab Emirates.\", \"Chengwei Wei, Yun-Cheng Wang, Bin Wang, and C-\", \"Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten\", \"Bosma, brian ichter, Fei Xia, Ed H. Chi, Quoc V Le,\", \"Sarah J. Zhang, Samuel Florin, Ariel N. Lee, Ea-\", \"mon Niknafs, Andrei Marginean, Annie Wang,\", \"Keith Tyser, Zad Chin, Yann Hicke, Nikhil Singh,\", \"Madeleine Udell, Yoon Kim, Tonio Buonassisi, Ar-\", \"mando Solar-Lezama, and Iddo Drori. 2023. Explor-\", \"Tianyi Zhang, Varsha Kishore, Felix Wu, Kilian Q.\", \"Weinberger, and Yoav Artzi. 2020. BERTScore:\", \"Lulu Zhao, Fujia Zheng, Keqing He, Weihao Zeng, Yue-\", \"jie Lei, Huixing Jiang, Wei Wu, Weiran Xu, Jun Guo,\", \"Ming Zhong, Da Yin, Tao Yu, Ahmad Zaidi, Mutethia\", \"Mutuma, Rahul Jha, Ahmed Hassan Awadallah, Asli\", \"Celikyilmaz, Yang Liu, Xipeng Qiu, and Dragomir\", \"Linguistics: Human Language Technologies , pages\", \"5905–5921, Online. Association for Computational\", \"Ben Zhou, Daniel Khashabi, Qiang Ning, and Dan Roth.\", \"2019. “going on a vacation” takes longer than “go-\", \"on Natural Language Processing (EMNLP-IJCNLP) ,\", \"pages 3363–3369, Hong Kong, China. Association\", \"for Computational Linguistics.Haichao Zhu, Li Dong, Furu Wei, Bing Qin, and Ting\", \"Transactions on Audio, Speech, and Language Pro-\", \"cessing , 30:2357–2367.\", \"In this section, we will provide a detailed expla-\", \"In the context of dialogue summarization, we ob-\", \"versions of the ROUGE metric, resulting in var-\", \"ied results. Specifically, we identified three widely\", \"of the ROUGE paper. However, this imple-\", \"running the Perl script, which can be inconve-\", \"Additionally, the last update for this imple-\", \"the Perl implementation. However, the pack-\", \"this package, we also report the results using\", \"by the Google research team. Recently, Hug-\", \"Face, we expect the package will receive sig-\", \"mains. Consequently, in this paper, we utilize\", \"score. It is also actively updated, with the\", \"In the original DialogSum paper (Chen et al., 2021),\", \"the authors used #Person1#, #Person2#, and so on\", \"did not contain speaker information. However, this\", \"address this issue, we performed additional prepro-\", \"Sum. Specifically, we employed the prompt tem-\", \"bidden names labeled by humans, the length of the\", \"predicted name, the presence of special symbols,\", \"method, we used FLAN-T5-XL again with the tem-\", \"candidate names, which consisted of five randomly\", \"female names. Simultaneously, the name was cor-\", \"ture research and development, we will make the\", \"DREAM (Sun et al., 2019) dataset is introduced for\", \"is designed as multi-choice questions. However, in\", \"real-world applications, where information queries\", \"are performed on dialogues, it is unlikely to have\", \"ducted in an unconstrained manner, without provid-\", \"racy, we utilize the BERTScore package to measure\", \"answer choices, selecting the highest-scoring op-\", \"evaluation interface, instruction templates, synthe-\", \"cluding query generation, text-based filtering,\", \"•Table 10, 11 and 12: shows the synthesized\", \"•Table 13, 14, 15, 16 and 17: shows case stud-\", \"ing SAMSum, DREAM, DialogSum, and\", \"(Sec. 3.2)Generate an answerable and specific question based on the\", \"(Sec. 3.2)Can we get an answer from the context, yes or no?\", \"any guessing, yes or no? Question: ${Question} Context: ${Summary}\", \"(Sec. 4.4)Evaluate the quality of the abstractive summary from the dialogue.\", \"Faithfullness: whether the summary is correct according to dialogue,\", \"Fluency: Whether summary is grammarly correct, Informativeness:\", \"Whether the summary contains all essential information, Conciseness:\", \"follow the template: ‘Faithfulness’: value, ‘Fluency’: value\", \"‘Informativeness’: value, ‘Conciseness’: value. You should rate on a\", \"(Sec. A.2)(1) Who is #Person1# in the following dialogue? ${Dialogue}\", \"(2) Select on proper name for #Person1# from ${candidate names}\", \"Table 7: Prompting templates for QDS triple generation, text-based query filtering, ChatGPT evaluation, and\", \"Dialogue:W: Tom, look at your shoes. How dirty they are! You must clean them.M: Oh, mum, but I cleaned them only yesterday.W: They are dirty now. You must clean them again.M: I do not want to clean them today. Even if I clean them today, they will get dirty again tomorrow.W: All right, then.M: Mum, give me something to eat, please.W: You had your breakfast in the morning, Tom, and you had lunch at school.M: I am hungry again.W: Oh, hungry? But if I give you something to eat today, you will be hungry again tomorrow.Query:Why did the woman say that she wouldn't give him anything to eat?Candidate Choices:A: Because his mother wants to correct his bad habit.B: Because he had lunch at school.C: Because his mother wants to leave him hungry.Seq2Seq ModelFinal Answer:Because his mother wants to correct his bad habit.Figure 7: Constrained DREAM evaluation as multi-choices question answering.\", \"Dialogue:W: Tom, look at your shoes. How dirty they are! You must clean them.M: Oh, mum, but I cleaned them only yesterday.W: They are dirty now. You must clean them again.M: I do not want to clean them today. Even if I clean them today, they will get dirty again tomorrow.W: All right, then.M: Mum, give me something to eat, please.W: You had your breakfast in the morning, Tom, and you had lunch at school.M: I am hungry again.W: Oh, hungry? But if I give you something to eat today, you will be hungry again tomorrow.Query:Why did the woman say that she wouldn't give him anything to eat?\", \"Emma: its me anna, emily, wendy, kate and you\", \"General Summary: Sharol is going to go to the beach with Emma, anna, emily,\", \"Summary: Sharol is going to go to the beach with Emma, Anna, Emily, Wendy and Kate.\", \"Reason for rejection: text-based filtering , the answer may not be answerable.\", \"Reason for rejection: semantic-based filtering , duplicate question.\", \"Reason for rejection: text-based filtering , the answer may not be answerable.\", \"Byron: Not really. If you take the No. 3 bus, you can get there in ten minutes. And\", \"if volleyball doesn’t interest you, they’ve got a huge indoor swimming pool, a\", \"weight room, and indoor tracks. It’s a great place to meet people. Would you\", \"Jacquenette: Now that you mentioned it, it would be nice to get away from the computer\", \"center for a change, and I really should get some more exercise. Working\", \"Jacquenette: OK, I’ll come, too. How about meeting me in front of the cinema at eight,\", \"Byron: Sure, see you then.\", \"Reason for rejection: semantic-based filtering , duplicate question.\", \"Reason for rejection: text-based filtering , the answer may not be answerable.\", \"Reason for rejection: semantic-based filtering , duplicate question.\", \"User: Yes, thank you. That’s all for now. Bye!\", \"Reason for rejection: semantic-based filtering , duplicate question.\", \"Reason for rejection: semantic-based filtering , duplicate question.\", \"Marsha: Guys, we’ve planned the trip with John last night as we promised\", \"Cynthia: great, thank you for that\", \"Mohammad: sure, but I really trust you\", \"Marsha: so as we decided last time, we will spend a week just on the beach\", \"Marsha: we all wanted some calm, nice place, right?\", \"Marsha: it’s quite basic the website, but it may actually be a good sign\", \"Mohammad: so let’s go there, it’s still cheaper than Italy for example\", \"Marsha and John planned the trip. They will spend a week on the beach with Cynthia, Mohammad\", \"Marsha, Cynthia, Mohammad and Gavin are going to Madagascar. They will spend a week on the\", \"Be, Madgascar. It was more expensivethan hoteles on main land,but it was the best place according\", \"Marsha, Cynthia, Mohammad and Gavin are going to Madagascar. They will spend a week on the beach\", \"Marsha informs the group that John had planned the trip, and they all agreed to spend a week on\", \"the beach. She shows them a picture of a hotel in Nosy Be and its website, which they all like\", \"Marsha, John, Cynthia, Mohammad and Gavin will spend a week on the beach in Nosy Be. It’s more\", \"expensive than hotels on the mainland, but it’s still cheaper than Italy.\", \"Ken: Hi, how are you?\", \"Ken: Just stressed; work stuff, fighting with Brad, too much going on at mom’s.\", \"Ang: Hang in there, it will get better!\", \"Ken: I know, but it’s a lot.\", \"Ken: Show Saturday night, then seeing the grandkids on Sunday at the zoo.\", \"Ken: Gotta run, work calls. Love you!\", \"Ken is stressed, because he has to deal with work issues and family issues. He is going to see a\", \"Ken discusses with Ang about feeling stressed due to work, family issues and too much going on. Ang\", \"to him vent. They discuss plans for the weekend, including a show on Saturday and seeing grandkids at\", \"Ken is stressed because of work, fighting with Brad and too much going on at mom’s. He will see a show\", \"M: When we think of energy or fuel for our homes and cars, we think of petroleum, a fossil fuel\", \"processed from oil removed from the ground, of which there is a limited supply. But alternative\", \"fuels can be many things. Wind, sun and water can all be used to create fuel.\", \"agree that by around 2025, the amount of petroleum we use will reach a peak. Then production\", \"fuels left, we have to find other fuel sources eventually. So the sooner we start, the better\", \"off we will be. The other big argument is that when long time, which leads to some long-term\", \"negative effects, like global warming and the greenhouse effect.\", \"(1) What do we usually refer to when we talk about energy according to the man?\", \"(2) What do most experts agree on according to the man?\", \"(3) What does the man think we should do now?\", \"(1) Fuel refined from oil extracted from underground.\", \"(2) Oil production will begin to decline worldwide by 2025.\", \"(3) Start developing alternative fuels.\", \"(1) When we refer energy, according the Man, it usually refers to petrol, natural gas, and other\", \"(2) Most experTS agree THAT by AROUND\", \"(3) The man thinks we must develop alternate energy and fuel source as soon as possible because it\", \"(1) petroleum\", \"(2) the amount of petroleum we use will reach a peak in 2025\", \"(3) Find alternative energy sources\", \"(1) When we talk about energy according to the man, we usually refer to petroleum, a fossil fuel\", \"processed from oil removed from the ground, of which there is a limited supply.\", \"(2) Most experts agree that by around 2025, the amount of petroleum we use will reach a peak and\", \"(3) There is no specific man mentioned in the given context who suggests something to do now.\", \"(1) petroleum, a fossil fuel processed from oil removed from the ground, of which there is a\", \"(2) that by around 2025, the amount of petroleum we use will reach a peak\", \"(3) develop alternative fuel and energy sources\", \"Whitaker: Hello, so how are we feeling today?\", \"Jill: Things are going well for me, doctor.\", \"Jill: Yes, I am applying for new health insurance, and I need a physical examination to qualify.\", \"Whitaker: Your basic physical exam will include lungs, heart, blood levels, and eyes, ears, and nose.\", \"Jill: I’ve been having a little trouble breathing. Would you look into that, please?\", \"Whitaker: We can do an allergy test, and later I can send you for an asthma test.\", \"Jill: I would appreciate it. When you give me a blood test, what are you looking for?\", \"Whitaker: I am going to check your cholesterol, blood sugar, and white blood cell count.\", \"Jill is going through an annual physical examination to apply for new health insurance, and Jill asks\", \"Doctor and patient discuss annual check-up, including labs, exam, insulin, asthmatic tests, chlolestrol,\", \"sugar and WBC count, allergies, healthy lifestyle, physical and mental health.\", \"Jilll has been having trouble breathing. Whitakker will check her cholesterol, blood sugar, and white\", \"Basic physical exam includes checking of lungs, heart, blood levels, eyes, ears, and nose. Blood test\", \"will include cholesterol, blood sugar, and white blood cell count.\", \"User: Hi, can you help me plan my Cambridge trip? I need a train from London Kings Cross to Cambridge.\", \"Agent: I can help you with that. One leaves friday at 05:17, is that time okay for you?\", \"User: Actually, I need to leave Tuesday after 10:30.\", \"User: Yes, please make a reservation for 6 people. I’ll need the reference number.\", \"User: Hmm, are you sure? I want something south indian, expensive and in the centre of town.\", \"Agent: I have curry garden for Indian in the centre of town, but no south indian.\", \"Agent: Other than the La Mimosa Restaurant, I also have the Shiraz Restaurant. Both are located in the\", \"Agent: Ok perfect, would you like me to book a reservation for you?\", \"User: No, that is all. Thank you so much.\", \"the user wants the agent to help purchase 6 train tickets. this train leaves at 10:30 on tuesday, from\", \"user wants the agent to help purchase 6 train tickets. this train leaves at 10:30 on friday, from london\", \"the night before and the agent suggests the Curry Garden for Indian food in Cambridge, which they find\", \"acceptable. Finally, the travel agent provides the necessary reference numbers for their reservations.\", \"the user wants to book 6 train tickets. this train leaves at 10:30 on tuesday, from london kings cross\", \"mediterranean dishes, which is located in the centre.\"], \"error\": null}}}"