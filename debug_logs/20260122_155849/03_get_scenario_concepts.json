{"problem": "The user is asking how AI systems, after retrieving a target webpage in connected search scenarios, extract effective information to form an answer.  \n    The underlying problem is understanding the **evidence extraction and content summarization modules** within a RAG pipeline â€” specifically, how raw webpage content is parsed, filtered, and condensed into high-quality, answer-ready text for downstream generation, while ensuring relevance, factual accuracy, and efficiency.", "scenario": "Retrieval-Augmented Generation (RAG) for AI-connected search and answer synthesis", "workflow": "1. **Query Understanding**  \n       - Input: User's natural language question  \n       - Output: Structured query representation (semantic vector, keywords)  \n       - Signals: Intent classification, entity extraction, query rewriting  \n\n    2. **Document Retrieval**  \n       - Input: Query vector/keywords  \n       - Output: Candidate webpages or document chunks  \n       - Signals: Topical relevance scores, semantic similarity, hybrid retrieval results  \n\n    3. **Passage Ranking**  \n       - Input: Candidate passages/chunks  \n       - Output: Ordered list prioritizing answerability and contextual fit  \n       - Signals: Relevance score, answerability score, generative passage likelihood  \n\n    4. **Evidence Extraction**  \n       - Input: Top-ranked passages  \n       - Output: Concise, high-value text snippets containing factual support  \n       - Signals: Faithfulness, helpfulness, conciseness metrics; redundancy reduction  \n\n    5. **Content Summarization (optional)**  \n       - Input: Retrieved evidence snippets or full passages  \n       - Output: Condensed summaries preserving factual accuracy  \n       - Signals: Coverage diversity, semantic compression, hallucination risk reduction  \n\n    6. **Answer Generation**  \n       - Input: Summarized evidence + original query  \n       - Output: Final synthesized answer  \n       - Signals: Coherence, factual grounding, citation alignment  \n\n    7. **Post-processing & Governance**  \n       - Input: Generated answer  \n       - Output: User-facing response with optional references  \n       - Signals: Compliance checks, formatting, confidence scoring", "key_concepts": ["- **Information Extraction**: Parsing and extracting structured or semi-structured data from HTML/webpages", "- **Evidence Extraction**: Selecting concise, relevant, high-quality supporting content from retrieved documents", "- **Passage Ranking**: Ordering retrieved content by answerability and contextual fit, not just topical relevance", "- **Content Summarization**: Condensing retrieved text to improve coverage and reduce hallucination risk", "- **Faithfulness / Helpfulness / Conciseness**: Quality criteria for extracted evidence", "- **RAG Pipeline**: Integration of retrieval and generation stages for accurate, up-to-date answers", "- **Parsing Tools**: XPath, CSS selectors, BeautifulSoup, pyquery for HTML structure navigation", "- **Compliance & Governance**: Respecting robots.txt, site terms, and ethical scraping practices"]}